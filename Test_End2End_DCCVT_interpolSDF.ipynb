{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f9796c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device:  NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "import kaolin\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import polyscope as ps\n",
    "\n",
    "# import diffvoronoi\n",
    "import pygdel3d\n",
    "import sdfpred_utils.sdfpred_utils as su\n",
    "import sdfpred_utils.loss_functions as lf\n",
    "from pytorch3d.loss import chamfer_distance\n",
    "from pytorch3d.ops import knn_points, knn_gather\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# cuda devices\n",
    "device = torch.device(\"cuda:0\")\n",
    "print(\"Using device: \", torch.cuda.get_device_name(device))\n",
    "\n",
    "# Improve reproducibility\n",
    "torch.manual_seed(69)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(69)\n",
    "\n",
    "input_dims = 3\n",
    "lr_sites = 0.005\n",
    "# lr_model = 0.00001\n",
    "destination = \"./images/autograd/End2End_DCCVT_interpolSDF/\"\n",
    "model_trained_it = \"\"\n",
    "\n",
    "# mesh = [\"sphere\"]\n",
    "\n",
    "mesh = [\"gargoyle\", \"/home/wylliam/dev/Kyushu_experiments/data/gargoyle\"]\n",
    "trained_model_path = f\"/home/wylliam/dev/HotSpot/log/3D/pc/HotSpot-all-2025-04-24-18-16-03/gargoyle/gargoyle/trained_models/model{model_trained_it}.pth\"\n",
    "\n",
    "# mesh = [\"gargoyle_unconverged\", \"/home/wylliam/dev/Kyushu_experiments/mesh/gargoyle_unconverged\"]\n",
    "# trained_model_path = f\"/home/wylliam/dev/HotSpot/log/3D/pc/HotSpot-all-2025-04-24-18-16-03/gargoyle/gargoyle/trained_models/model_500.pth\"\n",
    "\n",
    "\n",
    "# mesh = [\"chair\", \"/home/wylliam/dev/Kyushu_experiments/data/chair\"]\n",
    "# trained_model_path = f\"/home/wylliam/dev/HotSpot/log/3D/pc/HotSpot-all-2025-05-02-17-56-25/chair/chair/trained_models/model{model_trained_it}.pth\"\n",
    "# #\n",
    "# mesh = [\"bunny\", \"/home/wylliam/dev/Kyushu_experiments/data/bunny\"]\n",
    "# trained_model_path = f\"/home/wylliam/dev/HotSpot/log/3D/pc/HotSpot-all-2025-04-25-17-32-49/bunny/bunny/trained_models/model{model_trained_it}.pth\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3f27a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new sites\n",
      "Sites shape:  torch.Size([4096, 3])\n",
      "Sites:  tensor([-1.0027, -1.0065, -0.9978], device='cuda:0', grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wylliam/dev/Kyushu_experiments-1/venv/lib/python3.12/site-packages/torch/functional.py:554: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:4314.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[polyscope] Backend: openGL3_glfw -- Loaded openGL version: 3.3.0 NVIDIA 575.64.03\n"
     ]
    }
   ],
   "source": [
    "num_centroids = 16**3\n",
    "grid = 32  # 128\n",
    "print(\"Creating new sites\")\n",
    "noise_scale = 0.005\n",
    "domain_limit = 1\n",
    "x = torch.linspace(-domain_limit, domain_limit, int(round(num_centroids ** (1 / 3))))\n",
    "y = torch.linspace(-domain_limit, domain_limit, int(round(num_centroids ** (1 / 3))))\n",
    "z = torch.linspace(-domain_limit, domain_limit, int(round(num_centroids ** (1 / 3))))\n",
    "meshgrid = torch.meshgrid(x, y, z)\n",
    "meshgrid = torch.stack(meshgrid, dim=3).view(-1, 3)\n",
    "\n",
    "# add noise to meshgrid\n",
    "meshgrid += torch.randn_like(meshgrid) * noise_scale\n",
    "\n",
    "\n",
    "sites = meshgrid.to(device, dtype=torch.float32).requires_grad_(True)\n",
    "\n",
    "print(\"Sites shape: \", sites.shape)\n",
    "print(\"Sites: \", sites[0])\n",
    "ps.init()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2df77f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnfld_points shape:  torch.Size([1, 153600, 3])\n",
      "torch.float32\n",
      "torch.Size([4096, 3])\n",
      "Allocated: 63.913472 MB, Reserved: 65.011712 MB\n",
      "torch.Size([4096])\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# LOAD MODEL WITH HOTSPOT\n",
    "\n",
    "import sys\n",
    "\n",
    "if mesh[0] != \"sphere\":\n",
    "    sys.path.append(\"3rdparty/HotSpot\")\n",
    "    from dataset import shape_3d\n",
    "    import models.Net as Net\n",
    "\n",
    "    loss_type = \"igr_w_heat\"\n",
    "    loss_weights = [350, 0, 0, 1, 0, 0, 20]\n",
    "\n",
    "    train_set = shape_3d.ReconDataset(\n",
    "        file_path=mesh[1] + \".ply\",\n",
    "        n_points=grid * grid * 150,  # 15000, #args.n_points,\n",
    "        n_samples=10001,  # args.n_iterations,\n",
    "        grid_res=256,  # args.grid_res,\n",
    "        grid_range=1.1,  # args.grid_range,\n",
    "        sample_type=\"uniform_central_gaussian\",  # args.nonmnfld_sample_type,\n",
    "        sampling_std=0.5,  # args.nonmnfld_sample_std,\n",
    "        n_random_samples=7500,  # args.n_random_samples,\n",
    "        resample=True,\n",
    "        compute_sal_dist_gt=(True if \"sal\" in loss_type and loss_weights[5] > 0 else False),\n",
    "        scale_method=\"mean\",  # \"mean\" #args.pcd_scale_method,\n",
    "    )\n",
    "\n",
    "    model = Net.Network(\n",
    "        latent_size=0,  # args.latent_size,\n",
    "        in_dim=3,\n",
    "        decoder_hidden_dim=128,  # args.decoder_hidden_dim,\n",
    "        nl=\"sine\",  # args.nl,\n",
    "        encoder_type=\"none\",  # args.encoder_type,\n",
    "        decoder_n_hidden_layers=5,  # args.decoder_n_hidden_layers,\n",
    "        neuron_type=\"quadratic\",  # args.neuron_type,\n",
    "        init_type=\"mfgi\",  # args.init_type,\n",
    "        sphere_init_params=[1.6, 0.1],  # args.sphere_init_params,\n",
    "        n_repeat_period=30,  # args.n_repeat_period,\n",
    "    )\n",
    "    model.to(device)\n",
    "\n",
    "    ######\n",
    "    test_dataloader = torch.utils.data.DataLoader(\n",
    "        train_set, batch_size=1, shuffle=False, num_workers=0, pin_memory=False\n",
    "    )\n",
    "    test_data = next(iter(test_dataloader))\n",
    "    mnfld_points = test_data[\"mnfld_points\"].to(device)\n",
    "\n",
    "    # add noise to mnfld_points\n",
    "    # mnfld_points += torch.randn_like(mnfld_points) * noise_scale * 2\n",
    "\n",
    "    mnfld_points.requires_grad_()\n",
    "    print(\"mnfld_points shape: \", mnfld_points.shape)\n",
    "    if torch.cuda.is_available():\n",
    "        map_location = torch.device(\"cuda\")\n",
    "    else:\n",
    "        map_location = torch.device(\"cpu\")\n",
    "    model.load_state_dict(torch.load(trained_model_path, weights_only=True, map_location=map_location))\n",
    "    sdf0 = model(sites)\n",
    "\n",
    "else:\n",
    "\n",
    "    def sphere_sdf(points: torch.Tensor, center: torch.Tensor, radius: float) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Compute the SDF of a sphere at given 3D points.\n",
    "\n",
    "        Args:\n",
    "            points: (N, 3) tensor of 3D query points\n",
    "            center: (3,) tensor specifying the center of the sphere\n",
    "            radius: float, radius of the sphere\n",
    "\n",
    "        Returns:\n",
    "            sdf: (N,) tensor of signed distances\n",
    "        \"\"\"\n",
    "        return torch.norm(points - center, dim=-1) - radius\n",
    "\n",
    "    def sphere_sdf_with_noise(\n",
    "        points: torch.Tensor, center: torch.Tensor, radius: float, noise_amplitude=0.05\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Sphere SDF with smooth directional noise added near the surface.\n",
    "\n",
    "        Args:\n",
    "            points: (N, 3)\n",
    "            center: (3,)\n",
    "            radius: float\n",
    "            noise_amplitude: float\n",
    "\n",
    "        Returns:\n",
    "            sdf: (N,)\n",
    "        \"\"\"\n",
    "        rel = points - center\n",
    "        norm = torch.norm(rel, dim=-1)  # (N,)\n",
    "        base_sdf = norm - radius  # (N,)\n",
    "\n",
    "        # Smooth periodic noise based on direction\n",
    "        unit_dir = rel / (norm.unsqueeze(-1) + 1e-9)  # (N,3)\n",
    "        noise = torch.sin(10 * unit_dir[:, 0]) * torch.sin(10 * unit_dir[:, 1]) * torch.sin(10 * unit_dir[:, 2])\n",
    "\n",
    "        # Weight noise so it mostly affects surface area\n",
    "        falloff = torch.exp(-20 * (base_sdf**2))  # (N,) ~1 near surface, ~0 far\n",
    "        sdf = base_sdf + noise_amplitude * noise * falloff\n",
    "\n",
    "        return sdf\n",
    "\n",
    "    # generate points on the sphere\n",
    "    mnfld_points = torch.randn(grid * grid * 150, 3, device=device)\n",
    "    mnfld_points = mnfld_points / torch.norm(mnfld_points, dim=-1, keepdim=True) * 0.5\n",
    "    mnfld_points = mnfld_points.unsqueeze(0).requires_grad_()\n",
    "    sdf0 = sphere_sdf(sites, torch.zeros(3).to(device), 0.50)\n",
    "    # sdf0 = sphere_sdf_with_noise(sites, torch.zeros(3).to(device), 0.50, noise_amplitude=0.1)\n",
    "\n",
    "##add mnfld points with random noise to sites\n",
    "# N = mnfld_points.squeeze(0).shape[0]\n",
    "# num_samples = 24**3 - (num_centroids)\n",
    "# idx = torch.randint(0, N, (num_samples,))\n",
    "# sampled = mnfld_points.squeeze(0)[idx]\n",
    "# perturbed = sampled + (torch.rand_like(sampled)-0.5)*0.05\n",
    "# sites = torch.cat((sites, perturbed), dim=0)\n",
    "\n",
    "# make sites a leaf tensor\n",
    "sites = sites.detach().requires_grad_()\n",
    "print(sites.dtype)\n",
    "print(sites.shape)\n",
    "print(f\"Allocated: {torch.cuda.memory_allocated() / 1e6} MB, Reserved: {torch.cuda.memory_reserved() / 1e6} MB\")\n",
    "\n",
    "\n",
    "sdf0 = sdf0.detach().squeeze(-1).requires_grad_()\n",
    "print(sdf0.shape)\n",
    "print(sdf0.is_leaf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ba12786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delaunay simplices shape:  (27659, 4)\n",
      "sites shape:  torch.Size([4096, 3])\n"
     ]
    }
   ],
   "source": [
    "sites_np = sites.detach().cpu().numpy()\n",
    "d3dsimplices, _ = pygdel3d.triangulate(sites_np)\n",
    "d3dsimplices = np.array(d3dsimplices)\n",
    "print(\"Delaunay simplices shape: \", d3dsimplices.shape)\n",
    "\n",
    "print(\"sites shape: \", sites.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff63634a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ps_cloud = ps.register_point_cloud(\"initial_cvt_grid+pc_gt\", sites.detach().cpu().numpy(), enabled=False)\n",
    "# ps_cloud.add_scalar_quantity(\n",
    "#     \"vis_grid_pred\",\n",
    "#     sdf0.detach().cpu().numpy(),\n",
    "#     enabled=True,\n",
    "#     cmap=\"coolwarm\",\n",
    "#     vminmax=(-0.00005, 0.00005),\n",
    "# )\n",
    "# mnf_cloud = ps.register_point_cloud(\"mnfld_points_pred\", mnfld_points.squeeze(0).detach().cpu().numpy(), enabled=False)\n",
    "\n",
    "# v_vect, f_vect, sdf_verts, sdf_verts_grads, _ = su.get_clipped_mesh_numba(sites, None, d3dsimplices, False, sdf0, True)\n",
    "# ps_mesh = ps.register_surface_mesh(\n",
    "#     \"sdf unclipped initial mesh\",\n",
    "#     v_vect.detach().cpu().numpy(),\n",
    "#     f_vect,\n",
    "#     back_face_policy=\"identical\",\n",
    "#     enabled=False,\n",
    "# )\n",
    "# # ps_vert = ps.register_point_cloud(\"sdf unclipped initial verts\", v_vect.detach().cpu().numpy(), enabled=False)\n",
    "\n",
    "# v_vect, f_vect, _, _, _ = su.get_clipped_mesh_numba(sites, None, d3dsimplices, True, sdf0, True)\n",
    "# ps_mesh = ps.register_surface_mesh(\n",
    "#     \"sdf clipped initial mesh\",\n",
    "#     v_vect.detach().cpu().numpy(),\n",
    "#     f_vect,\n",
    "#     back_face_policy=\"identical\",\n",
    "#     enabled=False,\n",
    "# )\n",
    "\n",
    "# d3dsimplices, _ = pygdel3d.triangulate(sites_np)\n",
    "# d3dsimplices = torch.tensor(d3dsimplices, device=device)\n",
    "# marching_tetrehedra_mesh = kaolin.ops.conversions.marching_tetrahedra(\n",
    "#     sites.unsqueeze(0), d3dsimplices, sdf0.unsqueeze(0), return_tet_idx=False\n",
    "# )\n",
    "# vertices_list, faces_list = marching_tetrehedra_mesh\n",
    "# v_vect = vertices_list[0]\n",
    "# faces = faces_list[0]\n",
    "\n",
    "# ps.register_surface_mesh(\n",
    "#     \"init MTET\",\n",
    "#     v_vect.detach().cpu().numpy(),\n",
    "#     faces.detach().cpu().numpy(),\n",
    "#     back_face_policy=\"identical\",\n",
    "#     enabled=False,\n",
    "# )\n",
    "\n",
    "\n",
    "# # ps_cloud = ps.register_point_cloud(\"active sites\", tet_probs[2].reshape(-1, 3).detach().cpu().numpy(), enabled=False)\n",
    "# # ps_cloud.add_vector_quantity(\"site step dir\", tet_probs[0].reshape(-1, 3).detach().cpu().numpy())\n",
    "# # ps_vert.add_vector_quantity(\"verts step dir\", tet_probs[1].detach().cpu().numpy())\n",
    "\n",
    "\n",
    "# ps.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c1a4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SITES OPTIMISATION LOOP\n",
    "\n",
    "\n",
    "cvt_loss_values = []\n",
    "min_distance_loss_values = []\n",
    "chamfer_distance_loss_values = []\n",
    "eikonal_loss_values = []\n",
    "domain_restriction_loss_values = []\n",
    "sdf_loss_values = []\n",
    "div_loss_values = []\n",
    "loss_values = []\n",
    "\n",
    "voroloss = lf.Voroloss_opt().to(device)\n",
    "\n",
    "\n",
    "def train_DCCVT(\n",
    "    sites,\n",
    "    sites_sdf,\n",
    "    max_iter=100,\n",
    "    stop_train_threshold=1e-6,\n",
    "    upsampling=0,\n",
    "    lambda_weights=[0.1, 1.0, 0.1, 0.1, 1.0, 1.0, 0.1],\n",
    "    voroloss_optim=False,\n",
    "):\n",
    "    if not voroloss_optim:\n",
    "        optimizer = torch.optim.Adam(\n",
    "            [\n",
    "                {\"params\": [sites], \"lr\": lr_sites * 0.1},\n",
    "                {\"params\": [sites_sdf], \"lr\": lr_sites * 0.1},\n",
    "            ],\n",
    "            betas=(0.8, 0.95),\n",
    "        )\n",
    "    else:\n",
    "        optimizer = torch.optim.Adam([{\"params\": [sites], \"lr\": lr_sites * 0.1}])\n",
    "\n",
    "    # scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "    # scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\n",
    "\n",
    "    # optimizer_sites = torch.optim.Adam([{'params': [sites], 'lr': lr_sites}])\n",
    "    # optimizer_sdf = torch.optim.SGD([{'params': [sites_sdf], 'lr': lr_sites}])\n",
    "    # scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[80, 150, 200, 250], gamma=0.5)\n",
    "\n",
    "    prev_loss = float(\"inf\")\n",
    "    best_loss = float(\"inf\")\n",
    "    upsampled = 0.0\n",
    "    epoch = 0\n",
    "    lambda_cvt = lambda_weights[0]\n",
    "    lambda_chamfer = lambda_weights[4]\n",
    "    lambda_shl = lambda_cvt / 10\n",
    "    best_sites = sites.clone()\n",
    "    best_sites.best_loss = best_loss\n",
    "\n",
    "    while epoch <= max_iter:\n",
    "        optimizer.zero_grad()\n",
    "        # if mesh[0] == \"sphere\":\n",
    "        #     # generate sphere sdf\n",
    "        #     sites_sdf = sphere_sdf(sites, torch.zeros(3).to(device), 0.50)\n",
    "\n",
    "        if not voroloss_optim:\n",
    "            sites_np = sites.detach().cpu().numpy()\n",
    "            # d3dsimplices = diffvoronoi.get_delaunay_simplices(sites_np.reshape(input_dims * sites_np.shape[0]))\n",
    "            d3dsimplices, _ = pygdel3d.triangulate(sites_np)\n",
    "\n",
    "            d3dsimplices = np.array(d3dsimplices)\n",
    "\n",
    "            if epoch % 100 == 0 and epoch <= 500:\n",
    "                eps_H = lf.estimate_eps_H(sites, d3dsimplices, multiplier=1.5 * 5).detach()\n",
    "                print(\"Estimated eps_H: \", eps_H)\n",
    "            elif epoch % 100 == 0 and epoch <= 800:\n",
    "                eps_H = lf.estimate_eps_H(sites, d3dsimplices, multiplier=1.5 * 2).detach()\n",
    "                print(\"Estimated eps_H: \", eps_H)\n",
    "\n",
    "            cvt_loss = lf.compute_cvt_loss_vectorized_delaunay(sites, None, d3dsimplices)  # torch.tensor(0)  #\n",
    "\n",
    "            build_mesh = False\n",
    "            clip = True\n",
    "            mtet = False\n",
    "            sites_sdf_grads = None\n",
    "\n",
    "            if mtet:\n",
    "                print(\"Using MTET\")\n",
    "                d3dsimplices = torch.tensor(d3dsimplices, device=device)\n",
    "                marching_tetrehedra_mesh = kaolin.ops.conversions.marching_tetrahedra(\n",
    "                    sites.unsqueeze(0), d3dsimplices, sites_sdf.unsqueeze(0), return_tet_idx=False\n",
    "                )\n",
    "                vertices_list, faces_list = marching_tetrehedra_mesh\n",
    "                v_vect = vertices_list[0]\n",
    "                faces = faces_list[0]\n",
    "                print(\"v_vect shape: \", v_vect.shape)\n",
    "\n",
    "            else:\n",
    "                v_vect, f_vect, sites_sdf_grads, tets_sdf_grads, W = su.get_clipped_mesh_numba(\n",
    "                    sites, None, d3dsimplices, clip, sites_sdf, build_mesh\n",
    "                )\n",
    "\n",
    "            if build_mesh:\n",
    "                triangle_faces = [[f[0], f[i], f[i + 1]] for f in f_vect for i in range(1, len(f) - 1)]\n",
    "                triangle_faces = torch.tensor(triangle_faces, device=device)\n",
    "                hs_p = su.sample_mesh_points_heitz(v_vect, triangle_faces, num_samples=mnfld_points.shape[0])\n",
    "                chamfer_loss_mesh, _ = chamfer_distance(mnfld_points.detach(), hs_p.unsqueeze(0))\n",
    "            else:\n",
    "                chamfer_loss_mesh, _ = chamfer_distance(mnfld_points.detach(), v_vect.unsqueeze(0))\n",
    "\n",
    "            # do cvt loss on the clipped voronoi vertices positions TODO\n",
    "\n",
    "            print(\n",
    "                \"cvt_loss: \",\n",
    "                lambda_cvt / 10 * cvt_loss.item(),\n",
    "                \"chamfer_loss_mesh: \",\n",
    "                lambda_chamfer * chamfer_loss_mesh.item(),\n",
    "            )\n",
    "            sites_loss = lambda_cvt / 10 * cvt_loss + lambda_chamfer * chamfer_loss_mesh\n",
    "\n",
    "            if sites_sdf_grads is None:\n",
    "                sites_sdf_grads, tets_sdf_grads, W = su.sdf_space_grad_pytorch_diego_sites_tets(\n",
    "                    sites, sites_sdf, torch.tensor(d3dsimplices).to(device).detach()\n",
    "                )\n",
    "\n",
    "            # eik_loss = lambda_cvt / 10 * lf.discrete_tet_volume_eikonal_loss(sites, sites_sdf_grads, d3dsimplices)\n",
    "            # shl = lambda_cvt / 0.1 * lf.smoothed_heaviside_loss(sites, sites_sdf, sites_sdf_grads, d3dsimplices)\n",
    "\n",
    "            eik_loss = lambda_cvt / 1000 * lf.tet_sdf_grad_eikonal_loss(sites, tets_sdf_grads, d3dsimplices)\n",
    "            print(\"eikonal_loss: \", eik_loss.item())\n",
    "\n",
    "            shl = lambda_cvt / 1000 * lf.tet_sdf_motion_mean_curvature_loss(sites, sites_sdf, W, d3dsimplices, eps_H)\n",
    "            print(\"smoothed_heaviside_loss: \", shl.item())\n",
    "\n",
    "            # sites_eik_loss = lambda_cvt * 0.5 * torch.mean(((sites_sdf_grads**2).sum(dim=1) - 1) ** 2)\n",
    "\n",
    "            sdf_loss = eik_loss + shl  # sites_eik_loss  # +\n",
    "        else:\n",
    "            sites_loss = lambda_chamfer * voroloss(mnfld_points.squeeze(0), sites).mean()\n",
    "\n",
    "        loss = sites_loss + sdf_loss\n",
    "        loss_values.append(loss.item())\n",
    "        print(f\"Epoch {epoch}: loss = {loss.item()}\")\n",
    "\n",
    "        # print(f\"before loss.backward(): Allocated: {torch.cuda.memory_allocated() / 1e6} MB, Reserved: {torch.cuda.memory_reserved() / 1e6} MB\")\n",
    "        loss.backward()\n",
    "        # print(f\"After loss.backward(): Allocated: {torch.cuda.memory_allocated() / 1e6} MB, Reserved: {torch.cuda.memory_reserved() / 1e6} MB\")\n",
    "        print(\"-----------------\")\n",
    "\n",
    "        # torch.nn.utils.clip_grad_norm_(sites_sdf, 1.0)\n",
    "        # torch.nn.utils.clip_grad_norm_(sites, 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        # sites_sdf += (sites_sdf_grads*(sites-sites_positions)).sum(dim=1)\n",
    "\n",
    "        # scheduler.step()\n",
    "        print(\"Learning rate: \", optimizer.param_groups[0][\"lr\"])\n",
    "        # if epoch>100 and (epoch // 100) == upsampled+1 and loss.item() < 0.5 and upsampled < upsampling:\n",
    "\n",
    "        # TODO: test epoch == 300 growthrate 300%\n",
    "        if upsampled < upsampling and epoch / (max_iter * 0.80) > upsampled / upsampling:\n",
    "            print(\"sites length BEFORE UPSAMPLING: \", len(sites))\n",
    "            if len(sites) * 1.09 > grid**3:\n",
    "                print(\"Skipping upsampling, too many sites, sites length: \", len(sites), \"grid size: \", grid**3)\n",
    "                upsampled = upsampling\n",
    "                sites = sites.detach().requires_grad_(True)\n",
    "                sites_sdf = sites_sdf.detach().requires_grad_(True)\n",
    "\n",
    "                optimizer = torch.optim.Adam(\n",
    "                    [\n",
    "                        {\"params\": [sites], \"lr\": lr_sites * 0.1},\n",
    "                        {\"params\": [sites_sdf], \"lr\": lr_sites * 0.1},\n",
    "                    ]\n",
    "                )\n",
    "                eps_H = lf.estimate_eps_H(sites, d3dsimplices, multiplier=1.5 * 3).detach()\n",
    "                print(\"Estimated eps_H: \", eps_H)\n",
    "                # scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.99)\n",
    "                continue\n",
    "            # sites, sites_sdf = su.upsampling_vectorized_sites_sites_sdf(sites, tri=None, vor=None, simplices=d3dsimplices, model=sites_sdf)\n",
    "            # sites, sites_sdf = su.upsampling_curvature_vectorized_sites_sites_sdf(sites, tri=None, vor=None, simplices=d3dsimplices, model=sites_sdf)\n",
    "            sites, sites_sdf = su.upsampling_adaptive_vectorized_sites_sites_sdf(\n",
    "                sites,\n",
    "                simplices=d3dsimplices,\n",
    "                model=sites_sdf,\n",
    "                sites_sdf_grads=sites_sdf_grads,\n",
    "            )\n",
    "\n",
    "            # sites, sites_sdf = su.upsampling_chamfer_vectorized_sites_sites_sdf(\n",
    "            #     sites, d3dsimplices, sites_sdf, mnfld_points\n",
    "            # )\n",
    "\n",
    "            sites = sites.detach().requires_grad_(True)\n",
    "            sites_sdf = sites_sdf.detach().requires_grad_(True)\n",
    "\n",
    "            optimizer = torch.optim.Adam(\n",
    "                [\n",
    "                    {\"params\": [sites], \"lr\": lr_sites * 0.1},\n",
    "                    {\"params\": [sites_sdf], \"lr\": lr_sites * 0.1},\n",
    "                ]\n",
    "            )\n",
    "            # scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.98)\n",
    "            eps_H = lf.estimate_eps_H(sites, d3dsimplices, multiplier=1.5 * 5).detach()\n",
    "            print(\"Estimated eps_H: \", eps_H)\n",
    "\n",
    "            upsampled += 1.0\n",
    "            print(\"sites shape AFTER: \", sites.shape)\n",
    "            print(\"sites sdf shape AFTER: \", sites_sdf.shape)\n",
    "\n",
    "        if epoch % (max_iter / 10) == 0 or epoch == max_iter:\n",
    "            # print(f\"Epoch {epoch}: loss = {loss.item()}\")\n",
    "            # print(f\"Best Epoch {best_epoch}: Best loss = {best_loss}\")\n",
    "            # save model and sites\n",
    "            # ps.register_surface_mesh(f\"{epoch} triangle clipped mesh\", v_vect.detach().cpu().numpy(), triangle_faces.detach().cpu().numpy())\n",
    "\n",
    "            # ps.register_point_cloud('sampled points end', hs_p.detach().cpu().numpy())\n",
    "            # ps.register_point_cloud(\"sampled points end\", v_vect.detach().cpu().numpy(), enabled=False)\n",
    "\n",
    "            # if f_vect is not None:\n",
    "            #     ps_mesh = ps.register_surface_mesh(\n",
    "            #         f\"{epoch} sdf clipped pmesh\",\n",
    "            #         v_vect.detach().cpu().numpy(),\n",
    "            #         f_vect,\n",
    "            #         back_face_policy=\"identical\",\n",
    "            #         enabled=False,\n",
    "            #     )\n",
    "            #     ps_mesh.add_vector_quantity(\n",
    "            #         f\"{epoch} sdf verts grads\",\n",
    "            #         sdf_verts_grads.detach().cpu().numpy(),\n",
    "            #         enabled=False,\n",
    "            #     )\n",
    "\n",
    "            site_file_path = (\n",
    "                f\"{destination}{mesh[0]}{max_iter}_{epoch}_3d_sites_{num_centroids}_chamfer{lambda_chamfer}.pth\"\n",
    "            )\n",
    "            # model_file_path = f'{destination}{mesh[0]}{max_iter}_{epoch}_3d_model_{num_centroids}_chamfer{lambda_chamfer}.pth'\n",
    "            sdf_file_path = (\n",
    "                f\"{destination}{mesh[0]}{max_iter}_{epoch}_3d_sdf_{num_centroids}_chamfer{lambda_chamfer}.pth\"\n",
    "            )\n",
    "            torch.save(sites_sdf, sdf_file_path)\n",
    "            torch.save(sites, site_file_path)\n",
    "\n",
    "        epoch += 1\n",
    "\n",
    "    return sites, sites_sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "447548a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lambda_weights = [252,0,0,0,10.211111,0,100,0]\n",
    "# lambda_weights = [500,0,0,0,1000,0,100,0]\n",
    "lambda_weights = [100, 0, 0, 0, 1000, 0, 100, 0]\n",
    "\n",
    "\n",
    "lambda_cvt = lambda_weights[0]\n",
    "lambda_sdf = lambda_weights[1]\n",
    "lambda_min_distance = lambda_weights[2]\n",
    "lambda_laplace = lambda_weights[3]\n",
    "lambda_chamfer = lambda_weights[4]\n",
    "lambda_eikonal = lambda_weights[5]\n",
    "lambda_domain_restriction = lambda_weights[6]\n",
    "lambda_true_points = lambda_weights[7]\n",
    "\n",
    "max_iter = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccb5e968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated eps_H:  tensor(1.1722, device='cuda:0')\n",
      "cvt_loss:  0.1604638621211052 chamfer_loss_mesh:  1.720227999612689\n",
      "eikonal_loss:  5.770583152770996\n",
      "smoothed_heaviside_loss:  1.3549137293011881e-05\n",
      "Epoch 0: loss = 7.651288032531738\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.15594599768519402 chamfer_loss_mesh:  1.6712949145585299\n",
      "eikonal_loss:  3.8841874599456787\n",
      "smoothed_heaviside_loss:  1.3682946701010223e-05\n",
      "Epoch 1: loss = 5.711441993713379\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "sites length BEFORE UPSAMPLING:  4096\n",
      "Hybrid upsampling regime\n",
      "Sampled indices: 162 out of 303 candidates (M=303)\n",
      "Estimated eps_H:  tensor(1.1700, device='cuda:0')\n",
      "sites shape AFTER:  torch.Size([4744, 3])\n",
      "sites sdf shape AFTER:  torch.Size([4744])\n",
      "cvt_loss:  0.1708219200372696 chamfer_loss_mesh:  1.250246074050665\n",
      "eikonal_loss:  1.5825430154800415\n",
      "smoothed_heaviside_loss:  1.1809044735855423e-05\n",
      "Epoch 2: loss = 3.0036227703094482\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.16975808888673782 chamfer_loss_mesh:  1.1878195218741894\n",
      "eikonal_loss:  0.8593719601631165\n",
      "smoothed_heaviside_loss:  1.1766034731408581e-05\n",
      "Epoch 3: loss = 2.21696138381958\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.16854465007781982 chamfer_loss_mesh:  1.1425500269979239\n",
      "eikonal_loss:  0.7467086911201477\n",
      "smoothed_heaviside_loss:  1.1723735042323824e-05\n",
      "Epoch 4: loss = 2.0578150749206543\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.16656316816806793 chamfer_loss_mesh:  1.1127707548439503\n",
      "eikonal_loss:  0.3485940992832184\n",
      "smoothed_heaviside_loss:  1.1635434930212796e-05\n",
      "Epoch 5: loss = 1.6279397010803223\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1658417470753193 chamfer_loss_mesh:  1.0522198863327503\n",
      "eikonal_loss:  0.32110410928726196\n",
      "smoothed_heaviside_loss:  1.1575591088330839e-05\n",
      "Epoch 6: loss = 1.5391771793365479\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.16603229567408562 chamfer_loss_mesh:  1.0099877836182714\n",
      "eikonal_loss:  0.5869168639183044\n",
      "smoothed_heaviside_loss:  1.1550028830242809e-05\n",
      "Epoch 7: loss = 1.7629485130310059\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.16445182263851166 chamfer_loss_mesh:  0.9895139373838902\n",
      "eikonal_loss:  0.7185585498809814\n",
      "smoothed_heaviside_loss:  1.155080371972872e-05\n",
      "Epoch 8: loss = 1.8725358247756958\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.16423773020505905 chamfer_loss_mesh:  0.9640334756113589\n",
      "eikonal_loss:  0.30948618054389954\n",
      "smoothed_heaviside_loss:  1.1584330422920175e-05\n",
      "Epoch 9: loss = 1.4377689361572266\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.16335379332304 chamfer_loss_mesh:  0.9459708817303181\n",
      "eikonal_loss:  0.40995320677757263\n",
      "smoothed_heaviside_loss:  1.1581948456296232e-05\n",
      "Epoch 10: loss = 1.519289493560791\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.16061358153820038 chamfer_loss_mesh:  0.9176546009257436\n",
      "eikonal_loss:  0.18566761910915375\n",
      "smoothed_heaviside_loss:  1.156056077888934e-05\n",
      "Epoch 11: loss = 1.2639473676681519\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.15902860090136528 chamfer_loss_mesh:  0.8882783004082739\n",
      "eikonal_loss:  0.4092290997505188\n",
      "smoothed_heaviside_loss:  1.1595711839618161e-05\n",
      "Epoch 12: loss = 1.4565476179122925\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.15781845897436142 chamfer_loss_mesh:  0.8597933920100331\n",
      "eikonal_loss:  1.7787449359893799\n",
      "smoothed_heaviside_loss:  1.1637501302175224e-05\n",
      "Epoch 13: loss = 2.7963685989379883\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.15642857179045677 chamfer_loss_mesh:  0.8236648282036185\n",
      "eikonal_loss:  1.144736409187317\n",
      "smoothed_heaviside_loss:  1.1685655408655293e-05\n",
      "Epoch 14: loss = 2.1248414516448975\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.15494375489652157 chamfer_loss_mesh:  0.7958347559906542\n",
      "eikonal_loss:  0.2611471116542816\n",
      "smoothed_heaviside_loss:  1.162969692813931e-05\n",
      "Epoch 15: loss = 1.2119373083114624\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.15328440815210342 chamfer_loss_mesh:  0.7898724288679659\n",
      "eikonal_loss:  0.2627114951610565\n",
      "smoothed_heaviside_loss:  1.165862977359211e-05\n",
      "Epoch 16: loss = 1.2058799266815186\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.15125340782105923 chamfer_loss_mesh:  0.7771339733153582\n",
      "eikonal_loss:  0.2603016793727875\n",
      "smoothed_heaviside_loss:  1.1652314242383e-05\n",
      "Epoch 17: loss = 1.1887006759643555\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.14854257926344872 chamfer_loss_mesh:  0.7614257046952844\n",
      "eikonal_loss:  0.8916770815849304\n",
      "smoothed_heaviside_loss:  1.1712882042047568e-05\n",
      "Epoch 18: loss = 1.8016571998596191\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.14694302342832088 chamfer_loss_mesh:  0.7463858928531408\n",
      "eikonal_loss:  0.7468165755271912\n",
      "smoothed_heaviside_loss:  1.177109243144514e-05\n",
      "Epoch 19: loss = 1.6401572227478027\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.14492805115878582 chamfer_loss_mesh:  0.7530355360358953\n",
      "eikonal_loss:  0.4292295575141907\n",
      "smoothed_heaviside_loss:  1.1784266462200321e-05\n",
      "Epoch 20: loss = 1.327204942703247\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1432283315807581 chamfer_loss_mesh:  0.7396726286970079\n",
      "eikonal_loss:  0.9944879412651062\n",
      "smoothed_heaviside_loss:  1.1855989214382134e-05\n",
      "Epoch 21: loss = 1.8774007558822632\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.14166872017085552 chamfer_loss_mesh:  0.7368266233243048\n",
      "eikonal_loss:  0.6483024954795837\n",
      "smoothed_heaviside_loss:  1.1829917639261112e-05\n",
      "Epoch 22: loss = 1.5268096923828125\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13966954313218594 chamfer_loss_mesh:  0.734908040612936\n",
      "eikonal_loss:  0.4261704087257385\n",
      "smoothed_heaviside_loss:  1.1874802112288307e-05\n",
      "Epoch 23: loss = 1.3007597923278809\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13816838152706623 chamfer_loss_mesh:  0.7140417583286762\n",
      "eikonal_loss:  0.3302224576473236\n",
      "smoothed_heaviside_loss:  1.1889463166880887e-05\n",
      "Epoch 24: loss = 1.1824445724487305\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13707182370126247 chamfer_loss_mesh:  0.6988325039856136\n",
      "eikonal_loss:  0.2417539656162262\n",
      "smoothed_heaviside_loss:  1.1893564987985883e-05\n",
      "Epoch 25: loss = 1.0776702165603638\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1346539705991745 chamfer_loss_mesh:  0.681677891407162\n",
      "eikonal_loss:  0.24535341560840607\n",
      "smoothed_heaviside_loss:  1.1865096894325688e-05\n",
      "Epoch 26: loss = 1.0616971254348755\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13434412889182568 chamfer_loss_mesh:  0.6617959006689489\n",
      "eikonal_loss:  0.24139194190502167\n",
      "smoothed_heaviside_loss:  1.1885199455718976e-05\n",
      "Epoch 27: loss = 1.0375438928604126\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13257254846394062 chamfer_loss_mesh:  0.6523377960547805\n",
      "eikonal_loss:  0.7632243037223816\n",
      "smoothed_heaviside_loss:  1.1948736755584832e-05\n",
      "Epoch 28: loss = 1.5481464862823486\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1302073337137699 chamfer_loss_mesh:  0.6449229549616575\n",
      "eikonal_loss:  0.4035520553588867\n",
      "smoothed_heaviside_loss:  1.193379739561351e-05\n",
      "Epoch 29: loss = 1.178694248199463\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12829103507101536 chamfer_loss_mesh:  0.6323714624159038\n",
      "eikonal_loss:  0.270783394575119\n",
      "smoothed_heaviside_loss:  1.191544743051054e-05\n",
      "Epoch 30: loss = 1.0314579010009766\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1268953736871481 chamfer_loss_mesh:  0.6336552323773503\n",
      "eikonal_loss:  0.23956282436847687\n",
      "smoothed_heaviside_loss:  1.1940431249968242e-05\n",
      "Epoch 31: loss = 1.0001254081726074\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1257105078548193 chamfer_loss_mesh:  0.630947994068265\n",
      "eikonal_loss:  0.201687291264534\n",
      "smoothed_heaviside_loss:  1.1964246368734166e-05\n",
      "Epoch 32: loss = 0.9583577513694763\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12283613905310631 chamfer_loss_mesh:  0.6273007020354271\n",
      "eikonal_loss:  0.1796526163816452\n",
      "smoothed_heaviside_loss:  1.194505784951616e-05\n",
      "Epoch 33: loss = 0.9298014044761658\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12140702456235886 chamfer_loss_mesh:  0.5976087413728237\n",
      "eikonal_loss:  0.16231052577495575\n",
      "smoothed_heaviside_loss:  1.197702658828348e-05\n",
      "Epoch 34: loss = 0.8813382983207703\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12000045739114285 chamfer_loss_mesh:  0.5859003867954016\n",
      "eikonal_loss:  0.15100590884685516\n",
      "smoothed_heaviside_loss:  1.2015852007607464e-05\n",
      "Epoch 35: loss = 0.8569187521934509\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.11839793063700199 chamfer_loss_mesh:  0.5785622051917017\n",
      "eikonal_loss:  0.14518877863883972\n",
      "smoothed_heaviside_loss:  1.2036131920467597e-05\n",
      "Epoch 36: loss = 0.8421609401702881\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.11679981835186481 chamfer_loss_mesh:  0.5780929932370782\n",
      "eikonal_loss:  0.16614067554473877\n",
      "smoothed_heaviside_loss:  1.2087846698705107e-05\n",
      "Epoch 37: loss = 0.8610455989837646\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1161208376288414 chamfer_loss_mesh:  0.5736976163461804\n",
      "eikonal_loss:  0.1413678377866745\n",
      "smoothed_heaviside_loss:  1.2074903679604176e-05\n",
      "Epoch 38: loss = 0.8311983346939087\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.11427841149270535 chamfer_loss_mesh:  0.5668821977451444\n",
      "eikonal_loss:  0.12918385863304138\n",
      "smoothed_heaviside_loss:  1.2085157322871964e-05\n",
      "Epoch 39: loss = 0.8103565573692322\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.11302080005407333 chamfer_loss_mesh:  0.5537964170798659\n",
      "eikonal_loss:  0.11915542930364609\n",
      "smoothed_heaviside_loss:  1.2088569746993016e-05\n",
      "Epoch 40: loss = 0.7859846949577332\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.11185942217707634 chamfer_loss_mesh:  0.5439113592728972\n",
      "eikonal_loss:  0.11420082300901413\n",
      "smoothed_heaviside_loss:  1.2103481822123285e-05\n",
      "Epoch 41: loss = 0.76998370885849\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.11107781901955605 chamfer_loss_mesh:  0.5549159250222147\n",
      "eikonal_loss:  0.10863306373357773\n",
      "smoothed_heaviside_loss:  1.212097231473308e-05\n",
      "Epoch 42: loss = 0.7746388912200928\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.10959320701658726 chamfer_loss_mesh:  0.5440691020339727\n",
      "eikonal_loss:  0.09740415960550308\n",
      "smoothed_heaviside_loss:  1.2092464203306008e-05\n",
      "Epoch 43: loss = 0.7510786056518555\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.10792742483317852 chamfer_loss_mesh:  0.5420491797849536\n",
      "eikonal_loss:  0.09481866657733917\n",
      "smoothed_heaviside_loss:  1.2107924703741446e-05\n",
      "Epoch 44: loss = 0.7448073625564575\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.10681681334972382 chamfer_loss_mesh:  0.5361634539440274\n",
      "eikonal_loss:  0.09260241687297821\n",
      "smoothed_heaviside_loss:  1.2127539775974583e-05\n",
      "Epoch 45: loss = 0.7355948090553284\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.10594820603728294 chamfer_loss_mesh:  0.535834114998579\n",
      "eikonal_loss:  0.10675708204507828\n",
      "smoothed_heaviside_loss:  1.2147705092502292e-05\n",
      "Epoch 46: loss = 0.7485515475273132\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.10381365194916725 chamfer_loss_mesh:  0.5369248101487756\n",
      "eikonal_loss:  0.08688537776470184\n",
      "smoothed_heaviside_loss:  1.2156687262177002e-05\n",
      "Epoch 47: loss = 0.7276360392570496\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.10301420465111732 chamfer_loss_mesh:  0.5332661094143987\n",
      "eikonal_loss:  0.08863268047571182\n",
      "smoothed_heaviside_loss:  1.2164677173132077e-05\n",
      "Epoch 48: loss = 0.72492516040802\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.10189919732511044 chamfer_loss_mesh:  0.5206204950809479\n",
      "eikonal_loss:  0.08445950597524643\n",
      "smoothed_heaviside_loss:  1.2185730156488717e-05\n",
      "Epoch 49: loss = 0.7069913744926453\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.10093838907778263 chamfer_loss_mesh:  0.509768258780241\n",
      "eikonal_loss:  0.08237821608781815\n",
      "smoothed_heaviside_loss:  1.2199181583127938e-05\n",
      "Epoch 50: loss = 0.6930970549583435\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.09952067397534847 chamfer_loss_mesh:  0.5076194065622985\n",
      "eikonal_loss:  0.07970822602510452\n",
      "smoothed_heaviside_loss:  1.2224822967255022e-05\n",
      "Epoch 51: loss = 0.6868605017662048\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.0983022153377533 chamfer_loss_mesh:  0.5039848037995398\n",
      "eikonal_loss:  0.27039992809295654\n",
      "smoothed_heaviside_loss:  1.2251824045961257e-05\n",
      "Epoch 52: loss = 0.8726992607116699\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.09702938608825207 chamfer_loss_mesh:  0.5089138867333531\n",
      "eikonal_loss:  0.26393479108810425\n",
      "smoothed_heaviside_loss:  1.2263693861314096e-05\n",
      "Epoch 53: loss = 0.8698903322219849\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.09564448148012161 chamfer_loss_mesh:  0.5038503441028297\n",
      "eikonal_loss:  0.181572824716568\n",
      "smoothed_heaviside_loss:  1.2265528312127572e-05\n",
      "Epoch 54: loss = 0.781079888343811\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.09409982711076736 chamfer_loss_mesh:  0.4978219512850046\n",
      "eikonal_loss:  0.14400841295719147\n",
      "smoothed_heaviside_loss:  1.2280531336728018e-05\n",
      "Epoch 55: loss = 0.7359424829483032\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.09294815361499786 chamfer_loss_mesh:  0.49364526057615876\n",
      "eikonal_loss:  0.0975409746170044\n",
      "smoothed_heaviside_loss:  1.2291432540223468e-05\n",
      "Epoch 56: loss = 0.6841466426849365\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.09207705967128277 chamfer_loss_mesh:  0.4912068252451718\n",
      "eikonal_loss:  0.0855678915977478\n",
      "smoothed_heaviside_loss:  1.2292620340303984e-05\n",
      "Epoch 57: loss = 0.6688640713691711\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.0909277144819498 chamfer_loss_mesh:  0.4773820983245969\n",
      "eikonal_loss:  0.052254389971494675\n",
      "smoothed_heaviside_loss:  1.2292289284232538e-05\n",
      "Epoch 58: loss = 0.6205764412879944\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.09080994874238968 chamfer_loss_mesh:  0.48075817176140845\n",
      "eikonal_loss:  0.05061275511980057\n",
      "smoothed_heaviside_loss:  1.2316517313593067e-05\n",
      "Epoch 59: loss = 0.6221932172775269\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.0892759021371603 chamfer_loss_mesh:  0.47687379992567\n",
      "eikonal_loss:  0.044230151921510696\n",
      "smoothed_heaviside_loss:  1.2319839697738644e-05\n",
      "Epoch 60: loss = 0.6103922128677368\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.08821575902402401 chamfer_loss_mesh:  0.4734671674668789\n",
      "eikonal_loss:  0.13917210698127747\n",
      "smoothed_heaviside_loss:  1.2330831850704271e-05\n",
      "Epoch 61: loss = 0.7008674144744873\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.0874793715775013 chamfer_loss_mesh:  0.4645373555831611\n",
      "eikonal_loss:  0.04152219370007515\n",
      "smoothed_heaviside_loss:  1.232542399520753e-05\n",
      "Epoch 62: loss = 0.5935512781143188\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.08698408491909504 chamfer_loss_mesh:  0.4625730507541448\n",
      "eikonal_loss:  0.03621191158890724\n",
      "smoothed_heaviside_loss:  1.2325700481596868e-05\n",
      "Epoch 63: loss = 0.5857813954353333\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.08599045686423779 chamfer_loss_mesh:  0.45864449930377305\n",
      "eikonal_loss:  0.04252030327916145\n",
      "smoothed_heaviside_loss:  1.2342313311819453e-05\n",
      "Epoch 64: loss = 0.5871675610542297\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.08537859655916691 chamfer_loss_mesh:  0.45613106340169907\n",
      "eikonal_loss:  0.03837278112769127\n",
      "smoothed_heaviside_loss:  1.235763465956552e-05\n",
      "Epoch 65: loss = 0.5798948407173157\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.08457101881504059 chamfer_loss_mesh:  0.4510176077019423\n",
      "eikonal_loss:  0.031237101182341576\n",
      "smoothed_heaviside_loss:  1.2373259778541978e-05\n",
      "Epoch 66: loss = 0.5668380856513977\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.08370870724320412 chamfer_loss_mesh:  0.44585554860532284\n",
      "eikonal_loss:  0.02927396632730961\n",
      "smoothed_heaviside_loss:  1.2386974958644714e-05\n",
      "Epoch 67: loss = 0.5588505864143372\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.08281060494482517 chamfer_loss_mesh:  0.4428713582456112\n",
      "eikonal_loss:  0.027674421668052673\n",
      "smoothed_heaviside_loss:  1.2401216736179776e-05\n",
      "Epoch 68: loss = 0.5533688068389893\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.08178595453500748 chamfer_loss_mesh:  0.43313359492458403\n",
      "eikonal_loss:  0.026964589953422546\n",
      "smoothed_heaviside_loss:  1.240537403646158e-05\n",
      "Epoch 69: loss = 0.5418965816497803\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.0813671387732029 chamfer_loss_mesh:  0.4363219777587801\n",
      "eikonal_loss:  0.026263555511832237\n",
      "smoothed_heaviside_loss:  1.2444428648450412e-05\n",
      "Epoch 70: loss = 0.5439651012420654\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.08005539886653423 chamfer_loss_mesh:  0.4335810663178563\n",
      "eikonal_loss:  0.02613965980708599\n",
      "smoothed_heaviside_loss:  1.2413484910211992e-05\n",
      "Epoch 71: loss = 0.539788544178009\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.07911588996648788 chamfer_loss_mesh:  0.4297928826417774\n",
      "eikonal_loss:  0.09052334725856781\n",
      "smoothed_heaviside_loss:  1.2426025932654738e-05\n",
      "Epoch 72: loss = 0.5994445085525513\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.07877245545387268 chamfer_loss_mesh:  0.43994482257403433\n",
      "eikonal_loss:  0.07764902710914612\n",
      "smoothed_heaviside_loss:  1.2426791727193631e-05\n",
      "Epoch 73: loss = 0.596378743648529\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.07910938933491707 chamfer_loss_mesh:  0.43465723865665495\n",
      "eikonal_loss:  0.02728920616209507\n",
      "smoothed_heaviside_loss:  1.2436177712515928e-05\n",
      "Epoch 74: loss = 0.5410683155059814\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.07764576934278011 chamfer_loss_mesh:  0.4376620636321604\n",
      "eikonal_loss:  0.0321965254843235\n",
      "smoothed_heaviside_loss:  1.2453731869754847e-05\n",
      "Epoch 75: loss = 0.5475168228149414\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.076966374181211 chamfer_loss_mesh:  0.4336638667155057\n",
      "eikonal_loss:  0.0724697932600975\n",
      "smoothed_heaviside_loss:  1.2460131074476521e-05\n",
      "Epoch 76: loss = 0.5831124782562256\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.07627662736922503 chamfer_loss_mesh:  0.4328486684244126\n",
      "eikonal_loss:  0.07550334185361862\n",
      "smoothed_heaviside_loss:  1.2465508007153403e-05\n",
      "Epoch 77: loss = 0.5846410989761353\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.07522952277213335 chamfer_loss_mesh:  0.43199240462854505\n",
      "eikonal_loss:  0.06438886374235153\n",
      "smoothed_heaviside_loss:  1.2465984582377132e-05\n",
      "Epoch 78: loss = 0.5716232657432556\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.07469466887414455 chamfer_loss_mesh:  0.42829918675124645\n",
      "eikonal_loss:  0.08809792250394821\n",
      "smoothed_heaviside_loss:  1.2514406989794225e-05\n",
      "Epoch 79: loss = 0.5911043286323547\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.07384482771158218 chamfer_loss_mesh:  0.4327119095250964\n",
      "eikonal_loss:  0.040283042937517166\n",
      "smoothed_heaviside_loss:  1.249032993655419e-05\n",
      "Epoch 80: loss = 0.5468522906303406\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.07346560247242451 chamfer_loss_mesh:  0.4327773640397936\n",
      "eikonal_loss:  0.1017722487449646\n",
      "smoothed_heaviside_loss:  1.2494783732108772e-05\n",
      "Epoch 81: loss = 0.6080277562141418\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "sites length BEFORE UPSAMPLING:  4744\n",
      "Hybrid upsampling regime\n",
      "Sampled indices: 324 out of 813 candidates (M=474)\n",
      "Estimated eps_H:  tensor(1.0548, device='cuda:0')\n",
      "sites shape AFTER:  torch.Size([6040, 3])\n",
      "sites sdf shape AFTER:  torch.Size([6040])\n",
      "cvt_loss:  0.10735351592302322 chamfer_loss_mesh:  0.3952091792598367\n",
      "eikonal_loss:  0.02071911282837391\n",
      "smoothed_heaviside_loss:  9.605987543181982e-06\n",
      "Epoch 82: loss = 0.5232914090156555\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.10852319188416004 chamfer_loss_mesh:  0.37075611180625856\n",
      "eikonal_loss:  0.11139886826276779\n",
      "smoothed_heaviside_loss:  9.562590093992185e-06\n",
      "Epoch 83: loss = 0.5906877517700195\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.11133590713143349 chamfer_loss_mesh:  0.35742641193792224\n",
      "eikonal_loss:  0.5324152112007141\n",
      "smoothed_heaviside_loss:  9.572550879966002e-06\n",
      "Epoch 84: loss = 1.0011870861053467\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.11541897431015968 chamfer_loss_mesh:  0.3402058209758252\n",
      "eikonal_loss:  0.26254209876060486\n",
      "smoothed_heaviside_loss:  9.550334652885795e-06\n",
      "Epoch 85: loss = 0.7181764245033264\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.11792629025876522 chamfer_loss_mesh:  0.3324501449242234\n",
      "eikonal_loss:  1.1660701036453247\n",
      "smoothed_heaviside_loss:  9.479851541982498e-06\n",
      "Epoch 86: loss = 1.6164560317993164\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.11938781477510929 chamfer_loss_mesh:  0.3259452059864998\n",
      "eikonal_loss:  0.29798251390457153\n",
      "smoothed_heaviside_loss:  9.494145160715561e-06\n",
      "Epoch 87: loss = 0.7433249950408936\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.11965925805270672 chamfer_loss_mesh:  0.32240519067272544\n",
      "eikonal_loss:  0.1514507532119751\n",
      "smoothed_heaviside_loss:  9.473529644310474e-06\n",
      "Epoch 88: loss = 0.593524694442749\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.11972217820584774 chamfer_loss_mesh:  0.3102895861957222\n",
      "eikonal_loss:  0.11747761070728302\n",
      "smoothed_heaviside_loss:  9.462594789511058e-06\n",
      "Epoch 89: loss = 0.5474988222122192\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.11932865716516972 chamfer_loss_mesh:  0.3049016813747585\n",
      "eikonal_loss:  1.953682780265808\n",
      "smoothed_heaviside_loss:  9.487869647273328e-06\n",
      "Epoch 90: loss = 2.377922534942627\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.11908207088708878 chamfer_loss_mesh:  0.2955235249828547\n",
      "eikonal_loss:  0.04822077974677086\n",
      "smoothed_heaviside_loss:  9.445151590625755e-06\n",
      "Epoch 91: loss = 0.46283581852912903\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1176788192242384 chamfer_loss_mesh:  0.29397805337794125\n",
      "eikonal_loss:  0.04575173184275627\n",
      "smoothed_heaviside_loss:  9.457457053940743e-06\n",
      "Epoch 92: loss = 0.4574180841445923\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.11707336641848087 chamfer_loss_mesh:  0.2921006234828383\n",
      "eikonal_loss:  0.03383290022611618\n",
      "smoothed_heaviside_loss:  9.423001756658778e-06\n",
      "Epoch 93: loss = 0.44301632046699524\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.11627821251749992 chamfer_loss_mesh:  0.28732180362567306\n",
      "eikonal_loss:  0.060155238956213\n",
      "smoothed_heaviside_loss:  9.421778486284893e-06\n",
      "Epoch 94: loss = 0.4637646973133087\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.11659936979413033 chamfer_loss_mesh:  0.2843012916855514\n",
      "eikonal_loss:  0.062195684760808945\n",
      "smoothed_heaviside_loss:  9.425445568922441e-06\n",
      "Epoch 95: loss = 0.4631057679653168\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1149805448949337 chamfer_loss_mesh:  0.27955687255598605\n",
      "eikonal_loss:  0.04087991267442703\n",
      "smoothed_heaviside_loss:  9.417548426426947e-06\n",
      "Epoch 96: loss = 0.4354267418384552\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.11469008401036263 chamfer_loss_mesh:  0.27524467441253364\n",
      "eikonal_loss:  0.03279909864068031\n",
      "smoothed_heaviside_loss:  9.433582818019204e-06\n",
      "Epoch 97: loss = 0.4227433204650879\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1141518447548151 chamfer_loss_mesh:  0.2730657288338989\n",
      "eikonal_loss:  0.030536143109202385\n",
      "smoothed_heaviside_loss:  9.436862455913797e-06\n",
      "Epoch 98: loss = 0.4177631437778473\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.113168153911829 chamfer_loss_mesh:  0.27538754511624575\n",
      "eikonal_loss:  0.026021763682365417\n",
      "smoothed_heaviside_loss:  9.438191227673087e-06\n",
      "Epoch 99: loss = 0.4145869016647339\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "Estimated eps_H:  tensor(0.9038, device='cuda:0')\n",
      "cvt_loss:  0.11271081864833832 chamfer_loss_mesh:  0.26965851429849863\n",
      "eikonal_loss:  0.044360484927892685\n",
      "smoothed_heaviside_loss:  8.93376909516519e-06\n",
      "Epoch 100: loss = 0.42673876881599426\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.11167812161147594 chamfer_loss_mesh:  0.2682679332792759\n",
      "eikonal_loss:  0.039093028753995895\n",
      "smoothed_heaviside_loss:  8.927820090320893e-06\n",
      "Epoch 101: loss = 0.419048011302948\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.11120622046291828 chamfer_loss_mesh:  0.26888956199400127\n",
      "eikonal_loss:  0.10082993656396866\n",
      "smoothed_heaviside_loss:  8.931510819820687e-06\n",
      "Epoch 102: loss = 0.48093464970588684\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.11047731153666973 chamfer_loss_mesh:  0.2608783543109894\n",
      "eikonal_loss:  0.05718926340341568\n",
      "smoothed_heaviside_loss:  8.922258530219551e-06\n",
      "Epoch 103: loss = 0.42855384945869446\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.10974007658660412 chamfer_loss_mesh:  0.2584855246823281\n",
      "eikonal_loss:  1.2466915845870972\n",
      "smoothed_heaviside_loss:  8.9187951743952e-06\n",
      "Epoch 104: loss = 1.6149260997772217\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.10961889289319515 chamfer_loss_mesh:  0.2569683420006186\n",
      "eikonal_loss:  0.030654460191726685\n",
      "smoothed_heaviside_loss:  8.919776519178413e-06\n",
      "Epoch 105: loss = 0.39725062251091003\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1085271779447794 chamfer_loss_mesh:  0.25562988594174385\n",
      "eikonal_loss:  0.05529380589723587\n",
      "smoothed_heaviside_loss:  8.922589586290997e-06\n",
      "Epoch 106: loss = 0.41945981979370117\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.10829443112015724 chamfer_loss_mesh:  0.25225101853720844\n",
      "eikonal_loss:  0.0304415225982666\n",
      "smoothed_heaviside_loss:  8.92257048690226e-06\n",
      "Epoch 107: loss = 0.39099588990211487\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.10785584338009357 chamfer_loss_mesh:  0.2502189890947193\n",
      "eikonal_loss:  0.025935983285307884\n",
      "smoothed_heaviside_loss:  8.91642503120238e-06\n",
      "Epoch 108: loss = 0.38401973247528076\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.10730523616075516 chamfer_loss_mesh:  0.2481999108567834\n",
      "eikonal_loss:  0.020502572879195213\n",
      "smoothed_heaviside_loss:  8.912399607652333e-06\n",
      "Epoch 109: loss = 0.37601661682128906\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.10634302161633968 chamfer_loss_mesh:  0.24776070495136082\n",
      "eikonal_loss:  0.018976880237460136\n",
      "smoothed_heaviside_loss:  8.92364823812386e-06\n",
      "Epoch 110: loss = 0.3730895221233368\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.10603135451674461 chamfer_loss_mesh:  0.24667553952895105\n",
      "eikonal_loss:  0.017224324867129326\n",
      "smoothed_heaviside_loss:  8.926581358537078e-06\n",
      "Epoch 111: loss = 0.3699401617050171\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.10556274093687534 chamfer_loss_mesh:  0.24413486244156957\n",
      "eikonal_loss:  0.015670910477638245\n",
      "smoothed_heaviside_loss:  8.929133400670253e-06\n",
      "Epoch 112: loss = 0.36537742614746094\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1048747356981039 chamfer_loss_mesh:  0.24188135284930468\n",
      "eikonal_loss:  0.06735383719205856\n",
      "smoothed_heaviside_loss:  8.934870493249036e-06\n",
      "Epoch 113: loss = 0.4141188859939575\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.10511797852814198 chamfer_loss_mesh:  0.2408791333436966\n",
      "eikonal_loss:  0.06388930976390839\n",
      "smoothed_heaviside_loss:  8.9306968220626e-06\n",
      "Epoch 114: loss = 0.4098953306674957\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.10442731902003288 chamfer_loss_mesh:  0.23785079247318208\n",
      "eikonal_loss:  0.05142563208937645\n",
      "smoothed_heaviside_loss:  8.938840437622275e-06\n",
      "Epoch 115: loss = 0.39371269941329956\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.10345187969505787 chamfer_loss_mesh:  0.234701088629663\n",
      "eikonal_loss:  0.04377353936433792\n",
      "smoothed_heaviside_loss:  8.94984168553492e-06\n",
      "Epoch 116: loss = 0.3819354176521301\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1026458851993084 chamfer_loss_mesh:  0.24945498444139957\n",
      "eikonal_loss:  0.03672512248158455\n",
      "smoothed_heaviside_loss:  8.958061698649544e-06\n",
      "Epoch 117: loss = 0.38883495330810547\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.10242877528071404 chamfer_loss_mesh:  0.23047735157888383\n",
      "eikonal_loss:  0.02776663936674595\n",
      "smoothed_heaviside_loss:  8.958723810792435e-06\n",
      "Epoch 118: loss = 0.3606817126274109\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.10213930159807205 chamfer_loss_mesh:  0.2284774964209646\n",
      "eikonal_loss:  0.02871132269501686\n",
      "smoothed_heaviside_loss:  8.950216397352051e-06\n",
      "Epoch 119: loss = 0.35933706164360046\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.10160150937736034 chamfer_loss_mesh:  0.2275310835102573\n",
      "eikonal_loss:  0.022880760952830315\n",
      "smoothed_heaviside_loss:  8.961464118328877e-06\n",
      "Epoch 120: loss = 0.35202234983444214\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.10095085017383099 chamfer_loss_mesh:  0.2261093322886154\n",
      "eikonal_loss:  0.02537914551794529\n",
      "smoothed_heaviside_loss:  8.968231668404769e-06\n",
      "Epoch 121: loss = 0.3524482846260071\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.10079826228320599 chamfer_loss_mesh:  0.22509731934405863\n",
      "eikonal_loss:  0.0297390166670084\n",
      "smoothed_heaviside_loss:  8.955469638749491e-06\n",
      "Epoch 122: loss = 0.35564354062080383\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.10063549503684044 chamfer_loss_mesh:  0.22555733448825777\n",
      "eikonal_loss:  0.026347680017352104\n",
      "smoothed_heaviside_loss:  8.96503115654923e-06\n",
      "Epoch 123: loss = 0.3525494635105133\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.09981049224734306 chamfer_loss_mesh:  0.22218561207409948\n",
      "eikonal_loss:  0.023351255804300308\n",
      "smoothed_heaviside_loss:  8.963513209891971e-06\n",
      "Epoch 124: loss = 0.3453563153743744\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.09963683784008026 chamfer_loss_mesh:  0.2224290801677853\n",
      "eikonal_loss:  0.021240873262286186\n",
      "smoothed_heaviside_loss:  8.958138096204493e-06\n",
      "Epoch 125: loss = 0.3433157503604889\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.09861470200121403 chamfer_loss_mesh:  0.22265053121373057\n",
      "eikonal_loss:  0.021281473338603973\n",
      "smoothed_heaviside_loss:  8.973451258498244e-06\n",
      "Epoch 126: loss = 0.3425556719303131\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.09867198765277863 chamfer_loss_mesh:  0.22572645684704185\n",
      "eikonal_loss:  0.020799197256565094\n",
      "smoothed_heaviside_loss:  8.975813216238748e-06\n",
      "Epoch 127: loss = 0.345206618309021\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.09847640059888363 chamfer_loss_mesh:  0.22185734997037798\n",
      "eikonal_loss:  0.020151201635599136\n",
      "smoothed_heaviside_loss:  8.988549780042376e-06\n",
      "Epoch 128: loss = 0.34049394726753235\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.09801418520510197 chamfer_loss_mesh:  0.22126760450191796\n",
      "eikonal_loss:  0.0213263388723135\n",
      "smoothed_heaviside_loss:  8.995048119686544e-06\n",
      "Epoch 129: loss = 0.3406171202659607\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.09744366630911827 chamfer_loss_mesh:  0.21977171127218753\n",
      "eikonal_loss:  0.019612019881606102\n",
      "smoothed_heaviside_loss:  8.987015462480485e-06\n",
      "Epoch 130: loss = 0.33683639764785767\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.09661621414124966 chamfer_loss_mesh:  0.2206494245911017\n",
      "eikonal_loss:  0.02218819223344326\n",
      "smoothed_heaviside_loss:  8.994319614430424e-06\n",
      "Epoch 131: loss = 0.3394628167152405\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.0956894364207983 chamfer_loss_mesh:  0.2157303097192198\n",
      "eikonal_loss:  0.01969779096543789\n",
      "smoothed_heaviside_loss:  8.99801125342492e-06\n",
      "Epoch 132: loss = 0.33112654089927673\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.09502761997282505 chamfer_loss_mesh:  0.21037788246758282\n",
      "eikonal_loss:  0.019857965409755707\n",
      "smoothed_heaviside_loss:  9.013341696118005e-06\n",
      "Epoch 133: loss = 0.32527247071266174\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.09491188451647758 chamfer_loss_mesh:  0.20914876949973404\n",
      "eikonal_loss:  0.014086692593991756\n",
      "smoothed_heaviside_loss:  9.01828479982214e-06\n",
      "Epoch 134: loss = 0.318156361579895\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.09428098797798157 chamfer_loss_mesh:  0.20940572721883655\n",
      "eikonal_loss:  0.01400107890367508\n",
      "smoothed_heaviside_loss:  9.016649528348353e-06\n",
      "Epoch 135: loss = 0.31769680976867676\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.09383049793541431 chamfer_loss_mesh:  0.2088897890644148\n",
      "eikonal_loss:  0.01303903479129076\n",
      "smoothed_heaviside_loss:  9.013948329084087e-06\n",
      "Epoch 136: loss = 0.3157683312892914\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.09304606355726719 chamfer_loss_mesh:  0.20909846352878958\n",
      "eikonal_loss:  0.012375994585454464\n",
      "smoothed_heaviside_loss:  9.015726391226053e-06\n",
      "Epoch 137: loss = 0.31452953815460205\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.09262324310839176 chamfer_loss_mesh:  0.2128389896824956\n",
      "eikonal_loss:  0.018372148275375366\n",
      "smoothed_heaviside_loss:  9.015830983116757e-06\n",
      "Epoch 138: loss = 0.32384341955184937\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.09231158532202244 chamfer_loss_mesh:  0.21224042575340718\n",
      "eikonal_loss:  0.019036365672945976\n",
      "smoothed_heaviside_loss:  9.019378012453672e-06\n",
      "Epoch 139: loss = 0.32359740138053894\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.09167409501969814 chamfer_loss_mesh:  0.21086826745886356\n",
      "eikonal_loss:  0.022274184972047806\n",
      "smoothed_heaviside_loss:  9.02422016224591e-06\n",
      "Epoch 140: loss = 0.32482555508613586\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.09177979081869125 chamfer_loss_mesh:  0.2084779116557911\n",
      "eikonal_loss:  0.028276655822992325\n",
      "smoothed_heaviside_loss:  9.020764082379173e-06\n",
      "Epoch 141: loss = 0.32854339480400085\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.09130744263529778 chamfer_loss_mesh:  0.20660650625359267\n",
      "eikonal_loss:  0.0567350871860981\n",
      "smoothed_heaviside_loss:  9.02200372365769e-06\n",
      "Epoch 142: loss = 0.3546580672264099\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.09067094884812832 chamfer_loss_mesh:  0.20559466793201864\n",
      "eikonal_loss:  0.009388375096023083\n",
      "smoothed_heaviside_loss:  9.027537998917978e-06\n",
      "Epoch 143: loss = 0.3056630492210388\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.09061487391591072 chamfer_loss_mesh:  0.2045820001512766\n",
      "eikonal_loss:  0.00955934263765812\n",
      "smoothed_heaviside_loss:  9.013537237478886e-06\n",
      "Epoch 144: loss = 0.3047652542591095\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.08999367244541645 chamfer_loss_mesh:  0.20473012409638613\n",
      "eikonal_loss:  0.008651485666632652\n",
      "smoothed_heaviside_loss:  9.020965080708265e-06\n",
      "Epoch 145: loss = 0.30338430404663086\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.08963651955127716 chamfer_loss_mesh:  0.20204637257847935\n",
      "eikonal_loss:  0.008149419911205769\n",
      "smoothed_heaviside_loss:  9.025464350997936e-06\n",
      "Epoch 146: loss = 0.29984134435653687\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.08913485333323479 chamfer_loss_mesh:  0.20185518951620907\n",
      "eikonal_loss:  0.008494662120938301\n",
      "smoothed_heaviside_loss:  9.029732609633356e-06\n",
      "Epoch 147: loss = 0.2994937598705292\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.08886340074241161 chamfer_loss_mesh:  0.20298684830777347\n",
      "eikonal_loss:  0.007879610173404217\n",
      "smoothed_heaviside_loss:  9.030720320879482e-06\n",
      "Epoch 148: loss = 0.29973891377449036\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.08784945122897625 chamfer_loss_mesh:  0.1986277347896248\n",
      "eikonal_loss:  0.00720149977132678\n",
      "smoothed_heaviside_loss:  9.046312698046677e-06\n",
      "Epoch 149: loss = 0.29368776082992554\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.08750724606215954 chamfer_loss_mesh:  0.19680149853229523\n",
      "eikonal_loss:  0.007136087398976088\n",
      "smoothed_heaviside_loss:  9.049213986145332e-06\n",
      "Epoch 150: loss = 0.29145386815071106\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.08735211566090584 chamfer_loss_mesh:  0.19540889479685575\n",
      "eikonal_loss:  0.006528294179588556\n",
      "smoothed_heaviside_loss:  9.058280738827307e-06\n",
      "Epoch 151: loss = 0.2892983555793762\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.08706334047019482 chamfer_loss_mesh:  0.19406025239732116\n",
      "eikonal_loss:  0.006485247518867254\n",
      "smoothed_heaviside_loss:  9.057442184712272e-06\n",
      "Epoch 152: loss = 0.28761789202690125\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.08692152798175812 chamfer_loss_mesh:  0.19404792692512274\n",
      "eikonal_loss:  0.006579739507287741\n",
      "smoothed_heaviside_loss:  9.062910976354033e-06\n",
      "Epoch 153: loss = 0.28755825757980347\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.0865876954048872 chamfer_loss_mesh:  0.19324381719343364\n",
      "eikonal_loss:  0.006478510331362486\n",
      "smoothed_heaviside_loss:  9.071936801774427e-06\n",
      "Epoch 154: loss = 0.2863191068172455\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.0860458705574274 chamfer_loss_mesh:  0.1921491202665493\n",
      "eikonal_loss:  0.19315685331821442\n",
      "smoothed_heaviside_loss:  9.093318112718407e-06\n",
      "Epoch 155: loss = 0.4713609218597412\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.08581360802054405 chamfer_loss_mesh:  0.19124762911815196\n",
      "eikonal_loss:  0.006598477251827717\n",
      "smoothed_heaviside_loss:  9.073998626263347e-06\n",
      "Epoch 156: loss = 0.28366878628730774\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.08552217856049538 chamfer_loss_mesh:  0.19412132678553462\n",
      "eikonal_loss:  0.0076212696731090546\n",
      "smoothed_heaviside_loss:  9.081369171326514e-06\n",
      "Epoch 157: loss = 0.2872738540172577\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.0853189267218113 chamfer_loss_mesh:  0.19285645976196975\n",
      "eikonal_loss:  0.010160543024539948\n",
      "smoothed_heaviside_loss:  9.08766651264159e-06\n",
      "Epoch 158: loss = 0.28834500908851624\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.08468708954751492 chamfer_loss_mesh:  0.19011103722732514\n",
      "eikonal_loss:  0.009813617914915085\n",
      "smoothed_heaviside_loss:  9.091664651350584e-06\n",
      "Epoch 159: loss = 0.28462082147598267\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.08410429581999779 chamfer_loss_mesh:  0.18817963427864015\n",
      "eikonal_loss:  0.011371889151632786\n",
      "smoothed_heaviside_loss:  9.09934169612825e-06\n",
      "Epoch 160: loss = 0.28366491198539734\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.08407251909375191 chamfer_loss_mesh:  0.18589585670270026\n",
      "eikonal_loss:  0.012700068764388561\n",
      "smoothed_heaviside_loss:  9.097907422983553e-06\n",
      "Epoch 161: loss = 0.282677561044693\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "sites length BEFORE UPSAMPLING:  6040\n",
      "Hybrid upsampling regime\n",
      "Sampled indices: 486 out of 1804 candidates (M=604)\n",
      "Estimated eps_H:  tensor(0.8969, device='cuda:0')\n",
      "sites shape AFTER:  torch.Size([7984, 3])\n",
      "sites sdf shape AFTER:  torch.Size([7984])\n",
      "cvt_loss:  0.10312480852007866 chamfer_loss_mesh:  0.19520692876540124\n",
      "eikonal_loss:  0.0039060607086867094\n",
      "smoothed_heaviside_loss:  6.858243523311103e-06\n",
      "Epoch 162: loss = 0.3022446632385254\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.10648845694959164 chamfer_loss_mesh:  0.18571727559901774\n",
      "eikonal_loss:  0.0063699111342430115\n",
      "smoothed_heaviside_loss:  6.849527835584013e-06\n",
      "Epoch 163: loss = 0.2985824942588806\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.11082652024924755 chamfer_loss_mesh:  0.17789349658414721\n",
      "eikonal_loss:  0.004746861290186644\n",
      "smoothed_heaviside_loss:  6.795294211769942e-06\n",
      "Epoch 164: loss = 0.29347366094589233\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.11327930726110935 chamfer_loss_mesh:  0.1708763011265546\n",
      "eikonal_loss:  0.006403432693332434\n",
      "smoothed_heaviside_loss:  6.752457011316437e-06\n",
      "Epoch 165: loss = 0.2905657887458801\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.11466429568827152 chamfer_loss_mesh:  0.1671066856943071\n",
      "eikonal_loss:  0.006144221872091293\n",
      "smoothed_heaviside_loss:  6.7179134930484e-06\n",
      "Epoch 166: loss = 0.2879219055175781\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.11488704942166805 chamfer_loss_mesh:  0.16430813411716372\n",
      "eikonal_loss:  0.0033516332041472197\n",
      "smoothed_heaviside_loss:  6.701084203086793e-06\n",
      "Epoch 167: loss = 0.2825535237789154\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.11467908509075642 chamfer_loss_mesh:  0.1628119352972135\n",
      "eikonal_loss:  0.003078104229643941\n",
      "smoothed_heaviside_loss:  6.686020697088679e-06\n",
      "Epoch 168: loss = 0.28057581186294556\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.11441164650022984 chamfer_loss_mesh:  0.17270614625886083\n",
      "eikonal_loss:  0.0024634888395667076\n",
      "smoothed_heaviside_loss:  6.675476470263675e-06\n",
      "Epoch 169: loss = 0.28958794474601746\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.11432431638240814 chamfer_loss_mesh:  0.1723038440104574\n",
      "eikonal_loss:  0.007511544972658157\n",
      "smoothed_heaviside_loss:  6.664696684310911e-06\n",
      "Epoch 170: loss = 0.2941463589668274\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.11342094279825687 chamfer_loss_mesh:  0.15733035979792476\n",
      "eikonal_loss:  0.01159604825079441\n",
      "smoothed_heaviside_loss:  6.658147412963444e-06\n",
      "Epoch 171: loss = 0.2823539972305298\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.11257932521402836 chamfer_loss_mesh:  0.15301918028853834\n",
      "eikonal_loss:  0.0074030207470059395\n",
      "smoothed_heaviside_loss:  6.657494850514922e-06\n",
      "Epoch 172: loss = 0.27300819754600525\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.11129430495202541 chamfer_loss_mesh:  0.1518406643299386\n",
      "eikonal_loss:  0.029176270589232445\n",
      "smoothed_heaviside_loss:  6.663601652689977e-06\n",
      "Epoch 173: loss = 0.2923178970813751\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.11099988594651222 chamfer_loss_mesh:  0.15053617244120687\n",
      "eikonal_loss:  0.017283951863646507\n",
      "smoothed_heaviside_loss:  6.669371941825375e-06\n",
      "Epoch 174: loss = 0.27882668375968933\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.11061808094382286 chamfer_loss_mesh:  0.1499901118222624\n",
      "eikonal_loss:  0.01184591930359602\n",
      "smoothed_heaviside_loss:  6.664842203463195e-06\n",
      "Epoch 175: loss = 0.27246078848838806\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.10980353690683842 chamfer_loss_mesh:  0.1492859737481922\n",
      "eikonal_loss:  0.008883106522262096\n",
      "smoothed_heaviside_loss:  6.662595751549816e-06\n",
      "Epoch 176: loss = 0.2679792642593384\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.10961790569126606 chamfer_loss_mesh:  0.14861336967442185\n",
      "eikonal_loss:  0.006968896370381117\n",
      "smoothed_heaviside_loss:  6.657828180323122e-06\n",
      "Epoch 177: loss = 0.26520684361457825\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.10868433862924576 chamfer_loss_mesh:  0.14367338735610247\n",
      "eikonal_loss:  0.005991482641547918\n",
      "smoothed_heaviside_loss:  6.661190127488226e-06\n",
      "Epoch 178: loss = 0.25835585594177246\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.10883030481636524 chamfer_loss_mesh:  0.14291214756667614\n",
      "eikonal_loss:  0.7788465023040771\n",
      "smoothed_heaviside_loss:  6.659809969278285e-06\n",
      "Epoch 179: loss = 1.0305956602096558\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.10787471197545528 chamfer_loss_mesh:  0.14241081953514367\n",
      "eikonal_loss:  0.4057954251766205\n",
      "smoothed_heaviside_loss:  6.655843208136503e-06\n",
      "Epoch 180: loss = 0.6560876369476318\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.10735549964010715 chamfer_loss_mesh:  0.1412055571563542\n",
      "eikonal_loss:  0.377424031496048\n",
      "smoothed_heaviside_loss:  6.647338977927575e-06\n",
      "Epoch 181: loss = 0.625991702079773\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1066473126411438 chamfer_loss_mesh:  0.14186777116265148\n",
      "eikonal_loss:  0.006475025322288275\n",
      "smoothed_heaviside_loss:  6.649729130003834e-06\n",
      "Epoch 182: loss = 0.25499674677848816\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.10543761774897575 chamfer_loss_mesh:  0.14023233961779624\n",
      "eikonal_loss:  0.0045750620774924755\n",
      "smoothed_heaviside_loss:  6.6559236984176096e-06\n",
      "Epoch 183: loss = 0.2502516806125641\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.10506890714168549 chamfer_loss_mesh:  0.13788699288852513\n",
      "eikonal_loss:  0.3280251920223236\n",
      "smoothed_heaviside_loss:  6.649618626397569e-06\n",
      "Epoch 184: loss = 0.5709877014160156\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.10426678694784641 chamfer_loss_mesh:  0.13812865654472262\n",
      "eikonal_loss:  0.3365713953971863\n",
      "smoothed_heaviside_loss:  6.6561201492731925e-06\n",
      "Epoch 185: loss = 0.5789734721183777\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.10381287895143032 chamfer_loss_mesh:  0.13720084098167717\n",
      "eikonal_loss:  0.17656835913658142\n",
      "smoothed_heaviside_loss:  6.660854978690622e-06\n",
      "Epoch 186: loss = 0.4175887703895569\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.10299713350832462 chamfer_loss_mesh:  0.13622500409837812\n",
      "eikonal_loss:  0.18597106635570526\n",
      "smoothed_heaviside_loss:  6.663223302894039e-06\n",
      "Epoch 187: loss = 0.42519986629486084\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.10280738584697247 chamfer_loss_mesh:  0.13526958355214447\n",
      "eikonal_loss:  0.15921221673488617\n",
      "smoothed_heaviside_loss:  6.668762125627836e-06\n",
      "Epoch 188: loss = 0.39729586243629456\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.10246815159916878 chamfer_loss_mesh:  0.13540915097109973\n",
      "eikonal_loss:  0.10153891146183014\n",
      "smoothed_heaviside_loss:  6.678231329715345e-06\n",
      "Epoch 189: loss = 0.33942288160324097\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.10140487924218178 chamfer_loss_mesh:  0.13468872930388898\n",
      "eikonal_loss:  0.0660666823387146\n",
      "smoothed_heaviside_loss:  6.6814777710533235e-06\n",
      "Epoch 190: loss = 0.30216696858406067\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.10132633149623871 chamfer_loss_mesh:  0.1363666815450415\n",
      "eikonal_loss:  0.056726884096860886\n",
      "smoothed_heaviside_loss:  6.692866008961573e-06\n",
      "Epoch 191: loss = 0.2944265902042389\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1007456798106432 chamfer_loss_mesh:  0.1430514093954116\n",
      "eikonal_loss:  0.05659256502985954\n",
      "smoothed_heaviside_loss:  6.695465799566591e-06\n",
      "Epoch 192: loss = 0.3003963530063629\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1005076989531517 chamfer_loss_mesh:  0.14104321599006653\n",
      "eikonal_loss:  0.0470108762383461\n",
      "smoothed_heaviside_loss:  6.694658168271417e-06\n",
      "Epoch 193: loss = 0.28856849670410156\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.10029057040810585 chamfer_loss_mesh:  0.13029671390540898\n",
      "eikonal_loss:  0.03812782093882561\n",
      "smoothed_heaviside_loss:  6.696763648506021e-06\n",
      "Epoch 194: loss = 0.2687217891216278\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.09983413852751255 chamfer_loss_mesh:  0.1306131307501346\n",
      "eikonal_loss:  0.03284532576799393\n",
      "smoothed_heaviside_loss:  6.700091034872457e-06\n",
      "Epoch 195: loss = 0.26329928636550903\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.09944145567715168 chamfer_loss_mesh:  0.12925085320603102\n",
      "eikonal_loss:  0.03129800781607628\n",
      "smoothed_heaviside_loss:  6.700748144794488e-06\n",
      "Epoch 196: loss = 0.25999701023101807\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.09862398728728294 chamfer_loss_mesh:  0.12885205796919763\n",
      "eikonal_loss:  0.028648171573877335\n",
      "smoothed_heaviside_loss:  6.70397048452287e-06\n",
      "Epoch 197: loss = 0.2561309337615967\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.09777472354471684 chamfer_loss_mesh:  0.1289256615564227\n",
      "eikonal_loss:  0.02471833862364292\n",
      "smoothed_heaviside_loss:  6.702231075905729e-06\n",
      "Epoch 198: loss = 0.25142544507980347\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.0977086741477251 chamfer_loss_mesh:  0.12716290075331926\n",
      "eikonal_loss:  0.022679880261421204\n",
      "smoothed_heaviside_loss:  6.694533567497274e-06\n",
      "Epoch 199: loss = 0.24755814671516418\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "Estimated eps_H:  tensor(0.7365, device='cuda:0')\n",
      "cvt_loss:  0.09657274931669235 chamfer_loss_mesh:  0.12626494572032243\n",
      "eikonal_loss:  0.01962205395102501\n",
      "smoothed_heaviside_loss:  6.3569909798388835e-06\n",
      "Epoch 200: loss = 0.24246609210968018\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.09600133635103703 chamfer_loss_mesh:  0.1253750524483621\n",
      "eikonal_loss:  0.018910903483629227\n",
      "smoothed_heaviside_loss:  6.359889994200785e-06\n",
      "Epoch 201: loss = 0.24029365181922913\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.09567471221089363 chamfer_loss_mesh:  0.12564283679239452\n",
      "eikonal_loss:  0.016933267936110497\n",
      "smoothed_heaviside_loss:  6.359848612191854e-06\n",
      "Epoch 202: loss = 0.23825716972351074\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.0962787214666605 chamfer_loss_mesh:  0.13032846618443727\n",
      "eikonal_loss:  0.022219665348529816\n",
      "smoothed_heaviside_loss:  6.362162366713164e-06\n",
      "Epoch 203: loss = 0.24883320927619934\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.09576147422194481 chamfer_loss_mesh:  0.12936026905663311\n",
      "eikonal_loss:  0.01680700108408928\n",
      "smoothed_heaviside_loss:  6.367954028974054e-06\n",
      "Epoch 204: loss = 0.2419351190328598\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.09514134377241135 chamfer_loss_mesh:  0.1311088853981346\n",
      "eikonal_loss:  0.016558000817894936\n",
      "smoothed_heaviside_loss:  6.368130470946198e-06\n",
      "Epoch 205: loss = 0.24281460046768188\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.09488968178629875 chamfer_loss_mesh:  0.13014972500968724\n",
      "eikonal_loss:  0.04376617819070816\n",
      "smoothed_heaviside_loss:  6.370587925630389e-06\n",
      "Epoch 206: loss = 0.2688119411468506\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.0949005875736475 chamfer_loss_mesh:  0.12171345588285476\n",
      "eikonal_loss:  0.03644880652427673\n",
      "smoothed_heaviside_loss:  6.378389571182197e-06\n",
      "Epoch 207: loss = 0.2530692219734192\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.09463506750762463 chamfer_loss_mesh:  0.12217980111017823\n",
      "eikonal_loss:  0.01817583665251732\n",
      "smoothed_heaviside_loss:  6.384030257322593e-06\n",
      "Epoch 208: loss = 0.23499709367752075\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.09434795007109642 chamfer_loss_mesh:  0.13426702935248613\n",
      "eikonal_loss:  0.014480018988251686\n",
      "smoothed_heaviside_loss:  6.3885208874125965e-06\n",
      "Epoch 209: loss = 0.24310138821601868\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.09334421716630459 chamfer_loss_mesh:  0.12055945990141481\n",
      "eikonal_loss:  0.012332379817962646\n",
      "smoothed_heaviside_loss:  6.394369847839698e-06\n",
      "Epoch 210: loss = 0.22624245285987854\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.09318197146058083 chamfer_loss_mesh:  0.12082429020665586\n",
      "eikonal_loss:  0.010748743079602718\n",
      "smoothed_heaviside_loss:  6.394689989974722e-06\n",
      "Epoch 211: loss = 0.22476139664649963\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.0922053400427103 chamfer_loss_mesh:  0.12090545351384208\n",
      "eikonal_loss:  0.009879589080810547\n",
      "smoothed_heaviside_loss:  6.40491271042265e-06\n",
      "Epoch 212: loss = 0.222996786236763\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.09169787168502808 chamfer_loss_mesh:  0.12248934945091605\n",
      "eikonal_loss:  0.00876724161207676\n",
      "smoothed_heaviside_loss:  6.40860616840655e-06\n",
      "Epoch 213: loss = 0.22296087443828583\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.09172682650387287 chamfer_loss_mesh:  0.12236762268003076\n",
      "eikonal_loss:  0.0061044348403811455\n",
      "smoothed_heaviside_loss:  6.41176620774786e-06\n",
      "Epoch 214: loss = 0.22020529210567474\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.09114600718021393 chamfer_loss_mesh:  0.12195737508591264\n",
      "eikonal_loss:  0.008401365950703621\n",
      "smoothed_heaviside_loss:  6.412609309336403e-06\n",
      "Epoch 215: loss = 0.22151115536689758\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.09080184623599052 chamfer_loss_mesh:  0.12195592717034742\n",
      "eikonal_loss:  0.005035647191107273\n",
      "smoothed_heaviside_loss:  6.414960807887837e-06\n",
      "Epoch 216: loss = 0.2177998274564743\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.09007261134684086 chamfer_loss_mesh:  0.11946898302994668\n",
      "eikonal_loss:  0.005081204231828451\n",
      "smoothed_heaviside_loss:  6.4213086261588614e-06\n",
      "Epoch 217: loss = 0.21462921798229218\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.08974572643637657 chamfer_loss_mesh:  0.11908454325748608\n",
      "eikonal_loss:  0.004961869679391384\n",
      "smoothed_heaviside_loss:  6.42434997644159e-06\n",
      "Epoch 218: loss = 0.21379856765270233\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.0893399678170681 chamfer_loss_mesh:  0.11944670404773206\n",
      "eikonal_loss:  0.005921360105276108\n",
      "smoothed_heaviside_loss:  6.427875177905662e-06\n",
      "Epoch 219: loss = 0.21471445262432098\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.08942604064941406 chamfer_loss_mesh:  0.11939331307075918\n",
      "eikonal_loss:  0.005896564107388258\n",
      "smoothed_heaviside_loss:  6.431449037336279e-06\n",
      "Epoch 220: loss = 0.21472235023975372\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.08872922509908676 chamfer_loss_mesh:  0.12138098099967465\n",
      "eikonal_loss:  0.006439171731472015\n",
      "smoothed_heaviside_loss:  6.438089712901274e-06\n",
      "Epoch 221: loss = 0.21655581891536713\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.0883920956403017 chamfer_loss_mesh:  0.12135652650613338\n",
      "eikonal_loss:  0.007412382867187262\n",
      "smoothed_heaviside_loss:  6.435283466998953e-06\n",
      "Epoch 222: loss = 0.2171674370765686\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.0878631230443716 chamfer_loss_mesh:  0.11827667913166806\n",
      "eikonal_loss:  0.007995235733687878\n",
      "smoothed_heaviside_loss:  6.4409505284857005e-06\n",
      "Epoch 223: loss = 0.21414147317409515\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.0877259112894535 chamfer_loss_mesh:  0.11850303417304531\n",
      "eikonal_loss:  0.008976208977401257\n",
      "smoothed_heaviside_loss:  6.442429821618134e-06\n",
      "Epoch 224: loss = 0.21521160006523132\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.08737629279494286 chamfer_loss_mesh:  0.1197930469061248\n",
      "eikonal_loss:  0.012029825709760189\n",
      "smoothed_heaviside_loss:  6.45619138595066e-06\n",
      "Epoch 225: loss = 0.21920563280582428\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.08721737191081047 chamfer_loss_mesh:  0.11917142546735704\n",
      "eikonal_loss:  0.014153200201690197\n",
      "smoothed_heaviside_loss:  6.460897566284984e-06\n",
      "Epoch 226: loss = 0.22054846584796906\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.08648297749459743 chamfer_loss_mesh:  0.12079920270480216\n",
      "eikonal_loss:  0.005569108296185732\n",
      "smoothed_heaviside_loss:  6.4710025071690325e-06\n",
      "Epoch 227: loss = 0.21285776793956757\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.08638295345008373 chamfer_loss_mesh:  0.11759328481275588\n",
      "eikonal_loss:  0.0165728572756052\n",
      "smoothed_heaviside_loss:  6.477628176071448e-06\n",
      "Epoch 228: loss = 0.22055557370185852\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.08622612804174423 chamfer_loss_mesh:  0.11738740431610495\n",
      "eikonal_loss:  0.009698460809886456\n",
      "smoothed_heaviside_loss:  6.4812279561010655e-06\n",
      "Epoch 229: loss = 0.21331848204135895\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.08583119139075279 chamfer_loss_mesh:  0.11710553371813148\n",
      "eikonal_loss:  0.00906770583242178\n",
      "smoothed_heaviside_loss:  6.485965514002601e-06\n",
      "Epoch 230: loss = 0.2120109349489212\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.08532540872693062 chamfer_loss_mesh:  0.1164362984127365\n",
      "eikonal_loss:  0.00919960718601942\n",
      "smoothed_heaviside_loss:  6.4940768425003625e-06\n",
      "Epoch 231: loss = 0.2109677940607071\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.08511741645634174 chamfer_loss_mesh:  0.11641687160590664\n",
      "eikonal_loss:  0.007454357575625181\n",
      "smoothed_heaviside_loss:  6.495406069007004e-06\n",
      "Epoch 232: loss = 0.20899513363838196\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.08458330295979977 chamfer_loss_mesh:  0.11567360343178734\n",
      "eikonal_loss:  0.0070222849026322365\n",
      "smoothed_heaviside_loss:  6.503017630166141e-06\n",
      "Epoch 233: loss = 0.20728570222854614\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.08432572707533836 chamfer_loss_mesh:  0.11536192323546857\n",
      "eikonal_loss:  0.006576025392860174\n",
      "smoothed_heaviside_loss:  6.5093213379441295e-06\n",
      "Epoch 234: loss = 0.20627018809318542\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.08426175452768803 chamfer_loss_mesh:  0.11506637383718044\n",
      "eikonal_loss:  0.004038088954985142\n",
      "smoothed_heaviside_loss:  6.516475878015626e-06\n",
      "Epoch 235: loss = 0.20337273180484772\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.08371882140636444 chamfer_loss_mesh:  0.11532328790053725\n",
      "eikonal_loss:  0.005248225759714842\n",
      "smoothed_heaviside_loss:  6.517931524285814e-06\n",
      "Epoch 236: loss = 0.20429685711860657\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.08335644379258156 chamfer_loss_mesh:  0.11472191545180976\n",
      "eikonal_loss:  0.003957014996558428\n",
      "smoothed_heaviside_loss:  6.522229796246393e-06\n",
      "Epoch 237: loss = 0.202041894197464\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.08288935758173466 chamfer_loss_mesh:  0.11435984197305515\n",
      "eikonal_loss:  0.003933066967874765\n",
      "smoothed_heaviside_loss:  6.523354386445135e-06\n",
      "Epoch 238: loss = 0.20118878781795502\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.0828349869698286 chamfer_loss_mesh:  0.11418573558330536\n",
      "eikonal_loss:  0.0038717021234333515\n",
      "smoothed_heaviside_loss:  6.528876383526949e-06\n",
      "Epoch 239: loss = 0.20089896023273468\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.08221822790801525 chamfer_loss_mesh:  0.11338527838233858\n",
      "eikonal_loss:  0.0038356073200702667\n",
      "smoothed_heaviside_loss:  6.528553058160469e-06\n",
      "Epoch 240: loss = 0.19944563508033752\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.08171635679900646 chamfer_loss_mesh:  0.11355639435350895\n",
      "eikonal_loss:  0.0038223587907850742\n",
      "smoothed_heaviside_loss:  6.5305212046951056e-06\n",
      "Epoch 241: loss = 0.19910162687301636\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "sites length BEFORE UPSAMPLING:  7984\n",
      "Hybrid upsampling regime\n",
      "Sampled indices: 665 out of 3067 candidates (M=798)\n",
      "Estimated eps_H:  tensor(0.7376, device='cuda:0')\n",
      "sites shape AFTER:  torch.Size([10644, 3])\n",
      "sites sdf shape AFTER:  torch.Size([10644])\n",
      "cvt_loss:  0.09321784600615501 chamfer_loss_mesh:  0.1195512741105631\n",
      "eikonal_loss:  0.002940388396382332\n",
      "smoothed_heaviside_loss:  4.885976977675455e-06\n",
      "Epoch 242: loss = 0.21571439504623413\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.09629055857658386 chamfer_loss_mesh:  0.11364763486199081\n",
      "eikonal_loss:  0.00204540160484612\n",
      "smoothed_heaviside_loss:  4.870079919783166e-06\n",
      "Epoch 243: loss = 0.21198846399784088\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.09983358904719353 chamfer_loss_mesh:  0.10867205128306523\n",
      "eikonal_loss:  0.03630898520350456\n",
      "smoothed_heaviside_loss:  4.834498213313054e-06\n",
      "Epoch 244: loss = 0.24481946229934692\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.10212148539721966 chamfer_loss_mesh:  0.10769319487735629\n",
      "eikonal_loss:  0.027485385537147522\n",
      "smoothed_heaviside_loss:  4.804241598321823e-06\n",
      "Epoch 245: loss = 0.23730486631393433\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.10174183174967766 chamfer_loss_mesh:  0.10930928692687303\n",
      "eikonal_loss:  0.3935950696468353\n",
      "smoothed_heaviside_loss:  4.784546490554931e-06\n",
      "Epoch 246: loss = 0.6046509742736816\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.10160754434764385 chamfer_loss_mesh:  0.1068673373083584\n",
      "eikonal_loss:  0.01754087023437023\n",
      "smoothed_heaviside_loss:  4.770389750774484e-06\n",
      "Epoch 247: loss = 0.22602051496505737\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.10146023705601692 chamfer_loss_mesh:  0.10414652933832258\n",
      "eikonal_loss:  0.16982170939445496\n",
      "smoothed_heaviside_loss:  4.765859102917602e-06\n",
      "Epoch 248: loss = 0.3754332363605499\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.10003747418522835 chamfer_loss_mesh:  0.10021797788795084\n",
      "eikonal_loss:  0.09987889975309372\n",
      "smoothed_heaviside_loss:  4.764215645991499e-06\n",
      "Epoch 249: loss = 0.3001391291618347\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.09923098608851433 chamfer_loss_mesh:  0.10530240251682699\n",
      "eikonal_loss:  0.07094033807516098\n",
      "smoothed_heaviside_loss:  4.761026048072381e-06\n",
      "Epoch 250: loss = 0.2754784822463989\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.09849518537521362 chamfer_loss_mesh:  0.10420910257380456\n",
      "eikonal_loss:  0.04426067695021629\n",
      "smoothed_heaviside_loss:  4.752634140459122e-06\n",
      "Epoch 251: loss = 0.24696971476078033\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.09690104052424431 chamfer_loss_mesh:  0.10696456592995673\n",
      "eikonal_loss:  0.03148120269179344\n",
      "smoothed_heaviside_loss:  4.75320257464773e-06\n",
      "Epoch 252: loss = 0.2353515774011612\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.09636924602091312 chamfer_loss_mesh:  0.09627835243009031\n",
      "eikonal_loss:  0.023705875501036644\n",
      "smoothed_heaviside_loss:  4.751853794005001e-06\n",
      "Epoch 253: loss = 0.2163582295179367\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.0958024151623249 chamfer_loss_mesh:  0.09616936586098745\n",
      "eikonal_loss:  0.01834278367459774\n",
      "smoothed_heaviside_loss:  4.755252575705526e-06\n",
      "Epoch 254: loss = 0.21031931042671204\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.09466495364904404 chamfer_loss_mesh:  0.0941926846280694\n",
      "eikonal_loss:  0.021211668848991394\n",
      "smoothed_heaviside_loss:  4.754260771733243e-06\n",
      "Epoch 255: loss = 0.2100740671157837\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.09390175342559814 chamfer_loss_mesh:  0.09514461271464825\n",
      "eikonal_loss:  0.017971446737647057\n",
      "smoothed_heaviside_loss:  4.751379492518026e-06\n",
      "Epoch 256: loss = 0.207022562623024\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.09339365176856518 chamfer_loss_mesh:  0.09276881610276178\n",
      "eikonal_loss:  0.04650551825761795\n",
      "smoothed_heaviside_loss:  4.754582732857671e-06\n",
      "Epoch 257: loss = 0.23267275094985962\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.09197003208100796 chamfer_loss_mesh:  0.09148144454229623\n",
      "eikonal_loss:  0.0380992665886879\n",
      "smoothed_heaviside_loss:  4.755650024890201e-06\n",
      "Epoch 258: loss = 0.22155550122261047\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.09149775840342045 chamfer_loss_mesh:  0.09094564302358776\n",
      "eikonal_loss:  0.042560119181871414\n",
      "smoothed_heaviside_loss:  4.7594817260687705e-06\n",
      "Epoch 259: loss = 0.2250082939863205\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.09031055495142937 chamfer_loss_mesh:  0.09207653056364506\n",
      "eikonal_loss:  0.014428791590034962\n",
      "smoothed_heaviside_loss:  4.762535809277324e-06\n",
      "Epoch 260: loss = 0.19682063162326813\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.08972145617008209 chamfer_loss_mesh:  0.09262408275390044\n",
      "eikonal_loss:  0.05009768530726433\n",
      "smoothed_heaviside_loss:  4.780634299095254e-06\n",
      "Epoch 261: loss = 0.232448011636734\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.08881174959242344 chamfer_loss_mesh:  0.09025725739775226\n",
      "eikonal_loss:  0.42810073494911194\n",
      "smoothed_heaviside_loss:  4.788038040715037e-06\n",
      "Epoch 262: loss = 0.6071745157241821\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.08814788423478603 chamfer_loss_mesh:  0.09053017129190266\n",
      "eikonal_loss:  0.011209864169359207\n",
      "smoothed_heaviside_loss:  4.776813966600457e-06\n",
      "Epoch 263: loss = 0.1898927092552185\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.08727705106139183 chamfer_loss_mesh:  0.08995505049824715\n",
      "eikonal_loss:  0.012055435217916965\n",
      "smoothed_heaviside_loss:  4.782973974215565e-06\n",
      "Epoch 264: loss = 0.1892923265695572\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.08675548247992992 chamfer_loss_mesh:  0.08966209134086967\n",
      "eikonal_loss:  0.011216995306313038\n",
      "smoothed_heaviside_loss:  4.784764769283356e-06\n",
      "Epoch 265: loss = 0.18763935565948486\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.08601032197475433 chamfer_loss_mesh:  0.08892416371963918\n",
      "eikonal_loss:  0.012444226071238518\n",
      "smoothed_heaviside_loss:  4.785374130733544e-06\n",
      "Epoch 266: loss = 0.1873834878206253\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.08536184206604958 chamfer_loss_mesh:  0.08824904216453433\n",
      "eikonal_loss:  0.010578176937997341\n",
      "smoothed_heaviside_loss:  4.7863336476439144e-06\n",
      "Epoch 267: loss = 0.18419384956359863\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.08483825251460075 chamfer_loss_mesh:  0.08785005775280297\n",
      "eikonal_loss:  0.009030811488628387\n",
      "smoothed_heaviside_loss:  4.788554178958293e-06\n",
      "Epoch 268: loss = 0.18172390758991241\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.08366573601961136 chamfer_loss_mesh:  0.08732909191166982\n",
      "eikonal_loss:  0.041883453726768494\n",
      "smoothed_heaviside_loss:  4.791055289388169e-06\n",
      "Epoch 269: loss = 0.21288305521011353\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.08354871533811092 chamfer_loss_mesh:  0.08685403008712456\n",
      "eikonal_loss:  0.004206111654639244\n",
      "smoothed_heaviside_loss:  4.7973403525247704e-06\n",
      "Epoch 270: loss = 0.17461365461349487\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.08328498341143131 chamfer_loss_mesh:  0.0859609863255173\n",
      "eikonal_loss:  0.004001576453447342\n",
      "smoothed_heaviside_loss:  4.799313501280267e-06\n",
      "Epoch 271: loss = 0.17325232923030853\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.08271541446447372 chamfer_loss_mesh:  0.08539318514522165\n",
      "eikonal_loss:  0.0035667673218995333\n",
      "smoothed_heaviside_loss:  4.8032557060651015e-06\n",
      "Epoch 272: loss = 0.17168016731739044\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.08177545852959156 chamfer_loss_mesh:  0.08529893239028752\n",
      "eikonal_loss:  0.0033812958281487226\n",
      "smoothed_heaviside_loss:  4.806134711543564e-06\n",
      "Epoch 273: loss = 0.17046047747135162\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.08150415495038033 chamfer_loss_mesh:  0.08504135621478781\n",
      "eikonal_loss:  0.003324028104543686\n",
      "smoothed_heaviside_loss:  4.810558948520338e-06\n",
      "Epoch 274: loss = 0.16987435519695282\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.08059459738433361 chamfer_loss_mesh:  0.08377337508136407\n",
      "eikonal_loss:  0.0031397968996316195\n",
      "smoothed_heaviside_loss:  4.81163215226843e-06\n",
      "Epoch 275: loss = 0.16751258075237274\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.0804388802498579 chamfer_loss_mesh:  0.08392363815801218\n",
      "eikonal_loss:  0.00301498849876225\n",
      "smoothed_heaviside_loss:  4.816432465304388e-06\n",
      "Epoch 276: loss = 0.16738232970237732\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.08016439154744148 chamfer_loss_mesh:  0.08372026059078053\n",
      "eikonal_loss:  0.0028419657610356808\n",
      "smoothed_heaviside_loss:  4.820874437427847e-06\n",
      "Epoch 277: loss = 0.16673143208026886\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.07925826124846935 chamfer_loss_mesh:  0.08314988372148946\n",
      "eikonal_loss:  0.002811258193105459\n",
      "smoothed_heaviside_loss:  4.825630639970768e-06\n",
      "Epoch 278: loss = 0.16522422432899475\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.07863709703087807 chamfer_loss_mesh:  0.08267813245765865\n",
      "eikonal_loss:  0.002740870462730527\n",
      "smoothed_heaviside_loss:  4.832812919630669e-06\n",
      "Epoch 279: loss = 0.16406093537807465\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.07800125982612371 chamfer_loss_mesh:  0.08233823609771207\n",
      "eikonal_loss:  0.002725503407418728\n",
      "smoothed_heaviside_loss:  4.833344519283855e-06\n",
      "Epoch 280: loss = 0.16306984424591064\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.07774473633617163 chamfer_loss_mesh:  0.08192074892576784\n",
      "eikonal_loss:  0.004009217023849487\n",
      "smoothed_heaviside_loss:  4.8331116886402015e-06\n",
      "Epoch 281: loss = 0.16367954015731812\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.07721396163105965 chamfer_loss_mesh:  0.08735489245736971\n",
      "eikonal_loss:  0.002704391023144126\n",
      "smoothed_heaviside_loss:  4.839060693484498e-06\n",
      "Epoch 282: loss = 0.16727806627750397\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.07650142535567284 chamfer_loss_mesh:  0.0815275707282126\n",
      "eikonal_loss:  0.00313672237098217\n",
      "smoothed_heaviside_loss:  4.8415868150186725e-06\n",
      "Epoch 283: loss = 0.16117055714130402\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.07617995142936707 chamfer_loss_mesh:  0.08132703078445047\n",
      "eikonal_loss:  0.002876047510653734\n",
      "smoothed_heaviside_loss:  4.849329798162216e-06\n",
      "Epoch 284: loss = 0.16038787364959717\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.07557024247944355 chamfer_loss_mesh:  0.08090274059213698\n",
      "eikonal_loss:  0.0026487584691494703\n",
      "smoothed_heaviside_loss:  4.8477591008122545e-06\n",
      "Epoch 285: loss = 0.15912657976150513\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.07525647524744272 chamfer_loss_mesh:  0.08044087735470384\n",
      "eikonal_loss:  0.002694172551855445\n",
      "smoothed_heaviside_loss:  4.8531542233831715e-06\n",
      "Epoch 286: loss = 0.158396378159523\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.07493359968066216 chamfer_loss_mesh:  0.08054135832935572\n",
      "eikonal_loss:  0.0026843452360481024\n",
      "smoothed_heaviside_loss:  4.859757609665394e-06\n",
      "Epoch 287: loss = 0.15816417336463928\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.07451961748301983 chamfer_loss_mesh:  0.08050525502767414\n",
      "eikonal_loss:  0.0026428268756717443\n",
      "smoothed_heaviside_loss:  4.864843049290357e-06\n",
      "Epoch 288: loss = 0.15767256915569305\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.07397331763058901 chamfer_loss_mesh:  0.08012535545276478\n",
      "eikonal_loss:  0.0025794468820095062\n",
      "smoothed_heaviside_loss:  4.870114480581833e-06\n",
      "Epoch 289: loss = 0.15668299794197083\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.07395688910037279 chamfer_loss_mesh:  0.0795861633378081\n",
      "eikonal_loss:  0.002541049150750041\n",
      "smoothed_heaviside_loss:  4.872919362242101e-06\n",
      "Epoch 290: loss = 0.15608897805213928\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.07370466832071543 chamfer_loss_mesh:  0.08690588583704084\n",
      "eikonal_loss:  0.0025121900252997875\n",
      "smoothed_heaviside_loss:  4.8692754717194475e-06\n",
      "Epoch 291: loss = 0.1631276160478592\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.07349907420575619 chamfer_loss_mesh:  0.07893890142440796\n",
      "eikonal_loss:  0.00017979710537474602\n",
      "smoothed_heaviside_loss:  4.868797987001017e-06\n",
      "Epoch 292: loss = 0.15262265503406525\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.07286179345101118 chamfer_loss_mesh:  0.0791053898865357\n",
      "eikonal_loss:  0.00018397546955384314\n",
      "smoothed_heaviside_loss:  4.873111265624175e-06\n",
      "Epoch 293: loss = 0.1521560251712799\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.07213599979877472 chamfer_loss_mesh:  0.07868128886912018\n",
      "eikonal_loss:  0.0002312799042556435\n",
      "smoothed_heaviside_loss:  4.878349045611685e-06\n",
      "Epoch 294: loss = 0.15105344355106354\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.0719000305980444 chamfer_loss_mesh:  0.0786654491093941\n",
      "eikonal_loss:  0.00022817325952928513\n",
      "smoothed_heaviside_loss:  4.8799456635606475e-06\n",
      "Epoch 295: loss = 0.15079852938652039\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.0715191476047039 chamfer_loss_mesh:  0.07857683522161096\n",
      "eikonal_loss:  0.00023398113262373954\n",
      "smoothed_heaviside_loss:  4.8776710173115134e-06\n",
      "Epoch 296: loss = 0.15033484995365143\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.07108981721103191 chamfer_loss_mesh:  0.07825843204045668\n",
      "eikonal_loss:  0.0003845197206828743\n",
      "smoothed_heaviside_loss:  4.8822284952620976e-06\n",
      "Epoch 297: loss = 0.1497376561164856\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.07031422574073076 chamfer_loss_mesh:  0.08231306856032461\n",
      "eikonal_loss:  0.0003600850177463144\n",
      "smoothed_heaviside_loss:  4.887846444034949e-06\n",
      "Epoch 298: loss = 0.15299226343631744\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.06987768691033125 chamfer_loss_mesh:  0.08343485387740657\n",
      "eikonal_loss:  0.0004177286464255303\n",
      "smoothed_heaviside_loss:  4.889521278528264e-06\n",
      "Epoch 299: loss = 0.15373514592647552\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "Estimated eps_H:  tensor(0.6011, device='cuda:0')\n",
      "cvt_loss:  0.07003377191722393 chamfer_loss_mesh:  0.08027725561987609\n",
      "eikonal_loss:  0.0003804871521424502\n",
      "smoothed_heaviside_loss:  4.842310772801284e-06\n",
      "Epoch 300: loss = 0.15069635212421417\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.06937492173165083 chamfer_loss_mesh:  0.07925337558845058\n",
      "eikonal_loss:  0.0003699337539728731\n",
      "smoothed_heaviside_loss:  4.845933744945796e-06\n",
      "Epoch 301: loss = 0.1490030735731125\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.06915788166224957 chamfer_loss_mesh:  0.07897381874499843\n",
      "eikonal_loss:  0.0002127056213794276\n",
      "smoothed_heaviside_loss:  4.851598532695789e-06\n",
      "Epoch 302: loss = 0.14834925532341003\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.0687617203220725 chamfer_loss_mesh:  0.07837176963221282\n",
      "eikonal_loss:  0.00020351691637188196\n",
      "smoothed_heaviside_loss:  4.855151928495616e-06\n",
      "Epoch 303: loss = 0.14734187722206116\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.06816724315285683 chamfer_loss_mesh:  0.07775583071634173\n",
      "eikonal_loss:  0.00022680408437736332\n",
      "smoothed_heaviside_loss:  4.856588930124417e-06\n",
      "Epoch 304: loss = 0.1461547315120697\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.06804898846894503 chamfer_loss_mesh:  0.07773646211717278\n",
      "eikonal_loss:  0.0001890063431346789\n",
      "smoothed_heaviside_loss:  4.854927738051629e-06\n",
      "Epoch 305: loss = 0.14597931504249573\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.06778967566788197 chamfer_loss_mesh:  0.07831183756934479\n",
      "eikonal_loss:  0.00018654504674486816\n",
      "smoothed_heaviside_loss:  4.857470685237786e-06\n",
      "Epoch 306: loss = 0.14629290997982025\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.0673703383654356 chamfer_loss_mesh:  0.0761546689318493\n",
      "eikonal_loss:  0.0003271607856731862\n",
      "smoothed_heaviside_loss:  4.862677997152787e-06\n",
      "Epoch 307: loss = 0.14385703206062317\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.06675512529909611 chamfer_loss_mesh:  0.07497312617488205\n",
      "eikonal_loss:  0.000362605118425563\n",
      "smoothed_heaviside_loss:  4.865685241384199e-06\n",
      "Epoch 308: loss = 0.14209572970867157\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.06655653472989798 chamfer_loss_mesh:  0.07498835475416854\n",
      "eikonal_loss:  0.0032851025462150574\n",
      "smoothed_heaviside_loss:  4.87216993860784e-06\n",
      "Epoch 309: loss = 0.14483486115932465\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.06635637488216162 chamfer_loss_mesh:  0.07472068682545796\n",
      "eikonal_loss:  0.0002671982510946691\n",
      "smoothed_heaviside_loss:  4.875809736404335e-06\n",
      "Epoch 310: loss = 0.14134915173053741\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.06585079245269299 chamfer_loss_mesh:  0.07445058145094663\n",
      "eikonal_loss:  0.00021596105943899602\n",
      "smoothed_heaviside_loss:  4.8831220738065895e-06\n",
      "Epoch 311: loss = 0.14052222669124603\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.0657598627731204 chamfer_loss_mesh:  0.07403804193018004\n",
      "eikonal_loss:  0.0002321696374565363\n",
      "smoothed_heaviside_loss:  4.88854993818677e-06\n",
      "Epoch 312: loss = 0.14003495872020721\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.06525601260364056 chamfer_loss_mesh:  0.0779361289460212\n",
      "eikonal_loss:  0.00010279699927195907\n",
      "smoothed_heaviside_loss:  4.895455731457332e-06\n",
      "Epoch 313: loss = 0.14329983294010162\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.06485136691480875 chamfer_loss_mesh:  0.07797740545356646\n",
      "eikonal_loss:  9.448290802538395e-05\n",
      "smoothed_heaviside_loss:  4.901973625237588e-06\n",
      "Epoch 314: loss = 0.14292815327644348\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.06441743578761816 chamfer_loss_mesh:  0.07396508590318263\n",
      "eikonal_loss:  0.00012124127533752471\n",
      "smoothed_heaviside_loss:  4.9045224841393065e-06\n",
      "Epoch 315: loss = 0.13850867748260498\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.06386781111359596 chamfer_loss_mesh:  0.07305950566660613\n",
      "eikonal_loss:  9.944538032868877e-05\n",
      "smoothed_heaviside_loss:  4.910759344056714e-06\n",
      "Epoch 316: loss = 0.1370316594839096\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.0634731026366353 chamfer_loss_mesh:  0.0728623999748379\n",
      "eikonal_loss:  0.00012025570322293788\n",
      "smoothed_heaviside_loss:  4.91638957100804e-06\n",
      "Epoch 317: loss = 0.13646067678928375\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.06330717355012894 chamfer_loss_mesh:  0.07411439582938328\n",
      "eikonal_loss:  9.538773156236857e-05\n",
      "smoothed_heaviside_loss:  4.916886155115208e-06\n",
      "Epoch 318: loss = 0.1375218778848648\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.0628856010735035 chamfer_loss_mesh:  0.073999137384817\n",
      "eikonal_loss:  0.0001040244969772175\n",
      "smoothed_heaviside_loss:  4.918471859127749e-06\n",
      "Epoch 319: loss = 0.1369936764240265\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.06265155039727688 chamfer_loss_mesh:  0.07262859435286373\n",
      "eikonal_loss:  8.552449435228482e-05\n",
      "smoothed_heaviside_loss:  4.921704658045201e-06\n",
      "Epoch 320: loss = 0.13537059724330902\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.06242860574275255 chamfer_loss_mesh:  0.0743533528293483\n",
      "eikonal_loss:  0.004170404747128487\n",
      "smoothed_heaviside_loss:  4.929897841066122e-06\n",
      "Epoch 321: loss = 0.1409572958946228\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "sites length BEFORE UPSAMPLING:  10644\n",
      "Hybrid upsampling regime\n",
      "Sampled indices: 898 out of 4639 candidates (M=1064)\n",
      "Estimated eps_H:  tensor(0.6029, device='cuda:0')\n",
      "sites shape AFTER:  torch.Size([14236, 3])\n",
      "sites sdf shape AFTER:  torch.Size([14236])\n",
      "cvt_loss:  0.07271533366292715 chamfer_loss_mesh:  0.08443984552286565\n",
      "eikonal_loss:  0.00017583319277036935\n",
      "smoothed_heaviside_loss:  3.698981117850053e-06\n",
      "Epoch 322: loss = 0.15733471512794495\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.07573924027383327 chamfer_loss_mesh:  0.07579525117762387\n",
      "eikonal_loss:  0.0007360542076639831\n",
      "smoothed_heaviside_loss:  3.6797650864173193e-06\n",
      "Epoch 323: loss = 0.1522742360830307\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.07806789595633745 chamfer_loss_mesh:  0.0729728490114212\n",
      "eikonal_loss:  0.017648963257670403\n",
      "smoothed_heaviside_loss:  3.652051645985921e-06\n",
      "Epoch 324: loss = 0.16869336366653442\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.07875095121562481 chamfer_loss_mesh:  0.07172003097366542\n",
      "eikonal_loss:  0.008277532644569874\n",
      "smoothed_heaviside_loss:  3.6284102407080354e-06\n",
      "Epoch 325: loss = 0.15875214338302612\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.07894441485404968 chamfer_loss_mesh:  0.07043632649583742\n",
      "eikonal_loss:  0.01573885791003704\n",
      "smoothed_heaviside_loss:  3.618481514422456e-06\n",
      "Epoch 326: loss = 0.16512322425842285\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.07814431563019753 chamfer_loss_mesh:  0.06907199713168666\n",
      "eikonal_loss:  0.01794121228158474\n",
      "smoothed_heaviside_loss:  3.616359890656895e-06\n",
      "Epoch 327: loss = 0.1651611477136612\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.07717294618487358 chamfer_loss_mesh:  0.06771153857698664\n",
      "eikonal_loss:  0.018496574833989143\n",
      "smoothed_heaviside_loss:  3.6104545415582834e-06\n",
      "Epoch 328: loss = 0.16338467597961426\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.07577875163406134 chamfer_loss_mesh:  0.06960274185985327\n",
      "eikonal_loss:  0.022678034380078316\n",
      "smoothed_heaviside_loss:  3.6114122394792503e-06\n",
      "Epoch 329: loss = 0.16806313395500183\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.07455924525856972 chamfer_loss_mesh:  0.06834886153228581\n",
      "eikonal_loss:  0.1068742647767067\n",
      "smoothed_heaviside_loss:  3.61238926416263e-06\n",
      "Epoch 330: loss = 0.24978597462177277\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.07387636695057154 chamfer_loss_mesh:  0.06493893306469545\n",
      "eikonal_loss:  0.10647513717412949\n",
      "smoothed_heaviside_loss:  3.607997541621444e-06\n",
      "Epoch 331: loss = 0.24529403448104858\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.07259787060320377 chamfer_loss_mesh:  0.06937202124390751\n",
      "eikonal_loss:  0.01418494712561369\n",
      "smoothed_heaviside_loss:  3.6067174278286984e-06\n",
      "Epoch 332: loss = 0.156158447265625\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.07128727156668901 chamfer_loss_mesh:  0.06526603829115629\n",
      "eikonal_loss:  0.012006350792944431\n",
      "smoothed_heaviside_loss:  3.603671530072461e-06\n",
      "Epoch 333: loss = 0.14856326580047607\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.07051785010844469 chamfer_loss_mesh:  0.0634276875643991\n",
      "eikonal_loss:  0.010386372916400433\n",
      "smoothed_heaviside_loss:  3.6028006888955133e-06\n",
      "Epoch 334: loss = 0.14433550834655762\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.06988311186432838 chamfer_loss_mesh:  0.06223060336196795\n",
      "eikonal_loss:  0.009529120288789272\n",
      "smoothed_heaviside_loss:  3.6061599075765116e-06\n",
      "Epoch 335: loss = 0.14164642989635468\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.06900531705468893 chamfer_loss_mesh:  0.06254732579691336\n",
      "eikonal_loss:  0.008141227066516876\n",
      "smoothed_heaviside_loss:  3.6069002362637548e-06\n",
      "Epoch 336: loss = 0.13969747722148895\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.06841765251010656 chamfer_loss_mesh:  0.06257976201595739\n",
      "eikonal_loss:  0.0025614758487790823\n",
      "smoothed_heaviside_loss:  3.6131693832430756e-06\n",
      "Epoch 337: loss = 0.13356250524520874\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.06769132800400257 chamfer_loss_mesh:  0.06622704677283764\n",
      "eikonal_loss:  0.0024145410861819983\n",
      "smoothed_heaviside_loss:  3.6154881399852457e-06\n",
      "Epoch 338: loss = 0.1363365352153778\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.06709077395498753 chamfer_loss_mesh:  0.06022367597324774\n",
      "eikonal_loss:  0.002370554720982909\n",
      "smoothed_heaviside_loss:  3.617082711571129e-06\n",
      "Epoch 339: loss = 0.12968862056732178\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.06594992242753506 chamfer_loss_mesh:  0.06413926894310862\n",
      "eikonal_loss:  0.02170608565211296\n",
      "smoothed_heaviside_loss:  3.6217516026226804e-06\n",
      "Epoch 340: loss = 0.15179890394210815\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.06513356231153011 chamfer_loss_mesh:  0.06434580427594483\n",
      "eikonal_loss:  0.014515836723148823\n",
      "smoothed_heaviside_loss:  3.61931211045885e-06\n",
      "Epoch 341: loss = 0.14399883151054382\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.06449231877923012 chamfer_loss_mesh:  0.06044772453606129\n",
      "eikonal_loss:  0.009709048084914684\n",
      "smoothed_heaviside_loss:  3.6190656373946695e-06\n",
      "Epoch 342: loss = 0.13465270400047302\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.0638600392267108 chamfer_loss_mesh:  0.05909584433538839\n",
      "eikonal_loss:  0.02546447329223156\n",
      "smoothed_heaviside_loss:  3.619003791754949e-06\n",
      "Epoch 343: loss = 0.148423969745636\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.06313813850283623 chamfer_loss_mesh:  0.05866604624316096\n",
      "eikonal_loss:  0.005114423576742411\n",
      "smoothed_heaviside_loss:  3.6241483485355275e-06\n",
      "Epoch 344: loss = 0.12692223489284515\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.06228164304047823 chamfer_loss_mesh:  0.061415659729391336\n",
      "eikonal_loss:  0.14537839591503143\n",
      "smoothed_heaviside_loss:  3.6311864732851973e-06\n",
      "Epoch 345: loss = 0.269079327583313\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.06161597557365894 chamfer_loss_mesh:  0.058715468185255304\n",
      "eikonal_loss:  0.003238916862756014\n",
      "smoothed_heaviside_loss:  3.6314256703917636e-06\n",
      "Epoch 346: loss = 0.12357398122549057\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.06115655414760113 chamfer_loss_mesh:  0.0578605176997371\n",
      "eikonal_loss:  0.002775747561827302\n",
      "smoothed_heaviside_loss:  3.631107801993494e-06\n",
      "Epoch 347: loss = 0.12179645150899887\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.06046007387340069 chamfer_loss_mesh:  0.05773015436716378\n",
      "eikonal_loss:  0.00263255019672215\n",
      "smoothed_heaviside_loss:  3.6349524634715635e-06\n",
      "Epoch 348: loss = 0.12082641571760178\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.060072047635912895 chamfer_loss_mesh:  0.05772625081590377\n",
      "eikonal_loss:  0.002454598667100072\n",
      "smoothed_heaviside_loss:  3.636205974544282e-06\n",
      "Epoch 349: loss = 0.12025653570890427\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.05924380850046873 chamfer_loss_mesh:  0.05723422145820223\n",
      "eikonal_loss:  0.006957014556974173\n",
      "smoothed_heaviside_loss:  3.6427754821488634e-06\n",
      "Epoch 350: loss = 0.12343868613243103\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.05880673881620169 chamfer_loss_mesh:  0.05671376493410207\n",
      "eikonal_loss:  0.002188541693612933\n",
      "smoothed_heaviside_loss:  3.6427370559977135e-06\n",
      "Epoch 351: loss = 0.11771269142627716\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.05837772972881794 chamfer_loss_mesh:  0.05812708332086913\n",
      "eikonal_loss:  0.002398619893938303\n",
      "smoothed_heaviside_loss:  3.6444853321881965e-06\n",
      "Epoch 352: loss = 0.11890707165002823\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.05791166331619024 chamfer_loss_mesh:  0.05599851283477619\n",
      "eikonal_loss:  0.0017787214601412416\n",
      "smoothed_heaviside_loss:  3.6474114040174754e-06\n",
      "Epoch 353: loss = 0.11569254100322723\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.057373177260160446 chamfer_loss_mesh:  0.05585080725722946\n",
      "eikonal_loss:  0.0016689397161826491\n",
      "smoothed_heaviside_loss:  3.6504570744000375e-06\n",
      "Epoch 354: loss = 0.11489657312631607\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.057105361483991146 chamfer_loss_mesh:  0.05661498653353192\n",
      "eikonal_loss:  0.0013772598467767239\n",
      "smoothed_heaviside_loss:  3.6517139960778877e-06\n",
      "Epoch 355: loss = 0.11510126292705536\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.05637485999614 chamfer_loss_mesh:  0.05602211967925541\n",
      "eikonal_loss:  0.001315058209002018\n",
      "smoothed_heaviside_loss:  3.658374907899997e-06\n",
      "Epoch 356: loss = 0.11371569335460663\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.05604809150099754 chamfer_loss_mesh:  0.055262818932533264\n",
      "eikonal_loss:  0.0013510340359061956\n",
      "smoothed_heaviside_loss:  3.6639230529544875e-06\n",
      "Epoch 357: loss = 0.11266560852527618\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.05549767054617405 chamfer_loss_mesh:  0.055053278629202396\n",
      "eikonal_loss:  0.0012597538297995925\n",
      "smoothed_heaviside_loss:  3.6693006677523954e-06\n",
      "Epoch 358: loss = 0.11181437224149704\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.05498128943145275 chamfer_loss_mesh:  0.05500001861946657\n",
      "eikonal_loss:  0.0011694348650053144\n",
      "smoothed_heaviside_loss:  3.6704805097542703e-06\n",
      "Epoch 359: loss = 0.11115442216396332\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.05440060514956713 chamfer_loss_mesh:  0.05519796104636043\n",
      "eikonal_loss:  0.2169041931629181\n",
      "smoothed_heaviside_loss:  3.6719320632983e-06\n",
      "Epoch 360: loss = 0.32650643587112427\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.05388964433223009 chamfer_loss_mesh:  0.05798179336125031\n",
      "eikonal_loss:  0.17785201966762543\n",
      "smoothed_heaviside_loss:  3.6748303955391748e-06\n",
      "Epoch 361: loss = 0.2897271513938904\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.05343444645404816 chamfer_loss_mesh:  0.06250075239222497\n",
      "eikonal_loss:  0.12093295902013779\n",
      "smoothed_heaviside_loss:  3.677204631458153e-06\n",
      "Epoch 362: loss = 0.2368718385696411\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.053149559535086155 chamfer_loss_mesh:  0.06790901534259319\n",
      "eikonal_loss:  0.08225280046463013\n",
      "smoothed_heaviside_loss:  3.6815160910919076e-06\n",
      "Epoch 363: loss = 0.20331504940986633\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.052687861025333405 chamfer_loss_mesh:  0.05818543286295608\n",
      "eikonal_loss:  0.05787750706076622\n",
      "smoothed_heaviside_loss:  3.682788474179688e-06\n",
      "Epoch 364: loss = 0.1687544882297516\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.052415928803384304 chamfer_loss_mesh:  0.05542215512832627\n",
      "eikonal_loss:  0.04224906861782074\n",
      "smoothed_heaviside_loss:  3.6872272630716907e-06\n",
      "Epoch 365: loss = 0.15009084343910217\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.05193204153329134 chamfer_loss_mesh:  0.05430367309600115\n",
      "eikonal_loss:  0.035488907247781754\n",
      "smoothed_heaviside_loss:  3.6914586871716892e-06\n",
      "Epoch 366: loss = 0.14172831177711487\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.051489174365997314 chamfer_loss_mesh:  0.05469979078043252\n",
      "eikonal_loss:  0.025696588680148125\n",
      "smoothed_heaviside_loss:  3.699575017890311e-06\n",
      "Epoch 367: loss = 0.1318892538547516\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.05106537137180567 chamfer_loss_mesh:  0.05391505692387\n",
      "eikonal_loss:  0.020847788080573082\n",
      "smoothed_heaviside_loss:  3.6996138987888116e-06\n",
      "Epoch 368: loss = 0.12583191692829132\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.05083842668682337 chamfer_loss_mesh:  0.05388343925005756\n",
      "eikonal_loss:  0.017538486048579216\n",
      "smoothed_heaviside_loss:  3.7058441648696316e-06\n",
      "Epoch 369: loss = 0.12226405739784241\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.050359638407826424 chamfer_loss_mesh:  0.05472295742947608\n",
      "eikonal_loss:  0.015917913988232613\n",
      "smoothed_heaviside_loss:  3.7090846944920486e-06\n",
      "Epoch 370: loss = 0.12100421637296677\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.04966522101312876 chamfer_loss_mesh:  0.053497009503189474\n",
      "eikonal_loss:  0.013331291265785694\n",
      "smoothed_heaviside_loss:  3.711297949848813e-06\n",
      "Epoch 371: loss = 0.1164972335100174\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.04929893184453249 chamfer_loss_mesh:  0.053571173339150846\n",
      "eikonal_loss:  0.01189916767179966\n",
      "smoothed_heaviside_loss:  3.7127654195501236e-06\n",
      "Epoch 372: loss = 0.1147729903459549\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.04892706871032715 chamfer_loss_mesh:  0.05310010237735696\n",
      "eikonal_loss:  0.0017692309338599443\n",
      "smoothed_heaviside_loss:  3.717176241480047e-06\n",
      "Epoch 373: loss = 0.10380011796951294\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.048717972822487354 chamfer_loss_mesh:  0.05296143353916705\n",
      "eikonal_loss:  0.0018962001195177436\n",
      "smoothed_heaviside_loss:  3.7214169879007386e-06\n",
      "Epoch 374: loss = 0.1035793274641037\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.04834986291825771 chamfer_loss_mesh:  0.05269400207907893\n",
      "eikonal_loss:  0.0021733464673161507\n",
      "smoothed_heaviside_loss:  3.7260231238178676e-06\n",
      "Epoch 375: loss = 0.10322093963623047\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.047950479201972485 chamfer_loss_mesh:  0.052537056035362184\n",
      "eikonal_loss:  0.0022525142412632704\n",
      "smoothed_heaviside_loss:  3.7293289096851368e-06\n",
      "Epoch 376: loss = 0.10274378210306168\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.047667548060417175 chamfer_loss_mesh:  0.05289515684125945\n",
      "eikonal_loss:  0.002446413040161133\n",
      "smoothed_heaviside_loss:  3.7370057270891266e-06\n",
      "Epoch 377: loss = 0.10301285982131958\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.04720832221210003 chamfer_loss_mesh:  0.05230932583799586\n",
      "eikonal_loss:  0.002114817500114441\n",
      "smoothed_heaviside_loss:  3.742297849385068e-06\n",
      "Epoch 378: loss = 0.10163620859384537\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.04700866527855396 chamfer_loss_mesh:  0.05232667535892688\n",
      "eikonal_loss:  0.0016146472189575434\n",
      "smoothed_heaviside_loss:  3.7471988889592467e-06\n",
      "Epoch 379: loss = 0.10095373541116714\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.04688037093728781 chamfer_loss_mesh:  0.05197776044951752\n",
      "eikonal_loss:  0.001258565578609705\n",
      "smoothed_heaviside_loss:  3.750708856387064e-06\n",
      "Epoch 380: loss = 0.10012044757604599\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.04620731808245182 chamfer_loss_mesh:  0.05198649159865454\n",
      "eikonal_loss:  0.0010673494543880224\n",
      "smoothed_heaviside_loss:  3.7543334201473044e-06\n",
      "Epoch 381: loss = 0.09926491230726242\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.04598229192197323 chamfer_loss_mesh:  0.051769278798019513\n",
      "eikonal_loss:  0.0008555285749025643\n",
      "smoothed_heaviside_loss:  3.757284957828233e-06\n",
      "Epoch 382: loss = 0.09861085563898087\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.045350999571383 chamfer_loss_mesh:  0.05240898099145852\n",
      "eikonal_loss:  0.0007371741230599582\n",
      "smoothed_heaviside_loss:  3.762481128433137e-06\n",
      "Epoch 383: loss = 0.09850091487169266\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.044949278235435486 chamfer_loss_mesh:  0.05256716758594848\n",
      "eikonal_loss:  0.00065373326651752\n",
      "smoothed_heaviside_loss:  3.7659090139641194e-06\n",
      "Epoch 384: loss = 0.09817394614219666\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.04484894219785929 chamfer_loss_mesh:  0.05171344673726708\n",
      "eikonal_loss:  0.0007254923111759126\n",
      "smoothed_heaviside_loss:  3.772469881369034e-06\n",
      "Epoch 385: loss = 0.09729164838790894\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.044771358370780945 chamfer_loss_mesh:  0.05286130908643827\n",
      "eikonal_loss:  0.0007551641901955009\n",
      "smoothed_heaviside_loss:  3.7773206713609397e-06\n",
      "Epoch 386: loss = 0.09839160740375519\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.04431772045791149 chamfer_loss_mesh:  0.05138859705766663\n",
      "eikonal_loss:  0.0006444479222409427\n",
      "smoothed_heaviside_loss:  3.7799400161020458e-06\n",
      "Epoch 387: loss = 0.09635454416275024\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.043904464691877365 chamfer_loss_mesh:  0.05131320358486846\n",
      "eikonal_loss:  0.0007204334833659232\n",
      "smoothed_heaviside_loss:  3.7817389966221526e-06\n",
      "Epoch 388: loss = 0.09594188630580902\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.04362450912594795 chamfer_loss_mesh:  0.05150933429831639\n",
      "eikonal_loss:  0.000557953433599323\n",
      "smoothed_heaviside_loss:  3.7881052321608877e-06\n",
      "Epoch 389: loss = 0.09569558501243591\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.043313754722476006 chamfer_loss_mesh:  0.05277546006254852\n",
      "eikonal_loss:  0.0005364801036193967\n",
      "smoothed_heaviside_loss:  3.7927973153273342e-06\n",
      "Epoch 390: loss = 0.09662948548793793\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.042874603532254696 chamfer_loss_mesh:  0.05148201671545394\n",
      "eikonal_loss:  0.0005162895540706813\n",
      "smoothed_heaviside_loss:  3.79426751351275e-06\n",
      "Epoch 391: loss = 0.09487670660018921\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.04245405085384846 chamfer_loss_mesh:  0.05286587474984117\n",
      "eikonal_loss:  0.0004917188198305666\n",
      "smoothed_heaviside_loss:  3.798922762143775e-06\n",
      "Epoch 392: loss = 0.09581544250249863\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.04252835176885128 chamfer_loss_mesh:  0.052035742555744946\n",
      "eikonal_loss:  0.00047017709584906697\n",
      "smoothed_heaviside_loss:  3.802573701250367e-06\n",
      "Epoch 393: loss = 0.09503807127475739\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.04251777194440365 chamfer_loss_mesh:  0.0511832331540063\n",
      "eikonal_loss:  0.0006018338608555496\n",
      "smoothed_heaviside_loss:  3.8114496874186443e-06\n",
      "Epoch 394: loss = 0.09430664777755737\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.041896598413586617 chamfer_loss_mesh:  0.050608115998329595\n",
      "eikonal_loss:  0.0005684370989911258\n",
      "smoothed_heaviside_loss:  3.8148432395246346e-06\n",
      "Epoch 395: loss = 0.09307695925235748\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.04149452783167362 chamfer_loss_mesh:  0.05518677789950743\n",
      "eikonal_loss:  0.00044449028791859746\n",
      "smoothed_heaviside_loss:  3.818210643657949e-06\n",
      "Epoch 396: loss = 0.09712961316108704\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.041274745017290115 chamfer_loss_mesh:  0.054114141676109284\n",
      "eikonal_loss:  0.0005241127219051123\n",
      "smoothed_heaviside_loss:  3.823917268164223e-06\n",
      "Epoch 397: loss = 0.09591682255268097\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.04108074586838484 chamfer_loss_mesh:  0.053488340199692175\n",
      "eikonal_loss:  0.0004424867802299559\n",
      "smoothed_heaviside_loss:  3.829363322438439e-06\n",
      "Epoch 398: loss = 0.09501540660858154\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.040747481398284435 chamfer_loss_mesh:  0.053146570280659944\n",
      "eikonal_loss:  0.0017527254531159997\n",
      "smoothed_heaviside_loss:  3.83288261218695e-06\n",
      "Epoch 399: loss = 0.09565060585737228\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "Estimated eps_H:  tensor(0.4942, device='cuda:0')\n",
      "cvt_loss:  0.040324763394892216 chamfer_loss_mesh:  0.053727926569990814\n",
      "eikonal_loss:  0.0013708134647458792\n",
      "smoothed_heaviside_loss:  3.913038653990952e-06\n",
      "Epoch 400: loss = 0.09542741626501083\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.04010926466435194 chamfer_loss_mesh:  0.05887414590688422\n",
      "eikonal_loss:  0.0013346914201974869\n",
      "smoothed_heaviside_loss:  3.917493359040236e-06\n",
      "Epoch 401: loss = 0.10032201558351517\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "sites length BEFORE UPSAMPLING:  14236\n",
      "Hybrid upsampling regime\n",
      "Sampled indices: 1222 out of 6691 candidates (M=1423)\n",
      "Estimated eps_H:  tensor(0.4945, device='cuda:0')\n",
      "sites shape AFTER:  torch.Size([19124, 3])\n",
      "sites sdf shape AFTER:  torch.Size([19124])\n",
      "cvt_loss:  0.05151074379682541 chamfer_loss_mesh:  0.05943803262198344\n",
      "eikonal_loss:  0.0010193869238719344\n",
      "smoothed_heaviside_loss:  2.926276920334203e-06\n",
      "Epoch 402: loss = 0.11197108775377274\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.053772726096212864 chamfer_loss_mesh:  0.05816173506900668\n",
      "eikonal_loss:  8.381139195989817e-05\n",
      "smoothed_heaviside_loss:  2.9091052056173794e-06\n",
      "Epoch 403: loss = 0.11202117800712585\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.05484967026859522 chamfer_loss_mesh:  0.053940377256367356\n",
      "eikonal_loss:  0.0002149288629880175\n",
      "smoothed_heaviside_loss:  2.887711843868601e-06\n",
      "Epoch 404: loss = 0.10900786519050598\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.05480526480823755 chamfer_loss_mesh:  0.05432513353298418\n",
      "eikonal_loss:  0.005048026796430349\n",
      "smoothed_heaviside_loss:  2.8745912459271494e-06\n",
      "Epoch 405: loss = 0.11418129503726959\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.05412922240793705 chamfer_loss_mesh:  0.05117174441693351\n",
      "eikonal_loss:  0.0037859384901821613\n",
      "smoothed_heaviside_loss:  2.8619795102713397e-06\n",
      "Epoch 406: loss = 0.10908976197242737\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.05332136061042547 chamfer_loss_mesh:  0.052495401178020984\n",
      "eikonal_loss:  0.007029268890619278\n",
      "smoothed_heaviside_loss:  2.855193770301412e-06\n",
      "Epoch 407: loss = 0.11284889280796051\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.05258902441710234 chamfer_loss_mesh:  0.04996872303308919\n",
      "eikonal_loss:  0.004443570505827665\n",
      "smoothed_heaviside_loss:  2.8527538233902305e-06\n",
      "Epoch 408: loss = 0.10700417309999466\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.051717269234359264 chamfer_loss_mesh:  0.05371488077798858\n",
      "eikonal_loss:  0.0031445231288671494\n",
      "smoothed_heaviside_loss:  2.850656528607942e-06\n",
      "Epoch 409: loss = 0.10857952386140823\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.05085124168545008 chamfer_loss_mesh:  0.050331167585682124\n",
      "eikonal_loss:  0.0018080900190398097\n",
      "smoothed_heaviside_loss:  2.8468662094383035e-06\n",
      "Epoch 410: loss = 0.10299334675073624\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.050010173581540585 chamfer_loss_mesh:  0.04829052704735659\n",
      "eikonal_loss:  0.004309577867388725\n",
      "smoothed_heaviside_loss:  2.843594529622351e-06\n",
      "Epoch 411: loss = 0.10261312127113342\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.04890750162303448 chamfer_loss_mesh:  0.04840877227252349\n",
      "eikonal_loss:  0.007386333774775267\n",
      "smoothed_heaviside_loss:  2.83780241261411e-06\n",
      "Epoch 412: loss = 0.10470545291900635\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.047951783053576946 chamfer_loss_mesh:  0.04798872396349907\n",
      "eikonal_loss:  0.0037218970246613026\n",
      "smoothed_heaviside_loss:  2.839592298187199e-06\n",
      "Epoch 413: loss = 0.09966524690389633\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.04712589085102081 chamfer_loss_mesh:  0.046641245717182755\n",
      "eikonal_loss:  0.003243464743718505\n",
      "smoothed_heaviside_loss:  2.837574129443965e-06\n",
      "Epoch 414: loss = 0.0970134362578392\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.04629108589142561 chamfer_loss_mesh:  0.047652698413003236\n",
      "eikonal_loss:  0.0026957967784255743\n",
      "smoothed_heaviside_loss:  2.8355111680866685e-06\n",
      "Epoch 415: loss = 0.09664241969585419\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.045639402233064175 chamfer_loss_mesh:  0.045281791244633496\n",
      "eikonal_loss:  0.0015533905243501067\n",
      "smoothed_heaviside_loss:  2.8358524559735088e-06\n",
      "Epoch 416: loss = 0.09247741848230362\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.04489011596888304 chamfer_loss_mesh:  0.04519735011854209\n",
      "eikonal_loss:  0.001325341290794313\n",
      "smoothed_heaviside_loss:  2.838577984221047e-06\n",
      "Epoch 417: loss = 0.0914156436920166\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.04421507008373737 chamfer_loss_mesh:  0.04488909326028079\n",
      "eikonal_loss:  0.0011889904271811247\n",
      "smoothed_heaviside_loss:  2.842086360033136e-06\n",
      "Epoch 418: loss = 0.09029599279165268\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.043772896751761436 chamfer_loss_mesh:  0.04456525493878871\n",
      "eikonal_loss:  0.0011036942014470696\n",
      "smoothed_heaviside_loss:  2.839188482539612e-06\n",
      "Epoch 419: loss = 0.08944468200206757\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.04280592314898968 chamfer_loss_mesh:  0.04381476537673734\n",
      "eikonal_loss:  0.0009439765708521008\n",
      "smoothed_heaviside_loss:  2.839177341229515e-06\n",
      "Epoch 420: loss = 0.08756750077009201\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.04225591663271189 chamfer_loss_mesh:  0.04438733958522789\n",
      "eikonal_loss:  0.0008761974168010056\n",
      "smoothed_heaviside_loss:  2.8411693620000733e-06\n",
      "Epoch 421: loss = 0.08752229809761047\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.041636466048657894 chamfer_loss_mesh:  0.0429745159635786\n",
      "eikonal_loss:  0.0008168926578946412\n",
      "smoothed_heaviside_loss:  2.843251422746107e-06\n",
      "Epoch 422: loss = 0.08543071895837784\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.041020363569259644 chamfer_loss_mesh:  0.04281543078832328\n",
      "eikonal_loss:  0.008933251723647118\n",
      "smoothed_heaviside_loss:  2.8443203063943656e-06\n",
      "Epoch 423: loss = 0.09277188777923584\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.04040833096951246 chamfer_loss_mesh:  0.042720010242192075\n",
      "eikonal_loss:  0.000686870887875557\n",
      "smoothed_heaviside_loss:  2.8455622214096365e-06\n",
      "Epoch 424: loss = 0.08381805568933487\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.039890031330287457 chamfer_loss_mesh:  0.04231545244692825\n",
      "eikonal_loss:  0.0006557085434906185\n",
      "smoothed_heaviside_loss:  2.8459037366701523e-06\n",
      "Epoch 425: loss = 0.08286404609680176\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.03926755394786596 chamfer_loss_mesh:  0.05438996231532656\n",
      "eikonal_loss:  0.0007054644520394504\n",
      "smoothed_heaviside_loss:  2.8483686946856324e-06\n",
      "Epoch 426: loss = 0.09436582773923874\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.03868552390486002 chamfer_loss_mesh:  0.041908650018740445\n",
      "eikonal_loss:  0.0006282617687247694\n",
      "smoothed_heaviside_loss:  2.8501438009698177e-06\n",
      "Epoch 427: loss = 0.08122528344392776\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.038361947517842054 chamfer_loss_mesh:  0.04178924791631289\n",
      "eikonal_loss:  0.0006015952676534653\n",
      "smoothed_heaviside_loss:  2.852161514965701e-06\n",
      "Epoch 428: loss = 0.08075565099716187\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.03804528387263417 chamfer_loss_mesh:  0.041377206798642874\n",
      "eikonal_loss:  0.0005270253168419003\n",
      "smoothed_heaviside_loss:  2.854544391084346e-06\n",
      "Epoch 429: loss = 0.07995236665010452\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.037493903655558825 chamfer_loss_mesh:  0.041897728806361556\n",
      "eikonal_loss:  0.0010315851541236043\n",
      "smoothed_heaviside_loss:  2.8558326903294073e-06\n",
      "Epoch 430: loss = 0.08042606711387634\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.037077078595757484 chamfer_loss_mesh:  0.041511779272696\n",
      "eikonal_loss:  0.0005272829439491034\n",
      "smoothed_heaviside_loss:  2.8574429506988963e-06\n",
      "Epoch 431: loss = 0.0791189968585968\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.03684949828311801 chamfer_loss_mesh:  0.04139318480156362\n",
      "eikonal_loss:  0.000478969857795164\n",
      "smoothed_heaviside_loss:  2.8599197321454994e-06\n",
      "Epoch 432: loss = 0.07872451096773148\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.036495060194283724 chamfer_loss_mesh:  0.040734892536420375\n",
      "eikonal_loss:  0.0004473290464375168\n",
      "smoothed_heaviside_loss:  2.864854423023644e-06\n",
      "Epoch 433: loss = 0.07768014073371887\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.035756879951804876 chamfer_loss_mesh:  0.0410849170293659\n",
      "eikonal_loss:  0.0005187588394619524\n",
      "smoothed_heaviside_loss:  2.8660545012826333e-06\n",
      "Epoch 434: loss = 0.07736341655254364\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.03534020623192191 chamfer_loss_mesh:  0.040737133531365544\n",
      "eikonal_loss:  0.00048298813635483384\n",
      "smoothed_heaviside_loss:  2.870156322387629e-06\n",
      "Epoch 435: loss = 0.07656320184469223\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.03515533171594143 chamfer_loss_mesh:  0.04175202047917992\n",
      "eikonal_loss:  0.00040712207555770874\n",
      "smoothed_heaviside_loss:  2.8725767151627224e-06\n",
      "Epoch 436: loss = 0.07731734961271286\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.03477657679468393 chamfer_loss_mesh:  0.04021571658086032\n",
      "eikonal_loss:  0.00039018664392642677\n",
      "smoothed_heaviside_loss:  2.87425291389809e-06\n",
      "Epoch 437: loss = 0.07538535445928574\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.0343616702593863 chamfer_loss_mesh:  0.039943035517353565\n",
      "eikonal_loss:  0.0004193553177174181\n",
      "smoothed_heaviside_loss:  2.8749664124916308e-06\n",
      "Epoch 438: loss = 0.07472693920135498\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.03385588526725769 chamfer_loss_mesh:  0.04005409209639765\n",
      "eikonal_loss:  0.030669955536723137\n",
      "smoothed_heaviside_loss:  2.876725602618535e-06\n",
      "Epoch 439: loss = 0.10458280891180038\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.03358845133334398 chamfer_loss_mesh:  0.03910242230631411\n",
      "eikonal_loss:  0.0003689692821353674\n",
      "smoothed_heaviside_loss:  2.8802635370084317e-06\n",
      "Epoch 440: loss = 0.0730627253651619\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.03339905524626374 chamfer_loss_mesh:  0.03853525049635209\n",
      "eikonal_loss:  0.0003550009860191494\n",
      "smoothed_heaviside_loss:  2.8821584692195756e-06\n",
      "Epoch 441: loss = 0.07229219377040863\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.03287440864369273 chamfer_loss_mesh:  0.038912530726520345\n",
      "eikonal_loss:  0.0003435157996136695\n",
      "smoothed_heaviside_loss:  2.8842005121987313e-06\n",
      "Epoch 442: loss = 0.07213333994150162\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.032477162312716246 chamfer_loss_mesh:  0.03896756606991403\n",
      "eikonal_loss:  0.00033259575138799846\n",
      "smoothed_heaviside_loss:  2.8885128813271876e-06\n",
      "Epoch 443: loss = 0.07178021222352982\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.032239160500466824 chamfer_loss_mesh:  0.038349073292920366\n",
      "eikonal_loss:  0.0003248419670853764\n",
      "smoothed_heaviside_loss:  2.890296173063689e-06\n",
      "Epoch 444: loss = 0.07091595977544785\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.03199389670044184 chamfer_loss_mesh:  0.038086396671133116\n",
      "eikonal_loss:  0.0004155356145929545\n",
      "smoothed_heaviside_loss:  2.8937724891875405e-06\n",
      "Epoch 445: loss = 0.07049872726202011\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.03187329974025488 chamfer_loss_mesh:  0.040674025512998924\n",
      "eikonal_loss:  0.00032547718728892505\n",
      "smoothed_heaviside_loss:  2.8980114166188287e-06\n",
      "Epoch 446: loss = 0.07287570834159851\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.03133252961561084 chamfer_loss_mesh:  0.040472717955708504\n",
      "eikonal_loss:  0.0003195428871549666\n",
      "smoothed_heaviside_loss:  2.8990255032113055e-06\n",
      "Epoch 447: loss = 0.07212768495082855\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.03100857138633728 chamfer_loss_mesh:  0.03766596637433395\n",
      "eikonal_loss:  0.0013964567333459854\n",
      "smoothed_heaviside_loss:  2.903573431467521e-06\n",
      "Epoch 448: loss = 0.07007389515638351\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.030717686749994755 chamfer_loss_mesh:  0.03852487134281546\n",
      "eikonal_loss:  0.0013274617958813906\n",
      "smoothed_heaviside_loss:  2.9068141884636134e-06\n",
      "Epoch 449: loss = 0.07057292014360428\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.030518011189997196 chamfer_loss_mesh:  0.03719304731930606\n",
      "eikonal_loss:  0.0012786665465682745\n",
      "smoothed_heaviside_loss:  2.908955821112613e-06\n",
      "Epoch 450: loss = 0.06899262964725494\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.030150527600198984 chamfer_loss_mesh:  0.037053254345664755\n",
      "eikonal_loss:  0.0010169740999117494\n",
      "smoothed_heaviside_loss:  2.911968522312236e-06\n",
      "Epoch 451: loss = 0.06822367012500763\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.030066922772675753 chamfer_loss_mesh:  0.03771457704715431\n",
      "eikonal_loss:  0.0008657127036713064\n",
      "smoothed_heaviside_loss:  2.9141453978809295e-06\n",
      "Epoch 452: loss = 0.06865012645721436\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.02995143411681056 chamfer_loss_mesh:  0.03810955968219787\n",
      "eikonal_loss:  0.0008102228748612106\n",
      "smoothed_heaviside_loss:  2.9148052362870658e-06\n",
      "Epoch 453: loss = 0.06887412816286087\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.029548436868935823 chamfer_loss_mesh:  0.037103960494278\n",
      "eikonal_loss:  0.000661275174934417\n",
      "smoothed_heaviside_loss:  2.9174018436606275e-06\n",
      "Epoch 454: loss = 0.06731659173965454\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.02911875955760479 chamfer_loss_mesh:  0.036656518204836175\n",
      "eikonal_loss:  0.0006049370276741683\n",
      "smoothed_heaviside_loss:  2.9210116281319642e-06\n",
      "Epoch 455: loss = 0.06638313084840775\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.02909247763454914 chamfer_loss_mesh:  0.0366225212928839\n",
      "eikonal_loss:  0.0005901494878344238\n",
      "smoothed_heaviside_loss:  2.924360387623892e-06\n",
      "Epoch 456: loss = 0.06630807369947433\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.028922955971211195 chamfer_loss_mesh:  0.03643154559540562\n",
      "eikonal_loss:  0.02852402999997139\n",
      "smoothed_heaviside_loss:  2.9297032142494572e-06\n",
      "Epoch 457: loss = 0.09388146549463272\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.028683627024292946 chamfer_loss_mesh:  0.03640801878646016\n",
      "eikonal_loss:  0.0004543430113699287\n",
      "smoothed_heaviside_loss:  2.9301020276761847e-06\n",
      "Epoch 458: loss = 0.06554891914129257\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.028517176397144794 chamfer_loss_mesh:  0.03933089828933589\n",
      "eikonal_loss:  0.0006494724657386541\n",
      "smoothed_heaviside_loss:  2.9330592496989993e-06\n",
      "Epoch 459: loss = 0.06850047409534454\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.028113445732742548 chamfer_loss_mesh:  0.03569681211956777\n",
      "eikonal_loss:  0.0004883137298747897\n",
      "smoothed_heaviside_loss:  2.9376694783422863e-06\n",
      "Epoch 460: loss = 0.0643015131354332\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.027857411187142134 chamfer_loss_mesh:  0.03575093433028087\n",
      "eikonal_loss:  0.0005110975471325219\n",
      "smoothed_heaviside_loss:  2.939089199571754e-06\n",
      "Epoch 461: loss = 0.06412238627672195\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.02752897096797824 chamfer_loss_mesh:  0.03576847302610986\n",
      "eikonal_loss:  0.0005799764185212553\n",
      "smoothed_heaviside_loss:  2.941778802778572e-06\n",
      "Epoch 462: loss = 0.06388036161661148\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.027326890267431736 chamfer_loss_mesh:  0.03568752435967326\n",
      "eikonal_loss:  0.0005838517681695521\n",
      "smoothed_heaviside_loss:  2.946257836811128e-06\n",
      "Epoch 463: loss = 0.06360121816396713\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.027170239482074976 chamfer_loss_mesh:  0.03654648389783688\n",
      "eikonal_loss:  0.0005943836877122521\n",
      "smoothed_heaviside_loss:  2.949034524135641e-06\n",
      "Epoch 464: loss = 0.06431405991315842\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.027118679136037827 chamfer_loss_mesh:  0.035504901461536065\n",
      "eikonal_loss:  0.0006085906061343849\n",
      "smoothed_heaviside_loss:  2.9516320410039043e-06\n",
      "Epoch 465: loss = 0.06323511898517609\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.026883059181272984 chamfer_loss_mesh:  0.035440643841866404\n",
      "eikonal_loss:  0.0006276910426095128\n",
      "smoothed_heaviside_loss:  2.9549362352554454e-06\n",
      "Epoch 466: loss = 0.06295434385538101\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.026617336552590132 chamfer_loss_mesh:  0.03602544165914878\n",
      "eikonal_loss:  0.0006384997977875173\n",
      "smoothed_heaviside_loss:  2.9595255455205915e-06\n",
      "Epoch 467: loss = 0.0632842406630516\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.02645348198711872 chamfer_loss_mesh:  0.035233031667303294\n",
      "eikonal_loss:  0.0006818623514845967\n",
      "smoothed_heaviside_loss:  2.9635300506924978e-06\n",
      "Epoch 468: loss = 0.06237134337425232\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.026330857072025537 chamfer_loss_mesh:  0.03516785000101663\n",
      "eikonal_loss:  0.0018313579494133592\n",
      "smoothed_heaviside_loss:  2.96682969747053e-06\n",
      "Epoch 469: loss = 0.06333303451538086\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.026100389659404755 chamfer_loss_mesh:  0.03522033148328774\n",
      "eikonal_loss:  0.0007405045325867832\n",
      "smoothed_heaviside_loss:  2.970558171000448e-06\n",
      "Epoch 470: loss = 0.06206419691443443\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.02585672540590167 chamfer_loss_mesh:  0.0350523587258067\n",
      "eikonal_loss:  0.0006832397193647921\n",
      "smoothed_heaviside_loss:  2.973781874970882e-06\n",
      "Epoch 471: loss = 0.06159529834985733\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.0257028266787529 chamfer_loss_mesh:  0.034879263694165275\n",
      "eikonal_loss:  0.0007561987731605768\n",
      "smoothed_heaviside_loss:  2.977207032017759e-06\n",
      "Epoch 472: loss = 0.061341267079114914\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.025715148076415062 chamfer_loss_mesh:  0.034919543395517394\n",
      "eikonal_loss:  0.0006835918175056577\n",
      "smoothed_heaviside_loss:  2.9811535569024272e-06\n",
      "Epoch 473: loss = 0.06132126972079277\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.025545386597514153 chamfer_loss_mesh:  0.0448722203145735\n",
      "eikonal_loss:  0.0006829427438788116\n",
      "smoothed_heaviside_loss:  2.9846466986782616e-06\n",
      "Epoch 474: loss = 0.071103535592556\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.02550926525145769 chamfer_loss_mesh:  0.043260224629193544\n",
      "eikonal_loss:  0.0012312025064602494\n",
      "smoothed_heaviside_loss:  2.9885088679293403e-06\n",
      "Epoch 475: loss = 0.07000367343425751\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.02518732799217105 chamfer_loss_mesh:  0.034847464121412486\n",
      "eikonal_loss:  0.0011031446047127247\n",
      "smoothed_heaviside_loss:  2.9912800982856425e-06\n",
      "Epoch 476: loss = 0.06114092841744423\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.02506648888811469 chamfer_loss_mesh:  0.034843651519622654\n",
      "eikonal_loss:  0.0010025898227468133\n",
      "smoothed_heaviside_loss:  2.9941934371890966e-06\n",
      "Epoch 477: loss = 0.06091572344303131\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.02481467556208372 chamfer_loss_mesh:  0.034729404433164746\n",
      "eikonal_loss:  0.0009220467763952911\n",
      "smoothed_heaviside_loss:  2.9976006317156134e-06\n",
      "Epoch 478: loss = 0.0604691281914711\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.024846727028489113 chamfer_loss_mesh:  0.03468643990345299\n",
      "eikonal_loss:  0.0008367313421331346\n",
      "smoothed_heaviside_loss:  2.999747721332824e-06\n",
      "Epoch 479: loss = 0.06037289649248123\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.02447951352223754 chamfer_loss_mesh:  0.03500836101011373\n",
      "eikonal_loss:  0.0006562769995070994\n",
      "smoothed_heaviside_loss:  3.0043993319850415e-06\n",
      "Epoch 480: loss = 0.06014715135097504\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.024422782007604837 chamfer_loss_mesh:  0.03484990884317085\n",
      "eikonal_loss:  0.1704750955104828\n",
      "smoothed_heaviside_loss:  3.006193082910613e-06\n",
      "Epoch 481: loss = 0.22975079715251923\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "sites length BEFORE UPSAMPLING:  19124\n",
      "Hybrid upsampling regime\n",
      "Sampled indices: 1625 out of 9421 candidates (M=1912)\n",
      "Estimated eps_H:  tensor(0.4093, device='cuda:0')\n",
      "sites shape AFTER:  torch.Size([25624, 3])\n",
      "sites sdf shape AFTER:  torch.Size([25624])\n",
      "cvt_loss:  0.036290786229074 chamfer_loss_mesh:  0.03572534114937298\n",
      "eikonal_loss:  0.027728086337447166\n",
      "smoothed_heaviside_loss:  2.3171023713075556e-06\n",
      "Epoch 482: loss = 0.09974653273820877\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.03832306945696473 chamfer_loss_mesh:  0.03397417094674893\n",
      "eikonal_loss:  0.01647586189210415\n",
      "smoothed_heaviside_loss:  2.3058196347847115e-06\n",
      "Epoch 483: loss = 0.08877541124820709\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.03900601761415601 chamfer_loss_mesh:  0.032957203075056896\n",
      "eikonal_loss:  0.01937165856361389\n",
      "smoothed_heaviside_loss:  2.287858023919398e-06\n",
      "Epoch 484: loss = 0.0913371667265892\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.0387237430550158 chamfer_loss_mesh:  0.03220202779630199\n",
      "eikonal_loss:  0.014335200190544128\n",
      "smoothed_heaviside_loss:  2.2770784653403098e-06\n",
      "Epoch 485: loss = 0.08526325225830078\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.03770941635593772 chamfer_loss_mesh:  0.032556101359659806\n",
      "eikonal_loss:  0.007081227842718363\n",
      "smoothed_heaviside_loss:  2.2688104763801675e-06\n",
      "Epoch 486: loss = 0.07734901458024979\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.03701386507600546 chamfer_loss_mesh:  0.0320300787279848\n",
      "eikonal_loss:  0.0035472277086228132\n",
      "smoothed_heaviside_loss:  2.262444468215108e-06\n",
      "Epoch 487: loss = 0.07259343564510345\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.035942348185926676 chamfer_loss_mesh:  0.03288047810201533\n",
      "eikonal_loss:  0.002367007313296199\n",
      "smoothed_heaviside_loss:  2.2565614017366897e-06\n",
      "Epoch 488: loss = 0.07119209319353104\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.03518272424116731 chamfer_loss_mesh:  0.030777911888435483\n",
      "eikonal_loss:  0.0017017681384459138\n",
      "smoothed_heaviside_loss:  2.2528308818436926e-06\n",
      "Epoch 489: loss = 0.06766466051340103\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.034122762735933065 chamfer_loss_mesh:  0.030143071853672154\n",
      "eikonal_loss:  0.0013617099029943347\n",
      "smoothed_heaviside_loss:  2.2510737380798673e-06\n",
      "Epoch 490: loss = 0.06562979519367218\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.033135160338133574 chamfer_loss_mesh:  0.03145567461615428\n",
      "eikonal_loss:  0.0009664623066782951\n",
      "smoothed_heaviside_loss:  2.2481369796878425e-06\n",
      "Epoch 491: loss = 0.06555954366922379\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.03270389745011926 chamfer_loss_mesh:  0.030015362426638603\n",
      "eikonal_loss:  0.000812418875284493\n",
      "smoothed_heaviside_loss:  2.2471267584478483e-06\n",
      "Epoch 492: loss = 0.06353393197059631\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.03215077565982938 chamfer_loss_mesh:  0.029892224119976163\n",
      "eikonal_loss:  0.0006997209857217968\n",
      "smoothed_heaviside_loss:  2.2457304567069514e-06\n",
      "Epoch 493: loss = 0.06274496763944626\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.03131021047011018 chamfer_loss_mesh:  0.029564926080638543\n",
      "eikonal_loss:  0.0004367222136352211\n",
      "smoothed_heaviside_loss:  2.2435672235587845e-06\n",
      "Epoch 494: loss = 0.06131410598754883\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.03049753839150071 chamfer_loss_mesh:  0.029542792617576197\n",
      "eikonal_loss:  0.00035386389936320484\n",
      "smoothed_heaviside_loss:  2.243825065306737e-06\n",
      "Epoch 495: loss = 0.06039644032716751\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.02971930429339409 chamfer_loss_mesh:  0.029545168217737228\n",
      "eikonal_loss:  0.0003124797367490828\n",
      "smoothed_heaviside_loss:  2.2432434434449533e-06\n",
      "Epoch 496: loss = 0.05957919731736183\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.029216059483587742 chamfer_loss_mesh:  0.029627990443259478\n",
      "eikonal_loss:  0.00026864762185141444\n",
      "smoothed_heaviside_loss:  2.2437925508711487e-06\n",
      "Epoch 497: loss = 0.05911494046449661\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.02883469220250845 chamfer_loss_mesh:  0.029256312700454146\n",
      "eikonal_loss:  0.00024038521223701537\n",
      "smoothed_heaviside_loss:  2.241843276351574e-06\n",
      "Epoch 498: loss = 0.058333635330200195\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.02845640294253826 chamfer_loss_mesh:  0.02919951657531783\n",
      "eikonal_loss:  0.00022845008061267436\n",
      "smoothed_heaviside_loss:  2.241198444608017e-06\n",
      "Epoch 499: loss = 0.05788661167025566\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "Estimated eps_H:  tensor(0.3287, device='cuda:0')\n",
      "cvt_loss:  0.028068453539162874 chamfer_loss_mesh:  0.02920748374890536\n",
      "eikonal_loss:  5.860562305315398e-05\n",
      "smoothed_heaviside_loss:  2.336022589588538e-06\n",
      "Epoch 500: loss = 0.05733687803149223\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.02766894642263651 chamfer_loss_mesh:  0.0301599720842205\n",
      "eikonal_loss:  3.951622420572676e-05\n",
      "smoothed_heaviside_loss:  2.337244723094045e-06\n",
      "Epoch 501: loss = 0.0578707717359066\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.027250854764133692 chamfer_loss_mesh:  0.029882925446145236\n",
      "eikonal_loss:  2.9244391043903306e-05\n",
      "smoothed_heaviside_loss:  2.3373245312541258e-06\n",
      "Epoch 502: loss = 0.05716536194086075\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.026690377853810787 chamfer_loss_mesh:  0.028948195904376917\n",
      "eikonal_loss:  3.087802542722784e-05\n",
      "smoothed_heaviside_loss:  2.3388095087284455e-06\n",
      "Epoch 503: loss = 0.05567179247736931\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.026297334115952253 chamfer_loss_mesh:  0.0288061401079176\n",
      "eikonal_loss:  2.4295974071719684e-05\n",
      "smoothed_heaviside_loss:  2.3385407530440716e-06\n",
      "Epoch 504: loss = 0.05513010919094086\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.025888807140290737 chamfer_loss_mesh:  0.02943577419500798\n",
      "eikonal_loss:  2.738537841651123e-05\n",
      "smoothed_heaviside_loss:  2.339561206099461e-06\n",
      "Epoch 505: loss = 0.05535430833697319\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.02572281751781702 chamfer_loss_mesh:  0.028519565603346564\n",
      "eikonal_loss:  2.2821255697635934e-05\n",
      "smoothed_heaviside_loss:  2.3400698410114273e-06\n",
      "Epoch 506: loss = 0.05426754057407379\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.025091117713600397 chamfer_loss_mesh:  0.02840501292666886\n",
      "eikonal_loss:  2.385339030297473e-05\n",
      "smoothed_heaviside_loss:  2.3429852262779605e-06\n",
      "Epoch 507: loss = 0.05352232605218887\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.024880825076252222 chamfer_loss_mesh:  0.028413602194632404\n",
      "eikonal_loss:  2.8559841666719876e-05\n",
      "smoothed_heaviside_loss:  2.343518417546875e-06\n",
      "Epoch 508: loss = 0.05332533270120621\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.024516868870705366 chamfer_loss_mesh:  0.029484875994967297\n",
      "eikonal_loss:  2.8884298444609158e-05\n",
      "smoothed_heaviside_loss:  2.3442055407940643e-06\n",
      "Epoch 509: loss = 0.05403297394514084\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.02431145403534174 chamfer_loss_mesh:  0.02796278022287879\n",
      "eikonal_loss:  2.2692353013553657e-05\n",
      "smoothed_heaviside_loss:  2.344255108255311e-06\n",
      "Epoch 510: loss = 0.052299272269010544\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.023957144003361464 chamfer_loss_mesh:  0.028332411602605134\n",
      "eikonal_loss:  1.9609649825724773e-05\n",
      "smoothed_heaviside_loss:  2.3455122573068365e-06\n",
      "Epoch 511: loss = 0.05231151357293129\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.023689388763159513 chamfer_loss_mesh:  0.028272606868995354\n",
      "eikonal_loss:  1.8285654732608236e-05\n",
      "smoothed_heaviside_loss:  2.346005885556224e-06\n",
      "Epoch 512: loss = 0.05198262631893158\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.023366105742752552 chamfer_loss_mesh:  0.029308965167729184\n",
      "eikonal_loss:  1.602499651198741e-05\n",
      "smoothed_heaviside_loss:  2.348290308873402e-06\n",
      "Epoch 513: loss = 0.0526934415102005\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.023211624938994646 chamfer_loss_mesh:  0.028152639060863294\n",
      "eikonal_loss:  2.3306723960558884e-05\n",
      "smoothed_heaviside_loss:  2.3496570520364912e-06\n",
      "Epoch 514: loss = 0.051389921456575394\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.02289450028911233 chamfer_loss_mesh:  0.027715685064322315\n",
      "eikonal_loss:  2.0158278857707046e-05\n",
      "smoothed_heaviside_loss:  2.3506411253038095e-06\n",
      "Epoch 515: loss = 0.050632692873477936\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.022578442003577948 chamfer_loss_mesh:  0.02753861917881295\n",
      "eikonal_loss:  0.0009098189184442163\n",
      "smoothed_heaviside_loss:  2.352684532525018e-06\n",
      "Epoch 516: loss = 0.051029231399297714\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.02247514668852091 chamfer_loss_mesh:  0.027394286007620394\n",
      "eikonal_loss:  1.4992740943853278e-05\n",
      "smoothed_heaviside_loss:  2.354832986384281e-06\n",
      "Epoch 517: loss = 0.049886781722307205\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.022130711004137993 chamfer_loss_mesh:  0.027736969059333205\n",
      "eikonal_loss:  1.485781012888765e-05\n",
      "smoothed_heaviside_loss:  2.3559211967949523e-06\n",
      "Epoch 518: loss = 0.049884896725416183\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.02191877458244562 chamfer_loss_mesh:  0.02742745346040465\n",
      "eikonal_loss:  0.0009037853451445699\n",
      "smoothed_heaviside_loss:  2.357827952437219e-06\n",
      "Epoch 519: loss = 0.05025237053632736\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.02170668449252844 chamfer_loss_mesh:  0.027249991035205312\n",
      "eikonal_loss:  1.669764969847165e-05\n",
      "smoothed_heaviside_loss:  2.359528480155859e-06\n",
      "Epoch 520: loss = 0.048975735902786255\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.0216236081905663 chamfer_loss_mesh:  0.02738537295954302\n",
      "eikonal_loss:  2.1133324480615556e-05\n",
      "smoothed_heaviside_loss:  2.360928874622914e-06\n",
      "Epoch 521: loss = 0.04903247579932213\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.021299526561051607 chamfer_loss_mesh:  0.027412275812821463\n",
      "eikonal_loss:  0.007355596870183945\n",
      "smoothed_heaviside_loss:  2.362789928156417e-06\n",
      "Epoch 522: loss = 0.056069761514663696\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.02099876757711172 chamfer_loss_mesh:  0.027268726626061834\n",
      "eikonal_loss:  0.00035045677213929594\n",
      "smoothed_heaviside_loss:  2.3656441499042558e-06\n",
      "Epoch 523: loss = 0.0486203171312809\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.020977382082492113 chamfer_loss_mesh:  0.02722288445511367\n",
      "eikonal_loss:  0.0003780911210924387\n",
      "smoothed_heaviside_loss:  2.365904265388963e-06\n",
      "Epoch 524: loss = 0.04858072102069855\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.020690993405878544 chamfer_loss_mesh:  0.027290278012515046\n",
      "eikonal_loss:  0.0003605980018619448\n",
      "smoothed_heaviside_loss:  2.3669217625865713e-06\n",
      "Epoch 525: loss = 0.04834423586726189\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.020515129435807467 chamfer_loss_mesh:  0.027863570721819997\n",
      "eikonal_loss:  1.734768011374399e-05\n",
      "smoothed_heaviside_loss:  2.367722345297807e-06\n",
      "Epoch 526: loss = 0.04839841276407242\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.020391016732901335 chamfer_loss_mesh:  0.027384061468183063\n",
      "eikonal_loss:  6.04080269113183e-05\n",
      "smoothed_heaviside_loss:  2.3680047434027074e-06\n",
      "Epoch 527: loss = 0.04783785343170166\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.020255728159099817 chamfer_loss_mesh:  0.02728321123868227\n",
      "eikonal_loss:  0.0005844356492161751\n",
      "smoothed_heaviside_loss:  2.3688860437687254e-06\n",
      "Epoch 528: loss = 0.0481257401406765\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.02011744538322091 chamfer_loss_mesh:  0.027024754672311246\n",
      "eikonal_loss:  0.0005769591662101448\n",
      "smoothed_heaviside_loss:  2.370273932683631e-06\n",
      "Epoch 529: loss = 0.04772153124213219\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.01989443553611636 chamfer_loss_mesh:  0.02710800981731154\n",
      "eikonal_loss:  0.0019353301031515002\n",
      "smoothed_heaviside_loss:  2.3726913696009433e-06\n",
      "Epoch 530: loss = 0.04894014820456505\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.019625038839876652 chamfer_loss_mesh:  0.027509966457728297\n",
      "eikonal_loss:  0.0015452381921932101\n",
      "smoothed_heaviside_loss:  2.3741174572933232e-06\n",
      "Epoch 531: loss = 0.04868261516094208\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.019618910737335682 chamfer_loss_mesh:  0.02690266046556644\n",
      "eikonal_loss:  0.0012688038405030966\n",
      "smoothed_heaviside_loss:  2.3751676963001955e-06\n",
      "Epoch 532: loss = 0.04779275134205818\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.019505134550854564 chamfer_loss_mesh:  0.02684476930880919\n",
      "eikonal_loss:  0.0009863777086138725\n",
      "smoothed_heaviside_loss:  2.3756094833515817e-06\n",
      "Epoch 533: loss = 0.04733865708112717\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.019413913832977414 chamfer_loss_mesh:  0.02667037733772304\n",
      "eikonal_loss:  0.0007978174835443497\n",
      "smoothed_heaviside_loss:  2.377374812567723e-06\n",
      "Epoch 534: loss = 0.04688448831439018\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.019389267545193434 chamfer_loss_mesh:  0.026628567866282538\n",
      "eikonal_loss:  0.0006580179906450212\n",
      "smoothed_heaviside_loss:  2.3793731998011936e-06\n",
      "Epoch 535: loss = 0.04667823389172554\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.01926106633618474 chamfer_loss_mesh:  0.026848054403671995\n",
      "eikonal_loss:  0.0005493857315741479\n",
      "smoothed_heaviside_loss:  2.3807783691154327e-06\n",
      "Epoch 536: loss = 0.0466608852148056\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.01915805391035974 chamfer_loss_mesh:  0.027034891900257207\n",
      "eikonal_loss:  0.000464658165583387\n",
      "smoothed_heaviside_loss:  2.3821889953978825e-06\n",
      "Epoch 537: loss = 0.046659983694553375\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.01909878454171121 chamfer_loss_mesh:  0.026860016077989712\n",
      "eikonal_loss:  0.00039843894774094224\n",
      "smoothed_heaviside_loss:  2.384811068623094e-06\n",
      "Epoch 538: loss = 0.046359624713659286\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.018750701565295458 chamfer_loss_mesh:  0.026380996132502332\n",
      "eikonal_loss:  0.00034497849992476404\n",
      "smoothed_heaviside_loss:  2.3865766252129106e-06\n",
      "Epoch 539: loss = 0.04547906294465065\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.018671699799597263 chamfer_loss_mesh:  0.02700377990549896\n",
      "eikonal_loss:  0.0003228198329452425\n",
      "smoothed_heaviside_loss:  2.3887623683549464e-06\n",
      "Epoch 540: loss = 0.04600068926811218\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.01857195980846882 chamfer_loss_mesh:  0.026789444746100344\n",
      "eikonal_loss:  0.0002731784188654274\n",
      "smoothed_heaviside_loss:  2.3906861770228716e-06\n",
      "Epoch 541: loss = 0.04563697800040245\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.01845050835981965 chamfer_loss_mesh:  0.026234098186250776\n",
      "eikonal_loss:  0.0002448000304866582\n",
      "smoothed_heaviside_loss:  2.39199857787753e-06\n",
      "Epoch 542: loss = 0.044931795448064804\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.018374331993982196 chamfer_loss_mesh:  0.027739893994294107\n",
      "eikonal_loss:  0.00022148972493596375\n",
      "smoothed_heaviside_loss:  2.394360535618034e-06\n",
      "Epoch 543: loss = 0.04633810743689537\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.018213227158412337 chamfer_loss_mesh:  0.028640770324273035\n",
      "eikonal_loss:  0.00021398323588073254\n",
      "smoothed_heaviside_loss:  2.395555156908813e-06\n",
      "Epoch 544: loss = 0.047070376574993134\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.018126979703083634 chamfer_loss_mesh:  0.027702979423338547\n",
      "eikonal_loss:  0.00018833711510524154\n",
      "smoothed_heaviside_loss:  2.39745691033022e-06\n",
      "Epoch 545: loss = 0.04602069407701492\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.01792144146747887 chamfer_loss_mesh:  0.026234067263430916\n",
      "eikonal_loss:  1.5095800335984677e-05\n",
      "smoothed_heaviside_loss:  2.4002063128136797e-06\n",
      "Epoch 546: loss = 0.04417300596833229\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.017829162534326315 chamfer_loss_mesh:  0.026041352612082846\n",
      "eikonal_loss:  0.00012358570529613644\n",
      "smoothed_heaviside_loss:  2.4028156531130662e-06\n",
      "Epoch 547: loss = 0.043996505439281464\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.017787303077057004 chamfer_loss_mesh:  0.026328114472562447\n",
      "eikonal_loss:  0.00016274557856377214\n",
      "smoothed_heaviside_loss:  2.4030919121287297e-06\n",
      "Epoch 548: loss = 0.04428056627511978\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.017817633925005794 chamfer_loss_mesh:  0.025862247639452107\n",
      "eikonal_loss:  0.00013876566663384438\n",
      "smoothed_heaviside_loss:  2.4056778329395456e-06\n",
      "Epoch 549: loss = 0.043821047991514206\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.017694103298708797 chamfer_loss_mesh:  0.026499837986193597\n",
      "eikonal_loss:  0.3673993945121765\n",
      "smoothed_heaviside_loss:  2.4075743567664176e-06\n",
      "Epoch 550: loss = 0.41159576177597046\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.017573970835655928 chamfer_loss_mesh:  0.02608853901620023\n",
      "eikonal_loss:  6.375336670316756e-05\n",
      "smoothed_heaviside_loss:  2.4096907509374432e-06\n",
      "Epoch 551: loss = 0.043728675693273544\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.017429987201467156 chamfer_loss_mesh:  0.02593822864582762\n",
      "eikonal_loss:  5.2786770538659766e-05\n",
      "smoothed_heaviside_loss:  2.4115099677146645e-06\n",
      "Epoch 552: loss = 0.04342341050505638\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.01743355649523437 chamfer_loss_mesh:  0.029688977519981563\n",
      "eikonal_loss:  7.918618939584121e-05\n",
      "smoothed_heaviside_loss:  2.415318704152014e-06\n",
      "Epoch 553: loss = 0.04720413312315941\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.01739592757076025 chamfer_loss_mesh:  0.026959254682878964\n",
      "eikonal_loss:  6.342986307572573e-05\n",
      "smoothed_heaviside_loss:  2.4183793811971555e-06\n",
      "Epoch 554: loss = 0.044421032071113586\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.017214588588103652 chamfer_loss_mesh:  0.02608314753160812\n",
      "eikonal_loss:  7.04599660821259e-05\n",
      "smoothed_heaviside_loss:  2.4205760382756125e-06\n",
      "Epoch 555: loss = 0.04337061941623688\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.016986345872282982 chamfer_loss_mesh:  0.02717211827985011\n",
      "eikonal_loss:  8.395130134886131e-05\n",
      "smoothed_heaviside_loss:  2.422713350824779e-06\n",
      "Epoch 556: loss = 0.04424484074115753\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.016980470390990376 chamfer_loss_mesh:  0.02625973502290435\n",
      "eikonal_loss:  0.0003848469059448689\n",
      "smoothed_heaviside_loss:  2.425309730824665e-06\n",
      "Epoch 557: loss = 0.043627478182315826\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.016957998741418123 chamfer_loss_mesh:  0.026197869374300353\n",
      "eikonal_loss:  0.00022305220772977918\n",
      "smoothed_heaviside_loss:  2.4278240289277164e-06\n",
      "Epoch 558: loss = 0.04338134825229645\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.01708787865936756 chamfer_loss_mesh:  0.026134743166039698\n",
      "eikonal_loss:  0.00021185100194998085\n",
      "smoothed_heaviside_loss:  2.4305443275807193e-06\n",
      "Epoch 559: loss = 0.04343690350651741\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.017100429395213723 chamfer_loss_mesh:  0.026841431463253684\n",
      "eikonal_loss:  0.00033745108521543443\n",
      "smoothed_heaviside_loss:  2.431310576866963e-06\n",
      "Epoch 560: loss = 0.044281743466854095\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.01698551350273192 chamfer_loss_mesh:  0.027104750188300386\n",
      "eikonal_loss:  0.000540257606189698\n",
      "smoothed_heaviside_loss:  2.4336998194485204e-06\n",
      "Epoch 561: loss = 0.04463295638561249\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "sites length BEFORE UPSAMPLING:  25624\n",
      "Hybrid upsampling regime\n",
      "Sampled indices: 2172 out of 12480 candidates (M=2562)\n",
      "Estimated eps_H:  tensor(0.3429, device='cuda:0')\n",
      "sites shape AFTER:  torch.Size([34312, 3])\n",
      "sites sdf shape AFTER:  torch.Size([34312])\n",
      "cvt_loss:  0.028153660241514444 chamfer_loss_mesh:  0.02763848169706762\n",
      "eikonal_loss:  0.00010338460560888052\n",
      "smoothed_heaviside_loss:  1.8115173361366033e-06\n",
      "Epoch 562: loss = 0.05589733645319939\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.030103204771876335 chamfer_loss_mesh:  0.025972771254600957\n",
      "eikonal_loss:  0.0012037154519930482\n",
      "smoothed_heaviside_loss:  1.794905301721883e-06\n",
      "Epoch 563: loss = 0.0572814866900444\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.030419749673455954 chamfer_loss_mesh:  0.02420346027065534\n",
      "eikonal_loss:  0.0010644129943102598\n",
      "smoothed_heaviside_loss:  1.7803148466555285e-06\n",
      "Epoch 564: loss = 0.05568940192461014\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.02971959998831153 chamfer_loss_mesh:  0.023773072825861163\n",
      "eikonal_loss:  0.00016981990484055132\n",
      "smoothed_heaviside_loss:  1.7709107851260342e-06\n",
      "Epoch 565: loss = 0.05366426333785057\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.028789581265300512 chamfer_loss_mesh:  0.023989949113456532\n",
      "eikonal_loss:  0.00031259979004971683\n",
      "smoothed_heaviside_loss:  1.764702233231219e-06\n",
      "Epoch 566: loss = 0.05309389904141426\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.02814741339534521 chamfer_loss_mesh:  0.024061519070528448\n",
      "eikonal_loss:  0.000339262536726892\n",
      "smoothed_heaviside_loss:  1.7599189732209197e-06\n",
      "Epoch 567: loss = 0.05254995822906494\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.027326748240739107 chamfer_loss_mesh:  0.025595321858418174\n",
      "eikonal_loss:  0.000422025186708197\n",
      "smoothed_heaviside_loss:  1.7560627156854025e-06\n",
      "Epoch 568: loss = 0.053345851600170135\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.026469307485967875 chamfer_loss_mesh:  0.023513468477176502\n",
      "eikonal_loss:  0.0005671438411809504\n",
      "smoothed_heaviside_loss:  1.7524015447634156e-06\n",
      "Epoch 569: loss = 0.05055167153477669\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.025658844970166683 chamfer_loss_mesh:  0.02288658834004309\n",
      "eikonal_loss:  0.0017188864294439554\n",
      "smoothed_heaviside_loss:  1.7481830809629173e-06\n",
      "Epoch 570: loss = 0.050266068428754807\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.024904164019972086 chamfer_loss_mesh:  0.022974019884713925\n",
      "eikonal_loss:  0.0010154986521229148\n",
      "smoothed_heaviside_loss:  1.7456299019613652e-06\n",
      "Epoch 571: loss = 0.04889542609453201\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.024240680504590273 chamfer_loss_mesh:  0.02267783747811336\n",
      "eikonal_loss:  0.0007567346910946071\n",
      "smoothed_heaviside_loss:  1.7439414250475238e-06\n",
      "Epoch 572: loss = 0.04767699912190437\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.02362641505897045 chamfer_loss_mesh:  0.02461929398123175\n",
      "eikonal_loss:  0.0006731764297001064\n",
      "smoothed_heaviside_loss:  1.7418750530850957e-06\n",
      "Epoch 573: loss = 0.04892062768340111\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.02310078125447035 chamfer_loss_mesh:  0.02270896584377624\n",
      "eikonal_loss:  0.0006045034970156848\n",
      "smoothed_heaviside_loss:  1.7404338450432988e-06\n",
      "Epoch 574: loss = 0.046415988355875015\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.022826101630926132 chamfer_loss_mesh:  0.022397911379812285\n",
      "eikonal_loss:  0.0005324629019014537\n",
      "smoothed_heaviside_loss:  1.7394768292433582e-06\n",
      "Epoch 575: loss = 0.045758213847875595\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.0224970537237823 chamfer_loss_mesh:  0.022558155251317658\n",
      "eikonal_loss:  0.00044301687739789486\n",
      "smoothed_heaviside_loss:  1.7397278497810476e-06\n",
      "Epoch 576: loss = 0.04549996554851532\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.022102007642388344 chamfer_loss_mesh:  0.02273892459925264\n",
      "eikonal_loss:  0.00038337361183948815\n",
      "smoothed_heaviside_loss:  1.7391321307513863e-06\n",
      "Epoch 577: loss = 0.045226044952869415\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.02159027149900794 chamfer_loss_mesh:  0.022983453163760714\n",
      "eikonal_loss:  0.0003730786847881973\n",
      "smoothed_heaviside_loss:  1.7395568647771142e-06\n",
      "Epoch 578: loss = 0.04494854435324669\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.02135191112756729 chamfer_loss_mesh:  0.022772183001507074\n",
      "eikonal_loss:  0.00031558802584186196\n",
      "smoothed_heaviside_loss:  1.739196363814699e-06\n",
      "Epoch 579: loss = 0.04444142431020737\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.021098926663398743 chamfer_loss_mesh:  0.022264795916271396\n",
      "eikonal_loss:  0.0002851046738214791\n",
      "smoothed_heaviside_loss:  1.7393870166415581e-06\n",
      "Epoch 580: loss = 0.043650563806295395\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.020653391256928444 chamfer_loss_mesh:  0.022642088879365474\n",
      "eikonal_loss:  0.0009757844964042306\n",
      "smoothed_heaviside_loss:  1.7396995417584549e-06\n",
      "Epoch 581: loss = 0.044273003935813904\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.020454153418540955 chamfer_loss_mesh:  0.021998297597747296\n",
      "eikonal_loss:  0.036639563739299774\n",
      "smoothed_heaviside_loss:  1.7402077219230705e-06\n",
      "Epoch 582: loss = 0.07909375429153442\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.020155347883701324 chamfer_loss_mesh:  0.022810818336438388\n",
      "eikonal_loss:  0.0010786190396174788\n",
      "smoothed_heaviside_loss:  1.7400221850039088e-06\n",
      "Epoch 583: loss = 0.04404652491211891\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.019926701206713915 chamfer_loss_mesh:  0.02198374022555072\n",
      "eikonal_loss:  0.0008918343228287995\n",
      "smoothed_heaviside_loss:  1.7414270132576348e-06\n",
      "Epoch 584: loss = 0.042804013937711716\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.019617415964603424 chamfer_loss_mesh:  0.02205532291554846\n",
      "eikonal_loss:  0.000349035719409585\n",
      "smoothed_heaviside_loss:  1.740860966492619e-06\n",
      "Epoch 585: loss = 0.042023513466119766\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.019404537742957473 chamfer_loss_mesh:  0.021861003915546462\n",
      "eikonal_loss:  0.00022673617058899254\n",
      "smoothed_heaviside_loss:  1.7434861092624487e-06\n",
      "Epoch 586: loss = 0.04149401932954788\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.01913061598315835 chamfer_loss_mesh:  0.02181189483962953\n",
      "eikonal_loss:  0.00020837158081121743\n",
      "smoothed_heaviside_loss:  1.744406858961156e-06\n",
      "Epoch 587: loss = 0.041152630001306534\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.019045181106776 chamfer_loss_mesh:  0.021764153643744066\n",
      "eikonal_loss:  0.0020073268096894026\n",
      "smoothed_heaviside_loss:  1.7453354530516663e-06\n",
      "Epoch 588: loss = 0.042818404734134674\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.018782357219606638 chamfer_loss_mesh:  0.02317358121217694\n",
      "eikonal_loss:  0.015521085821092129\n",
      "smoothed_heaviside_loss:  1.746497787280532e-06\n",
      "Epoch 589: loss = 0.05747877061367035\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.01854429836384952 chamfer_loss_mesh:  0.02217280416516587\n",
      "eikonal_loss:  0.000410887150792405\n",
      "smoothed_heaviside_loss:  1.7474188780397526e-06\n",
      "Epoch 590: loss = 0.041129738092422485\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.018430204363539815 chamfer_loss_mesh:  0.02229414531029761\n",
      "eikonal_loss:  0.00016778282588347793\n",
      "smoothed_heaviside_loss:  1.74875128777785e-06\n",
      "Epoch 591: loss = 0.040893882513046265\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.01814664574339986 chamfer_loss_mesh:  0.022193555196281523\n",
      "eikonal_loss:  0.00014896558423060924\n",
      "smoothed_heaviside_loss:  1.7496248574389028e-06\n",
      "Epoch 592: loss = 0.04049091413617134\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.017974907532334328 chamfer_loss_mesh:  0.022110903955763206\n",
      "eikonal_loss:  0.00013949969434179366\n",
      "smoothed_heaviside_loss:  1.7514797718831687e-06\n",
      "Epoch 593: loss = 0.04022706300020218\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.017865350237116218 chamfer_loss_mesh:  0.02148229395970702\n",
      "eikonal_loss:  0.00012739916564896703\n",
      "smoothed_heaviside_loss:  1.7542088244226761e-06\n",
      "Epoch 594: loss = 0.039476796984672546\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.017641750164330006 chamfer_loss_mesh:  0.022747510229237378\n",
      "eikonal_loss:  0.0017373882001265883\n",
      "smoothed_heaviside_loss:  1.7563521623742417e-06\n",
      "Epoch 595: loss = 0.04212840646505356\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.01758654834702611 chamfer_loss_mesh:  0.021542557078646496\n",
      "eikonal_loss:  0.0001508462883066386\n",
      "smoothed_heaviside_loss:  1.7567268741913722e-06\n",
      "Epoch 596: loss = 0.039281707257032394\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.017451891908422112 chamfer_loss_mesh:  0.021558935259236023\n",
      "eikonal_loss:  0.00018408590403851122\n",
      "smoothed_heaviside_loss:  1.7589339904588996e-06\n",
      "Epoch 597: loss = 0.039196670055389404\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.017341027269139886 chamfer_loss_mesh:  0.021414500224636868\n",
      "eikonal_loss:  0.00012453494127839804\n",
      "smoothed_heaviside_loss:  1.760098939485033e-06\n",
      "Epoch 598: loss = 0.0388818234205246\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.017202015733346343 chamfer_loss_mesh:  0.022332762455334887\n",
      "eikonal_loss:  0.00010918554471572861\n",
      "smoothed_heaviside_loss:  1.7624819292905158e-06\n",
      "Epoch 599: loss = 0.0396457239985466\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "Estimated eps_H:  tensor(0.1122, device='cuda:0')\n",
      "cvt_loss:  0.016960198991000652 chamfer_loss_mesh:  0.021279069187585264\n",
      "eikonal_loss:  0.0001467129768570885\n",
      "smoothed_heaviside_loss:  1.9726719528989634e-06\n",
      "Epoch 600: loss = 0.038387954235076904\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.01689802506007254 chamfer_loss_mesh:  0.021508010831894353\n",
      "eikonal_loss:  0.00010097977792611346\n",
      "smoothed_heaviside_loss:  1.9740864445338957e-06\n",
      "Epoch 601: loss = 0.03850898891687393\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.016839749878272414 chamfer_loss_mesh:  0.02120156932505779\n",
      "eikonal_loss:  0.23642627894878387\n",
      "smoothed_heaviside_loss:  1.9749702460103435e-06\n",
      "Epoch 602: loss = 0.2744695842266083\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.016716967802494764 chamfer_loss_mesh:  0.021432033463497646\n",
      "eikonal_loss:  0.5438166856765747\n",
      "smoothed_heaviside_loss:  1.97613803720742e-06\n",
      "Epoch 603: loss = 0.5819676518440247\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.016557798953726888 chamfer_loss_mesh:  0.021076653865748085\n",
      "eikonal_loss:  0.3614668548107147\n",
      "smoothed_heaviside_loss:  1.9768840502365492e-06\n",
      "Epoch 604: loss = 0.3991032838821411\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.016427173977717757 chamfer_loss_mesh:  0.021719184587709606\n",
      "eikonal_loss:  0.22503431141376495\n",
      "smoothed_heaviside_loss:  1.9772976429521805e-06\n",
      "Epoch 605: loss = 0.2631826400756836\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.0162162771448493 chamfer_loss_mesh:  0.021362415282055736\n",
      "eikonal_loss:  7.046382961561903e-05\n",
      "smoothed_heaviside_loss:  1.9782000890700147e-06\n",
      "Epoch 606: loss = 0.03765113651752472\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.016067593824118376 chamfer_loss_mesh:  0.02112441507051699\n",
      "eikonal_loss:  6.799670518375933e-05\n",
      "smoothed_heaviside_loss:  1.9791532395174727e-06\n",
      "Epoch 607: loss = 0.03726198524236679\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.016064615920186043 chamfer_loss_mesh:  0.02104340455844067\n",
      "eikonal_loss:  6.661738007096574e-05\n",
      "smoothed_heaviside_loss:  1.9798853827524e-06\n",
      "Epoch 608: loss = 0.03717661648988724\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.016018672613427043 chamfer_loss_mesh:  0.020987710740882903\n",
      "eikonal_loss:  5.2286912250565365e-05\n",
      "smoothed_heaviside_loss:  1.9810988760582404e-06\n",
      "Epoch 609: loss = 0.03706064820289612\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.0158791767898947 chamfer_loss_mesh:  0.021112358808750287\n",
      "eikonal_loss:  5.1356742915231735e-05\n",
      "smoothed_heaviside_loss:  1.9825474737444893e-06\n",
      "Epoch 610: loss = 0.03704487532377243\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.015817165840417147 chamfer_loss_mesh:  0.020911633328069\n",
      "eikonal_loss:  0.0005340223433449864\n",
      "smoothed_heaviside_loss:  1.983272113648127e-06\n",
      "Epoch 611: loss = 0.037264805287122726\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.015771676553413272 chamfer_loss_mesh:  0.02087240864057094\n",
      "eikonal_loss:  0.0007732708472758532\n",
      "smoothed_heaviside_loss:  1.9845185761369066e-06\n",
      "Epoch 612: loss = 0.03741934150457382\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.015558808809146285 chamfer_loss_mesh:  0.021553443730226718\n",
      "eikonal_loss:  6.53375027468428e-05\n",
      "smoothed_heaviside_loss:  1.985738663279335e-06\n",
      "Epoch 613: loss = 0.037179574370384216\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.015360846882686019 chamfer_loss_mesh:  0.022091420760261826\n",
      "eikonal_loss:  5.105898253532359e-06\n",
      "smoothed_heaviside_loss:  1.9869255538651487e-06\n",
      "Epoch 614: loss = 0.0374593585729599\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.015246515395119786 chamfer_loss_mesh:  0.020951421902282164\n",
      "eikonal_loss:  7.275173175003147e-06\n",
      "smoothed_heaviside_loss:  1.987420318982913e-06\n",
      "Epoch 615: loss = 0.03620719909667969\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.015164599753916264 chamfer_loss_mesh:  0.021223087969701737\n",
      "eikonal_loss:  1.2133686141169164e-05\n",
      "smoothed_heaviside_loss:  1.9883741515513975e-06\n",
      "Epoch 616: loss = 0.036401811987161636\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.015145799843594432 chamfer_loss_mesh:  0.020806593965971842\n",
      "eikonal_loss:  5.659064754581777e-06\n",
      "smoothed_heaviside_loss:  1.9906781290046638e-06\n",
      "Epoch 617: loss = 0.03596004098653793\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.015016236575320363 chamfer_loss_mesh:  0.020781506464118138\n",
      "eikonal_loss:  5.41784766028286e-06\n",
      "smoothed_heaviside_loss:  1.99199462258548e-06\n",
      "Epoch 618: loss = 0.035805150866508484\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.014864293625578284 chamfer_loss_mesh:  0.02109307206410449\n",
      "eikonal_loss:  0.00018137143342755735\n",
      "smoothed_heaviside_loss:  1.9928741039620945e-06\n",
      "Epoch 619: loss = 0.03614072874188423\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.0147901417221874 chamfer_loss_mesh:  0.020643772586481646\n",
      "eikonal_loss:  8.051946679188404e-06\n",
      "smoothed_heaviside_loss:  1.993657633647672e-06\n",
      "Epoch 620: loss = 0.03544396162033081\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.014691810356453061 chamfer_loss_mesh:  0.021981901227263734\n",
      "eikonal_loss:  6.312316600087797e-06\n",
      "smoothed_heaviside_loss:  1.9952046841353877e-06\n",
      "Epoch 621: loss = 0.036682017147541046\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.014719375176355243 chamfer_loss_mesh:  0.021704796381527558\n",
      "eikonal_loss:  5.668634912581183e-06\n",
      "smoothed_heaviside_loss:  1.9963711110904114e-06\n",
      "Epoch 622: loss = 0.03643183782696724\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.014631845988333225 chamfer_loss_mesh:  0.02284322545165196\n",
      "eikonal_loss:  1.683039590716362e-05\n",
      "smoothed_heaviside_loss:  1.997989784285892e-06\n",
      "Epoch 623: loss = 0.03749389946460724\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.014546375023201108 chamfer_loss_mesh:  0.022412907128455117\n",
      "eikonal_loss:  3.5185764772904804e-06\n",
      "smoothed_heaviside_loss:  1.9993065052403836e-06\n",
      "Epoch 624: loss = 0.03696480020880699\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.014479560777544975 chamfer_loss_mesh:  0.02232277074654121\n",
      "eikonal_loss:  3.3765413718356285e-06\n",
      "smoothed_heaviside_loss:  2.000395852519432e-06\n",
      "Epoch 625: loss = 0.03680770471692085\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.01446205424144864 chamfer_loss_mesh:  0.02072766983474139\n",
      "eikonal_loss:  0.00016530325228814036\n",
      "smoothed_heaviside_loss:  2.0015743302792544e-06\n",
      "Epoch 626: loss = 0.0353570319712162\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.01441734959371388 chamfer_loss_mesh:  0.02081665297737345\n",
      "eikonal_loss:  9.51012916630134e-05\n",
      "smoothed_heaviside_loss:  2.0029999632242834e-06\n",
      "Epoch 627: loss = 0.03533110395073891\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.014325737720355392 chamfer_loss_mesh:  0.02066953675239347\n",
      "eikonal_loss:  5.682477421942167e-05\n",
      "smoothed_heaviside_loss:  2.004792577281478e-06\n",
      "Epoch 628: loss = 0.035054102540016174\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.014270637184381485 chamfer_loss_mesh:  0.02070402115350589\n",
      "eikonal_loss:  2.508517172827851e-05\n",
      "smoothed_heaviside_loss:  2.006644081120612e-06\n",
      "Epoch 629: loss = 0.03500174731016159\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.014192684320732951 chamfer_loss_mesh:  0.02060949191218242\n",
      "eikonal_loss:  3.9494287193519995e-05\n",
      "smoothed_heaviside_loss:  2.0079437490494456e-06\n",
      "Epoch 630: loss = 0.03484367951750755\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.014196594711393118 chamfer_loss_mesh:  0.02064801810774952\n",
      "eikonal_loss:  6.41738870399422e-06\n",
      "smoothed_heaviside_loss:  2.0099889752600575e-06\n",
      "Epoch 631: loss = 0.03485304117202759\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.014187874039635062 chamfer_loss_mesh:  0.020477871657931246\n",
      "eikonal_loss:  7.267829914781032e-06\n",
      "smoothed_heaviside_loss:  2.0121271973039256e-06\n",
      "Epoch 632: loss = 0.034675028175115585\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.014188730856403708 chamfer_loss_mesh:  0.020455940102692693\n",
      "eikonal_loss:  3.898597697116202e-06\n",
      "smoothed_heaviside_loss:  2.0141703771514585e-06\n",
      "Epoch 633: loss = 0.03465058282017708\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.014207124477252364 chamfer_loss_mesh:  0.021159487005206756\n",
      "eikonal_loss:  6.896475952089531e-06\n",
      "smoothed_heaviside_loss:  2.016321104747476e-06\n",
      "Epoch 634: loss = 0.03537552431225777\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.013966549886390567 chamfer_loss_mesh:  0.020845440303673968\n",
      "eikonal_loss:  3.44223303727631e-06\n",
      "smoothed_heaviside_loss:  2.018450459218002e-06\n",
      "Epoch 635: loss = 0.03481745347380638\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.013979482464492321 chamfer_loss_mesh:  0.02080878402921371\n",
      "eikonal_loss:  0.0002392524474998936\n",
      "smoothed_heaviside_loss:  2.0207505713187857e-06\n",
      "Epoch 636: loss = 0.035029537975788116\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.01384315313771367 chamfer_loss_mesh:  0.020540512196021155\n",
      "eikonal_loss:  0.000260834873188287\n",
      "smoothed_heaviside_loss:  2.0227905679348623e-06\n",
      "Epoch 637: loss = 0.034646522253751755\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.013740512076765299 chamfer_loss_mesh:  0.020476949430303648\n",
      "eikonal_loss:  2.6572106435196474e-05\n",
      "smoothed_heaviside_loss:  2.0248687633284135e-06\n",
      "Epoch 638: loss = 0.0342460572719574\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.013710202183574438 chamfer_loss_mesh:  0.021071437004138716\n",
      "eikonal_loss:  4.519752565101953e-06\n",
      "smoothed_heaviside_loss:  2.0268992102501215e-06\n",
      "Epoch 639: loss = 0.034788187593221664\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.013775074621662498 chamfer_loss_mesh:  0.020446132111828774\n",
      "eikonal_loss:  8.261473340098746e-06\n",
      "smoothed_heaviside_loss:  2.0286106519051827e-06\n",
      "Epoch 640: loss = 0.03423149883747101\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.013657097006216645 chamfer_loss_mesh:  0.020413915990502574\n",
      "eikonal_loss:  4.690296918852255e-06\n",
      "smoothed_heaviside_loss:  2.0315608253440587e-06\n",
      "Epoch 641: loss = 0.034077733755111694\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "sites length BEFORE UPSAMPLING:  34312\n",
      "Skipping upsampling, too many sites, sites length:  34312 grid size:  32768\n",
      "Estimated eps_H:  tensor(0.1741, device='cuda:0')\n",
      "cvt_loss:  0.013687305618077517 chamfer_loss_mesh:  0.020808631234103814\n",
      "eikonal_loss:  4.940372491546441e-06\n",
      "smoothed_heaviside_loss:  1.973441840164014e-06\n",
      "Epoch 641: loss = 0.034502848982810974\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.014249724335968494 chamfer_loss_mesh:  0.02084505103994161\n",
      "eikonal_loss:  7.551042017439613e-06\n",
      "smoothed_heaviside_loss:  1.9692329260578845e-06\n",
      "Epoch 642: loss = 0.03510429710149765\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.013453880092129111 chamfer_loss_mesh:  0.020392617443576455\n",
      "eikonal_loss:  4.339629413152579e-06\n",
      "smoothed_heaviside_loss:  1.965229785128031e-06\n",
      "Epoch 643: loss = 0.033852800726890564\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012991901021450758 chamfer_loss_mesh:  0.02086560198222287\n",
      "eikonal_loss:  3.419662562009762e-06\n",
      "smoothed_heaviside_loss:  1.9616115878307028e-06\n",
      "Epoch 644: loss = 0.0338628850877285\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012666404945775867 chamfer_loss_mesh:  0.021360901882871985\n",
      "eikonal_loss:  1.3238784049462993e-05\n",
      "smoothed_heaviside_loss:  1.9575895748857874e-06\n",
      "Epoch 645: loss = 0.03404250368475914\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012688463320955634 chamfer_loss_mesh:  0.02253915590699762\n",
      "eikonal_loss:  0.00012048207281623036\n",
      "smoothed_heaviside_loss:  1.955121433638851e-06\n",
      "Epoch 646: loss = 0.03535005450248718\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.01285226782783866 chamfer_loss_mesh:  0.023265074560185894\n",
      "eikonal_loss:  7.123706018319353e-05\n",
      "smoothed_heaviside_loss:  1.953327000592253e-06\n",
      "Epoch 647: loss = 0.03619053587317467\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012606173986569047 chamfer_loss_mesh:  0.023031865566736087\n",
      "eikonal_loss:  0.002120087156072259\n",
      "smoothed_heaviside_loss:  1.9514598079695133e-06\n",
      "Epoch 648: loss = 0.03776007890701294\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012543225893750787 chamfer_loss_mesh:  0.021584004571195692\n",
      "eikonal_loss:  0.0014978618128225207\n",
      "smoothed_heaviside_loss:  1.950140813278267e-06\n",
      "Epoch 649: loss = 0.03562704101204872\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012489226646721363 chamfer_loss_mesh:  0.02126444087480195\n",
      "eikonal_loss:  0.0009575189906172454\n",
      "smoothed_heaviside_loss:  1.9487456484057475e-06\n",
      "Epoch 650: loss = 0.03471313416957855\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012370981276035309 chamfer_loss_mesh:  0.020958876120857894\n",
      "eikonal_loss:  0.0007016162853688002\n",
      "smoothed_heaviside_loss:  1.9477206478768494e-06\n",
      "Epoch 651: loss = 0.03403342515230179\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012380118714645505 chamfer_loss_mesh:  0.020199040591251105\n",
      "eikonal_loss:  0.0005282763740979135\n",
      "smoothed_heaviside_loss:  1.947119699252653e-06\n",
      "Epoch 652: loss = 0.033109381794929504\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012359139509499073 chamfer_loss_mesh:  0.02048963142442517\n",
      "eikonal_loss:  0.0004104673571418971\n",
      "smoothed_heaviside_loss:  1.9461431293166243e-06\n",
      "Epoch 653: loss = 0.03326118364930153\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012414851225912571 chamfer_loss_mesh:  0.020623570890165865\n",
      "eikonal_loss:  0.00030745298136025667\n",
      "smoothed_heaviside_loss:  1.946038764799596e-06\n",
      "Epoch 654: loss = 0.03334782272577286\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012487854110077024 chamfer_loss_mesh:  0.02083126310026273\n",
      "eikonal_loss:  0.00024694702005945146\n",
      "smoothed_heaviside_loss:  1.9458686892903643e-06\n",
      "Epoch 655: loss = 0.03356800973415375\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012438878184184432 chamfer_loss_mesh:  0.020779607439180836\n",
      "eikonal_loss:  0.00030869696638546884\n",
      "smoothed_heaviside_loss:  1.945968506333884e-06\n",
      "Epoch 656: loss = 0.033529132604599\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012323884293437004 chamfer_loss_mesh:  0.020601220967364497\n",
      "eikonal_loss:  0.0005291298730298877\n",
      "smoothed_heaviside_loss:  1.9459539544186555e-06\n",
      "Epoch 657: loss = 0.03345618396997452\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012310291640460491 chamfer_loss_mesh:  0.020486200810410082\n",
      "eikonal_loss:  0.00032331072725355625\n",
      "smoothed_heaviside_loss:  1.9465612695057644e-06\n",
      "Epoch 658: loss = 0.0331217497587204\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012312380131334066 chamfer_loss_mesh:  0.021601172193186358\n",
      "eikonal_loss:  0.00028694115462712944\n",
      "smoothed_heaviside_loss:  1.9471503946988378e-06\n",
      "Epoch 659: loss = 0.034202441573143005\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012145458022132516 chamfer_loss_mesh:  0.021960349840810522\n",
      "eikonal_loss:  0.00026424252428114414\n",
      "smoothed_heaviside_loss:  1.9476524357742164e-06\n",
      "Epoch 660: loss = 0.0343719981610775\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.01210826332680881 chamfer_loss_mesh:  0.021765727069578134\n",
      "eikonal_loss:  0.00022363875177688897\n",
      "smoothed_heaviside_loss:  1.948316594280186e-06\n",
      "Epoch 661: loss = 0.034099578857421875\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.01200514379888773 chamfer_loss_mesh:  0.021152780391275883\n",
      "eikonal_loss:  0.0002050706243608147\n",
      "smoothed_heaviside_loss:  1.949079887708649e-06\n",
      "Epoch 662: loss = 0.03336494043469429\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.0120109086856246 chamfer_loss_mesh:  0.020531400878098793\n",
      "eikonal_loss:  0.00016763966414146125\n",
      "smoothed_heaviside_loss:  1.9495689684845274e-06\n",
      "Epoch 663: loss = 0.032711900770664215\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.0120081368368119 chamfer_loss_mesh:  0.021390907932072878\n",
      "eikonal_loss:  0.00014623190509155393\n",
      "smoothed_heaviside_loss:  1.949890929608955e-06\n",
      "Epoch 664: loss = 0.03354722633957863\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011892784386873245 chamfer_loss_mesh:  0.022748110495740548\n",
      "eikonal_loss:  0.00013058375043328851\n",
      "smoothed_heaviside_loss:  1.9503215753502445e-06\n",
      "Epoch 665: loss = 0.03477342799305916\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011992036597803235 chamfer_loss_mesh:  0.022079446353018284\n",
      "eikonal_loss:  0.00011000219092238694\n",
      "smoothed_heaviside_loss:  1.9519836769177346e-06\n",
      "Epoch 666: loss = 0.03418343514204025\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011974816443398595 chamfer_loss_mesh:  0.021077259589219466\n",
      "eikonal_loss:  0.0002155719412257895\n",
      "smoothed_heaviside_loss:  1.9530507415765896e-06\n",
      "Epoch 667: loss = 0.033269599080085754\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012015884276479483 chamfer_loss_mesh:  0.02079181285807863\n",
      "eikonal_loss:  0.00032253170502372086\n",
      "smoothed_heaviside_loss:  1.9538172182365088e-06\n",
      "Epoch 668: loss = 0.03313218429684639\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012021129950881004 chamfer_loss_mesh:  0.021288171410560608\n",
      "eikonal_loss:  0.00034829697688110173\n",
      "smoothed_heaviside_loss:  1.9554074697225587e-06\n",
      "Epoch 669: loss = 0.03365955501794815\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011951703345403075 chamfer_loss_mesh:  0.024113369363476522\n",
      "eikonal_loss:  0.0001351529936073348\n",
      "smoothed_heaviside_loss:  1.9567785329854814e-06\n",
      "Epoch 670: loss = 0.03620218113064766\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012107170186936855 chamfer_loss_mesh:  0.021211806597420946\n",
      "eikonal_loss:  8.277247252408415e-05\n",
      "smoothed_heaviside_loss:  1.9577928469516337e-06\n",
      "Epoch 671: loss = 0.03340370953083038\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012102321488782763 chamfer_loss_mesh:  0.02074228905257769\n",
      "eikonal_loss:  6.67520216666162e-05\n",
      "smoothed_heaviside_loss:  1.9588155737437773e-06\n",
      "Epoch 672: loss = 0.032913319766521454\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012040943838655949 chamfer_loss_mesh:  0.02097390461130999\n",
      "eikonal_loss:  5.839494406245649e-05\n",
      "smoothed_heaviside_loss:  1.959655264727189e-06\n",
      "Epoch 673: loss = 0.033075202256441116\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012049080105498433 chamfer_loss_mesh:  0.02151600165234413\n",
      "eikonal_loss:  5.3704356105299667e-05\n",
      "smoothed_heaviside_loss:  1.960938561751391e-06\n",
      "Epoch 674: loss = 0.03362074866890907\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012165838852524757 chamfer_loss_mesh:  0.022215419448912144\n",
      "eikonal_loss:  5.0887028919532895e-05\n",
      "smoothed_heaviside_loss:  1.9623307707661297e-06\n",
      "Epoch 675: loss = 0.034434106200933456\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012015110114589334 chamfer_loss_mesh:  0.02447358929202892\n",
      "eikonal_loss:  4.927887857775204e-05\n",
      "smoothed_heaviside_loss:  1.9639448964881012e-06\n",
      "Epoch 676: loss = 0.03653993830084801\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012015318498015404 chamfer_loss_mesh:  0.021817810193169862\n",
      "eikonal_loss:  4.704529055743478e-05\n",
      "smoothed_heaviside_loss:  1.9650926788017387e-06\n",
      "Epoch 677: loss = 0.03388214111328125\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011973489308729768 chamfer_loss_mesh:  0.02189373117289506\n",
      "eikonal_loss:  4.564178016153164e-05\n",
      "smoothed_heaviside_loss:  1.9662056729430333e-06\n",
      "Epoch 678: loss = 0.033914826810359955\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012183008948341012 chamfer_loss_mesh:  0.021080461010569707\n",
      "eikonal_loss:  0.0002773056039586663\n",
      "smoothed_heaviside_loss:  1.967688604054274e-06\n",
      "Epoch 679: loss = 0.03354274109005928\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012055760016664863 chamfer_loss_mesh:  0.021200110495556146\n",
      "eikonal_loss:  0.0011085508158430457\n",
      "smoothed_heaviside_loss:  1.968564674825757e-06\n",
      "Epoch 680: loss = 0.034366391599178314\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012040914734825492 chamfer_loss_mesh:  0.02107375257764943\n",
      "eikonal_loss:  9.936153946910053e-05\n",
      "smoothed_heaviside_loss:  1.9698386495292652e-06\n",
      "Epoch 681: loss = 0.033215999603271484\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012047406053170562 chamfer_loss_mesh:  0.02173558277718257\n",
      "eikonal_loss:  7.363745680777356e-05\n",
      "smoothed_heaviside_loss:  1.9713911569851916e-06\n",
      "Epoch 682: loss = 0.03385859727859497\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012031119549646974 chamfer_loss_mesh:  0.021349427697714418\n",
      "eikonal_loss:  5.9974187024636194e-05\n",
      "smoothed_heaviside_loss:  1.9735384739760775e-06\n",
      "Epoch 683: loss = 0.03344249352812767\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.01193551579490304 chamfer_loss_mesh:  0.02357967969146557\n",
      "eikonal_loss:  5.503675856743939e-05\n",
      "smoothed_heaviside_loss:  1.975599388970295e-06\n",
      "Epoch 684: loss = 0.03557220846414566\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012047096388414502 chamfer_loss_mesh:  0.02097304241033271\n",
      "eikonal_loss:  5.075464287074283e-05\n",
      "smoothed_heaviside_loss:  1.9772103314608103e-06\n",
      "Epoch 685: loss = 0.03307287022471428\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012035724939778447 chamfer_loss_mesh:  0.020781873899977654\n",
      "eikonal_loss:  5.141073415870778e-05\n",
      "smoothed_heaviside_loss:  1.9786621123785153e-06\n",
      "Epoch 686: loss = 0.03287098929286003\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011976138921454549 chamfer_loss_mesh:  0.0212387658393709\n",
      "eikonal_loss:  4.3195337639190257e-05\n",
      "smoothed_heaviside_loss:  1.980276920221513e-06\n",
      "Epoch 687: loss = 0.033260080963373184\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.01208630041219294 chamfer_loss_mesh:  0.021941303202765994\n",
      "eikonal_loss:  3.936341454391368e-05\n",
      "smoothed_heaviside_loss:  1.9820629404421197e-06\n",
      "Epoch 688: loss = 0.03406894952058792\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012016914552077651 chamfer_loss_mesh:  0.021297953935572878\n",
      "eikonal_loss:  0.0004200763942208141\n",
      "smoothed_heaviside_loss:  1.9836884348478634e-06\n",
      "Epoch 689: loss = 0.033736929297447205\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012047355994582176 chamfer_loss_mesh:  0.020519131794571877\n",
      "eikonal_loss:  4.652208008337766e-05\n",
      "smoothed_heaviside_loss:  1.9856677226925967e-06\n",
      "Epoch 690: loss = 0.032614994794130325\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011966206366196275 chamfer_loss_mesh:  0.021169438696233556\n",
      "eikonal_loss:  5.005322236684151e-05\n",
      "smoothed_heaviside_loss:  1.987703853956191e-06\n",
      "Epoch 691: loss = 0.033187687397003174\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011988438200205564 chamfer_loss_mesh:  0.021305640984792262\n",
      "eikonal_loss:  4.63101350760553e-05\n",
      "smoothed_heaviside_loss:  1.9896629055438098e-06\n",
      "Epoch 692: loss = 0.033342380076646805\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.01187175395898521 chamfer_loss_mesh:  0.021531450329348445\n",
      "eikonal_loss:  4.319159052101895e-05\n",
      "smoothed_heaviside_loss:  1.9917624740628526e-06\n",
      "Epoch 693: loss = 0.03344838693737984\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011939944233745337 chamfer_loss_mesh:  0.020684648916358128\n",
      "eikonal_loss:  7.694165833527222e-05\n",
      "smoothed_heaviside_loss:  1.9937799606850604e-06\n",
      "Epoch 694: loss = 0.03270353004336357\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011889527086168528 chamfer_loss_mesh:  0.020812305592698976\n",
      "eikonal_loss:  5.124412928125821e-05\n",
      "smoothed_heaviside_loss:  1.995687625822029e-06\n",
      "Epoch 695: loss = 0.03275506943464279\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012014780659228563 chamfer_loss_mesh:  0.021104200641275384\n",
      "eikonal_loss:  3.013486639247276e-05\n",
      "smoothed_heaviside_loss:  1.997706704059965e-06\n",
      "Epoch 696: loss = 0.033151112496852875\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011931819608435035 chamfer_loss_mesh:  0.02219776069978252\n",
      "eikonal_loss:  2.2748641640646383e-05\n",
      "smoothed_heaviside_loss:  1.999330379476305e-06\n",
      "Epoch 697: loss = 0.03415432944893837\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012036620173603296 chamfer_loss_mesh:  0.020848397980444133\n",
      "eikonal_loss:  3.894433393725194e-05\n",
      "smoothed_heaviside_loss:  2.0015027075714897e-06\n",
      "Epoch 698: loss = 0.032925959676504135\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011960339033976197 chamfer_loss_mesh:  0.02184615732403472\n",
      "eikonal_loss:  2.0802854123758152e-05\n",
      "smoothed_heaviside_loss:  2.0031266103615053e-06\n",
      "Epoch 699: loss = 0.033829301595687866\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "Estimated eps_H:  tensor(0.1212, device='cuda:0')\n",
      "cvt_loss:  0.012057216372340918 chamfer_loss_mesh:  0.022380962036550045\n",
      "eikonal_loss:  1.5317780707846396e-05\n",
      "smoothed_heaviside_loss:  2.0822978967771633e-06\n",
      "Epoch 700: loss = 0.03445557877421379\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011973169166594744 chamfer_loss_mesh:  0.021923278836766258\n",
      "eikonal_loss:  1.8980577806360088e-05\n",
      "smoothed_heaviside_loss:  2.0846619008807465e-06\n",
      "Epoch 701: loss = 0.033917512744665146\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.01204584026709199 chamfer_loss_mesh:  0.021298357751220465\n",
      "eikonal_loss:  1.6410331227234565e-05\n",
      "smoothed_heaviside_loss:  2.0867421426373767e-06\n",
      "Epoch 702: loss = 0.03336269408464432\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.01193821313790977 chamfer_loss_mesh:  0.020855974071309902\n",
      "eikonal_loss:  1.713011988613289e-05\n",
      "smoothed_heaviside_loss:  2.0891156964353286e-06\n",
      "Epoch 703: loss = 0.032813407480716705\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011970970081165433 chamfer_loss_mesh:  0.022740074200555682\n",
      "eikonal_loss:  1.626581979508046e-05\n",
      "smoothed_heaviside_loss:  2.0912209492962575e-06\n",
      "Epoch 704: loss = 0.034729402512311935\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011891069589182734 chamfer_loss_mesh:  0.022705480660079047\n",
      "eikonal_loss:  1.6710835552657954e-05\n",
      "smoothed_heaviside_loss:  2.093137254632893e-06\n",
      "Epoch 705: loss = 0.03461535647511482\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011903329286724329 chamfer_loss_mesh:  0.021735066184191965\n",
      "eikonal_loss:  7.288556844287086e-06\n",
      "smoothed_heaviside_loss:  2.0954473711753963e-06\n",
      "Epoch 706: loss = 0.03364777937531471\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.01192827126942575 chamfer_loss_mesh:  0.02233304621768184\n",
      "eikonal_loss:  0.0001652146747801453\n",
      "smoothed_heaviside_loss:  2.098144022966153e-06\n",
      "Epoch 707: loss = 0.03442863002419472\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011926543666049838 chamfer_loss_mesh:  0.021688860215363093\n",
      "eikonal_loss:  7.062616532493848e-06\n",
      "smoothed_heaviside_loss:  2.099994844684261e-06\n",
      "Epoch 708: loss = 0.033624567091464996\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.01183275249786675 chamfer_loss_mesh:  0.02266486444568727\n",
      "eikonal_loss:  6.858230335637927e-06\n",
      "smoothed_heaviside_loss:  2.10229768526915e-06\n",
      "Epoch 709: loss = 0.034506574273109436\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.01182946958579123 chamfer_loss_mesh:  0.020713865524157882\n",
      "eikonal_loss:  7.444252787536243e-06\n",
      "smoothed_heaviside_loss:  2.1048285816505086e-06\n",
      "Epoch 710: loss = 0.03255288302898407\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011795515893027186 chamfer_loss_mesh:  0.020474624761845917\n",
      "eikonal_loss:  6.930341896804748e-06\n",
      "smoothed_heaviside_loss:  2.1069606646051398e-06\n",
      "Epoch 711: loss = 0.032279178500175476\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011770292185246944 chamfer_loss_mesh:  0.021156032744329423\n",
      "eikonal_loss:  6.851906164229149e-06\n",
      "smoothed_heaviside_loss:  2.1093478608236182e-06\n",
      "Epoch 712: loss = 0.032935287803411484\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011892059119418263 chamfer_loss_mesh:  0.0206154327315744\n",
      "eikonal_loss:  8.126044122036546e-06\n",
      "smoothed_heaviside_loss:  2.1119933535374003e-06\n",
      "Epoch 713: loss = 0.032517727464437485\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011907953303307295 chamfer_loss_mesh:  0.020453637262107804\n",
      "eikonal_loss:  0.0001894266315503046\n",
      "smoothed_heaviside_loss:  2.1144312540855026e-06\n",
      "Epoch 714: loss = 0.03255312889814377\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.01186289475299418 chamfer_loss_mesh:  0.020694318664027378\n",
      "eikonal_loss:  1.0289561942045111e-05\n",
      "smoothed_heaviside_loss:  2.1171003936615307e-06\n",
      "Epoch 715: loss = 0.03256961703300476\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.01180074061267078 chamfer_loss_mesh:  0.0207959528779611\n",
      "eikonal_loss:  2.716398739721626e-05\n",
      "smoothed_heaviside_loss:  2.1195498902670806e-06\n",
      "Epoch 716: loss = 0.03262597694993019\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011808107374235988 chamfer_loss_mesh:  0.02039938590314705\n",
      "eikonal_loss:  8.992340553959366e-06\n",
      "smoothed_heaviside_loss:  2.1230437141639413e-06\n",
      "Epoch 717: loss = 0.032218609005212784\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011790160788223147 chamfer_loss_mesh:  0.022190202798810787\n",
      "eikonal_loss:  9.681126357463654e-06\n",
      "smoothed_heaviside_loss:  2.125826995325042e-06\n",
      "Epoch 718: loss = 0.03399216756224632\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011720946058630943 chamfer_loss_mesh:  0.021359002857934684\n",
      "eikonal_loss:  1.0208451385551598e-05\n",
      "smoothed_heaviside_loss:  2.1284465674398234e-06\n",
      "Epoch 719: loss = 0.03309228643774986\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011704583885148168 chamfer_loss_mesh:  0.020712286641355604\n",
      "eikonal_loss:  2.128574669768568e-05\n",
      "smoothed_heaviside_loss:  2.131416067641112e-06\n",
      "Epoch 720: loss = 0.03244028612971306\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011725593358278275 chamfer_loss_mesh:  0.020766372472280636\n",
      "eikonal_loss:  9.537265214021318e-06\n",
      "smoothed_heaviside_loss:  2.1341581941669574e-06\n",
      "Epoch 721: loss = 0.0325036384165287\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011640801094472408 chamfer_loss_mesh:  0.021681473299395293\n",
      "eikonal_loss:  1.6777941709733568e-05\n",
      "smoothed_heaviside_loss:  2.136281864295597e-06\n",
      "Epoch 722: loss = 0.0333411879837513\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011717277811840177 chamfer_loss_mesh:  0.022208480004337616\n",
      "eikonal_loss:  1.288800012844149e-05\n",
      "smoothed_heaviside_loss:  2.138558329534135e-06\n",
      "Epoch 723: loss = 0.03394078463315964\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011728538665920496 chamfer_loss_mesh:  0.020882358512608334\n",
      "eikonal_loss:  2.5141745936707594e-05\n",
      "smoothed_heaviside_loss:  2.1410460249171592e-06\n",
      "Epoch 724: loss = 0.03263818100094795\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011783406371250749 chamfer_loss_mesh:  0.02080464764731005\n",
      "eikonal_loss:  1.676565079833381e-05\n",
      "smoothed_heaviside_loss:  2.143398432963295e-06\n",
      "Epoch 725: loss = 0.03260696306824684\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011756009189411998 chamfer_loss_mesh:  0.020985691662644967\n",
      "eikonal_loss:  9.415054591954686e-06\n",
      "smoothed_heaviside_loss:  2.1468274553626543e-06\n",
      "Epoch 726: loss = 0.03275326266884804\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.01177421654574573 chamfer_loss_mesh:  0.021966967324260622\n",
      "eikonal_loss:  2.292081990162842e-05\n",
      "smoothed_heaviside_loss:  2.1493920030479785e-06\n",
      "Epoch 727: loss = 0.0337662547826767\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011677811853587627 chamfer_loss_mesh:  0.02250473335152492\n",
      "eikonal_loss:  2.668674278538674e-05\n",
      "smoothed_heaviside_loss:  2.152401521016145e-06\n",
      "Epoch 728: loss = 0.034211382269859314\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011815301841124892 chamfer_loss_mesh:  0.023116164811654016\n",
      "eikonal_loss:  0.00041272732778452337\n",
      "smoothed_heaviside_loss:  2.1551365989580518e-06\n",
      "Epoch 729: loss = 0.03534634783864021\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011746310628950596 chamfer_loss_mesh:  0.02150805630662944\n",
      "eikonal_loss:  0.00024609657702967525\n",
      "smoothed_heaviside_loss:  2.157810513381264e-06\n",
      "Epoch 730: loss = 0.033502619713544846\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011700375471264124 chamfer_loss_mesh:  0.020886083802906796\n",
      "eikonal_loss:  0.00020104684517718852\n",
      "smoothed_heaviside_loss:  2.1603848381346324e-06\n",
      "Epoch 731: loss = 0.03278966620564461\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011762789217755198 chamfer_loss_mesh:  0.02152219894924201\n",
      "eikonal_loss:  0.00012688293645624071\n",
      "smoothed_heaviside_loss:  2.1629466573358513e-06\n",
      "Epoch 732: loss = 0.03341403231024742\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011830496368929744 chamfer_loss_mesh:  0.021463249140651897\n",
      "eikonal_loss:  0.00010447687236592174\n",
      "smoothed_heaviside_loss:  2.165344767490751e-06\n",
      "Epoch 733: loss = 0.033400390297174454\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011735503794625401 chamfer_loss_mesh:  0.020996038074372336\n",
      "eikonal_loss:  9.484965266892686e-05\n",
      "smoothed_heaviside_loss:  2.1683501927327598e-06\n",
      "Epoch 734: loss = 0.03282855823636055\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.01185208442620933 chamfer_loss_mesh:  0.021628235117532313\n",
      "eikonal_loss:  8.776328468229622e-05\n",
      "smoothed_heaviside_loss:  2.1712521629524417e-06\n",
      "Epoch 735: loss = 0.03357025608420372\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011729371035471559 chamfer_loss_mesh:  0.020807263354072347\n",
      "eikonal_loss:  5.366888581193052e-05\n",
      "smoothed_heaviside_loss:  2.174983364966465e-06\n",
      "Epoch 736: loss = 0.03259247541427612\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011797994375228882 chamfer_loss_mesh:  0.021264961105771363\n",
      "eikonal_loss:  4.7362253098981455e-05\n",
      "smoothed_heaviside_loss:  2.1783241663797526e-06\n",
      "Epoch 737: loss = 0.03311249613761902\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011789655545726418 chamfer_loss_mesh:  0.02076372220471967\n",
      "eikonal_loss:  4.494834502111189e-05\n",
      "smoothed_heaviside_loss:  2.1809830741403857e-06\n",
      "Epoch 738: loss = 0.03260050341486931\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011813377495855093 chamfer_loss_mesh:  0.02092983413604088\n",
      "eikonal_loss:  3.566883606254123e-05\n",
      "smoothed_heaviside_loss:  2.1840050976607017e-06\n",
      "Epoch 739: loss = 0.03278106451034546\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.01185935689136386 chamfer_loss_mesh:  0.02070297341560945\n",
      "eikonal_loss:  2.9116015866748057e-05\n",
      "smoothed_heaviside_loss:  2.1871146600460634e-06\n",
      "Epoch 740: loss = 0.032593633979558945\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011799097992479801 chamfer_loss_mesh:  0.020690455130534247\n",
      "eikonal_loss:  0.00011780619388446212\n",
      "smoothed_heaviside_loss:  2.1903779270360246e-06\n",
      "Epoch 741: loss = 0.032609548419713974\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011877502547577024 chamfer_loss_mesh:  0.020997678802814335\n",
      "eikonal_loss:  0.005231643561273813\n",
      "smoothed_heaviside_loss:  2.193407908634981e-06\n",
      "Epoch 742: loss = 0.03810901567339897\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011855191551148891 chamfer_loss_mesh:  0.02226751166745089\n",
      "eikonal_loss:  0.01163522619754076\n",
      "smoothed_heaviside_loss:  2.1962198388791876e-06\n",
      "Epoch 743: loss = 0.045760124921798706\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011794745223596692 chamfer_loss_mesh:  0.0218256791413296\n",
      "eikonal_loss:  1.631668237678241e-05\n",
      "smoothed_heaviside_loss:  2.1992671008774778e-06\n",
      "Epoch 744: loss = 0.03363893926143646\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011847754940390587 chamfer_loss_mesh:  0.023332169803325087\n",
      "eikonal_loss:  1.578262344992254e-05\n",
      "smoothed_heaviside_loss:  2.202474888690631e-06\n",
      "Epoch 745: loss = 0.0351979099214077\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011847205460071564 chamfer_loss_mesh:  0.02115049574058503\n",
      "eikonal_loss:  6.126335210865363e-05\n",
      "smoothed_heaviside_loss:  2.2054978217056487e-06\n",
      "Epoch 746: loss = 0.03306116908788681\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.01182977925054729 chamfer_loss_mesh:  0.021246469259494916\n",
      "eikonal_loss:  1.3560379557020497e-05\n",
      "smoothed_heaviside_loss:  2.2086383069108706e-06\n",
      "Epoch 747: loss = 0.03309201821684837\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.01181936007924378 chamfer_loss_mesh:  0.023791311832610518\n",
      "eikonal_loss:  0.0006008108612149954\n",
      "smoothed_heaviside_loss:  2.2118804281490156e-06\n",
      "Epoch 748: loss = 0.036213696002960205\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011812191223725677 chamfer_loss_mesh:  0.02402274913038127\n",
      "eikonal_loss:  0.00010591101454338059\n",
      "smoothed_heaviside_loss:  2.2147289655549685e-06\n",
      "Epoch 749: loss = 0.03594306483864784\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.01181362196803093 chamfer_loss_mesh:  0.02155197216779925\n",
      "eikonal_loss:  1.7747215679264627e-05\n",
      "smoothed_heaviside_loss:  2.2179494862939464e-06\n",
      "Epoch 750: loss = 0.03338555619120598\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011854741023853421 chamfer_loss_mesh:  0.022187245122040622\n",
      "eikonal_loss:  9.88212414085865e-05\n",
      "smoothed_heaviside_loss:  2.221059048679308e-06\n",
      "Epoch 751: loss = 0.034143026918172836\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.01188206602819264 chamfer_loss_mesh:  0.021318657672964036\n",
      "eikonal_loss:  6.38925121165812e-05\n",
      "smoothed_heaviside_loss:  2.223595174655202e-06\n",
      "Epoch 752: loss = 0.033266838639974594\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011777851032093167 chamfer_loss_mesh:  0.021896372345509008\n",
      "eikonal_loss:  0.049901362508535385\n",
      "smoothed_heaviside_loss:  2.2261649519350613e-06\n",
      "Epoch 753: loss = 0.08357781171798706\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.0118204765021801 chamfer_loss_mesh:  0.021296897102729417\n",
      "eikonal_loss:  0.028609057888388634\n",
      "smoothed_heaviside_loss:  2.229097617600928e-06\n",
      "Epoch 754: loss = 0.06172866374254227\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011870666639879346 chamfer_loss_mesh:  0.021347233996493742\n",
      "eikonal_loss:  0.015593779273331165\n",
      "smoothed_heaviside_loss:  2.2322117274597986e-06\n",
      "Epoch 755: loss = 0.04881390929222107\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011808137642219663 chamfer_loss_mesh:  0.022132924641482532\n",
      "eikonal_loss:  0.009921344928443432\n",
      "smoothed_heaviside_loss:  2.2354172415361973e-06\n",
      "Epoch 756: loss = 0.04386464133858681\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.0117919547483325 chamfer_loss_mesh:  0.023242599127115682\n",
      "eikonal_loss:  0.0001537706411909312\n",
      "smoothed_heaviside_loss:  2.2388051093003014e-06\n",
      "Epoch 757: loss = 0.035190559923648834\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011873060138896108 chamfer_loss_mesh:  0.020833629605476744\n",
      "eikonal_loss:  0.00011008582077920437\n",
      "smoothed_heaviside_loss:  2.2417009404307464e-06\n",
      "Epoch 758: loss = 0.03281901776790619\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.01183400978334248 chamfer_loss_mesh:  0.023789734768797643\n",
      "eikonal_loss:  0.002412938280031085\n",
      "smoothed_heaviside_loss:  2.244682264063158e-06\n",
      "Epoch 759: loss = 0.03803892806172371\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.01190009294077754 chamfer_loss_mesh:  0.02123974627465941\n",
      "eikonal_loss:  0.001583848730660975\n",
      "smoothed_heaviside_loss:  2.2482790882349946e-06\n",
      "Epoch 760: loss = 0.034725937992334366\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011819975916296244 chamfer_loss_mesh:  0.02127692823705729\n",
      "eikonal_loss:  0.00019726021855603904\n",
      "smoothed_heaviside_loss:  2.2515494038088946e-06\n",
      "Epoch 761: loss = 0.03329641371965408\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.01194765092805028 chamfer_loss_mesh:  0.021505660697584972\n",
      "eikonal_loss:  2.5048186216736212e-05\n",
      "smoothed_heaviside_loss:  2.255109166071634e-06\n",
      "Epoch 762: loss = 0.03348061442375183\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011922270059585571 chamfer_loss_mesh:  0.022874710339237936\n",
      "eikonal_loss:  4.8619443987263367e-05\n",
      "smoothed_heaviside_loss:  2.2581468783755554e-06\n",
      "Epoch 763: loss = 0.03484785929322243\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011837884085252881 chamfer_loss_mesh:  0.02067801142402459\n",
      "eikonal_loss:  3.9948576159076765e-05\n",
      "smoothed_heaviside_loss:  2.2618603452428943e-06\n",
      "Epoch 764: loss = 0.03255810588598251\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011837754864245653 chamfer_loss_mesh:  0.022639653252554126\n",
      "eikonal_loss:  4.04420898121316e-05\n",
      "smoothed_heaviside_loss:  2.2652179723081645e-06\n",
      "Epoch 765: loss = 0.03452011197805405\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.01196269178763032 chamfer_loss_mesh:  0.020779518308700062\n",
      "eikonal_loss:  8.879682718543336e-05\n",
      "smoothed_heaviside_loss:  2.2680280835629674e-06\n",
      "Epoch 766: loss = 0.0328332744538784\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012018631678074598 chamfer_loss_mesh:  0.022150476070237346\n",
      "eikonal_loss:  1.947281270986423e-05\n",
      "smoothed_heaviside_loss:  2.271029870826169e-06\n",
      "Epoch 767: loss = 0.03419085219502449\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011837458005174994 chamfer_loss_mesh:  0.023718115699011832\n",
      "eikonal_loss:  2.0726829461636953e-05\n",
      "smoothed_heaviside_loss:  2.2744636680727126e-06\n",
      "Epoch 768: loss = 0.03557857125997543\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011841630330309272 chamfer_loss_mesh:  0.021327443391783163\n",
      "eikonal_loss:  1.609479841135908e-05\n",
      "smoothed_heaviside_loss:  2.2775518573325826e-06\n",
      "Epoch 769: loss = 0.03318744897842407\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.01191256451420486 chamfer_loss_mesh:  0.02165750993299298\n",
      "eikonal_loss:  1.4107797142060008e-05\n",
      "smoothed_heaviside_loss:  2.280470880577923e-06\n",
      "Epoch 770: loss = 0.03358646109700203\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011784224770963192 chamfer_loss_mesh:  0.020786064851563424\n",
      "eikonal_loss:  1.496095228503691e-05\n",
      "smoothed_heaviside_loss:  2.28334465646185e-06\n",
      "Epoch 771: loss = 0.03258753567934036\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011801539221778512 chamfer_loss_mesh:  0.022847265427117236\n",
      "eikonal_loss:  6.875469989608973e-05\n",
      "smoothed_heaviside_loss:  2.287074266860145e-06\n",
      "Epoch 772: loss = 0.03471984714269638\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011832828167825937 chamfer_loss_mesh:  0.02291835335199721\n",
      "eikonal_loss:  3.800373451667838e-05\n",
      "smoothed_heaviside_loss:  2.2896897462487686e-06\n",
      "Epoch 773: loss = 0.03479147329926491\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011814619647338986 chamfer_loss_mesh:  0.02241188849438913\n",
      "eikonal_loss:  3.470482261036523e-05\n",
      "smoothed_heaviside_loss:  2.292462113473448e-06\n",
      "Epoch 774: loss = 0.034263502806425095\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011784223606809974 chamfer_loss_mesh:  0.021610496332868934\n",
      "eikonal_loss:  3.9544549508718774e-05\n",
      "smoothed_heaviside_loss:  2.295661715834285e-06\n",
      "Epoch 775: loss = 0.03343655914068222\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011732976417988539 chamfer_loss_mesh:  0.021103605831740424\n",
      "eikonal_loss:  0.0005204433691687882\n",
      "smoothed_heaviside_loss:  2.2983049348113127e-06\n",
      "Epoch 776: loss = 0.03335932269692421\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011788178235292435 chamfer_loss_mesh:  0.021234489395283163\n",
      "eikonal_loss:  0.00043841233127750456\n",
      "smoothed_heaviside_loss:  2.3011648409010377e-06\n",
      "Epoch 777: loss = 0.033463381230831146\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.01182561507448554 chamfer_loss_mesh:  0.0208318633667659\n",
      "eikonal_loss:  0.0002529852499719709\n",
      "smoothed_heaviside_loss:  2.3041445729177212e-06\n",
      "Epoch 778: loss = 0.03291276842355728\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011866679415106773 chamfer_loss_mesh:  0.022104777599452063\n",
      "eikonal_loss:  2.1385443687904626e-05\n",
      "smoothed_heaviside_loss:  2.3070060706231743e-06\n",
      "Epoch 779: loss = 0.03399515151977539\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011806505499407649 chamfer_loss_mesh:  0.021528423530980945\n",
      "eikonal_loss:  2.960994970635511e-05\n",
      "smoothed_heaviside_loss:  2.3101872557163006e-06\n",
      "Epoch 780: loss = 0.0333668477833271\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.01175898709334433 chamfer_loss_mesh:  0.020978626707801595\n",
      "eikonal_loss:  0.0023879536893218756\n",
      "smoothed_heaviside_loss:  2.3133350168791367e-06\n",
      "Epoch 781: loss = 0.035127878189086914\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011832707095891237 chamfer_loss_mesh:  0.02138155286957044\n",
      "eikonal_loss:  1.5806825103936717e-05\n",
      "smoothed_heaviside_loss:  2.3164930098573677e-06\n",
      "Epoch 782: loss = 0.03323238343000412\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011863220715895295 chamfer_loss_mesh:  0.02078350371448323\n",
      "eikonal_loss:  1.521539525128901e-05\n",
      "smoothed_heaviside_loss:  2.319611212442396e-06\n",
      "Epoch 783: loss = 0.032664258033037186\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011820212239399552 chamfer_loss_mesh:  0.02159151881642174\n",
      "eikonal_loss:  1.5223704394884408e-05\n",
      "smoothed_heaviside_loss:  2.322598675164045e-06\n",
      "Epoch 784: loss = 0.03342927619814873\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011762531939893961 chamfer_loss_mesh:  0.020912148102070205\n",
      "eikonal_loss:  0.0002937133249361068\n",
      "smoothed_heaviside_loss:  2.325093419131008e-06\n",
      "Epoch 785: loss = 0.03297071531414986\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011791939614340663 chamfer_loss_mesh:  0.022518324840348214\n",
      "eikonal_loss:  0.00034747342579066753\n",
      "smoothed_heaviside_loss:  2.3281500034499913e-06\n",
      "Epoch 786: loss = 0.03466006740927696\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011782509973272681 chamfer_loss_mesh:  0.021088826542836614\n",
      "eikonal_loss:  0.0001837099698605016\n",
      "smoothed_heaviside_loss:  2.331231826246949e-06\n",
      "Epoch 787: loss = 0.033057376742362976\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011848779395222664 chamfer_loss_mesh:  0.021411964553408325\n",
      "eikonal_loss:  2.2322912627714686e-05\n",
      "smoothed_heaviside_loss:  2.334010787308216e-06\n",
      "Epoch 788: loss = 0.03328540176153183\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.01189373666420579 chamfer_loss_mesh:  0.021070549337309785\n",
      "eikonal_loss:  1.8280694348504767e-05\n",
      "smoothed_heaviside_loss:  2.33740365729318e-06\n",
      "Epoch 789: loss = 0.0329849049448967\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011806216789409518 chamfer_loss_mesh:  0.02197009598603472\n",
      "eikonal_loss:  1.1881700629601255e-05\n",
      "smoothed_heaviside_loss:  2.3405100364470854e-06\n",
      "Epoch 790: loss = 0.03379053622484207\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011884714476764202 chamfer_loss_mesh:  0.021889332856517285\n",
      "eikonal_loss:  1.17710205813637e-05\n",
      "smoothed_heaviside_loss:  2.3425886865879875e-06\n",
      "Epoch 791: loss = 0.03378816321492195\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011918299132958055 chamfer_loss_mesh:  0.021301390006556176\n",
      "eikonal_loss:  1.2298812180233654e-05\n",
      "smoothed_heaviside_loss:  2.345504753975547e-06\n",
      "Epoch 792: loss = 0.033234331756830215\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011864947155117989 chamfer_loss_mesh:  0.02098236836900469\n",
      "eikonal_loss:  1.1643956895568408e-05\n",
      "smoothed_heaviside_loss:  2.3484767552872654e-06\n",
      "Epoch 793: loss = 0.03286130726337433\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.01182559528388083 chamfer_loss_mesh:  0.02093019793392159\n",
      "eikonal_loss:  0.0036089220084249973\n",
      "smoothed_heaviside_loss:  2.3514794520451687e-06\n",
      "Epoch 794: loss = 0.03636706620454788\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011882130056619644 chamfer_loss_mesh:  0.022456501028500497\n",
      "eikonal_loss:  1.3580530321632978e-05\n",
      "smoothed_heaviside_loss:  2.3542552298749797e-06\n",
      "Epoch 795: loss = 0.0343545638024807\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011832750169560313 chamfer_loss_mesh:  0.02211419996456243\n",
      "eikonal_loss:  1.1145273674628697e-05\n",
      "smoothed_heaviside_loss:  2.357236326133716e-06\n",
      "Epoch 796: loss = 0.033960454165935516\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011927641462534666 chamfer_loss_mesh:  0.020917292204103433\n",
      "eikonal_loss:  1.3899843906983733e-05\n",
      "smoothed_heaviside_loss:  2.360227199460496e-06\n",
      "Epoch 797: loss = 0.032861195504665375\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011869189329445362 chamfer_loss_mesh:  0.021702995582018048\n",
      "eikonal_loss:  2.9859074857085943e-05\n",
      "smoothed_heaviside_loss:  2.3627969767403556e-06\n",
      "Epoch 798: loss = 0.03360440582036972\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011881451355293393 chamfer_loss_mesh:  0.020961000700481236\n",
      "eikonal_loss:  2.0842762751271948e-05\n",
      "smoothed_heaviside_loss:  2.3655131826672005e-06\n",
      "Epoch 799: loss = 0.03286566212773323\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "Estimated eps_H:  tensor(0.1284, device='cuda:0')\n",
      "cvt_loss:  0.011963100405409932 chamfer_loss_mesh:  0.021785330318380147\n",
      "eikonal_loss:  2.034702993114479e-05\n",
      "smoothed_heaviside_loss:  2.3571315068693366e-06\n",
      "Epoch 800: loss = 0.03377113491296768\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011937404051423073 chamfer_loss_mesh:  0.022077492758398876\n",
      "eikonal_loss:  2.0742636479553767e-05\n",
      "smoothed_heaviside_loss:  2.3607240109413397e-06\n",
      "Epoch 801: loss = 0.0340379998087883\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011810585856437683 chamfer_loss_mesh:  0.021895313693676144\n",
      "eikonal_loss:  2.4040191419771872e-05\n",
      "smoothed_heaviside_loss:  2.3637562662770506e-06\n",
      "Epoch 802: loss = 0.033732302486896515\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.0118773162830621 chamfer_loss_mesh:  0.02086132917611394\n",
      "eikonal_loss:  1.822781632654369e-05\n",
      "smoothed_heaviside_loss:  2.3667826098972e-06\n",
      "Epoch 803: loss = 0.03275923803448677\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.01184905064292252 chamfer_loss_mesh:  0.020821718862862326\n",
      "eikonal_loss:  1.540857738291379e-05\n",
      "smoothed_heaviside_loss:  2.3701106783846626e-06\n",
      "Epoch 804: loss = 0.03268854692578316\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011834907345473766 chamfer_loss_mesh:  0.021922998712398112\n",
      "eikonal_loss:  1.2041592526657041e-05\n",
      "smoothed_heaviside_loss:  2.3732884528726572e-06\n",
      "Epoch 805: loss = 0.03377231955528259\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011923123383894563 chamfer_loss_mesh:  0.023085965949576348\n",
      "eikonal_loss:  1.2827971659135073e-05\n",
      "smoothed_heaviside_loss:  2.3765387595631182e-06\n",
      "Epoch 806: loss = 0.03502429276704788\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011895194184035063 chamfer_loss_mesh:  0.020822704755119048\n",
      "eikonal_loss:  1.1309420187899377e-05\n",
      "smoothed_heaviside_loss:  2.380211753916228e-06\n",
      "Epoch 807: loss = 0.032731588929891586\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011869834270328283 chamfer_loss_mesh:  0.022638196242041886\n",
      "eikonal_loss:  1.3140782357368153e-05\n",
      "smoothed_heaviside_loss:  2.383838591413223e-06\n",
      "Epoch 808: loss = 0.034523554146289825\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011878862278535962 chamfer_loss_mesh:  0.02171775486203842\n",
      "eikonal_loss:  1.1329806511639617e-05\n",
      "smoothed_heaviside_loss:  2.386681899224641e-06\n",
      "Epoch 809: loss = 0.03361033275723457\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011976355453953147 chamfer_loss_mesh:  0.020914252672810107\n",
      "eikonal_loss:  1.369949950458249e-05\n",
      "smoothed_heaviside_loss:  2.3900365704321302e-06\n",
      "Epoch 810: loss = 0.03290669992566109\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011898087104782462 chamfer_loss_mesh:  0.021479911083588377\n",
      "eikonal_loss:  1.2531664651760366e-05\n",
      "smoothed_heaviside_loss:  2.3932766453071963e-06\n",
      "Epoch 811: loss = 0.03339292109012604\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011819808278232813 chamfer_loss_mesh:  0.021229061530902982\n",
      "eikonal_loss:  2.6412413717480376e-05\n",
      "smoothed_heaviside_loss:  2.3963573312357767e-06\n",
      "Epoch 812: loss = 0.033077675849199295\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011858928482979536 chamfer_loss_mesh:  0.021046049369033426\n",
      "eikonal_loss:  3.5599005059339106e-05\n",
      "smoothed_heaviside_loss:  2.399479626546963e-06\n",
      "Epoch 813: loss = 0.03294297680258751\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011953971115872264 chamfer_loss_mesh:  0.021862892026547343\n",
      "eikonal_loss:  1.1419911061238963e-05\n",
      "smoothed_heaviside_loss:  2.4026689970924053e-06\n",
      "Epoch 814: loss = 0.033830683678388596\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011986525496467948 chamfer_loss_mesh:  0.021035264580859803\n",
      "eikonal_loss:  1.0360875421611127e-05\n",
      "smoothed_heaviside_loss:  2.4060075247689383e-06\n",
      "Epoch 815: loss = 0.0330345593392849\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011889521265402436 chamfer_loss_mesh:  0.023953729396453127\n",
      "eikonal_loss:  5.3634168580174446e-05\n",
      "smoothed_heaviside_loss:  2.4091061732178787e-06\n",
      "Epoch 816: loss = 0.03589929640293121\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011967791942879558 chamfer_loss_mesh:  0.021633113647112623\n",
      "eikonal_loss:  2.513134131731931e-05\n",
      "smoothed_heaviside_loss:  2.412123649264686e-06\n",
      "Epoch 817: loss = 0.033628448843955994\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011908435262739658 chamfer_loss_mesh:  0.021695679606636986\n",
      "eikonal_loss:  1.667471406108234e-05\n",
      "smoothed_heaviside_loss:  2.4155763185262913e-06\n",
      "Epoch 818: loss = 0.03362320736050606\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.01196164172142744 chamfer_loss_mesh:  0.022536140022566542\n",
      "eikonal_loss:  1.3692457287106663e-05\n",
      "smoothed_heaviside_loss:  2.418595158815151e-06\n",
      "Epoch 819: loss = 0.034513894468545914\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011984145967289805 chamfer_loss_mesh:  0.023082506231730804\n",
      "eikonal_loss:  1.1985719538643025e-05\n",
      "smoothed_heaviside_loss:  2.4217786176450318e-06\n",
      "Epoch 820: loss = 0.035081058740615845\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.01196322264149785 chamfer_loss_mesh:  0.022427509975386783\n",
      "eikonal_loss:  1.1018172699550632e-05\n",
      "smoothed_heaviside_loss:  2.4246107841463527e-06\n",
      "Epoch 821: loss = 0.03440417721867561\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011992453364655375 chamfer_loss_mesh:  0.02233050145150628\n",
      "eikonal_loss:  0.0013628866290673614\n",
      "smoothed_heaviside_loss:  2.4279231638502097e-06\n",
      "Epoch 822: loss = 0.03568826988339424\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012051975354552269 chamfer_loss_mesh:  0.0234043545788154\n",
      "eikonal_loss:  0.0011138764675706625\n",
      "smoothed_heaviside_loss:  2.4308562842634274e-06\n",
      "Epoch 823: loss = 0.03657263517379761\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011867486173287034 chamfer_loss_mesh:  0.022323241864796728\n",
      "eikonal_loss:  0.000967824540566653\n",
      "smoothed_heaviside_loss:  2.433869894957752e-06\n",
      "Epoch 824: loss = 0.035160988569259644\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.01187414163723588 chamfer_loss_mesh:  0.02296996535733342\n",
      "eikonal_loss:  0.0008048832532949746\n",
      "smoothed_heaviside_loss:  2.436497425151174e-06\n",
      "Epoch 825: loss = 0.03565142676234245\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011885145213454962 chamfer_loss_mesh:  0.02295833473908715\n",
      "eikonal_loss:  1.1328558684908785e-05\n",
      "smoothed_heaviside_loss:  2.4393505100306356e-06\n",
      "Epoch 826: loss = 0.03485725075006485\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011884206905961037 chamfer_loss_mesh:  0.02284187030454632\n",
      "eikonal_loss:  9.74563772615511e-06\n",
      "smoothed_heaviside_loss:  2.4421149191766744e-06\n",
      "Epoch 827: loss = 0.034738264977931976\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011856599012389779 chamfer_loss_mesh:  0.022315134629025124\n",
      "eikonal_loss:  9.217464139510412e-06\n",
      "smoothed_heaviside_loss:  2.4448117983411066e-06\n",
      "Epoch 828: loss = 0.03418339788913727\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.01184111344628036 chamfer_loss_mesh:  0.022944421289139427\n",
      "eikonal_loss:  0.00039566640043631196\n",
      "smoothed_heaviside_loss:  2.4472972199873766e-06\n",
      "Epoch 829: loss = 0.03518364951014519\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011812486918643117 chamfer_loss_mesh:  0.022319798517855816\n",
      "eikonal_loss:  0.00041782725020311773\n",
      "smoothed_heaviside_loss:  2.4499420305801323e-06\n",
      "Epoch 830: loss = 0.03455256298184395\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.01181381638161838 chamfer_loss_mesh:  0.02208216392318718\n",
      "eikonal_loss:  0.0004369143571238965\n",
      "smoothed_heaviside_loss:  2.4525784283468965e-06\n",
      "Epoch 831: loss = 0.03433534875512123\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011830705916509032 chamfer_loss_mesh:  0.02201221650466323\n",
      "eikonal_loss:  0.00036056473618373275\n",
      "smoothed_heaviside_loss:  2.455941285006702e-06\n",
      "Epoch 832: loss = 0.03420594334602356\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011940832482650876 chamfer_loss_mesh:  0.021842650312464684\n",
      "eikonal_loss:  0.0003317062510177493\n",
      "smoothed_heaviside_loss:  2.458951030348544e-06\n",
      "Epoch 833: loss = 0.034117650240659714\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011991111095994711 chamfer_loss_mesh:  0.021421243218355812\n",
      "eikonal_loss:  0.0057750302366912365\n",
      "smoothed_heaviside_loss:  2.4619512259960175e-06\n",
      "Epoch 834: loss = 0.03918984532356262\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011987139005213976 chamfer_loss_mesh:  0.022509300833917223\n",
      "eikonal_loss:  0.00015649710258003324\n",
      "smoothed_heaviside_loss:  2.4647167720104335e-06\n",
      "Epoch 835: loss = 0.03465540334582329\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012030667858198285 chamfer_loss_mesh:  0.021353202100726776\n",
      "eikonal_loss:  9.64648716035299e-05\n",
      "smoothed_heaviside_loss:  2.4678490717633395e-06\n",
      "Epoch 836: loss = 0.03348280116915703\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012015640968456864 chamfer_loss_mesh:  0.021702951926272362\n",
      "eikonal_loss:  6.320795364445075e-05\n",
      "smoothed_heaviside_loss:  2.4705211671971483e-06\n",
      "Epoch 837: loss = 0.03378427028656006\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.01195471384562552 chamfer_loss_mesh:  0.021748292056145146\n",
      "eikonal_loss:  4.3334814108675346e-05\n",
      "smoothed_heaviside_loss:  2.4740156732150353e-06\n",
      "Epoch 838: loss = 0.0337488166987896\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011997923720628023 chamfer_loss_mesh:  0.021280562577885576\n",
      "eikonal_loss:  3.4821860026568174e-05\n",
      "smoothed_heaviside_loss:  2.4766827664279845e-06\n",
      "Epoch 839: loss = 0.033315785229206085\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011925456346943974 chamfer_loss_mesh:  0.021647230823873542\n",
      "eikonal_loss:  0.00010780786396935582\n",
      "smoothed_heaviside_loss:  2.480055400155834e-06\n",
      "Epoch 840: loss = 0.03368297591805458\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011881741229444742 chamfer_loss_mesh:  0.023711498215561733\n",
      "eikonal_loss:  0.00010187005682382733\n",
      "smoothed_heaviside_loss:  2.4831506379996426e-06\n",
      "Epoch 841: loss = 0.03569759428501129\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011829212307929993 chamfer_loss_mesh:  0.022808035282650962\n",
      "eikonal_loss:  8.49185380502604e-05\n",
      "smoothed_heaviside_loss:  2.486495532139088e-06\n",
      "Epoch 842: loss = 0.034724656492471695\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011900966055691242 chamfer_loss_mesh:  0.02218045665358659\n",
      "eikonal_loss:  6.688163557555526e-05\n",
      "smoothed_heaviside_loss:  2.4895573460526066e-06\n",
      "Epoch 843: loss = 0.03415079414844513\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011917488882318139 chamfer_loss_mesh:  0.02231730832136236\n",
      "eikonal_loss:  0.00016667990712448955\n",
      "smoothed_heaviside_loss:  2.4919243060139706e-06\n",
      "Epoch 844: loss = 0.0344039723277092\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011874095071107149 chamfer_loss_mesh:  0.021365745851653628\n",
      "eikonal_loss:  4.675696254707873e-05\n",
      "smoothed_heaviside_loss:  2.4945352379290853e-06\n",
      "Epoch 845: loss = 0.033289093524217606\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011958484537899494 chamfer_loss_mesh:  0.022178144718054682\n",
      "eikonal_loss:  8.392822928726673e-05\n",
      "smoothed_heaviside_loss:  2.4972039227577625e-06\n",
      "Epoch 846: loss = 0.034223057329654694\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011972401989623904 chamfer_loss_mesh:  0.021958494471618906\n",
      "eikonal_loss:  3.4680731914704666e-05\n",
      "smoothed_heaviside_loss:  2.499925585652818e-06\n",
      "Epoch 847: loss = 0.03396807983517647\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011975541710853577 chamfer_loss_mesh:  0.02183140350098256\n",
      "eikonal_loss:  2.82616529148072e-05\n",
      "smoothed_heaviside_loss:  2.5033230031112907e-06\n",
      "Epoch 848: loss = 0.033837709575891495\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011921619297936559 chamfer_loss_mesh:  0.021397543605417013\n",
      "eikonal_loss:  2.815561310853809e-05\n",
      "smoothed_heaviside_loss:  2.506101509425207e-06\n",
      "Epoch 849: loss = 0.03334982693195343\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011953430948778987 chamfer_loss_mesh:  0.022690326659358107\n",
      "eikonal_loss:  1.4766354979656171e-05\n",
      "smoothed_heaviside_loss:  2.5093613658100367e-06\n",
      "Epoch 850: loss = 0.034661032259464264\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012025885516777635 chamfer_loss_mesh:  0.023134427465265617\n",
      "eikonal_loss:  0.000696611066814512\n",
      "smoothed_heaviside_loss:  2.51284109253902e-06\n",
      "Epoch 851: loss = 0.03585943579673767\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012059557484462857 chamfer_loss_mesh:  0.02203398798883427\n",
      "eikonal_loss:  1.9575911210267805e-05\n",
      "smoothed_heaviside_loss:  2.516369477234548e-06\n",
      "Epoch 852: loss = 0.034115634858608246\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012043381575495005 chamfer_loss_mesh:  0.022436015569837764\n",
      "eikonal_loss:  9.217864317179192e-06\n",
      "smoothed_heaviside_loss:  2.5200720301654655e-06\n",
      "Epoch 853: loss = 0.03449113294482231\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.01198593177832663 chamfer_loss_mesh:  0.02247486190753989\n",
      "eikonal_loss:  8.887919648259412e-06\n",
      "smoothed_heaviside_loss:  2.5235253815480974e-06\n",
      "Epoch 854: loss = 0.034472204744815826\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011941205011680722 chamfer_loss_mesh:  0.022353942767949775\n",
      "eikonal_loss:  8.039322892727796e-06\n",
      "smoothed_heaviside_loss:  2.526616981413099e-06\n",
      "Epoch 855: loss = 0.03430571407079697\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011957223759964108 chamfer_loss_mesh:  0.021853022190043703\n",
      "eikonal_loss:  1.1130789062008262e-05\n",
      "smoothed_heaviside_loss:  2.5296290004916955e-06\n",
      "Epoch 856: loss = 0.03382390737533569\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011924131540581584 chamfer_loss_mesh:  0.022288395484793\n",
      "eikonal_loss:  7.5828424996871036e-06\n",
      "smoothed_heaviside_loss:  2.5323647605546284e-06\n",
      "Epoch 857: loss = 0.034222640097141266\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011908406158909202 chamfer_loss_mesh:  0.022698683096677996\n",
      "eikonal_loss:  7.719053428445477e-06\n",
      "smoothed_heaviside_loss:  2.5362398901052075e-06\n",
      "Epoch 858: loss = 0.0346173457801342\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.01195348217152059 chamfer_loss_mesh:  0.02327657421119511\n",
      "eikonal_loss:  7.425894636980956e-06\n",
      "smoothed_heaviside_loss:  2.539556589908898e-06\n",
      "Epoch 859: loss = 0.03524002060294151\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.011986051686108112 chamfer_loss_mesh:  0.022119533241493627\n",
      "eikonal_loss:  8.000701200217009e-06\n",
      "smoothed_heaviside_loss:  2.542899892432615e-06\n",
      "Epoch 860: loss = 0.03411612659692764\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012122617335990071 chamfer_loss_mesh:  0.021930471120867878\n",
      "eikonal_loss:  9.081427378987428e-06\n",
      "smoothed_heaviside_loss:  2.546471705500153e-06\n",
      "Epoch 861: loss = 0.03406471386551857\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012036078842356801 chamfer_loss_mesh:  0.022609554434893653\n",
      "eikonal_loss:  1.2347563824732788e-05\n",
      "smoothed_heaviside_loss:  2.549979626564891e-06\n",
      "Epoch 862: loss = 0.03466052934527397\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.01207153545692563 chamfer_loss_mesh:  0.022504842490889132\n",
      "eikonal_loss:  1.9566461560316384e-05\n",
      "smoothed_heaviside_loss:  2.5532076506351586e-06\n",
      "Epoch 863: loss = 0.03459849953651428\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.01201251638121903 chamfer_loss_mesh:  0.02182590469601564\n",
      "eikonal_loss:  7.441482011927292e-06\n",
      "smoothed_heaviside_loss:  2.5574365736247273e-06\n",
      "Epoch 864: loss = 0.03384841978549957\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012117220321670175 chamfer_loss_mesh:  0.021744914192822762\n",
      "eikonal_loss:  2.689051143534016e-05\n",
      "smoothed_heaviside_loss:  2.560870825618622e-06\n",
      "Epoch 865: loss = 0.03389158844947815\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012073039542883635 chamfer_loss_mesh:  0.024161759938579053\n",
      "eikonal_loss:  7.590052973682759e-06\n",
      "smoothed_heaviside_loss:  2.5642516447987873e-06\n",
      "Epoch 866: loss = 0.0362449549138546\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012141437036916614 chamfer_loss_mesh:  0.021700012439396232\n",
      "eikonal_loss:  8.735702976991888e-06\n",
      "smoothed_heaviside_loss:  2.5674062271718867e-06\n",
      "Epoch 867: loss = 0.033852752298116684\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012123800115659833 chamfer_loss_mesh:  0.02294712066941429\n",
      "eikonal_loss:  9.765321919985581e-06\n",
      "smoothed_heaviside_loss:  2.5706819997139974e-06\n",
      "Epoch 868: loss = 0.03508325666189194\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012154908617958426 chamfer_loss_mesh:  0.022098920453572646\n",
      "eikonal_loss:  0.00021753272449132055\n",
      "smoothed_heaviside_loss:  2.573834080976667e-06\n",
      "Epoch 869: loss = 0.03447393327951431\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012216154718771577 chamfer_loss_mesh:  0.021650983399013057\n",
      "eikonal_loss:  2.5792018277570605e-05\n",
      "smoothed_heaviside_loss:  2.5773185825528344e-06\n",
      "Epoch 870: loss = 0.03389550372958183\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012254694011062384 chamfer_loss_mesh:  0.021856358216609806\n",
      "eikonal_loss:  0.00010755538096418604\n",
      "smoothed_heaviside_loss:  2.5807048587012105e-06\n",
      "Epoch 871: loss = 0.034221187233924866\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012150035472586751 chamfer_loss_mesh:  0.021866551833227277\n",
      "eikonal_loss:  0.00022308861662168056\n",
      "smoothed_heaviside_loss:  2.5841438855422894e-06\n",
      "Epoch 872: loss = 0.034242261201143265\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012107875663787127 chamfer_loss_mesh:  0.02319078703294508\n",
      "eikonal_loss:  5.613685425487347e-05\n",
      "smoothed_heaviside_loss:  2.587597691672272e-06\n",
      "Epoch 873: loss = 0.035357385873794556\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.01213492127135396 chamfer_loss_mesh:  0.02159615723940078\n",
      "eikonal_loss:  8.47030823933892e-05\n",
      "smoothed_heaviside_loss:  2.5911169814207824e-06\n",
      "Epoch 874: loss = 0.03381837531924248\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012157622259110212 chamfer_loss_mesh:  0.021614861907437444\n",
      "eikonal_loss:  0.0012434974778443575\n",
      "smoothed_heaviside_loss:  2.594741545181023e-06\n",
      "Epoch 875: loss = 0.03501857444643974\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012122991029173136 chamfer_loss_mesh:  0.0223962779273279\n",
      "eikonal_loss:  0.000874459685292095\n",
      "smoothed_heaviside_loss:  2.5979977635870455e-06\n",
      "Epoch 876: loss = 0.03539632633328438\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012157957535237074 chamfer_loss_mesh:  0.022737756808055565\n",
      "eikonal_loss:  0.0001192922136397101\n",
      "smoothed_heaviside_loss:  2.601663936729892e-06\n",
      "Epoch 877: loss = 0.03501760959625244\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012100239982828498 chamfer_loss_mesh:  0.021652336727129295\n",
      "eikonal_loss:  4.378599987830967e-05\n",
      "smoothed_heaviside_loss:  2.6048708150483435e-06\n",
      "Epoch 878: loss = 0.03379896655678749\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012076378334313631 chamfer_loss_mesh:  0.023194872483145446\n",
      "eikonal_loss:  4.061342406203039e-05\n",
      "smoothed_heaviside_loss:  2.6084057935804594e-06\n",
      "Epoch 879: loss = 0.035314470529556274\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012083302717655897 chamfer_loss_mesh:  0.026548685127636418\n",
      "eikonal_loss:  3.705483322846703e-05\n",
      "smoothed_heaviside_loss:  2.611830723253661e-06\n",
      "Epoch 880: loss = 0.03867165744304657\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.01211768132634461 chamfer_loss_mesh:  0.022800202714279294\n",
      "eikonal_loss:  3.734839629032649e-05\n",
      "smoothed_heaviside_loss:  2.6149618861381896e-06\n",
      "Epoch 881: loss = 0.034957848489284515\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012056980049237609 chamfer_loss_mesh:  0.023518296075053513\n",
      "eikonal_loss:  0.00011433012696215883\n",
      "smoothed_heaviside_loss:  2.6180321128776995e-06\n",
      "Epoch 882: loss = 0.03569222614169121\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012122350744903088 chamfer_loss_mesh:  0.022858217562315986\n",
      "eikonal_loss:  7.047477265587077e-05\n",
      "smoothed_heaviside_loss:  2.6214927402179455e-06\n",
      "Epoch 883: loss = 0.035053666681051254\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012133759446442127 chamfer_loss_mesh:  0.02191042949561961\n",
      "eikonal_loss:  1.6875519577297382e-05\n",
      "smoothed_heaviside_loss:  2.624925400596112e-06\n",
      "Epoch 884: loss = 0.03406368941068649\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012244181707501411 chamfer_loss_mesh:  0.021840322006028146\n",
      "eikonal_loss:  1.6184416381292976e-05\n",
      "smoothed_heaviside_loss:  2.628544052640791e-06\n",
      "Epoch 885: loss = 0.03410331904888153\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012226942926645279 chamfer_loss_mesh:  0.02238787419628352\n",
      "eikonal_loss:  1.5013433767308015e-05\n",
      "smoothed_heaviside_loss:  2.6317986794310855e-06\n",
      "Epoch 886: loss = 0.03463246300816536\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012191045098006725 chamfer_loss_mesh:  0.021871994249522686\n",
      "eikonal_loss:  1.3770967598247807e-05\n",
      "smoothed_heaviside_loss:  2.6352915938332444e-06\n",
      "Epoch 887: loss = 0.03407944738864899\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012235353933647275 chamfer_loss_mesh:  0.022194250050233677\n",
      "eikonal_loss:  1.2852538020524662e-05\n",
      "smoothed_heaviside_loss:  2.6392369818495354e-06\n",
      "Epoch 888: loss = 0.03444509580731392\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012163890060037374 chamfer_loss_mesh:  0.02216932625742629\n",
      "eikonal_loss:  5.685072028427385e-05\n",
      "smoothed_heaviside_loss:  2.64277900896559e-06\n",
      "Epoch 889: loss = 0.03439270704984665\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.01215860596857965 chamfer_loss_mesh:  0.022252874259720556\n",
      "eikonal_loss:  1.4774034752917942e-05\n",
      "smoothed_heaviside_loss:  2.64597997556848e-06\n",
      "Epoch 890: loss = 0.034428901970386505\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012151619885116816 chamfer_loss_mesh:  0.021831430785823613\n",
      "eikonal_loss:  1.558122312417254e-05\n",
      "smoothed_heaviside_loss:  2.6493034965824336e-06\n",
      "Epoch 891: loss = 0.03400128334760666\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012204328086227179 chamfer_loss_mesh:  0.022072505089454353\n",
      "eikonal_loss:  1.654666084505152e-05\n",
      "smoothed_heaviside_loss:  2.652065177244367e-06\n",
      "Epoch 892: loss = 0.03429603576660156\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012235457543283701 chamfer_loss_mesh:  0.021872010620427318\n",
      "eikonal_loss:  1.7493797713541426e-05\n",
      "smoothed_heaviside_loss:  2.654851186889573e-06\n",
      "Epoch 893: loss = 0.0341276191174984\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012297448702156544 chamfer_loss_mesh:  0.021943244064459577\n",
      "eikonal_loss:  2.4044287783908658e-05\n",
      "smoothed_heaviside_loss:  2.657269988048938e-06\n",
      "Epoch 894: loss = 0.03426739573478699\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012176433810964227 chamfer_loss_mesh:  0.02246682925033383\n",
      "eikonal_loss:  1.7188260244438425e-05\n",
      "smoothed_heaviside_loss:  2.66050528807682e-06\n",
      "Epoch 895: loss = 0.034663110971450806\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012217637849971652 chamfer_loss_mesh:  0.021975190975354053\n",
      "eikonal_loss:  1.8184917280450463e-05\n",
      "smoothed_heaviside_loss:  2.663599616425927e-06\n",
      "Epoch 896: loss = 0.034213677048683167\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012234988389536738 chamfer_loss_mesh:  0.023549988327431493\n",
      "eikonal_loss:  0.0003788807080127299\n",
      "smoothed_heaviside_loss:  2.666530917849741e-06\n",
      "Epoch 897: loss = 0.03616652637720108\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012244994286447763 chamfer_loss_mesh:  0.022136320694698952\n",
      "eikonal_loss:  2.3528136807726696e-05\n",
      "smoothed_heaviside_loss:  2.669943341970793e-06\n",
      "Epoch 898: loss = 0.03440751135349274\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012191481655463576 chamfer_loss_mesh:  0.023193770175566897\n",
      "eikonal_loss:  2.0244035113137215e-05\n",
      "smoothed_heaviside_loss:  2.6733293907454936e-06\n",
      "Epoch 899: loss = 0.03540816903114319\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012158423196524382 chamfer_loss_mesh:  0.02215541826444678\n",
      "eikonal_loss:  2.6210114810965024e-05\n",
      "smoothed_heaviside_loss:  2.6763755158754066e-06\n",
      "Epoch 900: loss = 0.034342728555202484\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012184293009340763 chamfer_loss_mesh:  0.022005740902386606\n",
      "eikonal_loss:  1.9783508832915686e-05\n",
      "smoothed_heaviside_loss:  2.679724047993659e-06\n",
      "Epoch 901: loss = 0.034212496131658554\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012217286275699735 chamfer_loss_mesh:  0.02286641756654717\n",
      "eikonal_loss:  1.974995029740967e-05\n",
      "smoothed_heaviside_loss:  2.683020056792884e-06\n",
      "Epoch 902: loss = 0.03510613739490509\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012205339735373855 chamfer_loss_mesh:  0.02192429019487463\n",
      "eikonal_loss:  1.9539094864740036e-05\n",
      "smoothed_heaviside_loss:  2.685813797143055e-06\n",
      "Epoch 903: loss = 0.03415185585618019\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.01224388019181788 chamfer_loss_mesh:  0.022299140255199745\n",
      "eikonal_loss:  2.688151471375022e-05\n",
      "smoothed_heaviside_loss:  2.68909434453235e-06\n",
      "Epoch 904: loss = 0.03457259386777878\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012149577960371971 chamfer_loss_mesh:  0.021901645595789887\n",
      "eikonal_loss:  2.5011211619130336e-05\n",
      "smoothed_heaviside_loss:  2.6921325115836225e-06\n",
      "Epoch 905: loss = 0.0340789295732975\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012159841135144234 chamfer_loss_mesh:  0.02186081292165909\n",
      "eikonal_loss:  2.0940033209626563e-05\n",
      "smoothed_heaviside_loss:  2.695427156140795e-06\n",
      "Epoch 906: loss = 0.0340442918241024\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012167132226750255 chamfer_loss_mesh:  0.023415082978317514\n",
      "eikonal_loss:  3.531546099111438e-05\n",
      "smoothed_heaviside_loss:  2.6983514089806704e-06\n",
      "Epoch 907: loss = 0.035620227456092834\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012138895690441132 chamfer_loss_mesh:  0.021835739971720614\n",
      "eikonal_loss:  3.005357393703889e-05\n",
      "smoothed_heaviside_loss:  2.701848188735312e-06\n",
      "Epoch 908: loss = 0.034007392823696136\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012216755421832204 chamfer_loss_mesh:  0.0218487111851573\n",
      "eikonal_loss:  2.3164879166870378e-05\n",
      "smoothed_heaviside_loss:  2.7045416572946124e-06\n",
      "Epoch 909: loss = 0.03409133478999138\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012181609636172652 chamfer_loss_mesh:  0.02237591615994461\n",
      "eikonal_loss:  2.506641612853855e-05\n",
      "smoothed_heaviside_loss:  2.707753765207599e-06\n",
      "Epoch 910: loss = 0.03458530455827713\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012278362410143018 chamfer_loss_mesh:  0.022719592379871756\n",
      "eikonal_loss:  0.00016082880028989166\n",
      "smoothed_heaviside_loss:  2.7110054361401126e-06\n",
      "Epoch 911: loss = 0.035161495208740234\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.01223504077643156 chamfer_loss_mesh:  0.02242300979560241\n",
      "eikonal_loss:  5.678289380739443e-05\n",
      "smoothed_heaviside_loss:  2.7144988052896224e-06\n",
      "Epoch 912: loss = 0.03471754863858223\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012278817594051361 chamfer_loss_mesh:  0.0221470672840951\n",
      "eikonal_loss:  3.318194285384379e-05\n",
      "smoothed_heaviside_loss:  2.7176934054296e-06\n",
      "Epoch 913: loss = 0.03446178510785103\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012145008658990264 chamfer_loss_mesh:  0.022214753698790446\n",
      "eikonal_loss:  0.00021446177561301738\n",
      "smoothed_heaviside_loss:  2.7205496735405177e-06\n",
      "Epoch 914: loss = 0.03457694128155708\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012174707371741533 chamfer_loss_mesh:  0.024336306523764506\n",
      "eikonal_loss:  7.785129855619743e-05\n",
      "smoothed_heaviside_loss:  2.723914576563402e-06\n",
      "Epoch 915: loss = 0.03659158572554588\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012189650442451239 chamfer_loss_mesh:  0.022076117602409795\n",
      "eikonal_loss:  3.496305726002902e-05\n",
      "smoothed_heaviside_loss:  2.72693500846799e-06\n",
      "Epoch 916: loss = 0.0343034565448761\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012198338517919183 chamfer_loss_mesh:  0.02391277303104289\n",
      "eikonal_loss:  0.003529248759150505\n",
      "smoothed_heaviside_loss:  2.7303015031066025e-06\n",
      "Epoch 917: loss = 0.03964308649301529\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012248489074409008 chamfer_loss_mesh:  0.021975534764351323\n",
      "eikonal_loss:  3.043807009817101e-05\n",
      "smoothed_heaviside_loss:  2.733834662649315e-06\n",
      "Epoch 918: loss = 0.0342571958899498\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012250482104718685 chamfer_loss_mesh:  0.022205751520232297\n",
      "eikonal_loss:  2.9606788302771747e-05\n",
      "smoothed_heaviside_loss:  2.737406248343177e-06\n",
      "Epoch 919: loss = 0.034488577395677567\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012241292279213667 chamfer_loss_mesh:  0.023758053430356085\n",
      "eikonal_loss:  2.4475588361383416e-05\n",
      "smoothed_heaviside_loss:  2.7407356810726924e-06\n",
      "Epoch 920: loss = 0.03602656349539757\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012129045790061355 chamfer_loss_mesh:  0.022259388060774654\n",
      "eikonal_loss:  2.4102771931211464e-05\n",
      "smoothed_heaviside_loss:  2.7439368750492577e-06\n",
      "Epoch 921: loss = 0.03441528230905533\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012098842998966575 chamfer_loss_mesh:  0.02186715391871985\n",
      "eikonal_loss:  2.3394455638481304e-05\n",
      "smoothed_heaviside_loss:  2.7469736778584775e-06\n",
      "Epoch 922: loss = 0.033992137759923935\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.01215157681144774 chamfer_loss_mesh:  0.02183523065468762\n",
      "eikonal_loss:  2.396061427134555e-05\n",
      "smoothed_heaviside_loss:  2.750529574768734e-06\n",
      "Epoch 923: loss = 0.03401351720094681\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012163884239271283 chamfer_loss_mesh:  0.02230549944215454\n",
      "eikonal_loss:  2.3070386305334978e-05\n",
      "smoothed_heaviside_loss:  2.7539774691831553e-06\n",
      "Epoch 924: loss = 0.03449520841240883\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.01220281352289021 chamfer_loss_mesh:  0.022160724256536923\n",
      "eikonal_loss:  2.651234171935357e-05\n",
      "smoothed_heaviside_loss:  2.75750403488928e-06\n",
      "Epoch 925: loss = 0.03439280763268471\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012203124351799488 chamfer_loss_mesh:  0.021901003492530435\n",
      "eikonal_loss:  3.669930811156519e-05\n",
      "smoothed_heaviside_loss:  2.761101086434792e-06\n",
      "Epoch 926: loss = 0.034143589437007904\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012249058345332742 chamfer_loss_mesh:  0.022539912606589496\n",
      "eikonal_loss:  3.339628892717883e-05\n",
      "smoothed_heaviside_loss:  2.7645353384286864e-06\n",
      "Epoch 927: loss = 0.03482513129711151\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012316179927438498 chamfer_loss_mesh:  0.022432404875871725\n",
      "eikonal_loss:  2.998993113578763e-05\n",
      "smoothed_heaviside_loss:  2.767872729236842e-06\n",
      "Epoch 928: loss = 0.03478134050965309\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012391391210258007 chamfer_loss_mesh:  0.022889944375492632\n",
      "eikonal_loss:  3.177292092004791e-05\n",
      "smoothed_heaviside_loss:  2.7712837891158415e-06\n",
      "Epoch 929: loss = 0.03531587868928909\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012378013925626874 chamfer_loss_mesh:  0.023324530047830194\n",
      "eikonal_loss:  1.983939546335023e-05\n",
      "smoothed_heaviside_loss:  2.7748433240049053e-06\n",
      "Epoch 930: loss = 0.03572515770792961\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012450977228581905 chamfer_loss_mesh:  0.022776925106882118\n",
      "eikonal_loss:  4.819804598810151e-05\n",
      "smoothed_heaviside_loss:  2.7784644771600142e-06\n",
      "Epoch 931: loss = 0.03527887910604477\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012411121279001236 chamfer_loss_mesh:  0.02297321771038696\n",
      "eikonal_loss:  2.154300091206096e-05\n",
      "smoothed_heaviside_loss:  2.782265028145048e-06\n",
      "Epoch 932: loss = 0.035408664494752884\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012469550129026175 chamfer_loss_mesh:  0.02210954698966816\n",
      "eikonal_loss:  1.8876053218264133e-05\n",
      "smoothed_heaviside_loss:  2.7860887712449767e-06\n",
      "Epoch 933: loss = 0.03460076078772545\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012508616782724857 chamfer_loss_mesh:  0.022096499378676526\n",
      "eikonal_loss:  2.1643416403094307e-05\n",
      "smoothed_heaviside_loss:  2.7896123810933204e-06\n",
      "Epoch 934: loss = 0.03462954983115196\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012647086987271905 chamfer_loss_mesh:  0.022695568986819126\n",
      "eikonal_loss:  1.7029875380103476e-05\n",
      "smoothed_heaviside_loss:  2.792686473185313e-06\n",
      "Epoch 935: loss = 0.03536247834563255\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012594646541401744 chamfer_loss_mesh:  0.022132644517114386\n",
      "eikonal_loss:  6.196114554768428e-05\n",
      "smoothed_heaviside_loss:  2.795859927573474e-06\n",
      "Epoch 936: loss = 0.03479204699397087\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012675414327532053 chamfer_loss_mesh:  0.022084626834839582\n",
      "eikonal_loss:  1.8272783563588746e-05\n",
      "smoothed_heaviside_loss:  2.7989335649181157e-06\n",
      "Epoch 937: loss = 0.034781113266944885\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.01271229237318039 chamfer_loss_mesh:  0.02268560820084531\n",
      "eikonal_loss:  2.1124562408658676e-05\n",
      "smoothed_heaviside_loss:  2.802207518470823e-06\n",
      "Epoch 938: loss = 0.03542182967066765\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012710023438557982 chamfer_loss_mesh:  0.021947678760625422\n",
      "eikonal_loss:  1.905269527924247e-05\n",
      "smoothed_heaviside_loss:  2.8055233087798115e-06\n",
      "Epoch 939: loss = 0.034679561853408813\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.01267421175725758 chamfer_loss_mesh:  0.022367476049112156\n",
      "eikonal_loss:  2.9051834644633345e-05\n",
      "smoothed_heaviside_loss:  2.809194938890869e-06\n",
      "Epoch 940: loss = 0.035073548555374146\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012617764296010137 chamfer_loss_mesh:  0.021951711460133083\n",
      "eikonal_loss:  1.8010330677498132e-05\n",
      "smoothed_heaviside_loss:  2.8128822577855317e-06\n",
      "Epoch 941: loss = 0.03459030017256737\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012723658001050353 chamfer_loss_mesh:  0.022233884010347538\n",
      "eikonal_loss:  2.3299682652577758e-05\n",
      "smoothed_heaviside_loss:  2.815989091686788e-06\n",
      "Epoch 942: loss = 0.03498365730047226\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012600884074345231 chamfer_loss_mesh:  0.02232721817563288\n",
      "eikonal_loss:  1.9206969227525406e-05\n",
      "smoothed_heaviside_loss:  2.8191268484079046e-06\n",
      "Epoch 943: loss = 0.0349501296877861\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012540447060018778 chamfer_loss_mesh:  0.021871132048545405\n",
      "eikonal_loss:  1.548358704894781e-05\n",
      "smoothed_heaviside_loss:  2.822747774189338e-06\n",
      "Epoch 944: loss = 0.0344298854470253\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012455455726012588 chamfer_loss_mesh:  0.021877509425394237\n",
      "eikonal_loss:  3.0399443858186714e-05\n",
      "smoothed_heaviside_loss:  2.8259398732188856e-06\n",
      "Epoch 945: loss = 0.0343661904335022\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012573490384966135 chamfer_loss_mesh:  0.022146381525089964\n",
      "eikonal_loss:  2.8064521757187322e-05\n",
      "smoothed_heaviside_loss:  2.8294462026678957e-06\n",
      "Epoch 946: loss = 0.034750763326883316\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012540873140096664 chamfer_loss_mesh:  0.02346029577893205\n",
      "eikonal_loss:  4.324475230532698e-05\n",
      "smoothed_heaviside_loss:  2.8325639505055733e-06\n",
      "Epoch 947: loss = 0.03604724630713463\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012493812246248126 chamfer_loss_mesh:  0.0226485153689282\n",
      "eikonal_loss:  2.239654895674903e-05\n",
      "smoothed_heaviside_loss:  2.8355450467643095e-06\n",
      "Epoch 948: loss = 0.03516755998134613\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012460363795980811 chamfer_loss_mesh:  0.022611744498135522\n",
      "eikonal_loss:  1.9031540432479233e-05\n",
      "smoothed_heaviside_loss:  2.8393294542183867e-06\n",
      "Epoch 949: loss = 0.03509398177266121\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012486155610531569 chamfer_loss_mesh:  0.02276086888741702\n",
      "eikonal_loss:  2.1945370463072322e-05\n",
      "smoothed_heaviside_loss:  2.843133870555903e-06\n",
      "Epoch 950: loss = 0.03527181223034859\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012524201301857829 chamfer_loss_mesh:  0.0221747177420184\n",
      "eikonal_loss:  2.561967085057404e-05\n",
      "smoothed_heaviside_loss:  2.846863935701549e-06\n",
      "Epoch 951: loss = 0.03472738340497017\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012570925755426288 chamfer_loss_mesh:  0.02215601307398174\n",
      "eikonal_loss:  3.01408381346846e-05\n",
      "smoothed_heaviside_loss:  2.8506131002359325e-06\n",
      "Epoch 952: loss = 0.03475993126630783\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012599320616573095 chamfer_loss_mesh:  0.02219269663328305\n",
      "eikonal_loss:  3.8596914237132296e-05\n",
      "smoothed_heaviside_loss:  2.854316107914201e-06\n",
      "Epoch 953: loss = 0.03483346849679947\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012534601846709847 chamfer_loss_mesh:  0.023201089788926765\n",
      "eikonal_loss:  3.37405908794608e-05\n",
      "smoothed_heaviside_loss:  2.8578888304764405e-06\n",
      "Epoch 954: loss = 0.03577228635549545\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012592491693794727 chamfer_loss_mesh:  0.022778769562137313\n",
      "eikonal_loss:  2.506989949324634e-05\n",
      "smoothed_heaviside_loss:  2.861518396457541e-06\n",
      "Epoch 955: loss = 0.035399194806814194\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012581499759107828 chamfer_loss_mesh:  0.023132781279855408\n",
      "eikonal_loss:  2.2443666239269078e-05\n",
      "smoothed_heaviside_loss:  2.8655410915234825e-06\n",
      "Epoch 956: loss = 0.03573958948254585\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012529098894447088 chamfer_loss_mesh:  0.022442853151005693\n",
      "eikonal_loss:  2.1476836991496384e-05\n",
      "smoothed_heaviside_loss:  2.868936235245201e-06\n",
      "Epoch 957: loss = 0.03499629721045494\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.0126223627012223 chamfer_loss_mesh:  0.02247624797746539\n",
      "eikonal_loss:  1.7423531971871853e-05\n",
      "smoothed_heaviside_loss:  2.8732667942676926e-06\n",
      "Epoch 958: loss = 0.03511890769004822\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012618767796084285 chamfer_loss_mesh:  0.02280541775689926\n",
      "eikonal_loss:  2.436818613205105e-05\n",
      "smoothed_heaviside_loss:  2.8775875762221403e-06\n",
      "Epoch 959: loss = 0.03545143082737923\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012557327281683683 chamfer_loss_mesh:  0.022518283003591932\n",
      "eikonal_loss:  1.754004006215837e-05\n",
      "smoothed_heaviside_loss:  2.8809979539801134e-06\n",
      "Epoch 960: loss = 0.03509603440761566\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.01264834776520729 chamfer_loss_mesh:  0.02373993265791796\n",
      "eikonal_loss:  2.664515341166407e-05\n",
      "smoothed_heaviside_loss:  2.884450168494368e-06\n",
      "Epoch 961: loss = 0.03641780838370323\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012585632503032684 chamfer_loss_mesh:  0.025944562366930768\n",
      "eikonal_loss:  2.5841018214123324e-05\n",
      "smoothed_heaviside_loss:  2.8877002478111535e-06\n",
      "Epoch 962: loss = 0.038558922708034515\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012591787381097674 chamfer_loss_mesh:  0.02461139956722036\n",
      "eikonal_loss:  2.6370262276032008e-05\n",
      "smoothed_heaviside_loss:  2.891330950660631e-06\n",
      "Epoch 963: loss = 0.037232451140880585\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012712294701486826 chamfer_loss_mesh:  0.022401984097086824\n",
      "eikonal_loss:  2.3080825485521927e-05\n",
      "smoothed_heaviside_loss:  2.894957788157626e-06\n",
      "Epoch 964: loss = 0.0351402573287487\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.01267538988031447 chamfer_loss_mesh:  0.023887758288765326\n",
      "eikonal_loss:  7.449712575180456e-05\n",
      "smoothed_heaviside_loss:  2.898513912441558e-06\n",
      "Epoch 965: loss = 0.03664054721593857\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012683846289291978 chamfer_loss_mesh:  0.023417134798364714\n",
      "eikonal_loss:  2.2957481633056886e-05\n",
      "smoothed_heaviside_loss:  2.9023337901890045e-06\n",
      "Epoch 966: loss = 0.036126844584941864\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012688562273979187 chamfer_loss_mesh:  0.0222841372305993\n",
      "eikonal_loss:  2.366027001698967e-05\n",
      "smoothed_heaviside_loss:  2.9058046493446454e-06\n",
      "Epoch 967: loss = 0.034999262541532516\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012587372912093997 chamfer_loss_mesh:  0.02231138205388561\n",
      "eikonal_loss:  3.6520956200547516e-05\n",
      "smoothed_heaviside_loss:  2.9093141620251117e-06\n",
      "Epoch 968: loss = 0.034938182681798935\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012725371634587646 chamfer_loss_mesh:  0.022870150132803246\n",
      "eikonal_loss:  0.0001795604039216414\n",
      "smoothed_heaviside_loss:  2.913320713560097e-06\n",
      "Epoch 969: loss = 0.0357779935002327\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012670763535425067 chamfer_loss_mesh:  0.022700227418681607\n",
      "eikonal_loss:  0.00010272970393998548\n",
      "smoothed_heaviside_loss:  2.9166549211367965e-06\n",
      "Epoch 970: loss = 0.03547663614153862\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012744762934744358 chamfer_loss_mesh:  0.022596233975491486\n",
      "eikonal_loss:  4.426888335729018e-05\n",
      "smoothed_heaviside_loss:  2.9198974971222924e-06\n",
      "Epoch 971: loss = 0.03538818657398224\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012795953080058098 chamfer_loss_mesh:  0.022818987417849712\n",
      "eikonal_loss:  1.6888378013391048e-05\n",
      "smoothed_heaviside_loss:  2.9237310172902653e-06\n",
      "Epoch 972: loss = 0.03563475236296654\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012834100052714348 chamfer_loss_mesh:  0.022382469978765585\n",
      "eikonal_loss:  1.5100314158189576e-05\n",
      "smoothed_heaviside_loss:  2.9276225177454762e-06\n",
      "Epoch 973: loss = 0.03523459658026695\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012801531702280045 chamfer_loss_mesh:  0.023956821678439155\n",
      "eikonal_loss:  1.7360667698085308e-05\n",
      "smoothed_heaviside_loss:  2.930991286120843e-06\n",
      "Epoch 974: loss = 0.03677864745259285\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012835476081818342 chamfer_loss_mesh:  0.022357589841703884\n",
      "eikonal_loss:  1.6116953702294268e-05\n",
      "smoothed_heaviside_loss:  2.9340769742702832e-06\n",
      "Epoch 975: loss = 0.03521211817860603\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012883235467597842 chamfer_loss_mesh:  0.022549647837877274\n",
      "eikonal_loss:  2.094373121508397e-05\n",
      "smoothed_heaviside_loss:  2.9376958536886377e-06\n",
      "Epoch 976: loss = 0.035456765443086624\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012910693185403943 chamfer_loss_mesh:  0.022287094907369465\n",
      "eikonal_loss:  1.7370888599543832e-05\n",
      "smoothed_heaviside_loss:  2.941219236163306e-06\n",
      "Epoch 977: loss = 0.035218097269535065\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012900731526315212 chamfer_loss_mesh:  0.02226307879027445\n",
      "eikonal_loss:  1.9448640159680508e-05\n",
      "smoothed_heaviside_loss:  2.9444645406329073e-06\n",
      "Epoch 978: loss = 0.035186201333999634\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012913208920508623 chamfer_loss_mesh:  0.022724982045474462\n",
      "eikonal_loss:  2.7468622647575103e-05\n",
      "smoothed_heaviside_loss:  2.948464270957629e-06\n",
      "Epoch 979: loss = 0.03566860780119896\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012982868356630206 chamfer_loss_mesh:  0.02252907506772317\n",
      "eikonal_loss:  2.9589418772957288e-05\n",
      "smoothed_heaviside_loss:  2.9521158921852475e-06\n",
      "Epoch 980: loss = 0.03554448485374451\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.01288168365135789 chamfer_loss_mesh:  0.022559446733794175\n",
      "eikonal_loss:  3.235907570342533e-05\n",
      "smoothed_heaviside_loss:  2.9556790650531184e-06\n",
      "Epoch 981: loss = 0.0354764461517334\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.013042133068665862 chamfer_loss_mesh:  0.022314252419164404\n",
      "eikonal_loss:  3.2336058211512864e-05\n",
      "smoothed_heaviside_loss:  2.959213361464208e-06\n",
      "Epoch 982: loss = 0.035391684621572495\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012980961473658681 chamfer_loss_mesh:  0.022756328689865768\n",
      "eikonal_loss:  3.817218748736195e-05\n",
      "smoothed_heaviside_loss:  2.962462076538941e-06\n",
      "Epoch 983: loss = 0.03577842563390732\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012931755045428872 chamfer_loss_mesh:  0.023419135686708614\n",
      "eikonal_loss:  4.058194826939143e-05\n",
      "smoothed_heaviside_loss:  2.9661784992640605e-06\n",
      "Epoch 984: loss = 0.03639443963766098\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012972325785085559 chamfer_loss_mesh:  0.022292308131000027\n",
      "eikonal_loss:  4.323103348724544e-05\n",
      "smoothed_heaviside_loss:  2.969686647702474e-06\n",
      "Epoch 985: loss = 0.035310834646224976\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.013023469364270568 chamfer_loss_mesh:  0.022331816580845043\n",
      "eikonal_loss:  4.312146847951226e-05\n",
      "smoothed_heaviside_loss:  2.973259597638389e-06\n",
      "Epoch 986: loss = 0.03540137782692909\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.013035422889515758 chamfer_loss_mesh:  0.022494990844279528\n",
      "eikonal_loss:  4.632133641280234e-05\n",
      "smoothed_heaviside_loss:  2.976922360176104e-06\n",
      "Epoch 987: loss = 0.03557971119880676\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012892086524516344 chamfer_loss_mesh:  0.022345102479448542\n",
      "eikonal_loss:  5.9634465287672356e-05\n",
      "smoothed_heaviside_loss:  2.98012651001045e-06\n",
      "Epoch 988: loss = 0.03529980406165123\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012894358951598406 chamfer_loss_mesh:  0.02243247945443727\n",
      "eikonal_loss:  6.023561581969261e-05\n",
      "smoothed_heaviside_loss:  2.9841448849765584e-06\n",
      "Epoch 989: loss = 0.03539005666971207\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012884229654446244 chamfer_loss_mesh:  0.02261982808704488\n",
      "eikonal_loss:  1.8728687791735865e-05\n",
      "smoothed_heaviside_loss:  2.987840844070888e-06\n",
      "Epoch 990: loss = 0.03552577272057533\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012856029206886888 chamfer_loss_mesh:  0.02236415821244009\n",
      "eikonal_loss:  1.7776004824554548e-05\n",
      "smoothed_heaviside_loss:  2.991331257362617e-06\n",
      "Epoch 991: loss = 0.03524095565080643\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012891526566818357 chamfer_loss_mesh:  0.023929664166644216\n",
      "eikonal_loss:  1.6441557818325236e-05\n",
      "smoothed_heaviside_loss:  2.9945329060865333e-06\n",
      "Epoch 992: loss = 0.03684062510728836\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012908503413200378 chamfer_loss_mesh:  0.022847767468192615\n",
      "eikonal_loss:  1.5884204913163558e-05\n",
      "smoothed_heaviside_loss:  2.997666115334141e-06\n",
      "Epoch 993: loss = 0.03577515482902527\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012931048404425383 chamfer_loss_mesh:  0.023979686375241727\n",
      "eikonal_loss:  1.7671593013801612e-05\n",
      "smoothed_heaviside_loss:  3.0012813567736885e-06\n",
      "Epoch 994: loss = 0.03693140670657158\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.01293682842515409 chamfer_loss_mesh:  0.02276717350468971\n",
      "eikonal_loss:  1.7070964531740174e-05\n",
      "smoothed_heaviside_loss:  3.0050687200855464e-06\n",
      "Epoch 995: loss = 0.03572407737374306\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012884845491498709 chamfer_loss_mesh:  0.022377726054401137\n",
      "eikonal_loss:  1.5554996934952214e-05\n",
      "smoothed_heaviside_loss:  3.0078306281211553e-06\n",
      "Epoch 996: loss = 0.03528113290667534\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.012848232872784138 chamfer_loss_mesh:  0.022370126316673122\n",
      "eikonal_loss:  3.5229790228186175e-05\n",
      "smoothed_heaviside_loss:  3.010938598890789e-06\n",
      "Epoch 997: loss = 0.03525659814476967\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.01291555818170309 chamfer_loss_mesh:  0.022349142454913817\n",
      "eikonal_loss:  2.3078981030266732e-05\n",
      "smoothed_heaviside_loss:  3.0144724405545276e-06\n",
      "Epoch 998: loss = 0.03529079258441925\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.013075906317681074 chamfer_loss_mesh:  0.023063439584802836\n",
      "eikonal_loss:  6.660984945483506e-05\n",
      "smoothed_heaviside_loss:  3.0185619834810495e-06\n",
      "Epoch 999: loss = 0.036208976060152054\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.013009036192670465 chamfer_loss_mesh:  0.022506148525280878\n",
      "eikonal_loss:  1.8797520169755444e-05\n",
      "smoothed_heaviside_loss:  3.0220035114325583e-06\n",
      "Epoch 1000: loss = 0.0355370007455349\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "Sites length:  34312\n",
      "min sites:  tensor(-1.0445, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "max sites:  tensor(1.0598, device='cuda:0', grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "site_file_path = f\"{destination}{max_iter}_cvt_{lambda_cvt}_chamfer_{lambda_chamfer}_eikonal_{lambda_eikonal}.npy\"\n",
    "# check if optimized sites file exists\n",
    "if not os.path.exists(site_file_path):\n",
    "    # import sites\n",
    "    print(\"Importing sites\")\n",
    "    sites = np.load(site_file_path)\n",
    "    sites = torch.from_numpy(sites).to(device).requires_grad_(True)\n",
    "else:\n",
    "    # import cProfile, pstats\n",
    "    # import time\n",
    "\n",
    "    # profiler = cProfile.Profile()\n",
    "    # profiler.enable()\n",
    "\n",
    "    # with torch.profiler.profile(\n",
    "    #     activities=[\n",
    "    #         torch.profiler.ProfilerActivity.CPU,\n",
    "    #         torch.profiler.ProfilerActivity.CUDA,\n",
    "    #     ],\n",
    "    #     record_shapes=False,\n",
    "    #     with_stack=True,  # Captures function calls\n",
    "    # ) as prof:\n",
    "    #     sites, optimized_sites_sdf = train_DCCVT(\n",
    "    #         sites, sdf0, max_iter=max_iter, upsampling=0, lambda_weights=lambda_weights\n",
    "    #     )\n",
    "\n",
    "    # print(prof.key_averages().table(sort_by=\"self_cuda_time_total\"))\n",
    "    # prof.export_chrome_trace(\"trace.json\")\n",
    "\n",
    "    sites, optimized_sites_sdf = train_DCCVT(\n",
    "        sites, sdf0, max_iter=max_iter, upsampling=10, lambda_weights=lambda_weights\n",
    "    )\n",
    "\n",
    "    sites_np = sites.detach().cpu().numpy()\n",
    "    np.save(site_file_path, sites_np)\n",
    "\n",
    "print(\"Sites length: \", len(sites))\n",
    "print(\"min sites: \", torch.min(sites))\n",
    "print(\"max sites: \", torch.max(sites))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b7f7237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sdf torch.Size([34312])\n",
      "sites ./images/autograd/End2End_DCCVT_interpolSDF/gargoyle1000_1000_3d_sites_4096_chamfer1000.pth\n",
      "sites_np shape:  (34312, 3)\n"
     ]
    }
   ],
   "source": [
    "epoch = 1000\n",
    "\n",
    "# model_file_path = f'{destination}{mesh[0]}{max_iter}_{epoch}_3d_model_{num_centroids}_chamfer{lambda_chamfer}.pth'\n",
    "site_file_path = f\"{destination}{mesh[0]}{max_iter}_{epoch}_3d_sites_{num_centroids}_chamfer{lambda_chamfer}.pth\"\n",
    "sdf_file_path = f\"{destination}{mesh[0]}{max_iter}_{epoch}_3d_sdf_{num_centroids}_chamfer{lambda_chamfer}.pth\"\n",
    "\n",
    "\n",
    "sites = torch.load(site_file_path)\n",
    "sdf_v = torch.load(sdf_file_path)\n",
    "\n",
    "sites_np = sites.detach().cpu().numpy()\n",
    "print(\"sdf\", sdf_v.shape)\n",
    "print(\"sites\", site_file_path)\n",
    "\n",
    "ps_cloud_f = ps.register_point_cloud(f\"{epoch} epoch_cvt_grid\", sites_np)\n",
    "ps_cloud_f.add_scalar_quantity(\n",
    "    \"vis_grid_pred\",\n",
    "    sdf_v.detach().cpu().numpy(),\n",
    "    enabled=True,\n",
    "    cmap=\"coolwarm\",\n",
    "    vminmax=(-0.15, 0.15),\n",
    ")\n",
    "\n",
    "print(\"sites_np shape: \", sites_np.shape)\n",
    "\n",
    "# print sites if Nan\n",
    "if np.isnan(sites_np).any():\n",
    "    print(\"sites_np contains NaN values\")\n",
    "    print(\"sites_np NaN values: \", np.isnan(sites_np).sum())\n",
    "# remove nan values from sites tensor\n",
    "sites_np = sites_np[~np.isnan(sites_np).any(axis=1)]\n",
    "sites = torch.from_numpy(sites_np).to(device).requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82a1aa94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wylliam/dev/Kyushu_experiments-1/sdfpred_utils/sdfpred_utils.py:2354: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  d3dsimplices = torch.tensor(d3dsimplices, device=sites.device)  # (M,4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of bisectors to compute: torch.Size([117992, 3])\n",
      "Number of bisectors sorted: torch.Size([117992, 2])\n",
      "46678\n"
     ]
    }
   ],
   "source": [
    "d3dsimplices, _ = pygdel3d.triangulate(sites_np)\n",
    "d3dsimplices = torch.tensor(d3dsimplices, device=device)\n",
    "b, f = su.NOT_mt_extraction(sites, sdf_v, d3dsimplices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9c0c094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<polyscope.surface_mesh.SurfaceMesh at 0x7fe4a030b830>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps.register_surface_mesh(\n",
    "    \"NOT_mt_extraction\",\n",
    "    b,\n",
    "    f,\n",
    "    back_face_policy=\"identical\",\n",
    "    enabled=False,\n",
    ")\n",
    "# ps.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d0f86bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zc true_Sdf shape:  torch.Size([35657, 4])\n",
      "zc optimized sdf : torch.Size([35657, 4])\n",
      "sum of zc true Sdf:  202.3155975341797\n",
      "sum of zc opti Sdf:  47.616817474365234\n",
      "Diff   of   sum:  154.69876098632812\n",
      "Mean of zc true Sdf:  0.0010846310760825872\n"
     ]
    }
   ],
   "source": [
    "# metric between sites sdf values and their corresponding sdf values on hotspot model\n",
    "true_Sdf = model(sites).squeeze(-1)\n",
    "d3dsimplices, _ = pygdel3d.triangulate(sites_np)\n",
    "d3dsimplices = np.array(d3dsimplices)\n",
    "vertices_to_compute, bisectors_to_compute, used_tet = su.compute_zero_crossing_vertices_3d(\n",
    "    sites, None, None, d3dsimplices, sdf_v\n",
    ")\n",
    "d3dsimplices = torch.tensor(d3dsimplices, device=device)\n",
    "d3d = d3dsimplices[used_tet]\n",
    "zc_sdf = sdf_v[d3d]\n",
    "zc_truesdf = true_Sdf[d3d]\n",
    "print(\"zc true_Sdf shape: \", zc_truesdf.shape)\n",
    "print(\"zc optimized sdf :\", zc_sdf.shape)\n",
    "print(\"sum of zc true Sdf: \", torch.sum(zc_truesdf).item())\n",
    "print(\"sum of zc opti Sdf: \", torch.sum(zc_sdf).item())\n",
    "print(\"Diff   of   sum: \", torch.sum(zc_truesdf - zc_sdf).item())\n",
    "print(\"Mean of zc true Sdf: \", torch.mean(zc_truesdf - zc_sdf).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9772bb82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Delaunay simplices...\n",
      "Number of Delaunay simplices: 207878\n",
      "Delaunay simplices shape: [[  512  1026     0  2049]\n",
      " [ 2816  3072     0   256]\n",
      " [  251   213    11     7]\n",
      " ...\n",
      " [30754 30750 30753 25569]\n",
      " [30753 30750 30755 30752]\n",
      " [30750 30755 30754 30753]]\n",
      "Max vertex index in simplices: 34311\n",
      "Min vertex index in simplices: 0\n",
      "Site index range: 34312\n",
      "Computing Delaunay simplices...\n",
      "Number of Delaunay simplices: 207878\n",
      "Delaunay simplices shape: [[31193 21134 21133 22038]\n",
      " [  514   513   512   257]\n",
      " [  512  1026     0  2049]\n",
      " ...\n",
      " [28408  8597 16534 33371]\n",
      " [16263  4874 19407 19404]\n",
      " [33371 24083 20529 26761]]\n",
      "Max vertex index in simplices: 34311\n",
      "Min vertex index in simplices: 0\n",
      "Site index range: 34312\n"
     ]
    }
   ],
   "source": [
    "# v_vect, f_vect = su.get_clipped_mesh_numba(sites, model, None, True)\n",
    "# ps.register_surface_mesh(\"model final clipped polygon mesh\", v_vect.detach().cpu().numpy(), f_vect)\n",
    "\n",
    "# v_vect, f_vect = su.get_clipped_mesh_numba(sites, model, None, False)\n",
    "# ps.register_surface_mesh(\"model final polygon mesh\", v_vect.detach().cpu().numpy(), f_vect)\n",
    "\n",
    "######################################################\n",
    "\n",
    "# if mesh[0] == \"sphere\":\n",
    "#     # generate sphere sdf\n",
    "#     print(\"Generating sphere SDF\")\n",
    "#     sdf_v = sphere_sdf(sites, torch.zeros(3).to(device), 0.50)\n",
    "\n",
    "\n",
    "(\n",
    "    v_vect,\n",
    "    f_vect,\n",
    "    _,\n",
    "    _,\n",
    "    _,\n",
    ") = su.get_clipped_mesh_numba(sites, None, None, False, sdf_v, True)\n",
    "\n",
    "f_vect = [[f[0], f[i], f[i + 1]] for f in f_vect for i in range(1, len(f) - 1)]\n",
    "\n",
    "ps.register_surface_mesh(\n",
    "    \"sdf final unclipped polygon mesh\",\n",
    "    v_vect.detach().cpu().numpy(),\n",
    "    f_vect,\n",
    "    back_face_policy=\"identical\",\n",
    "    enabled=False,\n",
    ")\n",
    "\n",
    "\n",
    "v_vect, f_vect, _, _, _ = su.get_clipped_mesh_numba(sites, None, None, True, sdf_v, True)\n",
    "f_vect = [[f[0], f[i], f[i + 1]] for f in f_vect for i in range(1, len(f) - 1)]\n",
    "ps.register_surface_mesh(\n",
    "    \"sdf final clipped polygon mesh\", v_vect.detach().cpu().numpy(), f_vect, back_face_policy=\"identical\"\n",
    ")\n",
    "# f_vect = [[f[0], f[i], f[i + 1]] for f in f_vect for i in range(1, len(f) - 1)]\n",
    "\n",
    "d3dsimplices, _ = pygdel3d.triangulate(sites_np)\n",
    "d3dsimplices = torch.tensor(d3dsimplices, device=device)\n",
    "marching_tetrehedra_mesh = kaolin.ops.conversions.marching_tetrahedra(\n",
    "    sites.unsqueeze(0), d3dsimplices, sdf_v.unsqueeze(0), return_tet_idx=False\n",
    ")\n",
    "vertices_list, faces_list = marching_tetrehedra_mesh\n",
    "v_vect = vertices_list[0]\n",
    "faces = faces_list[0]\n",
    "\n",
    "ps.register_surface_mesh(\n",
    "    \"MTET\", v_vect.detach().cpu().numpy(), faces.detach().cpu().numpy(), back_face_policy=\"identical\"\n",
    ")\n",
    "\n",
    "# export obj file\n",
    "output_obj_file = (\n",
    "    f\"{destination}{mesh[0]}{max_iter}_{epoch}_3d_sites_{num_centroids}_chamfer{lambda_chamfer}_outputmesh.obj\"\n",
    ")\n",
    "output_ply_file = (\n",
    "    f\"{destination}{mesh[0]}{max_iter}_{epoch}_3d_sites_{num_centroids}_chamfer{lambda_chamfer}_targetpointcloud.ply\"\n",
    ")\n",
    "su.save_obj(output_obj_file, v_vect.detach().cpu().numpy(), f_vect)\n",
    "su.save_target_pc_ply(output_ply_file, mnfld_points.squeeze(0).detach().cpu().numpy())\n",
    "\n",
    "\n",
    "ps.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa2a2308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sites, sdf = train_DCCVT(\n",
    "#     sites, sdf_v, max_iter=max_iter, upsampling=0, lambda_weights=lambda_weights, voroloss_optim=True\n",
    "# )\n",
    "# (\n",
    "#     v_vect,\n",
    "#     f_vect,\n",
    "#     _,\n",
    "#     _,\n",
    "#     _,\n",
    "# ) = su.get_clipped_mesh_numba(sites, None, None, False, sdf, True)\n",
    "# ps.register_surface_mesh(\"voromeh sdf final unclipped polygon mesh\", v_vect.detach().cpu().numpy(), f_vect)\n",
    "\n",
    "\n",
    "# v_vect, f_vect, _, _, _ = su.get_clipped_mesh_numba(sites, None, None, True, sdf, True)\n",
    "# ps.register_surface_mesh(\"voromeh sdf final clipped polygon mesh\", v_vect.detach().cpu().numpy(), f_vect)\n",
    "# # f_vect = [[f[0], f[i], f[i + 1]] for f in f_vect for i in range(1, len(f) - 1)]\n",
    "# ps.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a71d0ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 25436 is out of bounds for axis 0 with size 23337",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 35\u001b[39m\n\u001b[32m     30\u001b[39m     accuracy = np.mean(dists_ours_to_gt**\u001b[32m2\u001b[39m)\n\u001b[32m     32\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m accuracy, completeness\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m ours_pts, _ = \u001b[43msample_points_on_mesh\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_obj_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_points\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m m = mesh[\u001b[32m1\u001b[39m].replace(\u001b[33m\"\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmesh\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     37\u001b[39m gt_pts, _ = sample_points_on_mesh(m + \u001b[33m\"\u001b[39m\u001b[33m.obj\u001b[39m\u001b[33m\"\u001b[39m, n_points=\u001b[32m100000\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36msample_points_on_mesh\u001b[39m\u001b[34m(mesh_path, n_points)\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msample_points_on_mesh\u001b[39m(mesh_path, n_points=\u001b[32m100000\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     mesh = \u001b[43mtrimesh\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmesh_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m     \u001b[38;5;66;03m# normalize mesh\u001b[39;00m\n\u001b[32m     10\u001b[39m     mesh.apply_translation(-mesh.centroid)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/Kyushu_experiments-1/venv/lib/python3.12/site-packages/trimesh/exchange/load.py:111\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(file_obj, file_type, resolver, force, allow_remote, **kwargs)\u001b[39m\n\u001b[32m     81\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     82\u001b[39m \u001b[33;03mTHIS FUNCTION IS DEPRECATED but there are no current plans for it to be removed.\u001b[39;00m\n\u001b[32m     83\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    107\u001b[39m \u001b[33;03m  Loaded geometry as trimesh classes\u001b[39;00m\n\u001b[32m    108\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    110\u001b[39m \u001b[38;5;66;03m# call the most general loading case into a `Scene`.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m loaded = \u001b[43mload_scene\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    112\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfile_obj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfile_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    113\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfile_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfile_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    114\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresolver\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresolver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    115\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_remote\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_remote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    117\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m force == \u001b[33m\"\u001b[39m\u001b[33mmesh\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# new code should use `load_mesh` for this\u001b[39;00m\n\u001b[32m    121\u001b[39m     log.debug(\n\u001b[32m    122\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m`trimesh.load(force=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mmesh\u001b[39m\u001b[33m'\u001b[39m\u001b[33m)` is a compatibility wrapper for `trimesh.load_mesh`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    123\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/Kyushu_experiments-1/venv/lib/python3.12/site-packages/trimesh/exchange/load.py:216\u001b[39m, in \u001b[36mload_scene\u001b[39m\u001b[34m(file_obj, file_type, resolver, allow_remote, metadata, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m arg.file_type \u001b[38;5;129;01min\u001b[39;00m mesh_loaders:\n\u001b[32m    213\u001b[39m     \u001b[38;5;66;03m# use mesh loader\u001b[39;00m\n\u001b[32m    214\u001b[39m     parsed = deepcopy(kwargs)\n\u001b[32m    215\u001b[39m     parsed.update(\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m         \u001b[43mmesh_loaders\u001b[49m\u001b[43m[\u001b[49m\u001b[43marg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfile_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfile_obj\u001b[49m\u001b[43m=\u001b[49m\u001b[43marg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfile_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfile_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43marg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfile_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m            \u001b[49m\u001b[43mresolver\u001b[49m\u001b[43m=\u001b[49m\u001b[43marg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresolver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    220\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    221\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    222\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    223\u001b[39m     )\n\u001b[32m    224\u001b[39m     loaded = _load_kwargs(**parsed)\n\u001b[32m    226\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m arg.file_type \u001b[38;5;129;01min\u001b[39;00m compressed_loaders:\n\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# for archives, like ZIP files\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/Kyushu_experiments-1/venv/lib/python3.12/site-packages/trimesh/exchange/obj.py:244\u001b[39m, in \u001b[36mload_obj\u001b[39m\u001b[34m(file_obj, resolver, group_material, skip_materials, maintain_order, metadata, **kwargs)\u001b[39m\n\u001b[32m    242\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    243\u001b[39m     mask_v = np.zeros(\u001b[38;5;28mlen\u001b[39m(v), dtype=\u001b[38;5;28mbool\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m244\u001b[39m \u001b[43mmask_v\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfaces\u001b[49m\u001b[43m]\u001b[49m = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    246\u001b[39m \u001b[38;5;66;03m# reconstruct the faces with the new vertex indices\u001b[39;00m\n\u001b[32m    247\u001b[39m inverse = np.zeros(\u001b[38;5;28mlen\u001b[39m(v), dtype=np.int64)\n",
      "\u001b[31mIndexError\u001b[39m: index 25436 is out of bounds for axis 0 with size 23337"
     ]
    }
   ],
   "source": [
    "# chamfer metric\n",
    "# add sampled points to polyscope and ground truth mesh to polyscope\n",
    "\n",
    "import trimesh\n",
    "\n",
    "\n",
    "def sample_points_on_mesh(mesh_path, n_points=100000):\n",
    "    mesh = trimesh.load(mesh_path)\n",
    "    # normalize mesh\n",
    "    mesh.apply_translation(-mesh.centroid)\n",
    "    mesh.apply_scale(1.0 / np.max(np.abs(mesh.vertices)))\n",
    "    # export mesh to obj file\n",
    "    mesh.export(mesh_path.replace(\".obj\", \".obj\"))\n",
    "    print(mesh_path)\n",
    "    points, _ = trimesh.sample.sample_surface(mesh, n_points)\n",
    "    return points, mesh\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "\n",
    "def chamfer_accuracy_completeness(ours_pts, gt_pts):\n",
    "    # Completeness: GT  Ours\n",
    "    dists_gt_to_ours = cKDTree(ours_pts).query(gt_pts, k=1)[0]\n",
    "    completeness = np.mean(dists_gt_to_ours**2)\n",
    "\n",
    "    # Accuracy: Ours  GT\n",
    "    dists_ours_to_gt = cKDTree(gt_pts).query(ours_pts, k=1)[0]\n",
    "    accuracy = np.mean(dists_ours_to_gt**2)\n",
    "\n",
    "    return accuracy, completeness\n",
    "\n",
    "\n",
    "ours_pts, _ = sample_points_on_mesh(output_obj_file, n_points=100000)\n",
    "m = mesh[1].replace(\"data\", \"mesh\")\n",
    "gt_pts, _ = sample_points_on_mesh(m + \".obj\", n_points=100000)\n",
    "\n",
    "acc, comp = chamfer_accuracy_completeness(ours_pts, gt_pts)\n",
    "\n",
    "print(f\"Chamfer Accuracy (Ours  GT): {acc:.6f}\")\n",
    "print(f\"Chamfer Completeness (GT  Ours): {comp:.6f}\")\n",
    "print(f\"Chamfer Distance (symmetric): {acc + comp:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910f8f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_points_on_mesh(mesh_path, n_points=100000):\n",
    "    mesh = trimesh.load(mesh_path)\n",
    "\n",
    "    # Normalize mesh (centered and scaled uniformly)\n",
    "    bbox = mesh.bounds\n",
    "    center = mesh.centroid\n",
    "    scale = np.linalg.norm(bbox[1] - bbox[0])\n",
    "    mesh.apply_translation(-center)\n",
    "    mesh.apply_scale(1.0 / scale)\n",
    "\n",
    "    # Export normalized mesh\n",
    "    mesh.export(mesh_path.replace(\".obj\", \".obj\"))\n",
    "\n",
    "    points, _ = trimesh.sample.sample_surface(mesh, n_points)\n",
    "    return points, mesh\n",
    "\n",
    "\n",
    "_, _ = sample_points_on_mesh(\n",
    "    \"/home/wylliam/dev/Kyushu_experiments/outputs/gargoyle_unconverged/cdp1000_v0_cvt100_clipTrue_buildFalse_upsampling0_num_centroids32_target_size32_final.obj\",\n",
    "    n_points=100000,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
