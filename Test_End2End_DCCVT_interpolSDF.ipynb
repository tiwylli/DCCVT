{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1f9796c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device:  NVIDIA GeForce RTX 3080\n"
     ]
    }
   ],
   "source": [
    "import kaolin\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import polyscope as ps\n",
    "\n",
    "# import diffvoronoi\n",
    "import pygdel3d\n",
    "import sdfpred_utils.sdfpred_utils as su\n",
    "import sdfpred_utils.loss_functions as lf\n",
    "from pytorch3d.loss import chamfer_distance\n",
    "from pytorch3d.ops import knn_points, knn_gather\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# cuda devices\n",
    "device = torch.device(\"cuda:0\")\n",
    "print(\"Using device: \", torch.cuda.get_device_name(device))\n",
    "\n",
    "# Improve reproducibility\n",
    "torch.manual_seed(69)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(69)\n",
    "\n",
    "input_dims = 3\n",
    "lr_sites = 0.005\n",
    "# lr_model = 0.00001\n",
    "destination = \"./images/autograd/End2End_DCCVT_interpolSDF/\"\n",
    "model_trained_it = \"\"\n",
    "# ROOT_DIR = \"/home/wylliam/dev/Kyushu_experiments\"\n",
    "ROOT_DIR = \"/home/beltegeuse/projects/Voronoi/Kyushu_experiments\"\n",
    "\n",
    "\n",
    "# mesh = [\"sphere\"]\n",
    "\n",
    "# mesh = [\"gargoyle\", \"/home/wylliam/dev/Kyushu_experiments/data/gargoyle\"]\n",
    "# trained_model_path = f\"/home/wylliam/dev/HotSpot/log/3D/pc/HotSpot-all-2025-04-24-18-16-03/gargoyle/gargoyle/trained_models/model{model_trained_it}.pth\"\n",
    "\n",
    "mesh = [\n",
    "    \"gargoyle\",\n",
    "    f\"{ROOT_DIR}/mesh/thingi32/64764\",\n",
    "]\n",
    "trained_model_path = f\"{ROOT_DIR}/hotspots_model/thingi32/64764.pth\"\n",
    "\n",
    "# mesh = [\"zombie\", f\"{ROOT_DIR}/mesh/thingi32/398259\"]\n",
    "# trained_model_path = f\"{ROOT_DIR}/hotspots_model/thingi32/398259.pth\"\n",
    "\n",
    "# mesh = [\"gargoyle_unconverged\", \"/home/wylliam/dev/Kyushu_experiments/mesh/gargoyle_unconverged\"]\n",
    "# trained_model_path = f\"/home/wylliam/dev/HotSpot/log/3D/pc/HotSpot-all-2025-04-24-18-16-03/gargoyle/gargoyle/trained_models/model_500.pth\"\n",
    "\n",
    "\n",
    "# mesh = [\"chair\", \"/home/wylliam/dev/Kyushu_experiments/data/chair\"]\n",
    "# trained_model_path = f\"/home/wylliam/dev/HotSpot/log/3D/pc/HotSpot-all-2025-05-02-17-56-25/chair/chair/trained_models/model{model_trained_it}.pth\"\n",
    "# #\n",
    "# mesh = [\"bunny\", \"/home/wylliam/dev/Kyushu_experiments/data/bunny\"]\n",
    "# trained_model_path = f\"/home/wylliam/dev/HotSpot/log/3D/pc/HotSpot-all-2025-04-25-17-32-49/bunny/bunny/trained_models/model{model_trained_it}.pth\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3f27a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new sites\n",
      "Sites shape:  torch.Size([32768, 3])\n",
      "Sites:  tensor([-1.0027, -1.0065, -0.9978], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "[polyscope] Backend: openGL3_glfw -- Loaded openGL version: 3.3.0 NVIDIA 575.64.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/beltegeuse/projects/Voronoi/Kyushu_experiments/.venv/lib/python3.13/site-packages/torch/functional.py:554: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:4314.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "num_centroids = 32**3\n",
    "grid = 32  # 128\n",
    "print(\"Creating new sites\")\n",
    "noise_scale = 0.005\n",
    "domain_limit = 1\n",
    "x = torch.linspace(-domain_limit, domain_limit, int(round(num_centroids ** (1 / 3))))\n",
    "y = torch.linspace(-domain_limit, domain_limit, int(round(num_centroids ** (1 / 3))))\n",
    "z = torch.linspace(-domain_limit, domain_limit, int(round(num_centroids ** (1 / 3))))\n",
    "meshgrid = torch.meshgrid(x, y, z)\n",
    "meshgrid = torch.stack(meshgrid, dim=3).view(-1, 3)\n",
    "\n",
    "# add noise to meshgrid\n",
    "meshgrid += torch.randn_like(meshgrid) * noise_scale\n",
    "\n",
    "\n",
    "sites = meshgrid.to(device, dtype=torch.float32).requires_grad_(True)\n",
    "\n",
    "print(\"Sites shape: \", sites.shape)\n",
    "print(\"Sites: \", sites[0])\n",
    "ps.init()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2df77f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnfld_points shape:  torch.Size([1, 9600, 3])\n",
      "torch.float32\n",
      "torch.Size([32768, 3])\n",
      "Allocated: 430.440448 MB, Reserved: 444.596224 MB\n",
      "torch.Size([32768])\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# LOAD MODEL WITH HOTSPOT\n",
    "\n",
    "import sys\n",
    "\n",
    "if mesh[0] != \"sphere\":\n",
    "    sys.path.append(\"3rdparty/HotSpot\")\n",
    "    from dataset import shape_3d\n",
    "    import models.Net as Net\n",
    "\n",
    "    loss_type = \"igr_w_heat\"\n",
    "    loss_weights = [350, 0, 0, 1, 0, 0, 20]\n",
    "\n",
    "    train_set = shape_3d.ReconDataset(\n",
    "        file_path=mesh[1] + \".ply\",\n",
    "        n_points=grid * grid * 150,  # 15000, #args.n_points,\n",
    "        n_samples=10001,  # args.n_iterations,\n",
    "        grid_res=256,  # args.grid_res,\n",
    "        grid_range=1.1,  # args.grid_range,\n",
    "        sample_type=\"uniform_central_gaussian\",  # args.nonmnfld_sample_type,\n",
    "        sampling_std=0.5,  # args.nonmnfld_sample_std,\n",
    "        n_random_samples=7500,  # args.n_random_samples,\n",
    "        resample=True,\n",
    "        compute_sal_dist_gt=(True if \"sal\" in loss_type and loss_weights[5] > 0 else False),\n",
    "        scale_method=\"mean\",  # \"mean\" #args.pcd_scale_method,\n",
    "    )\n",
    "\n",
    "    model = Net.Network(\n",
    "        latent_size=0,  # args.latent_size,\n",
    "        in_dim=3,\n",
    "        decoder_hidden_dim=128,  # args.decoder_hidden_dim,\n",
    "        nl=\"sine\",  # args.nl,\n",
    "        encoder_type=\"none\",  # args.encoder_type,\n",
    "        decoder_n_hidden_layers=5,  # args.decoder_n_hidden_layers,\n",
    "        neuron_type=\"quadratic\",  # args.neuron_type,\n",
    "        init_type=\"mfgi\",  # args.init_type,\n",
    "        sphere_init_params=[1.6, 0.1],  # args.sphere_init_params,\n",
    "        n_repeat_period=30,  # args.n_repeat_period,\n",
    "    )\n",
    "    model.to(device)\n",
    "\n",
    "    ######\n",
    "    test_dataloader = torch.utils.data.DataLoader(\n",
    "        train_set, batch_size=1, shuffle=False, num_workers=0, pin_memory=False\n",
    "    )\n",
    "    test_data = next(iter(test_dataloader))\n",
    "    mnfld_points = test_data[\"mnfld_points\"].to(device)\n",
    "\n",
    "    # add noise to mnfld_points\n",
    "    # mnfld_points += torch.randn_like(mnfld_points) * noise_scale * 2\n",
    "\n",
    "    mnfld_points.requires_grad_()\n",
    "    print(\"mnfld_points shape: \", mnfld_points.shape)\n",
    "    if torch.cuda.is_available():\n",
    "        map_location = torch.device(\"cuda\")\n",
    "    else:\n",
    "        map_location = torch.device(\"cpu\")\n",
    "    model.load_state_dict(torch.load(trained_model_path, weights_only=True, map_location=map_location))\n",
    "    sdf0 = model(sites)\n",
    "\n",
    "else:\n",
    "\n",
    "    def sphere_sdf(points: torch.Tensor, center: torch.Tensor, radius: float) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Compute the SDF of a sphere at given 3D points.\n",
    "\n",
    "        Args:\n",
    "            points: (N, 3) tensor of 3D query points\n",
    "            center: (3,) tensor specifying the center of the sphere\n",
    "            radius: float, radius of the sphere\n",
    "\n",
    "        Returns:\n",
    "            sdf: (N,) tensor of signed distances\n",
    "        \"\"\"\n",
    "        return torch.norm(points - center, dim=-1) - radius\n",
    "\n",
    "    def sphere_sdf_with_noise(\n",
    "        points: torch.Tensor, center: torch.Tensor, radius: float, noise_amplitude=0.05\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Sphere SDF with smooth directional noise added near the surface.\n",
    "\n",
    "        Args:\n",
    "            points: (N, 3)\n",
    "            center: (3,)\n",
    "            radius: float\n",
    "            noise_amplitude: float\n",
    "\n",
    "        Returns:\n",
    "            sdf: (N,)\n",
    "        \"\"\"\n",
    "        rel = points - center\n",
    "        norm = torch.norm(rel, dim=-1)  # (N,)\n",
    "        base_sdf = norm - radius  # (N,)\n",
    "\n",
    "        # Smooth periodic noise based on direction\n",
    "        unit_dir = rel / (norm.unsqueeze(-1) + 1e-9)  # (N,3)\n",
    "        noise = torch.sin(10 * unit_dir[:, 0]) * torch.sin(10 * unit_dir[:, 1]) * torch.sin(10 * unit_dir[:, 2])\n",
    "\n",
    "        # Weight noise so it mostly affects surface area\n",
    "        falloff = torch.exp(-20 * (base_sdf**2))  # (N,) ~1 near surface, ~0 far\n",
    "        sdf = base_sdf + noise_amplitude * noise * falloff\n",
    "\n",
    "        return sdf\n",
    "\n",
    "    # generate points on the sphere\n",
    "    mnfld_points = torch.randn(grid * grid * 150, 3, device=device)\n",
    "    mnfld_points = mnfld_points / torch.norm(mnfld_points, dim=-1, keepdim=True) * 0.5\n",
    "    mnfld_points = mnfld_points.unsqueeze(0).requires_grad_()\n",
    "    sdf0 = sphere_sdf(sites, torch.zeros(3).to(device), 0.50)\n",
    "    # sdf0 = sphere_sdf_with_noise(sites, torch.zeros(3).to(device), 0.50, noise_amplitude=0.1)\n",
    "\n",
    "# # add mnfld points with random noise to sites\n",
    "# N = mnfld_points.squeeze(0).shape[0]\n",
    "# num_samples = 18**3 - (num_centroids)\n",
    "# idx = torch.randint(0, N, (num_samples,))\n",
    "# sampled = mnfld_points.squeeze(0)[idx]\n",
    "# perturbed = sampled + (torch.rand_like(sampled) - 0.5) * noise_scale * 10\n",
    "# sites = torch.cat((sites, perturbed), dim=0)\n",
    "# sdf0 = model(sites)\n",
    "\n",
    "# make sites a leaf tensor\n",
    "sites = sites.detach().requires_grad_()\n",
    "print(sites.dtype)\n",
    "print(sites.shape)\n",
    "print(f\"Allocated: {torch.cuda.memory_allocated() / 1e6} MB, Reserved: {torch.cuda.memory_reserved() / 1e6} MB\")\n",
    "\n",
    "\n",
    "sdf0 = sdf0.detach().squeeze(-1).requires_grad_()\n",
    "print(sdf0.shape)\n",
    "print(sdf0.is_leaf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ba12786",
   "metadata": {},
   "outputs": [],
   "source": [
    "sites_np = sites.detach().cpu().numpy()\n",
    "d3dsimplices, _ = pygdel3d.triangulate(sites_np)\n",
    "d3dsimplices = np.array(d3dsimplices)\n",
    "# print(\"Delaunay simplices shape: \", d3dsimplices.shape)\n",
    "\n",
    "# print(\"sites shape: \", sites.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff63634a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<polyscope.surface_mesh.SurfaceMesh at 0x7f3247f4be10>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p, faces = su.cvt_extraction(sites, sdf0, d3dsimplices, True)\n",
    "ps.register_point_cloud(\"cvt extraction\", p.detach().cpu().numpy(), enabled=False)\n",
    "ps.register_surface_mesh(\"cvt extraction\", p.detach().cpu().numpy(), faces, back_face_policy=\"identical\", enabled=False)\n",
    "\n",
    "ps_cloud = ps.register_point_cloud(\"initial_cvt_grid+pc_gt\", sites.detach().cpu().numpy(), enabled=False)\n",
    "ps_cloud.add_scalar_quantity(\n",
    "    \"vis_grid_pred\",\n",
    "    sdf0.detach().cpu().numpy(),\n",
    "    enabled=True,\n",
    "    cmap=\"coolwarm\",\n",
    "    vminmax=(-0.00005, 0.00005),\n",
    ")\n",
    "mnf_cloud = ps.register_point_cloud(\"mnfld_points_pred\", mnfld_points.squeeze(0).detach().cpu().numpy(), enabled=False)\n",
    "\n",
    "v_vect, f_vect, sdf_verts, sdf_verts_grads, _ = su.get_clipped_mesh_numba(sites, None, d3dsimplices, False, sdf0, True)\n",
    "ps_mesh = ps.register_surface_mesh(\n",
    "    \"sdf unclipped initial mesh\",\n",
    "    v_vect.detach().cpu().numpy(),\n",
    "    f_vect,\n",
    "    back_face_policy=\"identical\",\n",
    "    enabled=False,\n",
    ")\n",
    "# ps_vert = ps.register_point_cloud(\"sdf unclipped initial verts\", v_vect.detach().cpu().numpy(), enabled=False)\n",
    "\n",
    "v_vect, f_vect, _, _, _ = su.get_clipped_mesh_numba(sites, None, d3dsimplices, True, sdf0, True, barycentric_weights=True, quaternion_slerp=True)\n",
    "ps_mesh = ps.register_surface_mesh(\n",
    "    \"sdf clipped initial mesh interpol\",\n",
    "    v_vect.detach().cpu().numpy(),\n",
    "    f_vect,\n",
    "    back_face_policy=\"identical\",\n",
    ")\n",
    "\n",
    "\n",
    "v_vect, f_vect, _, _, _ = su.get_clipped_mesh_numba(sites, None, d3dsimplices, True, sdf0, True)\n",
    "ps_mesh = ps.register_surface_mesh(\n",
    "    \"sdf clipped initial mesh\",\n",
    "    v_vect.detach().cpu().numpy(),\n",
    "    f_vect,\n",
    "    back_face_policy=\"identical\",\n",
    "    enabled=False,\n",
    ")\n",
    "\n",
    "d3dsimplices, _ = pygdel3d.triangulate(sites_np)\n",
    "d3dsimplices = torch.tensor(d3dsimplices, device=device)\n",
    "marching_tetrehedra_mesh = kaolin.ops.conversions.marching_tetrahedra(\n",
    "    sites.unsqueeze(0), d3dsimplices, sdf0.unsqueeze(0), return_tet_idx=False\n",
    ")\n",
    "vertices_list, faces_list = marching_tetrehedra_mesh\n",
    "v_vect = vertices_list[0]\n",
    "faces = faces_list[0]\n",
    "\n",
    "ps.register_surface_mesh(\n",
    "    \"init MTET\",\n",
    "    v_vect.detach().cpu().numpy(),\n",
    "    faces.detach().cpu().numpy(),\n",
    "    back_face_policy=\"identical\",\n",
    "    enabled=False,\n",
    ")\n",
    "\n",
    "\n",
    "# ps_cloud = ps.register_point_cloud(\"active sites\", tet_probs[2].reshape(-1, 3).detach().cpu().numpy(), enabled=False)\n",
    "# ps_cloud.add_vector_quantity(\"site step dir\", tet_probs[0].reshape(-1, 3).detach().cpu().numpy())\n",
    "# ps_vert.add_vector_quantity(\"verts step dir\", tet_probs[1].detach().cpu().numpy())\n",
    "\n",
    "\n",
    "# ps.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52c1a4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SITES OPTIMISATION LOOP\n",
    "\n",
    "\n",
    "cvt_loss_values = []\n",
    "min_distance_loss_values = []\n",
    "chamfer_distance_loss_values = []\n",
    "eikonal_loss_values = []\n",
    "domain_restriction_loss_values = []\n",
    "sdf_loss_values = []\n",
    "div_loss_values = []\n",
    "loss_values = []\n",
    "\n",
    "voroloss = lf.Voroloss_opt().to(device)\n",
    "\n",
    "\n",
    "def train_DCCVT(\n",
    "    sites,\n",
    "    sites_sdf,\n",
    "    max_iter=100,\n",
    "    stop_train_threshold=1e-6,\n",
    "    upsampling=0,\n",
    "    lambda_weights=[0.1, 1.0, 0.1, 0.1, 1.0, 1.0, 0.1],\n",
    "    voroloss_optim=False,\n",
    "):\n",
    "    if not voroloss_optim:\n",
    "        optimizer = torch.optim.Adam(\n",
    "            [\n",
    "                {\"params\": [sites], \"lr\": lr_sites * 0.1},\n",
    "                {\"params\": [sites_sdf], \"lr\": lr_sites * 0.1},\n",
    "            ],\n",
    "            betas=(0.8, 0.95),\n",
    "        )\n",
    "    else:\n",
    "        optimizer = torch.optim.Adam([{\"params\": [sites], \"lr\": lr_sites * 0.1}])\n",
    "\n",
    "    # scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "    # scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\n",
    "\n",
    "    # optimizer_sites = torch.optim.Adam([{'params': [sites], 'lr': lr_sites}])\n",
    "    # optimizer_sdf = torch.optim.SGD([{'params': [sites_sdf], 'lr': lr_sites}])\n",
    "    # scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[80, 150, 200, 250], gamma=0.5)\n",
    "\n",
    "    prev_loss = float(\"inf\")\n",
    "    best_loss = float(\"inf\")\n",
    "    upsampled = 0.0\n",
    "    epoch = 0\n",
    "    lambda_cvt = lambda_weights[0]\n",
    "    lambda_chamfer = lambda_weights[4]\n",
    "    lambda_shl = lambda_cvt / 10\n",
    "    best_sites = sites.clone()\n",
    "    best_sites.best_loss = best_loss\n",
    "\n",
    "    while epoch <= max_iter:\n",
    "        optimizer.zero_grad()\n",
    "        # if mesh[0] == \"sphere\":\n",
    "        #     # generate sphere sdf\n",
    "        #     sites_sdf = sphere_sdf(sites, torch.zeros(3).to(device), 0.50)\n",
    "\n",
    "        if not voroloss_optim:\n",
    "            sites_np = sites.detach().cpu().numpy()\n",
    "            # d3dsimplices = diffvoronoi.get_delaunay_simplices(sites_np.reshape(input_dims * sites_np.shape[0]))\n",
    "            d3dsimplices, _ = pygdel3d.triangulate(sites_np)\n",
    "\n",
    "            d3dsimplices = np.array(d3dsimplices)\n",
    "\n",
    "            if epoch % 100 == 0 and epoch <= 500:\n",
    "                eps_H = lf.estimate_eps_H(sites, d3dsimplices, multiplier=1.5 * 5).detach()\n",
    "                print(\"Estimated eps_H: \", eps_H)\n",
    "            elif epoch % 100 == 0 and epoch <= 800:\n",
    "                eps_H = lf.estimate_eps_H(sites, d3dsimplices, multiplier=1.5 * 2).detach()\n",
    "                print(\"Estimated eps_H: \", eps_H)\n",
    "\n",
    "            # cvt_loss = lf.compute_cvt_loss_vectorized_delaunay(sites, None, d3dsimplices)  # torch.tensor(0)  #\n",
    "\n",
    "            build_mesh = False\n",
    "            clip = True\n",
    "            mtet = False\n",
    "            noised_sdf = False\n",
    "            sites_sdf_grads = None\n",
    "            \n",
    "            # Create small noise in sites_sdf that fade during the training process\n",
    "            if not noised_sdf:\n",
    "                # Create small noise in sites_sdf that fade during the training process\n",
    "                # This is to avoid numerical issues with the SDF being too close to zero\n",
    "                if epoch < max_iter * 0.5:\n",
    "                    noise_amplitude = 0.02 * (1 - epoch / (max_iter * 0.5))\n",
    "                    sites_noised_sdf = torch.randn_like(sites_sdf) * noise_amplitude + sites_sdf\n",
    "                else:\n",
    "                    sites_noised_sdf = sites_sdf\n",
    "            else:\n",
    "                sites_noised_sdf = sites_sdf\n",
    "\n",
    "            if mtet:\n",
    "                print(\"Using MTET\")\n",
    "                d3dsimplices = torch.tensor(d3dsimplices, device=device)\n",
    "                marching_tetrehedra_mesh = kaolin.ops.conversions.marching_tetrahedra(\n",
    "                    sites.unsqueeze(0), d3dsimplices, sites_noised_sdf.unsqueeze(0), return_tet_idx=False\n",
    "                )\n",
    "                vertices_list, faces_list = marching_tetrehedra_mesh\n",
    "                v_vect = vertices_list[0]\n",
    "                faces = faces_list[0]\n",
    "                print(\"v_vect shape: \", v_vect.shape)\n",
    "\n",
    "            else:\n",
    "                v_vect, faces_or_clippedvert, sites_sdf_grads, tets_sdf_grads, W = su.get_clipped_mesh_numba(\n",
    "                    sites, None, d3dsimplices, clip, sites_sdf, build_mesh\n",
    "                )\n",
    "            #  v_vect, faces_or_clippedvert = su.cvt_extraction(sites, sites_sdf, d3dsimplices, build_mesh)\n",
    "\n",
    "            if build_mesh:\n",
    "                triangle_faces = [[f[0], f[i], f[i + 1]] for f in faces_or_clippedvert for i in range(1, len(f) - 1)]\n",
    "                triangle_faces = torch.tensor(triangle_faces, device=device)\n",
    "                hs_p = su.sample_mesh_points_heitz(v_vect, triangle_faces, num_samples=mnfld_points.shape[0])\n",
    "                chamfer_loss_mesh, _ = chamfer_distance(mnfld_points.detach(), hs_p.unsqueeze(0))\n",
    "            else:\n",
    "                chamfer_loss_mesh, _ = chamfer_distance(mnfld_points.detach(), v_vect.unsqueeze(0))\n",
    "\n",
    "            if sites_sdf_grads is None:\n",
    "                sites_sdf_grads, tets_sdf_grads, W = su.sdf_space_grad_pytorch_diego_sites_tets(\n",
    "                    sites, sites_sdf, torch.tensor(d3dsimplices).to(device).detach()\n",
    "                )\n",
    "\n",
    "            # do cvt loss on the clipped voronoi vertices positions TODO\n",
    "            # cvt_loss = lf.compute_cvt_loss_CLIPPED_vertices(sites, None, None, d3dsimplices, faces_or_clippedvert)\n",
    "            cvt_loss = lf.compute_cvt_loss_true(sites, d3dsimplices, faces_or_clippedvert)\n",
    "\n",
    "            print(\n",
    "                \"cvt_loss: \",\n",
    "                lambda_cvt / 1 * cvt_loss.item(),\n",
    "                \"chamfer_loss_mesh: \",\n",
    "                lambda_chamfer * chamfer_loss_mesh.item(),\n",
    "            )\n",
    "            sites_loss = lambda_cvt / 1 * cvt_loss + lambda_chamfer * chamfer_loss_mesh\n",
    "\n",
    "            eik_loss = lambda_cvt / 10 * lf.discrete_tet_volume_eikonal_loss(sites, sites_sdf_grads, d3dsimplices)\n",
    "            # shl = lambda_cvt / 0.1 * lf.smoothed_heaviside_loss(sites, sites_sdf, sites_sdf_grads, d3dsimplices)\n",
    "\n",
    "            # eik_loss = lambda_cvt / 1000 * lf.tet_sdf_grad_eikonal_loss(sites, tets_sdf_grads, d3dsimplices)\n",
    "            print(\"eikonal_loss: \", eik_loss.item())\n",
    "\n",
    "            shl = lambda_cvt / 1 * lf.tet_sdf_motion_mean_curvature_loss(sites, sites_sdf, W, d3dsimplices, eps_H)\n",
    "            # print(\"smoothed_heaviside_loss: \", shl.item())\n",
    "\n",
    "            # sites_eik_loss = lambda_cvt * 0.5 * torch.mean(((sites_sdf_grads**2).sum(dim=1) - 1) ** 2)\n",
    "\n",
    "            sdf_loss = eik_loss + shl  # sites_eik_loss  # +\n",
    "        else:\n",
    "            sdf_loss = 0\n",
    "            sites_np = sites.detach().cpu().numpy()\n",
    "            # d3dsimplices = diffvoronoi.get_delaunay_simplices(sites_np.reshape(input_dims * sites_np.shape[0]))\n",
    "            d3dsimplices, _ = pygdel3d.triangulate(sites_np)\n",
    "            d3dsimplices = np.array(d3dsimplices)\n",
    "            cvt_loss = lf.compute_cvt_loss_vectorized_delaunay(sites, None, d3dsimplices)\n",
    "\n",
    "            sites_loss = (\n",
    "                lambda_chamfer * voroloss(mnfld_points.squeeze(0), sites).mean()\n",
    "            ) + lambda_cvt / 10000 * cvt_loss\n",
    "\n",
    "        loss = sites_loss + sdf_loss\n",
    "        loss_values.append(loss.item())\n",
    "        print(f\"Epoch {epoch}: loss = {loss.item()}\")\n",
    "\n",
    "        # print(f\"before loss.backward(): Allocated: {torch.cuda.memory_allocated() / 1e6} MB, Reserved: {torch.cuda.memory_reserved() / 1e6} MB\")\n",
    "        loss.backward()\n",
    "        # print(f\"After loss.backward(): Allocated: {torch.cuda.memory_allocated() / 1e6} MB, Reserved: {torch.cuda.memory_reserved() / 1e6} MB\")\n",
    "        print(\"-----------------\")\n",
    "\n",
    "        # torch.nn.utils.clip_grad_norm_(sites_sdf, 1.0)\n",
    "        # torch.nn.utils.clip_grad_norm_(sites, 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        # sites_sdf += (sites_sdf_grads*(sites-sites_positions)).sum(dim=1)\n",
    "\n",
    "        # scheduler.step()\n",
    "        print(\"Learning rate: \", optimizer.param_groups[0][\"lr\"])\n",
    "        # if epoch>100 and (epoch // 100) == upsampled+1 and loss.item() < 0.5 and upsampled < upsampling:\n",
    "\n",
    "        # TODO: test epoch == 300 growthrate 300%\n",
    "        if upsampled < upsampling and epoch / (max_iter * 0.80) > upsampled / upsampling:\n",
    "            print(\"sites length BEFORE UPSAMPLING: \", len(sites))\n",
    "            if len(sites) * 1.09 > grid**3:\n",
    "                print(\"Skipping upsampling, too many sites, sites length: \", len(sites), \"grid size: \", grid**3)\n",
    "                upsampled = upsampling\n",
    "                sites = sites.detach().requires_grad_(True)\n",
    "                sites_sdf = sites_sdf.detach().requires_grad_(True)\n",
    "\n",
    "                optimizer = torch.optim.Adam(\n",
    "                    [\n",
    "                        {\"params\": [sites], \"lr\": lr_sites * 0.1},\n",
    "                        {\"params\": [sites_sdf], \"lr\": lr_sites * 0.1},\n",
    "                    ]\n",
    "                )\n",
    "                eps_H = lf.estimate_eps_H(sites, d3dsimplices, multiplier=1.5 * 3).detach()\n",
    "                print(\"Estimated eps_H: \", eps_H)\n",
    "                # scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.99)\n",
    "                continue\n",
    "            # sites, sites_sdf = su.upsampling_vectorized_sites_sites_sdf(sites, tri=None, vor=None, simplices=d3dsimplices, model=sites_sdf)\n",
    "            # sites, sites_sdf = su.upsampling_curvature_vectorized_sites_sites_sdf(sites, tri=None, vor=None, simplices=d3dsimplices, model=sites_sdf)\n",
    "            sites, sites_sdf = su.upsampling_adaptive_vectorized_sites_sites_sdf(\n",
    "                sites,\n",
    "                simplices=d3dsimplices,\n",
    "                model=sites_sdf,\n",
    "                sites_sdf_grads=sites_sdf_grads,\n",
    "            )\n",
    "\n",
    "            # sites, sites_sdf = su.upsampling_chamfer_vectorized_sites_sites_sdf(\n",
    "            #     sites, d3dsimplices, sites_sdf, mnfld_points\n",
    "            # )\n",
    "\n",
    "            sites = sites.detach().requires_grad_(True)\n",
    "            sites_sdf = sites_sdf.detach().requires_grad_(True)\n",
    "\n",
    "            optimizer = torch.optim.Adam(\n",
    "                [\n",
    "                    {\"params\": [sites], \"lr\": lr_sites * 0.1},\n",
    "                    {\"params\": [sites_sdf], \"lr\": lr_sites * 0.1},\n",
    "                ]\n",
    "            )\n",
    "            # scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.98)\n",
    "            eps_H = lf.estimate_eps_H(sites, d3dsimplices, multiplier=1.5 * 5).detach()\n",
    "            print(\"Estimated eps_H: \", eps_H)\n",
    "\n",
    "            upsampled += 1.0\n",
    "            print(\"sites shape AFTER: \", sites.shape)\n",
    "            print(\"sites sdf shape AFTER: \", sites_sdf.shape)\n",
    "\n",
    "        if epoch % (max_iter / 10) == 0 or epoch == max_iter:\n",
    "            # print(f\"Epoch {epoch}: loss = {loss.item()}\")\n",
    "            # print(f\"Best Epoch {best_epoch}: Best loss = {best_loss}\")\n",
    "            # save model and sites\n",
    "            # ps.register_surface_mesh(f\"{epoch} triangle clipped mesh\", v_vect.detach().cpu().numpy(), triangle_faces.detach().cpu().numpy())\n",
    "\n",
    "            # ps.register_point_cloud('sampled points end', hs_p.detach().cpu().numpy())\n",
    "            # ps.register_point_cloud(\"sampled points end\", v_vect.detach().cpu().numpy(), enabled=False)\n",
    "\n",
    "            # if f_vect is not None:\n",
    "            #     ps_mesh = ps.register_surface_mesh(\n",
    "            #         f\"{epoch} sdf clipped pmesh\",\n",
    "            #         v_vect.detach().cpu().numpy(),\n",
    "            #         f_vect,\n",
    "            #         back_face_policy=\"identical\",\n",
    "            #         enabled=False,\n",
    "            #     )\n",
    "            #     ps_mesh.add_vector_quantity(\n",
    "            #         f\"{epoch} sdf verts grads\",\n",
    "            #         sdf_verts_grads.detach().cpu().numpy(),\n",
    "            #         enabled=False,\n",
    "            #     )\n",
    "\n",
    "            site_file_path = (\n",
    "                f\"{destination}{mesh[0]}{max_iter}_{epoch}_3d_sites_{num_centroids}_chamfer{lambda_chamfer}.pth\"\n",
    "            )\n",
    "            # model_file_path = f'{destination}{mesh[0]}{max_iter}_{epoch}_3d_model_{num_centroids}_chamfer{lambda_chamfer}.pth'\n",
    "            sdf_file_path = (\n",
    "                f\"{destination}{mesh[0]}{max_iter}_{epoch}_3d_sdf_{num_centroids}_chamfer{lambda_chamfer}.pth\"\n",
    "            )\n",
    "            torch.save(sites_sdf, sdf_file_path)\n",
    "            torch.save(sites, site_file_path)\n",
    "\n",
    "        epoch += 1\n",
    "\n",
    "    return sites, sites_sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "447548a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda weights:\n",
      "lambda_cvt: 100\n",
      "lambda_sdf: 0\n",
      "lambda_min_distance: 0\n",
      "lambda_laplace: 0\n",
      "lambda_chamfer: 1000\n",
      "lambda_eikonal: 0\n",
      "lambda_domain_restriction: 100\n",
      "lambda_true_points: 0\n"
     ]
    }
   ],
   "source": [
    "# lambda_weights = [252,0,0,0,10.211111,0,100,0]\n",
    "# lambda_weights = [500,0,0,0,1000,0,100,0]\n",
    "lambda_weights = [100, 0, 0, 0, 1000, 0, 100, 0]\n",
    "\n",
    "\n",
    "lambda_cvt = lambda_weights[0]\n",
    "lambda_sdf = lambda_weights[1]\n",
    "lambda_min_distance = lambda_weights[2]\n",
    "lambda_laplace = lambda_weights[3]\n",
    "lambda_chamfer = lambda_weights[4]\n",
    "lambda_eikonal = lambda_weights[5]\n",
    "lambda_domain_restriction = lambda_weights[6]\n",
    "lambda_true_points = lambda_weights[7]\n",
    "\n",
    "# Print the lambda weights\n",
    "print(\"Lambda weights:\")\n",
    "print(f\"lambda_cvt: {lambda_cvt}\")\n",
    "print(f\"lambda_sdf: {lambda_sdf}\")\n",
    "print(f\"lambda_min_distance: {lambda_min_distance}\") \n",
    "print(f\"lambda_laplace: {lambda_laplace}\")\n",
    "print(f\"lambda_chamfer: {lambda_chamfer}\")\n",
    "print(f\"lambda_eikonal: {lambda_eikonal}\")\n",
    "print(f\"lambda_domain_restriction: {lambda_domain_restriction}\")\n",
    "print(f\"lambda_true_points: {lambda_true_points}\")\n",
    "\n",
    "max_iter = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccb5e968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated eps_H:  tensor(0.5553, device='cuda:0')\n",
      "cvt_loss:  0.6529095582664013 chamfer_loss_mesh:  0.3807184984907508\n",
      "eikonal_loss:  3.8841521739959717\n",
      "Epoch 0: loss = 4.918846130371094\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.6137262098491192 chamfer_loss_mesh:  0.3589601255953312\n",
      "eikonal_loss:  4.561061382293701\n",
      "Epoch 1: loss = 5.5348124504089355\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.58885314501822 chamfer_loss_mesh:  0.33841945696622133\n",
      "eikonal_loss:  3.603055953979492\n",
      "Epoch 2: loss = 4.531392574310303\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.576185155659914 chamfer_loss_mesh:  0.32507942523807287\n",
      "eikonal_loss:  1.9474825859069824\n",
      "Epoch 3: loss = 2.849811315536499\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.5593745969235897 chamfer_loss_mesh:  0.30280568171292543\n",
      "eikonal_loss:  1.7402840852737427\n",
      "Epoch 4: loss = 2.603529214859009\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.5418918561190367 chamfer_loss_mesh:  0.2897225203923881\n",
      "eikonal_loss:  1.5641376972198486\n",
      "Epoch 5: loss = 2.3968162536621094\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.5331241060048342 chamfer_loss_mesh:  0.28211745666339993\n",
      "eikonal_loss:  1.617154598236084\n",
      "Epoch 6: loss = 2.4334611892700195\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.5230358336120844 chamfer_loss_mesh:  0.2721521304920316\n",
      "eikonal_loss:  1.901402473449707\n",
      "Epoch 7: loss = 2.697655200958252\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.5111455451697111 chamfer_loss_mesh:  0.26870527653954923\n",
      "eikonal_loss:  2.072174072265625\n",
      "Epoch 8: loss = 2.853090286254883\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.5022342782467604 chamfer_loss_mesh:  0.26705811615101993\n",
      "eikonal_loss:  1.8184316158294678\n",
      "Epoch 9: loss = 2.58878755569458\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.4904799163341522 chamfer_loss_mesh:  0.2586781920399517\n",
      "eikonal_loss:  1.5666203498840332\n",
      "Epoch 10: loss = 2.3168416023254395\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.4786635283380747 chamfer_loss_mesh:  0.2499562397133559\n",
      "eikonal_loss:  1.6460192203521729\n",
      "Epoch 11: loss = 2.3757004737854004\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.46994038857519627 chamfer_loss_mesh:  0.24259820929728448\n",
      "eikonal_loss:  1.5088231563568115\n",
      "Epoch 12: loss = 2.2224228382110596\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.45985085889697075 chamfer_loss_mesh:  0.23841952497605234\n",
      "eikonal_loss:  1.3418601751327515\n",
      "Epoch 13: loss = 2.0411906242370605\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.452561117708683 chamfer_loss_mesh:  0.23533293278887868\n",
      "eikonal_loss:  1.4463120698928833\n",
      "Epoch 14: loss = 2.1352641582489014\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.44598523527383804 chamfer_loss_mesh:  0.22862214245833457\n",
      "eikonal_loss:  1.7386633157730103\n",
      "Epoch 15: loss = 2.414328098297119\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.43830322101712227 chamfer_loss_mesh:  0.22677797824144363\n",
      "eikonal_loss:  1.3229730129241943\n",
      "Epoch 16: loss = 1.9891107082366943\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.43175797909498215 chamfer_loss_mesh:  0.2235007705166936\n",
      "eikonal_loss:  1.5012342929840088\n",
      "Epoch 17: loss = 2.157548189163208\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.4237252287566662 chamfer_loss_mesh:  0.22333208471536636\n",
      "eikonal_loss:  1.3387377262115479\n",
      "Epoch 18: loss = 1.9868483543395996\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.41860174387693405 chamfer_loss_mesh:  0.22090977290645242\n",
      "eikonal_loss:  1.238315224647522\n",
      "Epoch 19: loss = 1.8788793087005615\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.41243233717978 chamfer_loss_mesh:  0.21656460012309253\n",
      "eikonal_loss:  1.2837247848510742\n",
      "Epoch 20: loss = 1.9137728214263916\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.4065863788127899 chamfer_loss_mesh:  0.2104796003550291\n",
      "eikonal_loss:  1.118717074394226\n",
      "Epoch 21: loss = 1.7368338108062744\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.4010072909295559 chamfer_loss_mesh:  0.20881040836684406\n",
      "eikonal_loss:  3.7518808841705322\n",
      "Epoch 22: loss = 4.362748622894287\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.3954020328819752 chamfer_loss_mesh:  0.2071441849693656\n",
      "eikonal_loss:  3.486483097076416\n",
      "Epoch 23: loss = 4.090078353881836\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.3900713985785842 chamfer_loss_mesh:  0.20334351575002074\n",
      "eikonal_loss:  3.206925630569458\n",
      "Epoch 24: loss = 3.801388740539551\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.3841439727693796 chamfer_loss_mesh:  0.20302634220570326\n",
      "eikonal_loss:  4.670857906341553\n",
      "Epoch 25: loss = 5.25907564163208\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.37979413755238056 chamfer_loss_mesh:  0.19921400235034525\n",
      "eikonal_loss:  4.663215637207031\n",
      "Epoch 26: loss = 5.243271350860596\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.3774427343159914 chamfer_loss_mesh:  0.1982239482458681\n",
      "eikonal_loss:  4.2672882080078125\n",
      "Epoch 27: loss = 4.844000816345215\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.3737127874046564 chamfer_loss_mesh:  0.19743139273487031\n",
      "eikonal_loss:  4.060197830200195\n",
      "Epoch 28: loss = 4.632388114929199\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.36898632533848286 chamfer_loss_mesh:  0.19537148182280362\n",
      "eikonal_loss:  4.692121505737305\n",
      "Epoch 29: loss = 5.257523536682129\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.36546713672578335 chamfer_loss_mesh:  0.19127465202473104\n",
      "eikonal_loss:  4.455533981323242\n",
      "Epoch 30: loss = 5.013319492340088\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.36303321830928326 chamfer_loss_mesh:  0.1894822926260531\n",
      "eikonal_loss:  5.161416053771973\n",
      "Epoch 31: loss = 5.714975833892822\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.3605207893997431 chamfer_loss_mesh:  0.18698596977628767\n",
      "eikonal_loss:  4.556642532348633\n",
      "Epoch 32: loss = 5.105193138122559\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.35803872160613537 chamfer_loss_mesh:  0.18663954688236117\n",
      "eikonal_loss:  2.7841668128967285\n",
      "Epoch 33: loss = 3.3298888206481934\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.35629128105938435 chamfer_loss_mesh:  0.18678800552152097\n",
      "eikonal_loss:  3.0128846168518066\n",
      "Epoch 34: loss = 3.5570080280303955\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.3532783128321171 chamfer_loss_mesh:  0.1844465732574463\n",
      "eikonal_loss:  2.1561810970306396\n",
      "Epoch 35: loss = 2.6949501037597656\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.3506196429952979 chamfer_loss_mesh:  0.18311431631445885\n",
      "eikonal_loss:  1.9413269758224487\n",
      "Epoch 36: loss = 2.476104259490967\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.346223171800375 chamfer_loss_mesh:  0.17939668032340705\n",
      "eikonal_loss:  1.8889063596725464\n",
      "Epoch 37: loss = 2.415570020675659\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.3415341954678297 chamfer_loss_mesh:  0.17963003483600914\n",
      "eikonal_loss:  1.7453409433364868\n",
      "Epoch 38: loss = 2.267550468444824\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.3379175905138254 chamfer_loss_mesh:  0.17980349366553128\n",
      "eikonal_loss:  1.6145639419555664\n",
      "Epoch 39: loss = 2.133329391479492\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.33559624571353197 chamfer_loss_mesh:  0.17773263971321285\n",
      "eikonal_loss:  1.6699610948562622\n",
      "Epoch 40: loss = 2.184335231781006\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.3331294748932123 chamfer_loss_mesh:  0.17625337932258844\n",
      "eikonal_loss:  1.4772158861160278\n",
      "Epoch 41: loss = 1.987643837928772\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.3274508286267519 chamfer_loss_mesh:  0.17436526832170784\n",
      "eikonal_loss:  1.6687148809432983\n",
      "Epoch 42: loss = 2.171574354171753\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.3233271185308695 chamfer_loss_mesh:  0.1741623564157635\n",
      "eikonal_loss:  1.4597128629684448\n",
      "Epoch 43: loss = 1.958245873451233\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.31952066347002983 chamfer_loss_mesh:  0.17230378580279648\n",
      "eikonal_loss:  1.4992756843566895\n",
      "Epoch 44: loss = 1.992142677307129\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.31556945759803057 chamfer_loss_mesh:  0.17519606626592577\n",
      "eikonal_loss:  1.6616222858428955\n",
      "Epoch 45: loss = 2.153430461883545\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.31236973591148853 chamfer_loss_mesh:  0.17177226254716516\n",
      "eikonal_loss:  1.5378150939941406\n",
      "Epoch 46: loss = 2.023000478744507\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.3100359346717596 chamfer_loss_mesh:  0.16838524607010186\n",
      "eikonal_loss:  1.5036101341247559\n",
      "Epoch 47: loss = 1.9830751419067383\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.3061979543417692 chamfer_loss_mesh:  0.16785413026809692\n",
      "eikonal_loss:  1.4302970170974731\n",
      "Epoch 48: loss = 1.9053932428359985\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.30310596339404583 chamfer_loss_mesh:  0.16702560242265463\n",
      "eikonal_loss:  1.3615639209747314\n",
      "Epoch 49: loss = 1.8327394723892212\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.3003648016601801 chamfer_loss_mesh:  0.16749734641052783\n",
      "eikonal_loss:  1.39762282371521\n",
      "Epoch 50: loss = 1.8665283918380737\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.2967511769384146 chamfer_loss_mesh:  0.1680193527135998\n",
      "eikonal_loss:  1.2439976930618286\n",
      "Epoch 51: loss = 1.7098116874694824\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.29453260358422995 chamfer_loss_mesh:  0.1648084435146302\n",
      "eikonal_loss:  1.5364867448806763\n",
      "Epoch 52: loss = 1.996870756149292\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.29213603120297194 chamfer_loss_mesh:  0.1656397944316268\n",
      "eikonal_loss:  1.417067527770996\n",
      "Epoch 53: loss = 1.875886082649231\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.2904497552663088 chamfer_loss_mesh:  0.1626231533009559\n",
      "eikonal_loss:  1.2810392379760742\n",
      "Epoch 54: loss = 1.7351547479629517\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.28830463998019695 chamfer_loss_mesh:  0.16176988719962537\n",
      "eikonal_loss:  2.914457321166992\n",
      "Epoch 55: loss = 3.3655753135681152\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.2856999170035124 chamfer_loss_mesh:  0.1608847378520295\n",
      "eikonal_loss:  7.3375678062438965\n",
      "Epoch 56: loss = 7.785195350646973\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.2825852017849684 chamfer_loss_mesh:  0.16348599456250668\n",
      "eikonal_loss:  7.311452865600586\n",
      "Epoch 57: loss = 7.7585673332214355\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.280992710031569 chamfer_loss_mesh:  0.15989920939318836\n",
      "eikonal_loss:  5.298144340515137\n",
      "Epoch 58: loss = 5.7400803565979\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.27947304770350456 chamfer_loss_mesh:  0.15984600759111345\n",
      "eikonal_loss:  4.332492828369141\n",
      "Epoch 59: loss = 4.772856712341309\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.27738078497350216 chamfer_loss_mesh:  0.1593287306604907\n",
      "eikonal_loss:  3.401278495788574\n",
      "Epoch 60: loss = 3.8390321731567383\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.2751776250079274 chamfer_loss_mesh:  0.15692516171839088\n",
      "eikonal_loss:  2.7934348583221436\n",
      "Epoch 61: loss = 3.2265825271606445\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.27306368574500084 chamfer_loss_mesh:  0.15682989032939076\n",
      "eikonal_loss:  2.4186806678771973\n",
      "Epoch 62: loss = 2.8496203422546387\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.27130835223942995 chamfer_loss_mesh:  0.1566431310493499\n",
      "eikonal_loss:  2.053626537322998\n",
      "Epoch 63: loss = 2.4826245307922363\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.2691608387976885 chamfer_loss_mesh:  0.15718236682005227\n",
      "eikonal_loss:  1.8627235889434814\n",
      "Epoch 64: loss = 2.2901148796081543\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.2673974260687828 chamfer_loss_mesh:  0.15770933532621711\n",
      "eikonal_loss:  1.6487432718276978\n",
      "Epoch 65: loss = 2.074897289276123\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.2665699925273657 chamfer_loss_mesh:  0.15617467579431832\n",
      "eikonal_loss:  1.5585708618164062\n",
      "Epoch 66: loss = 1.9823622703552246\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.2657773904502392 chamfer_loss_mesh:  0.1551337045384571\n",
      "eikonal_loss:  1.6388620138168335\n",
      "Epoch 67: loss = 2.0608198642730713\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.2646555192768574 chamfer_loss_mesh:  0.15548427472822368\n",
      "eikonal_loss:  1.4890055656433105\n",
      "Epoch 68: loss = 1.910192608833313\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.2626563888043165 chamfer_loss_mesh:  0.15537935541942716\n",
      "eikonal_loss:  1.4821635484695435\n",
      "Epoch 69: loss = 1.901246428489685\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.26131346821784973 chamfer_loss_mesh:  0.15587470261380076\n",
      "eikonal_loss:  1.432751178741455\n",
      "Epoch 70: loss = 1.8509868383407593\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.25901184417307377 chamfer_loss_mesh:  0.15432870713993907\n",
      "eikonal_loss:  2.2288830280303955\n",
      "Epoch 71: loss = 2.6432716846466064\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.2577184699475765 chamfer_loss_mesh:  0.1538191136205569\n",
      "eikonal_loss:  1.3442407846450806\n",
      "Epoch 72: loss = 1.7568271160125732\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.25669638998806477 chamfer_loss_mesh:  0.15293361502699554\n",
      "eikonal_loss:  1.2508535385131836\n",
      "Epoch 73: loss = 1.6615321636199951\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.25460629258304834 chamfer_loss_mesh:  0.15267252456396818\n",
      "eikonal_loss:  1.2160438299179077\n",
      "Epoch 74: loss = 1.6243717670440674\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.2530698664486408 chamfer_loss_mesh:  0.1524191175121814\n",
      "eikonal_loss:  1.1867363452911377\n",
      "Epoch 75: loss = 1.593274712562561\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.25079494807869196 chamfer_loss_mesh:  0.1520386285847053\n",
      "eikonal_loss:  1.1582858562469482\n",
      "Epoch 76: loss = 1.5621695518493652\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.24929149076342583 chamfer_loss_mesh:  0.15222295769490302\n",
      "eikonal_loss:  1.1415408849716187\n",
      "Epoch 77: loss = 1.5441055297851562\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.2487480640411377 chamfer_loss_mesh:  0.15085749328136444\n",
      "eikonal_loss:  1.1397684812545776\n",
      "Epoch 78: loss = 1.5404255390167236\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.2483682706952095 chamfer_loss_mesh:  0.1487129193264991\n",
      "eikonal_loss:  1.1532232761383057\n",
      "Epoch 79: loss = 1.551356315612793\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.24803602136671543 chamfer_loss_mesh:  0.1491755829192698\n",
      "eikonal_loss:  1.1072040796279907\n",
      "Epoch 80: loss = 1.5054683685302734\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.24517439305782318 chamfer_loss_mesh:  0.14917796943336725\n",
      "eikonal_loss:  1.9393731355667114\n",
      "Epoch 81: loss = 2.334778308868408\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.2448040060698986 chamfer_loss_mesh:  0.15023026207927614\n",
      "eikonal_loss:  1.8267638683319092\n",
      "Epoch 82: loss = 2.222851514816284\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.24435743689537048 chamfer_loss_mesh:  0.1497105840826407\n",
      "eikonal_loss:  1.7012505531311035\n",
      "Epoch 83: loss = 2.096372127532959\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.2423831494525075 chamfer_loss_mesh:  0.14915119390934706\n",
      "eikonal_loss:  1.5587034225463867\n",
      "Epoch 84: loss = 1.951291561126709\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.24172780103981495 chamfer_loss_mesh:  0.14854129403829575\n",
      "eikonal_loss:  1.418046474456787\n",
      "Epoch 85: loss = 1.8093690872192383\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.24194975849241018 chamfer_loss_mesh:  0.14836031186860055\n",
      "eikonal_loss:  1.4051322937011719\n",
      "Epoch 86: loss = 1.7964969873428345\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.24118991568684578 chamfer_loss_mesh:  0.14886935241520405\n",
      "eikonal_loss:  1.3157575130462646\n",
      "Epoch 87: loss = 1.7068718671798706\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.23978520184755325 chamfer_loss_mesh:  0.1508869172539562\n",
      "eikonal_loss:  1.5088564157485962\n",
      "Epoch 88: loss = 1.9005833864212036\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.23966243024915457 chamfer_loss_mesh:  0.14899563393555582\n",
      "eikonal_loss:  1.4166641235351562\n",
      "Epoch 89: loss = 1.806376576423645\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.2382777165621519 chamfer_loss_mesh:  0.1475865428801626\n",
      "eikonal_loss:  1.3370757102966309\n",
      "Epoch 90: loss = 1.7239954471588135\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.23711139801889658 chamfer_loss_mesh:  0.1473963347962126\n",
      "eikonal_loss:  1.2824008464813232\n",
      "Epoch 91: loss = 1.6679643392562866\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.23605627939105034 chamfer_loss_mesh:  0.14673176337964833\n",
      "eikonal_loss:  1.2179784774780273\n",
      "Epoch 92: loss = 1.6018226146697998\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.23424176033586264 chamfer_loss_mesh:  0.1468368136556819\n",
      "eikonal_loss:  1.1609821319580078\n",
      "Epoch 93: loss = 1.5431166887283325\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.23233899846673012 chamfer_loss_mesh:  0.14643599570263177\n",
      "eikonal_loss:  1.1055643558502197\n",
      "Epoch 94: loss = 1.485395908355713\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.23169810883700848 chamfer_loss_mesh:  0.14639967412222177\n",
      "eikonal_loss:  1.0484020709991455\n",
      "Epoch 95: loss = 1.4275574684143066\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.23048869334161282 chamfer_loss_mesh:  0.14874931366648525\n",
      "eikonal_loss:  1.0156086683273315\n",
      "Epoch 96: loss = 1.3959054946899414\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.22850697860121727 chamfer_loss_mesh:  0.1455302262911573\n",
      "eikonal_loss:  1.010004997253418\n",
      "Epoch 97: loss = 1.385101079940796\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.22734382655471563 chamfer_loss_mesh:  0.14490944158751518\n",
      "eikonal_loss:  1.003801941871643\n",
      "Epoch 98: loss = 1.3771129846572876\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.22588414140045643 chamfer_loss_mesh:  0.14468877634499222\n",
      "eikonal_loss:  1.003104567527771\n",
      "Epoch 99: loss = 1.3747355937957764\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "Estimated eps_H:  tensor(0.5462, device='cuda:0')\n",
      "cvt_loss:  0.22587941493839025 chamfer_loss_mesh:  0.14648507931269705\n",
      "eikonal_loss:  0.9941868782043457\n",
      "Epoch 100: loss = 1.3676048517227173\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.22500185295939445 chamfer_loss_mesh:  0.14550094783771783\n",
      "eikonal_loss:  0.9416970610618591\n",
      "Epoch 101: loss = 1.31325364112854\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.22425653878599405 chamfer_loss_mesh:  0.14707307855132967\n",
      "eikonal_loss:  0.8771405220031738\n",
      "Epoch 102: loss = 1.2495241165161133\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.22460650652647018 chamfer_loss_mesh:  0.14516361989080906\n",
      "eikonal_loss:  0.9643173217773438\n",
      "Epoch 103: loss = 1.3351423740386963\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.22345762699842453 chamfer_loss_mesh:  0.1447249378543347\n",
      "eikonal_loss:  0.9478002190589905\n",
      "Epoch 104: loss = 1.317038655281067\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.2227868651971221 chamfer_loss_mesh:  0.14443491818383336\n",
      "eikonal_loss:  0.9257016181945801\n",
      "Epoch 105: loss = 1.2939801216125488\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.2217637374997139 chamfer_loss_mesh:  0.14525771257467568\n",
      "eikonal_loss:  0.8700892925262451\n",
      "Epoch 106: loss = 1.2381680011749268\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.22016637958586216 chamfer_loss_mesh:  0.14559918781742454\n",
      "eikonal_loss:  0.8580556511878967\n",
      "Epoch 107: loss = 1.2248785495758057\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.2202862873673439 chamfer_loss_mesh:  0.14453988114837557\n",
      "eikonal_loss:  0.8748651742935181\n",
      "Epoch 108: loss = 1.2407491207122803\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.2185269957408309 chamfer_loss_mesh:  0.14398968778550625\n",
      "eikonal_loss:  0.9406861066818237\n",
      "Epoch 109: loss = 1.3042612075805664\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.21743301767855883 chamfer_loss_mesh:  0.14399854990188032\n",
      "eikonal_loss:  0.9271450042724609\n",
      "Epoch 110: loss = 1.2896347045898438\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.21782813128083944 chamfer_loss_mesh:  0.1474807650083676\n",
      "eikonal_loss:  0.884930431842804\n",
      "Epoch 111: loss = 1.251297950744629\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.21795148495584726 chamfer_loss_mesh:  0.14303969510365278\n",
      "eikonal_loss:  0.846340537071228\n",
      "Epoch 112: loss = 1.2083914279937744\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.21724137477576733 chamfer_loss_mesh:  0.14395403559319675\n",
      "eikonal_loss:  0.8353027701377869\n",
      "Epoch 113: loss = 1.1975587606430054\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.2171512460336089 chamfer_loss_mesh:  0.143072844366543\n",
      "eikonal_loss:  0.8236204385757446\n",
      "Epoch 114: loss = 1.1849061250686646\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.21718787029385567 chamfer_loss_mesh:  0.1418423926224932\n",
      "eikonal_loss:  0.7902255654335022\n",
      "Epoch 115: loss = 1.1503182649612427\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.21668062545359135 chamfer_loss_mesh:  0.14168224879540503\n",
      "eikonal_loss:  0.7178758382797241\n",
      "Epoch 116: loss = 1.0773016214370728\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.21536448039114475 chamfer_loss_mesh:  0.14219000877346843\n",
      "eikonal_loss:  0.747079610824585\n",
      "Epoch 117: loss = 1.1056978702545166\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.21491420920938253 chamfer_loss_mesh:  0.14296939480118454\n",
      "eikonal_loss:  0.7668299674987793\n",
      "Epoch 118: loss = 1.1257779598236084\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.21416377276182175 chamfer_loss_mesh:  0.1412016135873273\n",
      "eikonal_loss:  0.7965189218521118\n",
      "Epoch 119: loss = 1.1529486179351807\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.21358877420425415 chamfer_loss_mesh:  0.1420078333467245\n",
      "eikonal_loss:  0.7371311783790588\n",
      "Epoch 120: loss = 1.093792200088501\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.21285449620336294 chamfer_loss_mesh:  0.14121353160589933\n",
      "eikonal_loss:  0.7190391421318054\n",
      "Epoch 121: loss = 1.0741722583770752\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.21177777089178562 chamfer_loss_mesh:  0.14026177814230323\n",
      "eikonal_loss:  0.6878335475921631\n",
      "Epoch 122: loss = 1.0409387350082397\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.21066837944090366 chamfer_loss_mesh:  0.14133250806480646\n",
      "eikonal_loss:  0.6537122130393982\n",
      "Epoch 123: loss = 1.0067799091339111\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.21021156571805477 chamfer_loss_mesh:  0.140250995173119\n",
      "eikonal_loss:  0.6304312944412231\n",
      "Epoch 124: loss = 0.9819602370262146\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.2095244126394391 chamfer_loss_mesh:  0.14488864690065384\n",
      "eikonal_loss:  0.5863944888114929\n",
      "Epoch 125: loss = 0.9418743252754211\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.20915884524583817 chamfer_loss_mesh:  0.13998545182403177\n",
      "eikonal_loss:  0.5665403008460999\n",
      "Epoch 126: loss = 0.916753351688385\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.20762861240655184 chamfer_loss_mesh:  0.1404887152602896\n",
      "eikonal_loss:  0.5559855699539185\n",
      "Epoch 127: loss = 0.9051729440689087\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.2063740510493517 chamfer_loss_mesh:  0.1396029838360846\n",
      "eikonal_loss:  0.5435287952423096\n",
      "Epoch 128: loss = 0.890576958656311\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.20532929338514805 chamfer_loss_mesh:  0.13912619033362716\n",
      "eikonal_loss:  0.5685044527053833\n",
      "Epoch 129: loss = 0.9140315651893616\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.20425450056791306 chamfer_loss_mesh:  0.13872302952222526\n",
      "eikonal_loss:  0.5540454983711243\n",
      "Epoch 130: loss = 0.8980953097343445\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.2046694979071617 chamfer_loss_mesh:  0.13878026220481843\n",
      "eikonal_loss:  0.5383618474006653\n",
      "Epoch 131: loss = 0.8828849196434021\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.2029505092650652 chamfer_loss_mesh:  0.1388591917930171\n",
      "eikonal_loss:  0.5279190540313721\n",
      "Epoch 132: loss = 0.8708029389381409\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.2023463137447834 chamfer_loss_mesh:  0.13933797890786082\n",
      "eikonal_loss:  0.5245813131332397\n",
      "Epoch 133: loss = 0.8673407435417175\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.20207585766911507 chamfer_loss_mesh:  0.1386763178743422\n",
      "eikonal_loss:  0.5055263638496399\n",
      "Epoch 134: loss = 0.8473533987998962\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.20024478435516357 chamfer_loss_mesh:  0.1394991995766759\n",
      "eikonal_loss:  0.48751768469810486\n",
      "Epoch 135: loss = 0.8283364176750183\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.19891392439603806 chamfer_loss_mesh:  0.13819393643643707\n",
      "eikonal_loss:  0.49945545196533203\n",
      "Epoch 136: loss = 0.8376389741897583\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.19851690158247948 chamfer_loss_mesh:  0.14266883954405785\n",
      "eikonal_loss:  0.4782716631889343\n",
      "Epoch 137: loss = 0.8205336332321167\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.19735984969884157 chamfer_loss_mesh:  0.1395521394442767\n",
      "eikonal_loss:  0.4831944704055786\n",
      "Epoch 138: loss = 0.8211839199066162\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1978640677407384 chamfer_loss_mesh:  0.1391033292748034\n",
      "eikonal_loss:  0.5167105793952942\n",
      "Epoch 139: loss = 0.8547559380531311\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1970620360225439 chamfer_loss_mesh:  0.1380809844704345\n",
      "eikonal_loss:  0.46817177534103394\n",
      "Epoch 140: loss = 0.804393470287323\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.19640601240098476 chamfer_loss_mesh:  0.13818501611240208\n",
      "eikonal_loss:  0.4484160542488098\n",
      "Epoch 141: loss = 0.7840869426727295\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.19580340012907982 chamfer_loss_mesh:  0.1419181644450873\n",
      "eikonal_loss:  0.4476392865180969\n",
      "Epoch 142: loss = 0.7864421606063843\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.19368347711861134 chamfer_loss_mesh:  0.1421240158379078\n",
      "eikonal_loss:  0.43830934166908264\n",
      "Epoch 143: loss = 0.7751983404159546\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.19311283249408007 chamfer_loss_mesh:  0.1384295610478148\n",
      "eikonal_loss:  1.1345257759094238\n",
      "Epoch 144: loss = 1.467150330543518\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.19172157626599073 chamfer_loss_mesh:  0.1375990395899862\n",
      "eikonal_loss:  0.9285138845443726\n",
      "Epoch 145: loss = 1.2589178085327148\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.19046759698539972 chamfer_loss_mesh:  0.13810649397782981\n",
      "eikonal_loss:  0.8625549674034119\n",
      "Epoch 146: loss = 1.192213773727417\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.19054339500144124 chamfer_loss_mesh:  0.1386263029417023\n",
      "eikonal_loss:  0.7599073648452759\n",
      "Epoch 147: loss = 1.090162754058838\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.19027566304430366 chamfer_loss_mesh:  0.14053401537239552\n",
      "eikonal_loss:  0.3842253088951111\n",
      "Epoch 148: loss = 0.7161213159561157\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.18953317776322365 chamfer_loss_mesh:  0.13900382327847183\n",
      "eikonal_loss:  0.37440037727355957\n",
      "Epoch 149: loss = 0.7040238976478577\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.18854482332244515 chamfer_loss_mesh:  0.14007464051246643\n",
      "eikonal_loss:  0.3596421778202057\n",
      "Epoch 150: loss = 0.6893484592437744\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1879774034023285 chamfer_loss_mesh:  0.13948908599559218\n",
      "eikonal_loss:  0.357532799243927\n",
      "Epoch 151: loss = 0.6860870122909546\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.187229597941041 chamfer_loss_mesh:  0.14059481327421963\n",
      "eikonal_loss:  0.35823720693588257\n",
      "Epoch 152: loss = 0.6871501207351685\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.18693178426474333 chamfer_loss_mesh:  0.14050686149857938\n",
      "eikonal_loss:  0.3505878150463104\n",
      "Epoch 153: loss = 0.6791154146194458\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.18675655592232943 chamfer_loss_mesh:  0.1384962088195607\n",
      "eikonal_loss:  0.33519381284713745\n",
      "Epoch 154: loss = 0.6615368127822876\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.18692068988457322 chamfer_loss_mesh:  0.14101798296906054\n",
      "eikonal_loss:  0.3220057785511017\n",
      "Epoch 155: loss = 0.6510363817214966\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.18648889381438494 chamfer_loss_mesh:  0.13874610885977745\n",
      "eikonal_loss:  0.31837570667266846\n",
      "Epoch 156: loss = 0.64470374584198\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.18496213015168905 chamfer_loss_mesh:  0.1400172186549753\n",
      "eikonal_loss:  0.3189850151538849\n",
      "Epoch 157: loss = 0.645057737827301\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.18463170854374766 chamfer_loss_mesh:  0.14007615391165018\n",
      "eikonal_loss:  0.32166534662246704\n",
      "Epoch 158: loss = 0.6474677324295044\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1836802694015205 chamfer_loss_mesh:  0.1418210449628532\n",
      "eikonal_loss:  0.3163829445838928\n",
      "Epoch 159: loss = 0.6429793834686279\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.18292150925844908 chamfer_loss_mesh:  0.14089095930103213\n",
      "eikonal_loss:  0.5939784646034241\n",
      "Epoch 160: loss = 0.9188862442970276\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.18211607821285725 chamfer_loss_mesh:  0.13906175445299596\n",
      "eikonal_loss:  0.5654522180557251\n",
      "Epoch 161: loss = 0.8877265453338623\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.18205922096967697 chamfer_loss_mesh:  0.14050540630705655\n",
      "eikonal_loss:  0.5039575695991516\n",
      "Epoch 162: loss = 0.8276193141937256\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.18207093235105276 chamfer_loss_mesh:  0.1397365122102201\n",
      "eikonal_loss:  0.4368460476398468\n",
      "Epoch 163: loss = 0.7597509026527405\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.18151969416067004 chamfer_loss_mesh:  0.13936682080384344\n",
      "eikonal_loss:  0.4921873211860657\n",
      "Epoch 164: loss = 0.8141723871231079\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.18084126058965921 chamfer_loss_mesh:  0.13947051775176078\n",
      "eikonal_loss:  0.4343596398830414\n",
      "Epoch 165: loss = 0.7557709217071533\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.18112267134711146 chamfer_loss_mesh:  0.14013635518494993\n",
      "eikonal_loss:  0.48599547147750854\n",
      "Epoch 166: loss = 0.8083545565605164\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.17960220575332642 chamfer_loss_mesh:  0.13813904661219567\n",
      "eikonal_loss:  0.8090915679931641\n",
      "Epoch 167: loss = 1.1279336214065552\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.17986248712986708 chamfer_loss_mesh:  0.13891587150283158\n",
      "eikonal_loss:  0.48901069164276123\n",
      "Epoch 168: loss = 0.8088904619216919\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.17931413603946567 chamfer_loss_mesh:  0.13805468915961683\n",
      "eikonal_loss:  0.5718291401863098\n",
      "Epoch 169: loss = 0.8902996778488159\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1797357341274619 chamfer_loss_mesh:  0.13823418703395873\n",
      "eikonal_loss:  0.3522592782974243\n",
      "Epoch 170: loss = 0.6713326573371887\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.17888708971440792 chamfer_loss_mesh:  0.13835495337843895\n",
      "eikonal_loss:  0.3473779857158661\n",
      "Epoch 171: loss = 0.6657241582870483\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1785277621820569 chamfer_loss_mesh:  0.13619619130622596\n",
      "eikonal_loss:  0.3324038088321686\n",
      "Epoch 172: loss = 0.6482318043708801\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1788170076906681 chamfer_loss_mesh:  0.13936303730588406\n",
      "eikonal_loss:  0.3215314447879791\n",
      "Epoch 173: loss = 0.640816330909729\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.17782191280275583 chamfer_loss_mesh:  0.13704237062484026\n",
      "eikonal_loss:  0.9494932889938354\n",
      "Epoch 174: loss = 1.2654616832733154\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1771743642166257 chamfer_loss_mesh:  0.13648017193190753\n",
      "eikonal_loss:  0.6919792294502258\n",
      "Epoch 175: loss = 1.0067386627197266\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1766531728208065 chamfer_loss_mesh:  0.13677244714926928\n",
      "eikonal_loss:  0.6226661205291748\n",
      "Epoch 176: loss = 0.9371980428695679\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.17686972860246897 chamfer_loss_mesh:  0.15398772666230798\n",
      "eikonal_loss:  0.5123746991157532\n",
      "Epoch 177: loss = 0.8443392515182495\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.17688358202576637 chamfer_loss_mesh:  0.1369172241538763\n",
      "eikonal_loss:  0.3262028396129608\n",
      "Epoch 178: loss = 0.6411106586456299\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.17608774360269308 chamfer_loss_mesh:  0.13659134856425226\n",
      "eikonal_loss:  0.3940543532371521\n",
      "Epoch 179: loss = 0.7078412175178528\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.17637121491134167 chamfer_loss_mesh:  0.13893521099817008\n",
      "eikonal_loss:  0.3726045787334442\n",
      "Epoch 180: loss = 0.6890193223953247\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.17640244914218783 chamfer_loss_mesh:  0.13456595479510725\n",
      "eikonal_loss:  0.35102590918540955\n",
      "Epoch 181: loss = 0.6631029844284058\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.17608655616641045 chamfer_loss_mesh:  0.13495213352143764\n",
      "eikonal_loss:  0.33557987213134766\n",
      "Epoch 182: loss = 0.6477280259132385\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.17689462983980775 chamfer_loss_mesh:  0.13579256483353674\n",
      "eikonal_loss:  0.31960275769233704\n",
      "Epoch 183: loss = 0.6333999633789062\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.17673620022833347 chamfer_loss_mesh:  0.15372363850474358\n",
      "eikonal_loss:  0.3376482427120209\n",
      "Epoch 184: loss = 0.6692174673080444\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1760405721142888 chamfer_loss_mesh:  0.13582946849055588\n",
      "eikonal_loss:  0.33822882175445557\n",
      "Epoch 185: loss = 0.6512093544006348\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1770005328580737 chamfer_loss_mesh:  0.13493298320099711\n",
      "eikonal_loss:  0.32527440786361694\n",
      "Epoch 186: loss = 0.638318657875061\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.17633024835959077 chamfer_loss_mesh:  0.13550541189033538\n",
      "eikonal_loss:  0.3166431188583374\n",
      "Epoch 187: loss = 0.6295912861824036\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.17604262102395296 chamfer_loss_mesh:  0.13526799739338458\n",
      "eikonal_loss:  0.2960967719554901\n",
      "Epoch 188: loss = 0.6085206866264343\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.17594501841813326 chamfer_loss_mesh:  0.1351014943793416\n",
      "eikonal_loss:  0.29113900661468506\n",
      "Epoch 189: loss = 0.6033002138137817\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.17482906114310026 chamfer_loss_mesh:  0.1371009711874649\n",
      "eikonal_loss:  0.28090330958366394\n",
      "Epoch 190: loss = 0.593948483467102\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.17383861122652888 chamfer_loss_mesh:  0.14913645281922072\n",
      "eikonal_loss:  0.28772974014282227\n",
      "Epoch 191: loss = 0.6118198037147522\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1742908963933587 chamfer_loss_mesh:  0.13371910608839244\n",
      "eikonal_loss:  0.29015693068504333\n",
      "Epoch 192: loss = 0.5992828607559204\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.174022582359612 chamfer_loss_mesh:  0.13465358642861247\n",
      "eikonal_loss:  0.29717856645584106\n",
      "Epoch 193: loss = 0.6069709062576294\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.17297264421358705 chamfer_loss_mesh:  0.1349263620795682\n",
      "eikonal_loss:  0.2795935869216919\n",
      "Epoch 194: loss = 0.5886088609695435\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1719326013699174 chamfer_loss_mesh:  0.13476314779836684\n",
      "eikonal_loss:  0.26242589950561523\n",
      "Epoch 195: loss = 0.5702384114265442\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.17190782818943262 chamfer_loss_mesh:  0.13478248729370534\n",
      "eikonal_loss:  0.2583516538143158\n",
      "Epoch 196: loss = 0.5661591291427612\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.17169578932225704 chamfer_loss_mesh:  0.13271320494823158\n",
      "eikonal_loss:  0.24662642180919647\n",
      "Epoch 197: loss = 0.5521529912948608\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.17056388314813375 chamfer_loss_mesh:  0.13756703992839903\n",
      "eikonal_loss:  0.24813514947891235\n",
      "Epoch 198: loss = 0.5573840737342834\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.17070265021175146 chamfer_loss_mesh:  0.15852288925088942\n",
      "eikonal_loss:  0.24169263243675232\n",
      "Epoch 199: loss = 0.5720375776290894\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "Estimated eps_H:  tensor(0.5432, device='cuda:0')\n",
      "cvt_loss:  0.1693521742708981 chamfer_loss_mesh:  0.13510628195945174\n",
      "eikonal_loss:  0.22826513648033142\n",
      "Epoch 200: loss = 0.5338414907455444\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.16929006669670343 chamfer_loss_mesh:  0.13621484686154872\n",
      "eikonal_loss:  0.2345263957977295\n",
      "Epoch 201: loss = 0.5411501526832581\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.16870361287146807 chamfer_loss_mesh:  0.13431915431283414\n",
      "eikonal_loss:  0.23613350093364716\n",
      "Epoch 202: loss = 0.540275514125824\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.16944422386586666 chamfer_loss_mesh:  0.13506349932868034\n",
      "eikonal_loss:  0.21915477514266968\n",
      "Epoch 203: loss = 0.5247824192047119\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.16897455789148808 chamfer_loss_mesh:  0.134268804686144\n",
      "eikonal_loss:  0.24301691353321075\n",
      "Epoch 204: loss = 0.5473817586898804\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.16825064085423946 chamfer_loss_mesh:  0.1332892570644617\n",
      "eikonal_loss:  0.23925843834877014\n",
      "Epoch 205: loss = 0.5419210195541382\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.16772716771811247 chamfer_loss_mesh:  0.1338810834567994\n",
      "eikonal_loss:  0.2325325310230255\n",
      "Epoch 206: loss = 0.5352632999420166\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.16789843793958426 chamfer_loss_mesh:  0.13455754378810525\n",
      "eikonal_loss:  0.22573143243789673\n",
      "Epoch 207: loss = 0.5293103456497192\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1673847669735551 chamfer_loss_mesh:  0.13525137910619378\n",
      "eikonal_loss:  0.17059393227100372\n",
      "Epoch 208: loss = 0.474353551864624\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1663709175772965 chamfer_loss_mesh:  0.13402705371845514\n",
      "eikonal_loss:  0.1766582727432251\n",
      "Epoch 209: loss = 0.47818028926849365\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1659159897826612 chamfer_loss_mesh:  0.13185064017307013\n",
      "eikonal_loss:  0.17918485403060913\n",
      "Epoch 210: loss = 0.4780764579772949\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.16603372059762478 chamfer_loss_mesh:  0.1691636862233281\n",
      "eikonal_loss:  0.18192026019096375\n",
      "Epoch 211: loss = 0.5182433724403381\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.16678532119840384 chamfer_loss_mesh:  0.1318564754910767\n",
      "eikonal_loss:  0.18397238850593567\n",
      "Epoch 212: loss = 0.48374098539352417\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.16725424211472273 chamfer_loss_mesh:  0.1323301694355905\n",
      "eikonal_loss:  0.17643657326698303\n",
      "Epoch 213: loss = 0.4771486520767212\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.16769538633525372 chamfer_loss_mesh:  0.13096656766720116\n",
      "eikonal_loss:  0.1670745611190796\n",
      "Epoch 214: loss = 0.46686428785324097\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.16837995499372482 chamfer_loss_mesh:  0.13153751206118613\n",
      "eikonal_loss:  0.1658073216676712\n",
      "Epoch 215: loss = 0.46685367822647095\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1685159746557474 chamfer_loss_mesh:  0.13289540947880596\n",
      "eikonal_loss:  0.160398468375206\n",
      "Epoch 216: loss = 0.4629387855529785\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1678873086348176 chamfer_loss_mesh:  0.13203753042034805\n",
      "eikonal_loss:  0.173744797706604\n",
      "Epoch 217: loss = 0.474799782037735\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.16864994540810585 chamfer_loss_mesh:  0.1309067738475278\n",
      "eikonal_loss:  0.1485643982887268\n",
      "Epoch 218: loss = 0.4492511749267578\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.16793868271633983 chamfer_loss_mesh:  0.13071422290522605\n",
      "eikonal_loss:  0.16014200448989868\n",
      "Epoch 219: loss = 0.4599265456199646\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.16792078968137503 chamfer_loss_mesh:  0.13058340118732303\n",
      "eikonal_loss:  0.1608147919178009\n",
      "Epoch 220: loss = 0.46045148372650146\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.16783394385129213 chamfer_loss_mesh:  0.13043849321547896\n",
      "eikonal_loss:  0.16981187462806702\n",
      "Epoch 221: loss = 0.4692169725894928\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.16735575627535582 chamfer_loss_mesh:  0.13072976435068995\n",
      "eikonal_loss:  0.15002959966659546\n",
      "Epoch 222: loss = 0.44924819469451904\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1668119803071022 chamfer_loss_mesh:  0.1705726608633995\n",
      "eikonal_loss:  0.1858963668346405\n",
      "Epoch 223: loss = 0.5244153738021851\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.16590551240369678 chamfer_loss_mesh:  0.14820067735854536\n",
      "eikonal_loss:  0.1850740760564804\n",
      "Epoch 224: loss = 0.5003145337104797\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1655148691497743 chamfer_loss_mesh:  0.13178589870221913\n",
      "eikonal_loss:  0.18227161467075348\n",
      "Epoch 225: loss = 0.48070812225341797\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1654264866374433 chamfer_loss_mesh:  0.1304309698753059\n",
      "eikonal_loss:  0.3100678026676178\n",
      "Epoch 226: loss = 0.6070612072944641\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.16525774262845516 chamfer_loss_mesh:  0.12996535224374384\n",
      "eikonal_loss:  0.27950409054756165\n",
      "Epoch 227: loss = 0.5758633613586426\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1649533398449421 chamfer_loss_mesh:  0.13160801609046757\n",
      "eikonal_loss:  0.26306676864624023\n",
      "Epoch 228: loss = 0.5607650279998779\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.16463424544781446 chamfer_loss_mesh:  0.13097839837428182\n",
      "eikonal_loss:  0.15424008667469025\n",
      "Epoch 229: loss = 0.45099031925201416\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.16476812306791544 chamfer_loss_mesh:  0.1312800741288811\n",
      "eikonal_loss:  0.14253666996955872\n",
      "Epoch 230: loss = 0.4397234320640564\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.16413989942520857 chamfer_loss_mesh:  0.13059542106930166\n",
      "eikonal_loss:  0.1370162069797516\n",
      "Epoch 231: loss = 0.4328905940055847\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.16367456410080194 chamfer_loss_mesh:  0.13040521298535168\n",
      "eikonal_loss:  0.13561007380485535\n",
      "Epoch 232: loss = 0.43083059787750244\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.16382751055061817 chamfer_loss_mesh:  0.14832882152404636\n",
      "eikonal_loss:  0.13471025228500366\n",
      "Epoch 233: loss = 0.44800764322280884\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.16265842132270336 chamfer_loss_mesh:  0.13096485054120421\n",
      "eikonal_loss:  0.13757669925689697\n",
      "Epoch 234: loss = 0.4323413372039795\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.16337299020960927 chamfer_loss_mesh:  0.1295846450375393\n",
      "eikonal_loss:  0.28170621395111084\n",
      "Epoch 235: loss = 0.5758069157600403\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1635185442864895 chamfer_loss_mesh:  0.1448573893867433\n",
      "eikonal_loss:  0.2820115089416504\n",
      "Epoch 236: loss = 0.5915324091911316\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1633361680433154 chamfer_loss_mesh:  0.12981852341908962\n",
      "eikonal_loss:  0.29549285769462585\n",
      "Epoch 237: loss = 0.5897928476333618\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.16262824647128582 chamfer_loss_mesh:  0.1295687980018556\n",
      "eikonal_loss:  0.2823536992073059\n",
      "Epoch 238: loss = 0.5756956934928894\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1622945419512689 chamfer_loss_mesh:  0.13151757593732327\n",
      "eikonal_loss:  0.27638354897499084\n",
      "Epoch 239: loss = 0.5713409185409546\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.16368702054023743 chamfer_loss_mesh:  0.1296762056881562\n",
      "eikonal_loss:  0.1816851794719696\n",
      "Epoch 240: loss = 0.47619426250457764\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.16460753977298737 chamfer_loss_mesh:  0.1524617400718853\n",
      "eikonal_loss:  1.8128728866577148\n",
      "Epoch 241: loss = 2.131089210510254\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.16427149530500174 chamfer_loss_mesh:  0.1568355510244146\n",
      "eikonal_loss:  0.30193382501602173\n",
      "Epoch 242: loss = 0.6241883635520935\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1637286739423871 chamfer_loss_mesh:  0.1312822860199958\n",
      "eikonal_loss:  0.2842203378677368\n",
      "Epoch 243: loss = 0.5803786516189575\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.16363183967769146 chamfer_loss_mesh:  0.12841718853451312\n",
      "eikonal_loss:  0.28084275126457214\n",
      "Epoch 244: loss = 0.5740401148796082\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.16265339218080044 chamfer_loss_mesh:  0.1287424092879519\n",
      "eikonal_loss:  0.2610187232494354\n",
      "Epoch 245: loss = 0.5535641312599182\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.162632972933352 chamfer_loss_mesh:  0.13005036453250796\n",
      "eikonal_loss:  0.2533746361732483\n",
      "Epoch 246: loss = 0.547208309173584\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.16328508500009775 chamfer_loss_mesh:  0.12963006156496704\n",
      "eikonal_loss:  0.2396681308746338\n",
      "Epoch 247: loss = 0.5337340235710144\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1629477133974433 chamfer_loss_mesh:  0.1294248504564166\n",
      "eikonal_loss:  0.21913498640060425\n",
      "Epoch 248: loss = 0.5126596689224243\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.16326089389622211 chamfer_loss_mesh:  0.15065660409163684\n",
      "eikonal_loss:  0.20924103260040283\n",
      "Epoch 249: loss = 0.5243115425109863\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1627754420042038 chamfer_loss_mesh:  0.12789838365279138\n",
      "eikonal_loss:  0.21569761633872986\n",
      "Epoch 250: loss = 0.5075253844261169\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.16310600331053138 chamfer_loss_mesh:  0.12792575580533594\n",
      "eikonal_loss:  0.21180510520935059\n",
      "Epoch 251: loss = 0.5039915442466736\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.16345420153811574 chamfer_loss_mesh:  0.1650761696510017\n",
      "eikonal_loss:  0.21087491512298584\n",
      "Epoch 252: loss = 0.5405603647232056\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1622302457690239 chamfer_loss_mesh:  0.12786555453203619\n",
      "eikonal_loss:  0.19809168577194214\n",
      "Epoch 253: loss = 0.48934340476989746\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.16171656316146255 chamfer_loss_mesh:  0.12781342957168818\n",
      "eikonal_loss:  0.2208872139453888\n",
      "Epoch 254: loss = 0.5115747451782227\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.16192460898309946 chamfer_loss_mesh:  0.1296948903473094\n",
      "eikonal_loss:  0.2285376936197281\n",
      "Epoch 255: loss = 0.5213148593902588\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1616115914657712 chamfer_loss_mesh:  0.12831788626499474\n",
      "eikonal_loss:  0.330070823431015\n",
      "Epoch 256: loss = 0.6211581826210022\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.16110686119645834 chamfer_loss_mesh:  0.12721304665319622\n",
      "eikonal_loss:  0.31497782468795776\n",
      "Epoch 257: loss = 0.6044565439224243\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.16060073394328356 chamfer_loss_mesh:  0.1277285919059068\n",
      "eikonal_loss:  0.30026546120643616\n",
      "Epoch 258: loss = 0.5897541642189026\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.16101945657283068 chamfer_loss_mesh:  0.12742461694870144\n",
      "eikonal_loss:  0.28736448287963867\n",
      "Epoch 259: loss = 0.5769680738449097\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1614471315406263 chamfer_loss_mesh:  0.12749296729452908\n",
      "eikonal_loss:  0.2980627715587616\n",
      "Epoch 260: loss = 0.5881627798080444\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.16183985862880945 chamfer_loss_mesh:  0.1650499616516754\n",
      "eikonal_loss:  0.29274237155914307\n",
      "Epoch 261: loss = 0.6207931637763977\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.16069733537733555 chamfer_loss_mesh:  0.1279738498851657\n",
      "eikonal_loss:  0.2766929864883423\n",
      "Epoch 262: loss = 0.5665262937545776\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.16085936222225428 chamfer_loss_mesh:  0.12805171718355268\n",
      "eikonal_loss:  0.2704525589942932\n",
      "Epoch 263: loss = 0.5605264902114868\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.16131852753460407 chamfer_loss_mesh:  0.14560241834260523\n",
      "eikonal_loss:  0.27326834201812744\n",
      "Epoch 264: loss = 0.5813515186309814\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.16124569810926914 chamfer_loss_mesh:  0.12689946743194014\n",
      "eikonal_loss:  0.2706327438354492\n",
      "Epoch 265: loss = 0.5599405765533447\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.16212487826123834 chamfer_loss_mesh:  0.12820379924960434\n",
      "eikonal_loss:  0.26324984431266785\n",
      "Epoch 266: loss = 0.5547420978546143\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.161395117174834 chamfer_loss_mesh:  0.1300896255997941\n",
      "eikonal_loss:  0.25344157218933105\n",
      "Epoch 267: loss = 0.5460913181304932\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1612467342056334 chamfer_loss_mesh:  0.12950392556376755\n",
      "eikonal_loss:  0.25554123520851135\n",
      "Epoch 268: loss = 0.5474570989608765\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1622676383703947 chamfer_loss_mesh:  0.1557357463752851\n",
      "eikonal_loss:  0.11838380247354507\n",
      "Epoch 269: loss = 0.4375530183315277\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1615278422832489 chamfer_loss_mesh:  0.1480839855503291\n",
      "eikonal_loss:  0.11497265845537186\n",
      "Epoch 270: loss = 0.4257507622241974\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1600033137947321 chamfer_loss_mesh:  0.13400685566011816\n",
      "eikonal_loss:  0.10824974626302719\n",
      "Epoch 271: loss = 0.4034268856048584\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1601113472133875 chamfer_loss_mesh:  0.1558717922307551\n",
      "eikonal_loss:  0.11328250169754028\n",
      "Epoch 272: loss = 0.43043363094329834\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.15989078674465418 chamfer_loss_mesh:  0.12873088417109102\n",
      "eikonal_loss:  0.11072200536727905\n",
      "Epoch 273: loss = 0.4005119204521179\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1590687781572342 chamfer_loss_mesh:  0.12978649465367198\n",
      "eikonal_loss:  0.109157994389534\n",
      "Epoch 274: loss = 0.3991808295249939\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.15843899454921484 chamfer_loss_mesh:  0.12760038953274488\n",
      "eikonal_loss:  0.10820944607257843\n",
      "Epoch 275: loss = 0.3954169750213623\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.15854242956265807 chamfer_loss_mesh:  0.12927390343975276\n",
      "eikonal_loss:  0.10354121029376984\n",
      "Epoch 276: loss = 0.39252644777297974\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.15757132787257433 chamfer_loss_mesh:  0.12928320211358368\n",
      "eikonal_loss:  0.09448635578155518\n",
      "Epoch 277: loss = 0.38251009583473206\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.15749909216538072 chamfer_loss_mesh:  0.1293180976063013\n",
      "eikonal_loss:  0.09220638871192932\n",
      "Epoch 278: loss = 0.3801927864551544\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.15723261749371886 chamfer_loss_mesh:  0.1572179899085313\n",
      "eikonal_loss:  0.08992056548595428\n",
      "Epoch 279: loss = 0.40554139018058777\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1564967562444508 chamfer_loss_mesh:  0.1281650911550969\n",
      "eikonal_loss:  0.08826448023319244\n",
      "Epoch 280: loss = 0.37409791350364685\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.15569505048915744 chamfer_loss_mesh:  0.12842121941503137\n",
      "eikonal_loss:  0.08374349027872086\n",
      "Epoch 281: loss = 0.36903148889541626\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.15544898342341185 chamfer_loss_mesh:  0.12837382382713258\n",
      "eikonal_loss:  0.08079522848129272\n",
      "Epoch 282: loss = 0.36579033732414246\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.15497400891035795 chamfer_loss_mesh:  0.12813341163564473\n",
      "eikonal_loss:  0.07898232340812683\n",
      "Epoch 283: loss = 0.36326125264167786\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.15428642509505153 chamfer_loss_mesh:  0.13264600420370698\n",
      "eikonal_loss:  0.07644977420568466\n",
      "Epoch 284: loss = 0.3645551800727844\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.15451419167220592 chamfer_loss_mesh:  0.12767774751409888\n",
      "eikonal_loss:  0.07408744841814041\n",
      "Epoch 285: loss = 0.3574536442756653\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1544737839139998 chamfer_loss_mesh:  0.12899117427878082\n",
      "eikonal_loss:  0.07217492908239365\n",
      "Epoch 286: loss = 0.356815367937088\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.15463365707546473 chamfer_loss_mesh:  0.12912062811665237\n",
      "eikonal_loss:  0.07120577245950699\n",
      "Epoch 287: loss = 0.35613560676574707\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.15447319019585848 chamfer_loss_mesh:  0.12816442176699638\n",
      "eikonal_loss:  0.06976963579654694\n",
      "Epoch 288: loss = 0.35358375310897827\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.15476008411496878 chamfer_loss_mesh:  0.15766908472869545\n",
      "eikonal_loss:  0.06637861579656601\n",
      "Epoch 289: loss = 0.37998539209365845\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.15443635638803244 chamfer_loss_mesh:  0.16340591537300497\n",
      "eikonal_loss:  0.06499727070331573\n",
      "Epoch 290: loss = 0.3840179443359375\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1539035583846271 chamfer_loss_mesh:  0.1284594472963363\n",
      "eikonal_loss:  0.0633845329284668\n",
      "Epoch 291: loss = 0.34692710638046265\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.15362994745373726 chamfer_loss_mesh:  0.14676307910121977\n",
      "eikonal_loss:  0.06913215667009354\n",
      "Epoch 292: loss = 0.37070488929748535\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.15361165860667825 chamfer_loss_mesh:  0.13222452253103256\n",
      "eikonal_loss:  0.06108008697628975\n",
      "Epoch 293: loss = 0.3480960726737976\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.15334750059992075 chamfer_loss_mesh:  0.13005055370740592\n",
      "eikonal_loss:  0.058685820549726486\n",
      "Epoch 294: loss = 0.34326499700546265\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.15326268039643764 chamfer_loss_mesh:  0.15568277740385383\n",
      "eikonal_loss:  0.056257739663124084\n",
      "Epoch 295: loss = 0.36638426780700684\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.15335469506680965 chamfer_loss_mesh:  0.12685077672358602\n",
      "eikonal_loss:  0.055073924362659454\n",
      "Epoch 296: loss = 0.33646082878112793\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.15254821628332138 chamfer_loss_mesh:  0.13379886513575912\n",
      "eikonal_loss:  0.053912196308374405\n",
      "Epoch 297: loss = 0.3414419889450073\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.15268687857314944 chamfer_loss_mesh:  0.14794239541515708\n",
      "eikonal_loss:  0.05406903475522995\n",
      "Epoch 298: loss = 0.35588231682777405\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.15314735937863588 chamfer_loss_mesh:  0.1283677847823128\n",
      "eikonal_loss:  0.05299033224582672\n",
      "Epoch 299: loss = 0.335689514875412\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "Estimated eps_H:  tensor(0.5416, device='cuda:0')\n",
      "cvt_loss:  0.1530108624137938 chamfer_loss_mesh:  0.162229742272757\n",
      "eikonal_loss:  0.0529397614300251\n",
      "Epoch 300: loss = 0.36936405301094055\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1521379454061389 chamfer_loss_mesh:  0.1278031850233674\n",
      "eikonal_loss:  0.05298250913619995\n",
      "Epoch 301: loss = 0.3341076076030731\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1515170093625784 chamfer_loss_mesh:  0.16073725419119\n",
      "eikonal_loss:  0.05300956219434738\n",
      "Epoch 302: loss = 0.3664483428001404\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.15041709411889315 chamfer_loss_mesh:  0.12934562982991338\n",
      "eikonal_loss:  0.05189523473381996\n",
      "Epoch 303: loss = 0.33284303545951843\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1498116645962 chamfer_loss_mesh:  0.1283758319914341\n",
      "eikonal_loss:  0.05119381099939346\n",
      "Epoch 304: loss = 0.3305667042732239\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.15045657055452466 chamfer_loss_mesh:  0.1296909904340282\n",
      "eikonal_loss:  0.050196800380945206\n",
      "Epoch 305: loss = 0.33153095841407776\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1496356911957264 chamfer_loss_mesh:  0.1286856277147308\n",
      "eikonal_loss:  0.049148522317409515\n",
      "Epoch 306: loss = 0.32865607738494873\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.14941971749067307 chamfer_loss_mesh:  0.146297097671777\n",
      "eikonal_loss:  0.04830507934093475\n",
      "Epoch 307: loss = 0.3452076315879822\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.14951317571103573 chamfer_loss_mesh:  0.12676161713898182\n",
      "eikonal_loss:  0.048070795834064484\n",
      "Epoch 308: loss = 0.3255317807197571\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.14929039170965552 chamfer_loss_mesh:  0.14032941544428468\n",
      "eikonal_loss:  0.046969883143901825\n",
      "Epoch 309: loss = 0.3377755880355835\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.14927576994523406 chamfer_loss_mesh:  0.12795580551028252\n",
      "eikonal_loss:  0.04550547152757645\n",
      "Epoch 310: loss = 0.32392367720603943\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1493187854066491 chamfer_loss_mesh:  0.1280777796637267\n",
      "eikonal_loss:  0.04684722423553467\n",
      "Epoch 311: loss = 0.32543042302131653\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.14912154292687774 chamfer_loss_mesh:  0.12680102372542024\n",
      "eikonal_loss:  0.04837774112820625\n",
      "Epoch 312: loss = 0.3254871964454651\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.14897421933710575 chamfer_loss_mesh:  0.1280687574762851\n",
      "eikonal_loss:  0.04720776528120041\n",
      "Epoch 313: loss = 0.32543864846229553\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.14903367264196277 chamfer_loss_mesh:  0.14332664432004094\n",
      "eikonal_loss:  0.04668896645307541\n",
      "Epoch 314: loss = 0.3402373194694519\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.14906884171068668 chamfer_loss_mesh:  0.1286663464270532\n",
      "eikonal_loss:  0.04555899277329445\n",
      "Epoch 315: loss = 0.3244817554950714\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.14865833800286055 chamfer_loss_mesh:  0.12873753439635038\n",
      "eikonal_loss:  0.04449087753891945\n",
      "Epoch 316: loss = 0.32307544350624084\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.14897582586854696 chamfer_loss_mesh:  0.14961145643610507\n",
      "eikonal_loss:  0.04326115921139717\n",
      "Epoch 317: loss = 0.34303733706474304\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.14789467677474022 chamfer_loss_mesh:  0.1281631411984563\n",
      "eikonal_loss:  0.041827231645584106\n",
      "Epoch 318: loss = 0.3190733790397644\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.14809540007263422 chamfer_loss_mesh:  0.148661361890845\n",
      "eikonal_loss:  0.04302429035305977\n",
      "Epoch 319: loss = 0.3409702181816101\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.14716271543875337 chamfer_loss_mesh:  0.14162316801957786\n",
      "eikonal_loss:  0.04160838574171066\n",
      "Epoch 320: loss = 0.33158430457115173\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.14669722877442837 chamfer_loss_mesh:  0.16402744222432375\n",
      "eikonal_loss:  0.03842002525925636\n",
      "Epoch 321: loss = 0.3503364026546478\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.14641834422945976 chamfer_loss_mesh:  0.12614749721251428\n",
      "eikonal_loss:  0.03956829756498337\n",
      "Epoch 322: loss = 0.31332552433013916\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1465612673200667 chamfer_loss_mesh:  0.14160988212097436\n",
      "eikonal_loss:  0.04039712995290756\n",
      "Epoch 323: loss = 0.32976076006889343\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.146252172999084 chamfer_loss_mesh:  0.16034074360504746\n",
      "eikonal_loss:  0.03983713313937187\n",
      "Epoch 324: loss = 0.34762218594551086\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.14600669965147972 chamfer_loss_mesh:  0.12638824409805238\n",
      "eikonal_loss:  0.039865635335445404\n",
      "Epoch 325: loss = 0.3134534955024719\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.14479426899924874 chamfer_loss_mesh:  0.1258249394595623\n",
      "eikonal_loss:  0.03949332609772682\n",
      "Epoch 326: loss = 0.31130605936050415\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1440336462110281 chamfer_loss_mesh:  0.12536522990558296\n",
      "eikonal_loss:  0.03853461891412735\n",
      "Epoch 327: loss = 0.3091268241405487\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.14415985206142068 chamfer_loss_mesh:  0.1293779059778899\n",
      "eikonal_loss:  0.03993038088083267\n",
      "Epoch 328: loss = 0.31466183066368103\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.14431353192776442 chamfer_loss_mesh:  0.12697259080596268\n",
      "eikonal_loss:  0.038424547761678696\n",
      "Epoch 329: loss = 0.31090542674064636\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.14437921345233917 chamfer_loss_mesh:  0.1268650230485946\n",
      "eikonal_loss:  0.03768628090620041\n",
      "Epoch 330: loss = 0.310124933719635\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1440111198462546 chamfer_loss_mesh:  0.12713889009319246\n",
      "eikonal_loss:  0.03658560290932655\n",
      "Epoch 331: loss = 0.3089296817779541\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1434309408068657 chamfer_loss_mesh:  0.127134146168828\n",
      "eikonal_loss:  0.03560798242688179\n",
      "Epoch 332: loss = 0.30736812949180603\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.14405903639271855 chamfer_loss_mesh:  0.12702957610599697\n",
      "eikonal_loss:  0.03496120870113373\n",
      "Epoch 333: loss = 0.3072459101676941\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.14346992829814553 chamfer_loss_mesh:  0.12618576874956489\n",
      "eikonal_loss:  0.033494122326374054\n",
      "Epoch 334: loss = 0.30434590578079224\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1431535929441452 chamfer_loss_mesh:  0.19392240210436285\n",
      "eikonal_loss:  0.03293171897530556\n",
      "Epoch 335: loss = 0.37120506167411804\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1428472576662898 chamfer_loss_mesh:  0.19683489517774433\n",
      "eikonal_loss:  0.03248259425163269\n",
      "Epoch 336: loss = 0.37336260080337524\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.14210103545337915 chamfer_loss_mesh:  0.12562135816551745\n",
      "eikonal_loss:  0.03211607784032822\n",
      "Epoch 337: loss = 0.3010360300540924\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.14226495986804366 chamfer_loss_mesh:  0.14861972886137664\n",
      "eikonal_loss:  0.03136037662625313\n",
      "Epoch 338: loss = 0.32344263792037964\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.14239787124097347 chamfer_loss_mesh:  0.13025494990870357\n",
      "eikonal_loss:  0.031162703409790993\n",
      "Epoch 339: loss = 0.30501335859298706\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.14269076054915786 chamfer_loss_mesh:  0.12662773951888084\n",
      "eikonal_loss:  0.03049100749194622\n",
      "Epoch 340: loss = 0.3010075092315674\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.14293817803263664 chamfer_loss_mesh:  0.12710614828392863\n",
      "eikonal_loss:  0.029302304610610008\n",
      "Epoch 341: loss = 0.30054548382759094\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.14352455036714673 chamfer_loss_mesh:  0.15512018580920994\n",
      "eikonal_loss:  0.029313480481505394\n",
      "Epoch 342: loss = 0.3291579484939575\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.14283506898209453 chamfer_loss_mesh:  0.1259317941730842\n",
      "eikonal_loss:  0.028331033885478973\n",
      "Epoch 343: loss = 0.2982977628707886\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.14272937551140785 chamfer_loss_mesh:  0.1258126285392791\n",
      "eikonal_loss:  0.027758579701185226\n",
      "Epoch 344: loss = 0.29749995470046997\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1426965929567814 chamfer_loss_mesh:  0.12482515012379736\n",
      "eikonal_loss:  0.027168521657586098\n",
      "Epoch 345: loss = 0.2958901524543762\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1421897322870791 chamfer_loss_mesh:  0.12730600428767502\n",
      "eikonal_loss:  0.026257110759615898\n",
      "Epoch 346: loss = 0.29695361852645874\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.14239965239539742 chamfer_loss_mesh:  0.1263979502255097\n",
      "eikonal_loss:  0.029877830296754837\n",
      "Epoch 347: loss = 0.2998766601085663\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.14190541114658117 chamfer_loss_mesh:  0.12850281200371683\n",
      "eikonal_loss:  0.0254938006401062\n",
      "Epoch 348: loss = 0.2971036732196808\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.14261292526498437 chamfer_loss_mesh:  0.1264659222215414\n",
      "eikonal_loss:  0.025677049532532692\n",
      "Epoch 349: loss = 0.29595789313316345\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1414933241903782 chamfer_loss_mesh:  0.12450618669390678\n",
      "eikonal_loss:  0.025111094117164612\n",
      "Epoch 350: loss = 0.2923128604888916\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.14082869747653604 chamfer_loss_mesh:  0.14696060679852962\n",
      "eikonal_loss:  0.02423851564526558\n",
      "Epoch 351: loss = 0.3132304847240448\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.14056095387786627 chamfer_loss_mesh:  0.12590928236022592\n",
      "eikonal_loss:  0.02349277213215828\n",
      "Epoch 352: loss = 0.2911660075187683\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1404094509780407 chamfer_loss_mesh:  0.12656982289627194\n",
      "eikonal_loss:  0.03391900658607483\n",
      "Epoch 353: loss = 0.3021017909049988\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1405426301062107 chamfer_loss_mesh:  0.12598573812283576\n",
      "eikonal_loss:  0.028300125151872635\n",
      "Epoch 354: loss = 0.2960323393344879\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.14097962994128466 chamfer_loss_mesh:  0.17123355064541101\n",
      "eikonal_loss:  0.026957720518112183\n",
      "Epoch 355: loss = 0.3403761386871338\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1405824557878077 chamfer_loss_mesh:  0.14579849084839225\n",
      "eikonal_loss:  0.026614617556333542\n",
      "Epoch 356: loss = 0.3142004907131195\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1408760785125196 chamfer_loss_mesh:  0.12617945321835577\n",
      "eikonal_loss:  0.025261234492063522\n",
      "Epoch 357: loss = 0.2935228645801544\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.14115513768047094 chamfer_loss_mesh:  0.12601543858181685\n",
      "eikonal_loss:  0.02483781799674034\n",
      "Epoch 358: loss = 0.2932148873806\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.14122636057436466 chamfer_loss_mesh:  0.12670106661971658\n",
      "eikonal_loss:  0.022340165451169014\n",
      "Epoch 359: loss = 0.2914751470088959\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.14154170639812946 chamfer_loss_mesh:  0.1568346342537552\n",
      "eikonal_loss:  0.020777158439159393\n",
      "Epoch 360: loss = 0.3203609585762024\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1405869727022946 chamfer_loss_mesh:  0.12462104496080428\n",
      "eikonal_loss:  0.023687278851866722\n",
      "Epoch 361: loss = 0.29010316729545593\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13994897017255425 chamfer_loss_mesh:  0.12571728439070284\n",
      "eikonal_loss:  0.02286488562822342\n",
      "Epoch 362: loss = 0.2897396385669708\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13966304250061512 chamfer_loss_mesh:  0.12585066724568605\n",
      "eikonal_loss:  0.02224644273519516\n",
      "Epoch 363: loss = 0.2889671325683594\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13956015463918447 chamfer_loss_mesh:  0.12618294567801058\n",
      "eikonal_loss:  0.03199612349271774\n",
      "Epoch 364: loss = 0.2989465892314911\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1390606164932251 chamfer_loss_mesh:  0.1277500850846991\n",
      "eikonal_loss:  0.03183301165699959\n",
      "Epoch 365: loss = 0.2998519837856293\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13891354901716113 chamfer_loss_mesh:  0.12452366354409605\n",
      "eikonal_loss:  0.027886338531970978\n",
      "Epoch 366: loss = 0.2925322651863098\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13913032598793507 chamfer_loss_mesh:  0.12497190618887544\n",
      "eikonal_loss:  0.030792012810707092\n",
      "Epoch 367: loss = 0.2961026728153229\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13881518971174955 chamfer_loss_mesh:  0.12493922258727252\n",
      "eikonal_loss:  0.109050452709198\n",
      "Epoch 368: loss = 0.3740134537220001\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13827162329107523 chamfer_loss_mesh:  0.12449940550141037\n",
      "eikonal_loss:  0.058694105595350266\n",
      "Epoch 369: loss = 0.3226741850376129\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13763161841779947 chamfer_loss_mesh:  0.13826327631250024\n",
      "eikonal_loss:  0.16338327527046204\n",
      "Epoch 370: loss = 0.4404873549938202\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13891695998609066 chamfer_loss_mesh:  0.17448831931687891\n",
      "eikonal_loss:  0.33425644040107727\n",
      "Epoch 371: loss = 0.6488716006278992\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13973891036584973 chamfer_loss_mesh:  0.14374227612279356\n",
      "eikonal_loss:  0.24944908916950226\n",
      "Epoch 372: loss = 0.5341393351554871\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.14013061299920082 chamfer_loss_mesh:  0.12433930533006787\n",
      "eikonal_loss:  0.49868232011795044\n",
      "Epoch 373: loss = 0.7643630504608154\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.14024489792063832 chamfer_loss_mesh:  0.12527426588349044\n",
      "eikonal_loss:  0.4031449258327484\n",
      "Epoch 374: loss = 0.6698756217956543\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13960391515865922 chamfer_loss_mesh:  0.12443822924979031\n",
      "eikonal_loss:  0.388477087020874\n",
      "Epoch 375: loss = 0.6537303924560547\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13986136764287949 chamfer_loss_mesh:  0.1243441947735846\n",
      "eikonal_loss:  0.324433296918869\n",
      "Epoch 376: loss = 0.5898498296737671\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13941311044618487 chamfer_loss_mesh:  0.12387827155180275\n",
      "eikonal_loss:  0.2876514792442322\n",
      "Epoch 377: loss = 0.5521537065505981\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1394411432556808 chamfer_loss_mesh:  0.156460446305573\n",
      "eikonal_loss:  0.27862027287483215\n",
      "Epoch 378: loss = 0.5757324695587158\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13979554641991854 chamfer_loss_mesh:  0.12459175195544958\n",
      "eikonal_loss:  0.319899320602417\n",
      "Epoch 379: loss = 0.5854980945587158\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.14077473897486925 chamfer_loss_mesh:  0.1270205102628097\n",
      "eikonal_loss:  0.7422094345092773\n",
      "Epoch 380: loss = 1.011216163635254\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1406265888363123 chamfer_loss_mesh:  0.12432086805347353\n",
      "eikonal_loss:  0.5970578193664551\n",
      "Epoch 381: loss = 0.8632170557975769\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.14039966044947505 chamfer_loss_mesh:  0.12460297148209065\n",
      "eikonal_loss:  0.7567342519760132\n",
      "Epoch 382: loss = 1.0229487419128418\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.14014244079589844 chamfer_loss_mesh:  0.1458337646909058\n",
      "eikonal_loss:  0.42141860723495483\n",
      "Epoch 383: loss = 0.7086069583892822\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1396500039845705 chamfer_loss_mesh:  0.12451110524125397\n",
      "eikonal_loss:  0.1716216802597046\n",
      "Epoch 384: loss = 0.4369959831237793\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13975820038467646 chamfer_loss_mesh:  0.12485722254496068\n",
      "eikonal_loss:  0.1566486358642578\n",
      "Epoch 385: loss = 0.4224766492843628\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13992877211421728 chamfer_loss_mesh:  0.12877577682957053\n",
      "eikonal_loss:  0.1444798856973648\n",
      "Epoch 386: loss = 0.41439735889434814\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13935700990259647 chamfer_loss_mesh:  0.15007215552031994\n",
      "eikonal_loss:  0.03998219594359398\n",
      "Epoch 387: loss = 0.3306250274181366\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1394778722897172 chamfer_loss_mesh:  0.1521976082585752\n",
      "eikonal_loss:  0.038428932428359985\n",
      "Epoch 388: loss = 0.33131757378578186\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13885853113606572 chamfer_loss_mesh:  0.12461698497645557\n",
      "eikonal_loss:  0.03898642957210541\n",
      "Epoch 389: loss = 0.303674578666687\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.138950371183455 chamfer_loss_mesh:  0.12412937940098345\n",
      "eikonal_loss:  0.03854558244347572\n",
      "Epoch 390: loss = 0.30283820629119873\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1388072152622044 chamfer_loss_mesh:  0.14745314547326416\n",
      "eikonal_loss:  0.03800776228308678\n",
      "Epoch 391: loss = 0.32548171281814575\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13875158037990332 chamfer_loss_mesh:  0.12373857316561043\n",
      "eikonal_loss:  0.03397306054830551\n",
      "Epoch 392: loss = 0.29767611622810364\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13891977723687887 chamfer_loss_mesh:  0.1251128560397774\n",
      "eikonal_loss:  0.033815059810876846\n",
      "Epoch 393: loss = 0.29906055331230164\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13871481642127037 chamfer_loss_mesh:  0.1470763236284256\n",
      "eikonal_loss:  0.03312668949365616\n",
      "Epoch 394: loss = 0.32013168931007385\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13887614477425814 chamfer_loss_mesh:  0.12385482841636986\n",
      "eikonal_loss:  0.03457760438323021\n",
      "Epoch 395: loss = 0.2985232472419739\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13868757523596287 chamfer_loss_mesh:  0.1568333391332999\n",
      "eikonal_loss:  0.03410493582487106\n",
      "Epoch 396: loss = 0.3308403491973877\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1386911841109395 chamfer_loss_mesh:  0.12861544382758439\n",
      "eikonal_loss:  0.032914645969867706\n",
      "Epoch 397: loss = 0.30143478512763977\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1385226845741272 chamfer_loss_mesh:  0.12308500299695879\n",
      "eikonal_loss:  0.032398223876953125\n",
      "Epoch 398: loss = 0.2952199876308441\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1376192318275571 chamfer_loss_mesh:  0.12397559476085007\n",
      "eikonal_loss:  0.031812798231840134\n",
      "Epoch 399: loss = 0.29462283849716187\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "Estimated eps_H:  tensor(0.5407, device='cuda:0')\n",
      "cvt_loss:  0.13847437221556902 chamfer_loss_mesh:  0.18266093684360385\n",
      "eikonal_loss:  0.03092963621020317\n",
      "Epoch 400: loss = 0.3532804250717163\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1379080000333488 chamfer_loss_mesh:  0.12306355347391218\n",
      "eikonal_loss:  0.030479421839118004\n",
      "Epoch 401: loss = 0.29266542196273804\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13728043995797634 chamfer_loss_mesh:  0.12368999887257814\n",
      "eikonal_loss:  0.030449703335762024\n",
      "Epoch 402: loss = 0.2926352918148041\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13737492263317108 chamfer_loss_mesh:  0.18701129010878503\n",
      "eikonal_loss:  0.02947690151631832\n",
      "Epoch 403: loss = 0.35507726669311523\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13764407485723495 chamfer_loss_mesh:  0.12390725896693766\n",
      "eikonal_loss:  0.028087638318538666\n",
      "Epoch 404: loss = 0.29085367918014526\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1374692190438509 chamfer_loss_mesh:  0.14985009329393506\n",
      "eikonal_loss:  0.027485733851790428\n",
      "Epoch 405: loss = 0.3160199522972107\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13829811941832304 chamfer_loss_mesh:  0.15116263239178807\n",
      "eikonal_loss:  0.026826757937669754\n",
      "Epoch 406: loss = 0.31750234961509705\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1383954891934991 chamfer_loss_mesh:  0.12361253902781755\n",
      "eikonal_loss:  0.02729903534054756\n",
      "Epoch 407: loss = 0.2905208468437195\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13872942654415965 chamfer_loss_mesh:  0.15320739476010203\n",
      "eikonal_loss:  0.026433631777763367\n",
      "Epoch 408: loss = 0.31958502531051636\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13856046134606004 chamfer_loss_mesh:  0.1891459833132103\n",
      "eikonal_loss:  0.026400987058877945\n",
      "Epoch 409: loss = 0.35532280802726746\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13821101747453213 chamfer_loss_mesh:  0.12270208389963955\n",
      "eikonal_loss:  0.027385931462049484\n",
      "Epoch 410: loss = 0.28951412439346313\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13813907280564308 chamfer_loss_mesh:  0.17062653205357492\n",
      "eikonal_loss:  0.02687903121113777\n",
      "Epoch 411: loss = 0.33685991168022156\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1380041241645813 chamfer_loss_mesh:  0.12433482334017754\n",
      "eikonal_loss:  0.026025734841823578\n",
      "Epoch 412: loss = 0.2895808517932892\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13772191014140844 chamfer_loss_mesh:  0.1848814426921308\n",
      "eikonal_loss:  0.025338593870401382\n",
      "Epoch 413: loss = 0.3491585850715637\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1376433065161109 chamfer_loss_mesh:  0.12318373774178326\n",
      "eikonal_loss:  0.024941304698586464\n",
      "Epoch 414: loss = 0.286984384059906\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13895535375922918 chamfer_loss_mesh:  0.1387184311170131\n",
      "eikonal_loss:  0.025386381894350052\n",
      "Epoch 415: loss = 0.3042772710323334\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13803635956719518 chamfer_loss_mesh:  0.12284792319405824\n",
      "eikonal_loss:  0.024205129593610764\n",
      "Epoch 416: loss = 0.2863059639930725\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1379744615405798 chamfer_loss_mesh:  0.12405173038132489\n",
      "eikonal_loss:  0.023150963708758354\n",
      "Epoch 417: loss = 0.2863939702510834\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13720348943024874 chamfer_loss_mesh:  0.123208126751706\n",
      "eikonal_loss:  0.022492144256830215\n",
      "Epoch 418: loss = 0.28412023186683655\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13689863262698054 chamfer_loss_mesh:  0.12386146408971399\n",
      "eikonal_loss:  0.13832023739814758\n",
      "Epoch 419: loss = 0.4002969563007355\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13672644272446632 chamfer_loss_mesh:  0.12233294546604156\n",
      "eikonal_loss:  0.11732152104377747\n",
      "Epoch 420: loss = 0.377598375082016\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13626895379275084 chamfer_loss_mesh:  0.1219968544319272\n",
      "eikonal_loss:  0.1086185947060585\n",
      "Epoch 421: loss = 0.3681022822856903\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.136650912463665 chamfer_loss_mesh:  0.16200519166886806\n",
      "eikonal_loss:  0.0999128669500351\n",
      "Epoch 422: loss = 0.39978688955307007\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13615813804790378 chamfer_loss_mesh:  0.12289381993468851\n",
      "eikonal_loss:  0.09118165075778961\n",
      "Epoch 423: loss = 0.3514515161514282\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.135924038477242 chamfer_loss_mesh:  0.1227210887009278\n",
      "eikonal_loss:  0.07762103527784348\n",
      "Epoch 424: loss = 0.33748432993888855\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1369755482301116 chamfer_loss_mesh:  0.12282768147997558\n",
      "eikonal_loss:  0.06965481489896774\n",
      "Epoch 425: loss = 0.33067697286605835\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1372437342070043 chamfer_loss_mesh:  0.12349798635113984\n",
      "eikonal_loss:  0.06675668805837631\n",
      "Epoch 426: loss = 0.328717976808548\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13736584223806858 chamfer_loss_mesh:  0.14958580140955746\n",
      "eikonal_loss:  0.06768689304590225\n",
      "Epoch 427: loss = 0.3558580279350281\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13699309201911092 chamfer_loss_mesh:  0.13878147001378238\n",
      "eikonal_loss:  0.06096188351511955\n",
      "Epoch 428: loss = 0.3379566967487335\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13647369341924787 chamfer_loss_mesh:  0.12158116442151368\n",
      "eikonal_loss:  0.0638110563158989\n",
      "Epoch 429: loss = 0.3230867385864258\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13504746602848172 chamfer_loss_mesh:  0.12237663031555712\n",
      "eikonal_loss:  0.05629619210958481\n",
      "Epoch 430: loss = 0.31494107842445374\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13586964923888445 chamfer_loss_mesh:  0.12291088933125138\n",
      "eikonal_loss:  0.05276559293270111\n",
      "Epoch 431: loss = 0.3127679228782654\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.135747529566288 chamfer_loss_mesh:  0.12520444579422474\n",
      "eikonal_loss:  0.0507175512611866\n",
      "Epoch 432: loss = 0.31289204955101013\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1356307417154312 chamfer_loss_mesh:  0.1739828148856759\n",
      "eikonal_loss:  0.049072910100221634\n",
      "Epoch 433: loss = 0.3599085211753845\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1362421317026019 chamfer_loss_mesh:  0.12241526565048844\n",
      "eikonal_loss:  0.04370339587330818\n",
      "Epoch 434: loss = 0.3035839796066284\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13575281482189894 chamfer_loss_mesh:  0.1466293615521863\n",
      "eikonal_loss:  0.041510943323373795\n",
      "Epoch 435: loss = 0.32511666417121887\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13653271598741412 chamfer_loss_mesh:  0.12164810323156416\n",
      "eikonal_loss:  0.03989261016249657\n",
      "Epoch 436: loss = 0.2992967367172241\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13579907827079296 chamfer_loss_mesh:  0.12205675011500716\n",
      "eikonal_loss:  0.04152481257915497\n",
      "Epoch 437: loss = 0.3006046712398529\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13544198591262102 chamfer_loss_mesh:  0.12205586972413585\n",
      "eikonal_loss:  0.03992082178592682\n",
      "Epoch 438: loss = 0.2986425459384918\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13504857197403908 chamfer_loss_mesh:  0.12241702643223107\n",
      "eikonal_loss:  0.035696350038051605\n",
      "Epoch 439: loss = 0.2943863570690155\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13493148144334555 chamfer_loss_mesh:  0.12166162196081132\n",
      "eikonal_loss:  0.03766315057873726\n",
      "Epoch 440: loss = 0.29548096656799316\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13471463462337852 chamfer_loss_mesh:  0.14023311086930335\n",
      "eikonal_loss:  0.03602838143706322\n",
      "Epoch 441: loss = 0.3122011423110962\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13561960076913238 chamfer_loss_mesh:  0.16765178588684648\n",
      "eikonal_loss:  0.03551040589809418\n",
      "Epoch 442: loss = 0.34000688791275024\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1352511695586145 chamfer_loss_mesh:  0.12256849731784314\n",
      "eikonal_loss:  0.034708112478256226\n",
      "Epoch 443: loss = 0.2937529981136322\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13488715048879385 chamfer_loss_mesh:  0.12584384239744395\n",
      "eikonal_loss:  0.0340765118598938\n",
      "Epoch 444: loss = 0.29603248834609985\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13463713694363832 chamfer_loss_mesh:  0.12838002294301987\n",
      "eikonal_loss:  0.034752007573843\n",
      "Epoch 445: loss = 0.2989940643310547\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13420864706858993 chamfer_loss_mesh:  0.12240067007951438\n",
      "eikonal_loss:  0.03205520659685135\n",
      "Epoch 446: loss = 0.28988951444625854\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13366646599024534 chamfer_loss_mesh:  0.12234336463734508\n",
      "eikonal_loss:  0.03093048557639122\n",
      "Epoch 447: loss = 0.2881658971309662\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1331905834376812 chamfer_loss_mesh:  0.12270387378521264\n",
      "eikonal_loss:  0.030975716188549995\n",
      "Epoch 448: loss = 0.2880956530570984\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13277106918394566 chamfer_loss_mesh:  0.12215334572829306\n",
      "eikonal_loss:  0.041219573467969894\n",
      "Epoch 449: loss = 0.29736948013305664\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13258992694318295 chamfer_loss_mesh:  0.15470250218641013\n",
      "eikonal_loss:  0.03934839740395546\n",
      "Epoch 450: loss = 0.3278661370277405\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1322489813901484 chamfer_loss_mesh:  0.12371930642984807\n",
      "eikonal_loss:  0.037470005452632904\n",
      "Epoch 451: loss = 0.29466331005096436\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13254110235720873 chamfer_loss_mesh:  0.15378743410110474\n",
      "eikonal_loss:  0.0360068753361702\n",
      "Epoch 452: loss = 0.32356083393096924\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13190717436373234 chamfer_loss_mesh:  0.1407973759341985\n",
      "eikonal_loss:  0.035057052969932556\n",
      "Epoch 453: loss = 0.30898693203926086\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13173057232052088 chamfer_loss_mesh:  0.12334344501141459\n",
      "eikonal_loss:  0.03401939570903778\n",
      "Epoch 454: loss = 0.29031917452812195\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13156572822481394 chamfer_loss_mesh:  0.1427250972483307\n",
      "eikonal_loss:  0.03325413912534714\n",
      "Epoch 455: loss = 0.3087707757949829\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13187353033572435 chamfer_loss_mesh:  0.12523937039077282\n",
      "eikonal_loss:  0.031878888607025146\n",
      "Epoch 456: loss = 0.29021772742271423\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13121238444000483 chamfer_loss_mesh:  0.12457533739507198\n",
      "eikonal_loss:  0.03131499141454697\n",
      "Epoch 457: loss = 0.2883281707763672\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13164975680410862 chamfer_loss_mesh:  0.160893308930099\n",
      "eikonal_loss:  0.03145080432295799\n",
      "Epoch 458: loss = 0.32522034645080566\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13160249218344688 chamfer_loss_mesh:  0.17301421030424535\n",
      "eikonal_loss:  0.031173553317785263\n",
      "Epoch 459: loss = 0.33701661229133606\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13109880965203047 chamfer_loss_mesh:  0.15434162924066186\n",
      "eikonal_loss:  0.030829697847366333\n",
      "Epoch 460: loss = 0.317496657371521\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13049482367932796 chamfer_loss_mesh:  0.12555326975416392\n",
      "eikonal_loss:  0.030168937519192696\n",
      "Epoch 461: loss = 0.2874436676502228\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12971960240975022 chamfer_loss_mesh:  0.12378278188407421\n",
      "eikonal_loss:  0.029032614082098007\n",
      "Epoch 462: loss = 0.2837626039981842\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13005519285798073 chamfer_loss_mesh:  0.12314868217799813\n",
      "eikonal_loss:  0.028475075960159302\n",
      "Epoch 463: loss = 0.282907098531723\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1302825752645731 chamfer_loss_mesh:  0.12544385390356183\n",
      "eikonal_loss:  0.04423452168703079\n",
      "Epoch 464: loss = 0.3011894226074219\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1303499797359109 chamfer_loss_mesh:  0.1361206523142755\n",
      "eikonal_loss:  0.028361737728118896\n",
      "Epoch 465: loss = 0.2960614264011383\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13035694137215614 chamfer_loss_mesh:  0.1639360561966896\n",
      "eikonal_loss:  0.0282466821372509\n",
      "Epoch 466: loss = 0.3237689733505249\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13130123261362314 chamfer_loss_mesh:  0.15296548372134566\n",
      "eikonal_loss:  0.027699146419763565\n",
      "Epoch 467: loss = 0.3131958246231079\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13111294247210026 chamfer_loss_mesh:  0.12334302300587296\n",
      "eikonal_loss:  0.027414757758378983\n",
      "Epoch 468: loss = 0.2831008732318878\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1309926388785243 chamfer_loss_mesh:  0.12292324390728027\n",
      "eikonal_loss:  0.026637345552444458\n",
      "Epoch 469: loss = 0.2817830741405487\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13190184254199266 chamfer_loss_mesh:  0.12315867934376001\n",
      "eikonal_loss:  0.026699379086494446\n",
      "Epoch 470: loss = 0.28299054503440857\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1321071176789701 chamfer_loss_mesh:  0.14382200606632978\n",
      "eikonal_loss:  0.02617044188082218\n",
      "Epoch 471: loss = 0.3033298850059509\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1313367742113769 chamfer_loss_mesh:  0.12290902668610215\n",
      "eikonal_loss:  0.02553923800587654\n",
      "Epoch 472: loss = 0.28101587295532227\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13174538034945726 chamfer_loss_mesh:  0.12259621871635318\n",
      "eikonal_loss:  0.024515733122825623\n",
      "Epoch 473: loss = 0.280088871717453\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1313073094934225 chamfer_loss_mesh:  0.1441256026737392\n",
      "eikonal_loss:  0.0231461301445961\n",
      "Epoch 474: loss = 0.29981139302253723\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13077245093882084 chamfer_loss_mesh:  0.12113519915146753\n",
      "eikonal_loss:  0.02359328418970108\n",
      "Epoch 475: loss = 0.27673375606536865\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13145898701623082 chamfer_loss_mesh:  0.1208935136673972\n",
      "eikonal_loss:  0.02065456472337246\n",
      "Epoch 476: loss = 0.2742392420768738\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13201874680817127 chamfer_loss_mesh:  0.12158441677456722\n",
      "eikonal_loss:  0.02066263183951378\n",
      "Epoch 477: loss = 0.27549704909324646\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13181177200749516 chamfer_loss_mesh:  0.1217074750456959\n",
      "eikonal_loss:  0.02020658180117607\n",
      "Epoch 478: loss = 0.2749572992324829\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13172910548746586 chamfer_loss_mesh:  0.14874478802084923\n",
      "eikonal_loss:  0.019923191517591476\n",
      "Epoch 479: loss = 0.3016294538974762\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13120747171342373 chamfer_loss_mesh:  0.12081829481758177\n",
      "eikonal_loss:  0.020592808723449707\n",
      "Epoch 480: loss = 0.27385103702545166\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13053478905931115 chamfer_loss_mesh:  0.12100972526241094\n",
      "eikonal_loss:  0.01864481158554554\n",
      "Epoch 481: loss = 0.271421879529953\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12985102366656065 chamfer_loss_mesh:  0.12188641994725913\n",
      "eikonal_loss:  0.01839440129697323\n",
      "Epoch 482: loss = 0.27136552333831787\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12959050945937634 chamfer_loss_mesh:  0.12195606541354209\n",
      "eikonal_loss:  0.01833609864115715\n",
      "Epoch 483: loss = 0.27111729979515076\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12935673585161567 chamfer_loss_mesh:  0.12067130592186004\n",
      "eikonal_loss:  0.015120589174330235\n",
      "Epoch 484: loss = 0.2663847804069519\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12918382417410612 chamfer_loss_mesh:  0.16362767200917006\n",
      "eikonal_loss:  0.014304994605481625\n",
      "Epoch 485: loss = 0.3083523213863373\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12913343962281942 chamfer_loss_mesh:  0.2042973937932402\n",
      "eikonal_loss:  0.028294481337070465\n",
      "Epoch 486: loss = 0.3629603385925293\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13032524148002267 chamfer_loss_mesh:  0.12181334022898227\n",
      "eikonal_loss:  0.025011079385876656\n",
      "Epoch 487: loss = 0.27838510274887085\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13029396068304777 chamfer_loss_mesh:  0.12203223013784736\n",
      "eikonal_loss:  0.02078792080283165\n",
      "Epoch 488: loss = 0.2743493318557739\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13077647890895605 chamfer_loss_mesh:  0.1387335651088506\n",
      "eikonal_loss:  0.016072073951363564\n",
      "Epoch 489: loss = 0.28681811690330505\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13048510299995542 chamfer_loss_mesh:  0.15498872380703688\n",
      "eikonal_loss:  0.014878515154123306\n",
      "Epoch 490: loss = 0.3015882074832916\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12938919244334102 chamfer_loss_mesh:  0.12145254004281014\n",
      "eikonal_loss:  0.013937129639089108\n",
      "Epoch 491: loss = 0.2660154104232788\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1298375427722931 chamfer_loss_mesh:  0.12058603169862181\n",
      "eikonal_loss:  0.011804817244410515\n",
      "Epoch 492: loss = 0.2634654939174652\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12981535401195288 chamfer_loss_mesh:  0.1437339815311134\n",
      "eikonal_loss:  0.012760786339640617\n",
      "Epoch 493: loss = 0.28754720091819763\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12902893358841538 chamfer_loss_mesh:  0.12135355063946918\n",
      "eikonal_loss:  0.012746568769216537\n",
      "Epoch 494: loss = 0.26436668634414673\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12845875462517142 chamfer_loss_mesh:  0.12129958486184478\n",
      "eikonal_loss:  0.014014792628586292\n",
      "Epoch 495: loss = 0.26501134037971497\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12864285381510854 chamfer_loss_mesh:  0.12108944792998955\n",
      "eikonal_loss:  0.01427906658500433\n",
      "Epoch 496: loss = 0.26525071263313293\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12800816912204027 chamfer_loss_mesh:  0.13201248657424003\n",
      "eikonal_loss:  0.0152784064412117\n",
      "Epoch 497: loss = 0.27653783559799194\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12792709749192 chamfer_loss_mesh:  0.15706282283645123\n",
      "eikonal_loss:  0.013739810325205326\n",
      "Epoch 498: loss = 0.2999681532382965\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1276723574846983 chamfer_loss_mesh:  0.12097248691134155\n",
      "eikonal_loss:  0.011739911511540413\n",
      "Epoch 499: loss = 0.26162415742874146\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "Estimated eps_H:  tensor(0.5402, device='cuda:0')\n",
      "cvt_loss:  0.1281993230804801 chamfer_loss_mesh:  0.12127446825616062\n",
      "eikonal_loss:  0.012247561477124691\n",
      "Epoch 500: loss = 0.2629600465297699\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12834208318963647 chamfer_loss_mesh:  0.1223122380906716\n",
      "eikonal_loss:  0.011665912345051765\n",
      "Epoch 501: loss = 0.26355868577957153\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1278577488847077 chamfer_loss_mesh:  0.1466791145503521\n",
      "eikonal_loss:  0.023532044142484665\n",
      "Epoch 502: loss = 0.2993069887161255\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12769761960953474 chamfer_loss_mesh:  0.11985523451585323\n",
      "eikonal_loss:  0.04306788742542267\n",
      "Epoch 503: loss = 0.2918596565723419\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12750598834827542 chamfer_loss_mesh:  0.12172243441455066\n",
      "eikonal_loss:  0.038243189454078674\n",
      "Epoch 504: loss = 0.2887125015258789\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12748399749398232 chamfer_loss_mesh:  0.1216538657899946\n",
      "eikonal_loss:  0.04069208726286888\n",
      "Epoch 505: loss = 0.29107022285461426\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.127686676569283 chamfer_loss_mesh:  0.1568527368362993\n",
      "eikonal_loss:  0.04082513600587845\n",
      "Epoch 506: loss = 0.3266041576862335\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12792879715561867 chamfer_loss_mesh:  0.15317247016355395\n",
      "eikonal_loss:  0.03318435698747635\n",
      "Epoch 507: loss = 0.31552624702453613\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12734485790133476 chamfer_loss_mesh:  0.1211712951771915\n",
      "eikonal_loss:  0.030912935733795166\n",
      "Epoch 508: loss = 0.28066954016685486\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12763278791680932 chamfer_loss_mesh:  0.13343681348487735\n",
      "eikonal_loss:  0.027148479595780373\n",
      "Epoch 509: loss = 0.2894587218761444\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12781182304024696 chamfer_loss_mesh:  0.11917897791136056\n",
      "eikonal_loss:  0.294792115688324\n",
      "Epoch 510: loss = 0.5430244207382202\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12815932277590036 chamfer_loss_mesh:  0.12083203182555735\n",
      "eikonal_loss:  0.4362547695636749\n",
      "Epoch 511: loss = 0.6864873766899109\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12877839617431164 chamfer_loss_mesh:  0.12038795102853328\n",
      "eikonal_loss:  0.9625188112258911\n",
      "Epoch 512: loss = 1.2129278182983398\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12886811746284366 chamfer_loss_mesh:  0.12118883023504168\n",
      "eikonal_loss:  0.835777759552002\n",
      "Epoch 513: loss = 1.0870780944824219\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1295817899517715 chamfer_loss_mesh:  0.14935716171748936\n",
      "eikonal_loss:  0.7363707423210144\n",
      "Epoch 514: loss = 1.0165541172027588\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12945376802235842 chamfer_loss_mesh:  0.12031015648972243\n",
      "eikonal_loss:  0.6626994013786316\n",
      "Epoch 515: loss = 0.9137078523635864\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12960145249962807 chamfer_loss_mesh:  0.11965016892645508\n",
      "eikonal_loss:  0.5797712802886963\n",
      "Epoch 516: loss = 0.8302680850028992\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1293797162361443 chamfer_loss_mesh:  0.12058777792844921\n",
      "eikonal_loss:  0.5208510756492615\n",
      "Epoch 517: loss = 0.7720643281936646\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12914545368403196 chamfer_loss_mesh:  0.12115307617932558\n",
      "eikonal_loss:  0.4759293794631958\n",
      "Epoch 518: loss = 0.7274734377861023\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12951368698850274 chamfer_loss_mesh:  0.15687983250245452\n",
      "eikonal_loss:  0.4064329266548157\n",
      "Epoch 519: loss = 0.6940711736679077\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12895578984171152 chamfer_loss_mesh:  0.12040223373332992\n",
      "eikonal_loss:  0.3794887363910675\n",
      "Epoch 520: loss = 0.6300920248031616\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12880709255114198 chamfer_loss_mesh:  0.12087178765796125\n",
      "eikonal_loss:  0.34026503562927246\n",
      "Epoch 521: loss = 0.5911886692047119\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12884755851700902 chamfer_loss_mesh:  0.14831527369096875\n",
      "eikonal_loss:  0.3239169120788574\n",
      "Epoch 522: loss = 0.6023250222206116\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12918859720230103 chamfer_loss_mesh:  0.17146575555671006\n",
      "eikonal_loss:  0.32343441247940063\n",
      "Epoch 523: loss = 0.6253352761268616\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12919518630951643 chamfer_loss_mesh:  0.12068905198248103\n",
      "eikonal_loss:  0.3131614625453949\n",
      "Epoch 524: loss = 0.5642920136451721\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12880072463303804 chamfer_loss_mesh:  0.12138255260651931\n",
      "eikonal_loss:  0.2982218861579895\n",
      "Epoch 525: loss = 0.549651026725769\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12948231305927038 chamfer_loss_mesh:  0.13904451043345034\n",
      "eikonal_loss:  0.2714264392852783\n",
      "Epoch 526: loss = 0.5411990284919739\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12952041579410434 chamfer_loss_mesh:  0.12788892490789294\n",
      "eikonal_loss:  0.25366640090942383\n",
      "Epoch 527: loss = 0.5123217105865479\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12984985951334238 chamfer_loss_mesh:  0.17723123892210424\n",
      "eikonal_loss:  0.23369359970092773\n",
      "Epoch 528: loss = 0.5420212745666504\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12942180037498474 chamfer_loss_mesh:  0.13617929653264582\n",
      "eikonal_loss:  0.20766368508338928\n",
      "Epoch 529: loss = 0.4745118021965027\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12928403448313475 chamfer_loss_mesh:  0.1220961130456999\n",
      "eikonal_loss:  0.18024411797523499\n",
      "Epoch 530: loss = 0.43287211656570435\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12925626942887902 chamfer_loss_mesh:  0.121562865388114\n",
      "eikonal_loss:  0.11979593336582184\n",
      "Epoch 531: loss = 0.37186354398727417\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12978645972907543 chamfer_loss_mesh:  0.17384924285579473\n",
      "eikonal_loss:  0.10936804860830307\n",
      "Epoch 532: loss = 0.4142518937587738\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12962991604581475 chamfer_loss_mesh:  0.1504579558968544\n",
      "eikonal_loss:  0.26655709743499756\n",
      "Epoch 533: loss = 0.5478925704956055\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13007341185584664 chamfer_loss_mesh:  0.15888620691839606\n",
      "eikonal_loss:  0.1053643673658371\n",
      "Epoch 534: loss = 0.3955719470977783\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13062652433291078 chamfer_loss_mesh:  0.12104483175789937\n",
      "eikonal_loss:  0.09753357619047165\n",
      "Epoch 535: loss = 0.3504546284675598\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13139874208718538 chamfer_loss_mesh:  0.14909583842381835\n",
      "eikonal_loss:  0.1017979234457016\n",
      "Epoch 536: loss = 0.3835410475730896\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1312467735260725 chamfer_loss_mesh:  0.1210882473969832\n",
      "eikonal_loss:  0.17965546250343323\n",
      "Epoch 537: loss = 0.43324095010757446\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13070638524368405 chamfer_loss_mesh:  0.12174483708804473\n",
      "eikonal_loss:  0.16145268082618713\n",
      "Epoch 538: loss = 0.41515499353408813\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1294849207624793 chamfer_loss_mesh:  0.15478537534363568\n",
      "eikonal_loss:  0.1431676149368286\n",
      "Epoch 539: loss = 0.4286881685256958\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12936957646161318 chamfer_loss_mesh:  0.12127113586757332\n",
      "eikonal_loss:  0.08273182809352875\n",
      "Epoch 540: loss = 0.3346233069896698\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12974555138498545 chamfer_loss_mesh:  0.1236153329955414\n",
      "eikonal_loss:  0.11993430554866791\n",
      "Epoch 541: loss = 0.37454599142074585\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1294092508032918 chamfer_loss_mesh:  0.17490868049208075\n",
      "eikonal_loss:  0.12304041534662247\n",
      "Epoch 542: loss = 0.4286094307899475\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12974906712770462 chamfer_loss_mesh:  0.18530811939854175\n",
      "eikonal_loss:  0.09805765748023987\n",
      "Epoch 543: loss = 0.41436612606048584\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12964732013642788 chamfer_loss_mesh:  0.12524303747341037\n",
      "eikonal_loss:  0.121946319937706\n",
      "Epoch 544: loss = 0.3780866265296936\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1295178197324276 chamfer_loss_mesh:  0.1529277942609042\n",
      "eikonal_loss:  0.11091858148574829\n",
      "Epoch 545: loss = 0.3946148157119751\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1295905327424407 chamfer_loss_mesh:  0.12124692148063332\n",
      "eikonal_loss:  0.10664217919111252\n",
      "Epoch 546: loss = 0.3587299585342407\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12918419670313597 chamfer_loss_mesh:  0.12085605703759938\n",
      "eikonal_loss:  0.11468187719583511\n",
      "Epoch 547: loss = 0.36597248911857605\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1295671332627535 chamfer_loss_mesh:  0.15975735732354224\n",
      "eikonal_loss:  0.10423079133033752\n",
      "Epoch 548: loss = 0.3948065936565399\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1295369933359325 chamfer_loss_mesh:  0.12007674376945943\n",
      "eikonal_loss:  0.10197457671165466\n",
      "Epoch 549: loss = 0.3528400659561157\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1289635431021452 chamfer_loss_mesh:  0.12033739767502993\n",
      "eikonal_loss:  0.09645134210586548\n",
      "Epoch 550: loss = 0.34700292348861694\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12977132573723793 chamfer_loss_mesh:  0.1613437052583322\n",
      "eikonal_loss:  0.08354060351848602\n",
      "Epoch 551: loss = 0.3759060502052307\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12952509569004178 chamfer_loss_mesh:  0.12306362623348832\n",
      "eikonal_loss:  0.0787828266620636\n",
      "Epoch 552: loss = 0.33262109756469727\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12948516523465514 chamfer_loss_mesh:  0.13625386054627597\n",
      "eikonal_loss:  0.0778111144900322\n",
      "Epoch 553: loss = 0.34480103850364685\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13000814942643046 chamfer_loss_mesh:  0.11998632544418797\n",
      "eikonal_loss:  0.07922805845737457\n",
      "Epoch 554: loss = 0.3304738402366638\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1298796385526657 chamfer_loss_mesh:  0.12023025192320347\n",
      "eikonal_loss:  0.06737571954727173\n",
      "Epoch 555: loss = 0.3187355101108551\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13031677808612585 chamfer_loss_mesh:  0.12272660387679935\n",
      "eikonal_loss:  0.0679607018828392\n",
      "Epoch 556: loss = 0.3222554922103882\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13001429615542293 chamfer_loss_mesh:  0.12164803774794564\n",
      "eikonal_loss:  0.06541935354471207\n",
      "Epoch 557: loss = 0.3183344006538391\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13051703572273254 chamfer_loss_mesh:  0.16990031872410327\n",
      "eikonal_loss:  0.06431657075881958\n",
      "Epoch 558: loss = 0.36598655581474304\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1301968703046441 chamfer_loss_mesh:  0.11981462739640847\n",
      "eikonal_loss:  0.06474995613098145\n",
      "Epoch 559: loss = 0.31601420044898987\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1304560457356274 chamfer_loss_mesh:  0.14075898798182607\n",
      "eikonal_loss:  0.058290135115385056\n",
      "Epoch 560: loss = 0.33075815439224243\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12997648445889354 chamfer_loss_mesh:  0.11923716374440119\n",
      "eikonal_loss:  0.055093973875045776\n",
      "Epoch 561: loss = 0.30556032061576843\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13015065342187881 chamfer_loss_mesh:  0.1354074920527637\n",
      "eikonal_loss:  0.05332501605153084\n",
      "Epoch 562: loss = 0.3201358914375305\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13037401949986815 chamfer_loss_mesh:  0.11839072249131277\n",
      "eikonal_loss:  0.05510704591870308\n",
      "Epoch 563: loss = 0.30512481927871704\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1307337894104421 chamfer_loss_mesh:  0.16884005162864923\n",
      "eikonal_loss:  0.0593455471098423\n",
      "Epoch 564: loss = 0.360172837972641\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13049645349383354 chamfer_loss_mesh:  0.13834945275448263\n",
      "eikonal_loss:  0.056023936718702316\n",
      "Epoch 565: loss = 0.3261229991912842\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1304563833400607 chamfer_loss_mesh:  0.11935574002563953\n",
      "eikonal_loss:  0.05085635557770729\n",
      "Epoch 566: loss = 0.3019220232963562\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1303223194554448 chamfer_loss_mesh:  0.1201603445224464\n",
      "eikonal_loss:  0.05231538787484169\n",
      "Epoch 567: loss = 0.3040521740913391\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13044718652963638 chamfer_loss_mesh:  0.12376175436656922\n",
      "eikonal_loss:  0.05150008574128151\n",
      "Epoch 568: loss = 0.3069625794887543\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13068956322968006 chamfer_loss_mesh:  0.11922586418222636\n",
      "eikonal_loss:  0.05388302728533745\n",
      "Epoch 569: loss = 0.30505281686782837\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13122032396495342 chamfer_loss_mesh:  0.11951123451581225\n",
      "eikonal_loss:  0.04749932140111923\n",
      "Epoch 570: loss = 0.2994851768016815\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13045115629211068 chamfer_loss_mesh:  0.11932511552004144\n",
      "eikonal_loss:  0.04304226115345955\n",
      "Epoch 571: loss = 0.29407215118408203\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13003898784518242 chamfer_loss_mesh:  0.11997683031950146\n",
      "eikonal_loss:  0.041029226034879684\n",
      "Epoch 572: loss = 0.2922985255718231\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12948859948664904 chamfer_loss_mesh:  0.14709419338032603\n",
      "eikonal_loss:  0.03679563105106354\n",
      "Epoch 573: loss = 0.31463220715522766\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12964167399331927 chamfer_loss_mesh:  0.19082543440163136\n",
      "eikonal_loss:  0.03695333003997803\n",
      "Epoch 574: loss = 0.35867422819137573\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12976324651390314 chamfer_loss_mesh:  0.12011939543299377\n",
      "eikonal_loss:  0.0398833230137825\n",
      "Epoch 575: loss = 0.2910197973251343\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12979370076209307 chamfer_loss_mesh:  0.1555517374072224\n",
      "eikonal_loss:  0.035498298704624176\n",
      "Epoch 576: loss = 0.32209864258766174\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12938029831275344 chamfer_loss_mesh:  0.11895956413354725\n",
      "eikonal_loss:  0.034779272973537445\n",
      "Epoch 577: loss = 0.28437525033950806\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1288724597543478 chamfer_loss_mesh:  0.11914387869182974\n",
      "eikonal_loss:  0.03295380249619484\n",
      "Epoch 578: loss = 0.28222498297691345\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12854966334998608 chamfer_loss_mesh:  0.12058009451720864\n",
      "eikonal_loss:  0.03156178072094917\n",
      "Epoch 579: loss = 0.2819479703903198\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12883817544206977 chamfer_loss_mesh:  0.11934951908187941\n",
      "eikonal_loss:  0.031530141830444336\n",
      "Epoch 580: loss = 0.28097403049468994\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12874933890998363 chamfer_loss_mesh:  0.11868160800077021\n",
      "eikonal_loss:  0.02910909429192543\n",
      "Epoch 581: loss = 0.27779659628868103\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1291925087571144 chamfer_loss_mesh:  0.12067685020156205\n",
      "eikonal_loss:  0.026416238397359848\n",
      "Epoch 582: loss = 0.27754145860671997\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13022343628108501 chamfer_loss_mesh:  0.1540335942991078\n",
      "eikonal_loss:  0.026259759441018105\n",
      "Epoch 583: loss = 0.3117743730545044\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12998853344470263 chamfer_loss_mesh:  0.13417602167464793\n",
      "eikonal_loss:  0.023695584386587143\n",
      "Epoch 584: loss = 0.2891182601451874\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12991358526051044 chamfer_loss_mesh:  0.11838533828267828\n",
      "eikonal_loss:  0.023816846311092377\n",
      "Epoch 585: loss = 0.2733749449253082\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12983938213437796 chamfer_loss_mesh:  0.13923051301389933\n",
      "eikonal_loss:  0.01823555864393711\n",
      "Epoch 586: loss = 0.28856441378593445\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12939581647515297 chamfer_loss_mesh:  0.12177629105281085\n",
      "eikonal_loss:  0.01830313540995121\n",
      "Epoch 587: loss = 0.27073490619659424\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12894136598333716 chamfer_loss_mesh:  0.2358553174417466\n",
      "eikonal_loss:  0.018820151686668396\n",
      "Epoch 588: loss = 0.3848767578601837\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1286260667257011 chamfer_loss_mesh:  0.13774007675237954\n",
      "eikonal_loss:  0.01860686019062996\n",
      "Epoch 589: loss = 0.28623318672180176\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12864477466791868 chamfer_loss_mesh:  0.15737189096398652\n",
      "eikonal_loss:  0.08508969098329544\n",
      "Epoch 590: loss = 0.3723672926425934\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12902994640171528 chamfer_loss_mesh:  0.1211655035149306\n",
      "eikonal_loss:  0.2627968192100525\n",
      "Epoch 591: loss = 0.5142525434494019\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12897530104964972 chamfer_loss_mesh:  0.11814533354481682\n",
      "eikonal_loss:  0.1040060967206955\n",
      "Epoch 592: loss = 0.35238784551620483\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12883275048807263 chamfer_loss_mesh:  0.16239049728028476\n",
      "eikonal_loss:  0.2580903470516205\n",
      "Epoch 593: loss = 0.5505751371383667\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1295946422033012 chamfer_loss_mesh:  0.14432966418098658\n",
      "eikonal_loss:  0.3658403158187866\n",
      "Epoch 594: loss = 0.6410261392593384\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12927678180858493 chamfer_loss_mesh:  0.11814314348157495\n",
      "eikonal_loss:  0.025805886834859848\n",
      "Epoch 595: loss = 0.27448710799217224\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1290764776058495 chamfer_loss_mesh:  0.11923325655516237\n",
      "eikonal_loss:  0.058579422533512115\n",
      "Epoch 596: loss = 0.30814963579177856\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12898972490802407 chamfer_loss_mesh:  0.16137422062456608\n",
      "eikonal_loss:  0.021463904529809952\n",
      "Epoch 597: loss = 0.31308919191360474\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.128803844563663 chamfer_loss_mesh:  0.11927860759897158\n",
      "eikonal_loss:  0.02119402587413788\n",
      "Epoch 598: loss = 0.2705383896827698\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12873304076492786 chamfer_loss_mesh:  0.11919606185983866\n",
      "eikonal_loss:  0.020258205011487007\n",
      "Epoch 599: loss = 0.26944881677627563\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "Estimated eps_H:  tensor(0.2158, device='cuda:0')\n",
      "cvt_loss:  0.1288783736526966 chamfer_loss_mesh:  0.12877958943136036\n",
      "eikonal_loss:  0.019466063007712364\n",
      "Epoch 600: loss = 0.27846962213516235\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12913173995912075 chamfer_loss_mesh:  0.11948388419114053\n",
      "eikonal_loss:  0.019306987524032593\n",
      "Epoch 601: loss = 0.26926881074905396\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1291243825107813 chamfer_loss_mesh:  0.11790212010964751\n",
      "eikonal_loss:  0.019906071946024895\n",
      "Epoch 602: loss = 0.26827871799468994\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12887455523014069 chamfer_loss_mesh:  0.11888492736034095\n",
      "eikonal_loss:  0.01968543790280819\n",
      "Epoch 603: loss = 0.26879096031188965\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1287990715354681 chamfer_loss_mesh:  0.11771043500630185\n",
      "eikonal_loss:  0.018754150718450546\n",
      "Epoch 604: loss = 0.26661109924316406\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12860014103353024 chamfer_loss_mesh:  0.11800236097769812\n",
      "eikonal_loss:  0.01789756678044796\n",
      "Epoch 605: loss = 0.2658464312553406\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12815160444006324 chamfer_loss_mesh:  0.1425828377250582\n",
      "eikonal_loss:  0.017118873074650764\n",
      "Epoch 606: loss = 0.28919997811317444\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12817168608307838 chamfer_loss_mesh:  0.11783007357735187\n",
      "eikonal_loss:  0.016717810183763504\n",
      "Epoch 607: loss = 0.2640659809112549\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12826622696593404 chamfer_loss_mesh:  0.1336268032900989\n",
      "eikonal_loss:  0.015921343117952347\n",
      "Epoch 608: loss = 0.2791626751422882\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12909246142953634 chamfer_loss_mesh:  0.11818874918390065\n",
      "eikonal_loss:  0.01526547409594059\n",
      "Epoch 609: loss = 0.2638947665691376\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1289590960368514 chamfer_loss_mesh:  0.11800623906310648\n",
      "eikonal_loss:  0.018554961308836937\n",
      "Epoch 610: loss = 0.26686808466911316\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1288758823648095 chamfer_loss_mesh:  0.13803632464259863\n",
      "eikonal_loss:  0.014634862542152405\n",
      "Epoch 611: loss = 0.28289544582366943\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12855054810643196 chamfer_loss_mesh:  0.11975636152783409\n",
      "eikonal_loss:  0.014394381083548069\n",
      "Epoch 612: loss = 0.26404696702957153\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12833313085138798 chamfer_loss_mesh:  0.11870772868860513\n",
      "eikonal_loss:  0.013750084675848484\n",
      "Epoch 613: loss = 0.2621392011642456\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12831008061766624 chamfer_loss_mesh:  0.13987973215989769\n",
      "eikonal_loss:  0.013242926448583603\n",
      "Epoch 614: loss = 0.2827821969985962\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12778225354850292 chamfer_loss_mesh:  0.11791393626481295\n",
      "eikonal_loss:  0.013087327592074871\n",
      "Epoch 615: loss = 0.26013293862342834\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12811326887458563 chamfer_loss_mesh:  0.12295146007090807\n",
      "eikonal_loss:  0.0127941919490695\n",
      "Epoch 616: loss = 0.2652081251144409\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1275349291972816 chamfer_loss_mesh:  0.11985964374616742\n",
      "eikonal_loss:  0.012483871541917324\n",
      "Epoch 617: loss = 0.26122811436653137\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12762465048581362 chamfer_loss_mesh:  0.11876166536239907\n",
      "eikonal_loss:  0.012166453525424004\n",
      "Epoch 618: loss = 0.25990208983421326\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12838579714298248 chamfer_loss_mesh:  0.11785824608523399\n",
      "eikonal_loss:  0.012347979471087456\n",
      "Epoch 619: loss = 0.2599406838417053\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12869425117969513 chamfer_loss_mesh:  0.15843051369301975\n",
      "eikonal_loss:  0.011743100360035896\n",
      "Epoch 620: loss = 0.30021509528160095\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12812576023861766 chamfer_loss_mesh:  0.11700623144861311\n",
      "eikonal_loss:  0.011344333179295063\n",
      "Epoch 621: loss = 0.25782355666160583\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12836216483265162 chamfer_loss_mesh:  0.165736346389167\n",
      "eikonal_loss:  0.011276481673121452\n",
      "Epoch 622: loss = 0.30672213435173035\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1280377502553165 chamfer_loss_mesh:  0.11843988613691181\n",
      "eikonal_loss:  0.011289909482002258\n",
      "Epoch 623: loss = 0.25911641120910645\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12777724768966436 chamfer_loss_mesh:  0.11761842324631289\n",
      "eikonal_loss:  0.010986879467964172\n",
      "Epoch 624: loss = 0.25773102045059204\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12765536084771156 chamfer_loss_mesh:  0.11834868928417563\n",
      "eikonal_loss:  0.011026156134903431\n",
      "Epoch 625: loss = 0.25837811827659607\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1276580849662423 chamfer_loss_mesh:  0.11948255996685475\n",
      "eikonal_loss:  0.010893570259213448\n",
      "Epoch 626: loss = 0.25938400626182556\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12699596118181944 chamfer_loss_mesh:  0.11739612818928435\n",
      "eikonal_loss:  0.010798047296702862\n",
      "Epoch 627: loss = 0.2565392255783081\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1272583962418139 chamfer_loss_mesh:  0.11947901657549664\n",
      "eikonal_loss:  0.010030867531895638\n",
      "Epoch 628: loss = 0.25811752676963806\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1274893176741898 chamfer_loss_mesh:  0.1699554268270731\n",
      "eikonal_loss:  0.010587010532617569\n",
      "Epoch 629: loss = 0.3093833327293396\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12718318030238152 chamfer_loss_mesh:  0.11686978541547433\n",
      "eikonal_loss:  0.010254459455609322\n",
      "Epoch 630: loss = 0.2556581497192383\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12691160663962364 chamfer_loss_mesh:  0.11784248636104167\n",
      "eikonal_loss:  0.009972356259822845\n",
      "Epoch 631: loss = 0.25607579946517944\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12753354385495186 chamfer_loss_mesh:  0.13183757255319506\n",
      "eikonal_loss:  0.010330494493246078\n",
      "Epoch 632: loss = 0.2710525691509247\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12718739453703165 chamfer_loss_mesh:  0.1179288883577101\n",
      "eikonal_loss:  0.010125843808054924\n",
      "Epoch 633: loss = 0.25659117102622986\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12719470541924238 chamfer_loss_mesh:  0.13791794481221586\n",
      "eikonal_loss:  0.015517406165599823\n",
      "Epoch 634: loss = 0.2819803059101105\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12644384987652302 chamfer_loss_mesh:  0.1187228481285274\n",
      "eikonal_loss:  0.014638418331742287\n",
      "Epoch 635: loss = 0.26115700602531433\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12609001714736223 chamfer_loss_mesh:  0.11988669575657696\n",
      "eikonal_loss:  0.01515826303511858\n",
      "Epoch 636: loss = 0.2624882757663727\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1259029610082507 chamfer_loss_mesh:  0.1467300025979057\n",
      "eikonal_loss:  0.015679242089390755\n",
      "Epoch 637: loss = 0.2896667718887329\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12566475197672844 chamfer_loss_mesh:  0.11987469042651355\n",
      "eikonal_loss:  0.015078055672347546\n",
      "Epoch 638: loss = 0.2619723379611969\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12528544757515192 chamfer_loss_mesh:  0.12038513523293659\n",
      "eikonal_loss:  0.014769737608730793\n",
      "Epoch 639: loss = 0.26179349422454834\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12529829982668161 chamfer_loss_mesh:  0.1199808029923588\n",
      "eikonal_loss:  0.01684456132352352\n",
      "Epoch 640: loss = 0.2634778618812561\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12535639107227325 chamfer_loss_mesh:  0.13635845971293747\n",
      "eikonal_loss:  0.01598188281059265\n",
      "Epoch 641: loss = 0.2790502607822418\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12564666103571653 chamfer_loss_mesh:  0.12106016220059246\n",
      "eikonal_loss:  0.016175325959920883\n",
      "Epoch 642: loss = 0.26423680782318115\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12539572780951858 chamfer_loss_mesh:  0.12109374074498191\n",
      "eikonal_loss:  0.017323533073067665\n",
      "Epoch 643: loss = 0.26516836881637573\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1260583638213575 chamfer_loss_mesh:  0.13934109301771969\n",
      "eikonal_loss:  0.019538069143891335\n",
      "Epoch 644: loss = 0.28629395365715027\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1263129524886608 chamfer_loss_mesh:  0.22271495254244655\n",
      "eikonal_loss:  0.015600872226059437\n",
      "Epoch 645: loss = 0.3659849464893341\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12640788918361068 chamfer_loss_mesh:  0.14663580805063248\n",
      "eikonal_loss:  0.016188085079193115\n",
      "Epoch 646: loss = 0.29058849811553955\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12656403705477715 chamfer_loss_mesh:  0.12032844097120687\n",
      "eikonal_loss:  0.01578560285270214\n",
      "Epoch 647: loss = 0.2640362083911896\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12647818075492978 chamfer_loss_mesh:  0.11970016930717975\n",
      "eikonal_loss:  0.04463566094636917\n",
      "Epoch 648: loss = 0.2921725809574127\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12729677837342024 chamfer_loss_mesh:  0.11973665095865726\n",
      "eikonal_loss:  0.030834082514047623\n",
      "Epoch 649: loss = 0.27922552824020386\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12700988445430994 chamfer_loss_mesh:  0.11953572538914159\n",
      "eikonal_loss:  0.028387784957885742\n",
      "Epoch 650: loss = 0.276289165019989\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1273428089916706 chamfer_loss_mesh:  0.11924369027838111\n",
      "eikonal_loss:  0.04083668440580368\n",
      "Epoch 651: loss = 0.2887795567512512\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12695258483290672 chamfer_loss_mesh:  0.12014161620754749\n",
      "eikonal_loss:  0.04239419475197792\n",
      "Epoch 652: loss = 0.29084521532058716\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12725291308015585 chamfer_loss_mesh:  0.11844237451441586\n",
      "eikonal_loss:  0.04358653351664543\n",
      "Epoch 653: loss = 0.2906384766101837\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12734609190374613 chamfer_loss_mesh:  0.14888899750076234\n",
      "eikonal_loss:  0.03695771098136902\n",
      "Epoch 654: loss = 0.3145468235015869\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12756313662976027 chamfer_loss_mesh:  0.12057567073497921\n",
      "eikonal_loss:  0.03640853241086006\n",
      "Epoch 655: loss = 0.28590255975723267\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12759340461343527 chamfer_loss_mesh:  0.15019040438346565\n",
      "eikonal_loss:  0.036497555673122406\n",
      "Epoch 656: loss = 0.3156365156173706\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1277840230613947 chamfer_loss_mesh:  0.11862405517604202\n",
      "eikonal_loss:  0.02137002721428871\n",
      "Epoch 657: loss = 0.269132524728775\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12717006029561162 chamfer_loss_mesh:  0.11833036842290312\n",
      "eikonal_loss:  0.022982174530625343\n",
      "Epoch 658: loss = 0.2698379158973694\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1270598964765668 chamfer_loss_mesh:  0.11810915020760149\n",
      "eikonal_loss:  0.04622674733400345\n",
      "Epoch 659: loss = 0.2927517294883728\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1274077338166535 chamfer_loss_mesh:  0.11671434913296252\n",
      "eikonal_loss:  0.042326297610998154\n",
      "Epoch 660: loss = 0.28780412673950195\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12788943713530898 chamfer_loss_mesh:  0.1565930142533034\n",
      "eikonal_loss:  0.038857024163007736\n",
      "Epoch 661: loss = 0.32469531893730164\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12756279902532697 chamfer_loss_mesh:  0.11818633356597275\n",
      "eikonal_loss:  0.033248551189899445\n",
      "Epoch 662: loss = 0.280353844165802\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12742893304675817 chamfer_loss_mesh:  0.11954127694480121\n",
      "eikonal_loss:  0.030599281191825867\n",
      "Epoch 663: loss = 0.27892473340034485\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12759893434122205 chamfer_loss_mesh:  0.13338110875338316\n",
      "eikonal_loss:  0.03132904693484306\n",
      "Epoch 664: loss = 0.29366281628608704\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12760877143591642 chamfer_loss_mesh:  0.11998322588624433\n",
      "eikonal_loss:  0.031406596302986145\n",
      "Epoch 665: loss = 0.28035250306129456\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12768302112817764 chamfer_loss_mesh:  0.13771845260635018\n",
      "eikonal_loss:  0.030872447416186333\n",
      "Epoch 666: loss = 0.2976253628730774\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12733949115499854 chamfer_loss_mesh:  0.11693268606904894\n",
      "eikonal_loss:  0.030778978019952774\n",
      "Epoch 667: loss = 0.27640295028686523\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12721639359369874 chamfer_loss_mesh:  0.11830667790491134\n",
      "eikonal_loss:  0.030263062566518784\n",
      "Epoch 668: loss = 0.27713826298713684\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12735786149278283 chamfer_loss_mesh:  0.13412594853434712\n",
      "eikonal_loss:  0.023681864142417908\n",
      "Epoch 669: loss = 0.2865186631679535\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12712622992694378 chamfer_loss_mesh:  0.21238082263153046\n",
      "eikonal_loss:  0.02143443562090397\n",
      "Epoch 670: loss = 0.36229509115219116\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12689577415585518 chamfer_loss_mesh:  0.13142070383764803\n",
      "eikonal_loss:  0.019847169518470764\n",
      "Epoch 671: loss = 0.279518187046051\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12681460939347744 chamfer_loss_mesh:  0.14171225484460592\n",
      "eikonal_loss:  0.018297087401151657\n",
      "Epoch 672: loss = 0.28818047046661377\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12659449130296707 chamfer_loss_mesh:  0.11877914948854595\n",
      "eikonal_loss:  0.02110067941248417\n",
      "Epoch 673: loss = 0.26783061027526855\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1266856910660863 chamfer_loss_mesh:  0.12111296382499859\n",
      "eikonal_loss:  0.019158994778990746\n",
      "Epoch 674: loss = 0.2683151066303253\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12644469970837235 chamfer_loss_mesh:  0.1411005068803206\n",
      "eikonal_loss:  0.01717890426516533\n",
      "Epoch 675: loss = 0.28608107566833496\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1275224261917174 chamfer_loss_mesh:  0.12151301780249923\n",
      "eikonal_loss:  0.01607094332575798\n",
      "Epoch 676: loss = 0.2664628326892853\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12831692583858967 chamfer_loss_mesh:  0.13464433141052723\n",
      "eikonal_loss:  0.014571286737918854\n",
      "Epoch 677: loss = 0.27888819575309753\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12874901294708252 chamfer_loss_mesh:  0.13742936425842345\n",
      "eikonal_loss:  0.013724016025662422\n",
      "Epoch 678: loss = 0.2812584340572357\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12799249961972237 chamfer_loss_mesh:  0.1476542529417202\n",
      "eikonal_loss:  0.012679053470492363\n",
      "Epoch 679: loss = 0.28968220949172974\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12768481392413378 chamfer_loss_mesh:  0.11797642218880355\n",
      "eikonal_loss:  0.012751316651701927\n",
      "Epoch 680: loss = 0.25977054238319397\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1275216811336577 chamfer_loss_mesh:  0.11980778072029352\n",
      "eikonal_loss:  0.013890963979065418\n",
      "Epoch 681: loss = 0.26257872581481934\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12858774280175567 chamfer_loss_mesh:  0.16695466183591634\n",
      "eikonal_loss:  0.012325076386332512\n",
      "Epoch 682: loss = 0.3092239797115326\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12848032638430595 chamfer_loss_mesh:  0.1176245859824121\n",
      "eikonal_loss:  0.012665288522839546\n",
      "Epoch 683: loss = 0.26012805104255676\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12869613710790873 chamfer_loss_mesh:  0.1452061696909368\n",
      "eikonal_loss:  0.012622585520148277\n",
      "Epoch 684: loss = 0.2878848910331726\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12876847758889198 chamfer_loss_mesh:  0.11930902837775648\n",
      "eikonal_loss:  0.020367782562971115\n",
      "Epoch 685: loss = 0.2698039412498474\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12862123548984528 chamfer_loss_mesh:  0.15661621000617743\n",
      "eikonal_loss:  0.023519953712821007\n",
      "Epoch 686: loss = 0.31011536717414856\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1275094924494624 chamfer_loss_mesh:  0.11711001570802182\n",
      "eikonal_loss:  0.03589985892176628\n",
      "Epoch 687: loss = 0.281879723072052\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12730539310723543 chamfer_loss_mesh:  0.11738494504243135\n",
      "eikonal_loss:  0.03299412503838539\n",
      "Epoch 688: loss = 0.2790454626083374\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12786152074113488 chamfer_loss_mesh:  0.13423101336229593\n",
      "eikonal_loss:  0.030792124569416046\n",
      "Epoch 689: loss = 0.2942464053630829\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12874752283096313 chamfer_loss_mesh:  0.14272546104621142\n",
      "eikonal_loss:  0.030173471197485924\n",
      "Epoch 690: loss = 0.3030088543891907\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.128277949988842 chamfer_loss_mesh:  0.11866261775139719\n",
      "eikonal_loss:  0.028628837317228317\n",
      "Epoch 691: loss = 0.2769320011138916\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12767212465405464 chamfer_loss_mesh:  0.14420272782444954\n",
      "eikonal_loss:  0.03035605698823929\n",
      "Epoch 692: loss = 0.30359408259391785\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12774240458384156 chamfer_loss_mesh:  0.13227981980890036\n",
      "eikonal_loss:  0.030837049707770348\n",
      "Epoch 693: loss = 0.292220801115036\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12805251171812415 chamfer_loss_mesh:  0.11638549040071666\n",
      "eikonal_loss:  0.025618012994527817\n",
      "Epoch 694: loss = 0.2714158296585083\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12826721649616957 chamfer_loss_mesh:  0.11865624401252717\n",
      "eikonal_loss:  0.02358410693705082\n",
      "Epoch 695: loss = 0.2718683183193207\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12843827717006207 chamfer_loss_mesh:  0.13896398013457656\n",
      "eikonal_loss:  0.022285185754299164\n",
      "Epoch 696: loss = 0.29104799032211304\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12919048313051462 chamfer_loss_mesh:  0.13917255273554474\n",
      "eikonal_loss:  0.022938471287488937\n",
      "Epoch 697: loss = 0.29266291856765747\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12836342211812735 chamfer_loss_mesh:  0.24611371918581426\n",
      "eikonal_loss:  0.02188028395175934\n",
      "Epoch 698: loss = 0.3977184593677521\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12781793484464288 chamfer_loss_mesh:  0.11739287583623081\n",
      "eikonal_loss:  0.020752867683768272\n",
      "Epoch 699: loss = 0.2673255205154419\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "Estimated eps_H:  tensor(0.2158, device='cuda:0')\n",
      "cvt_loss:  0.12782164849340916 chamfer_loss_mesh:  0.16161265375558287\n",
      "eikonal_loss:  0.01960163004696369\n",
      "Epoch 700: loss = 0.310397744178772\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12790625914931297 chamfer_loss_mesh:  0.15824219735804945\n",
      "eikonal_loss:  0.018927227705717087\n",
      "Epoch 701: loss = 0.30643633008003235\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12763836421072483 chamfer_loss_mesh:  0.11828837159555405\n",
      "eikonal_loss:  0.0191202312707901\n",
      "Epoch 702: loss = 0.26640641689300537\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12730432208627462 chamfer_loss_mesh:  0.11865564010804519\n",
      "eikonal_loss:  0.056246671825647354\n",
      "Epoch 703: loss = 0.3035654127597809\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1270611654035747 chamfer_loss_mesh:  0.11950105545111\n",
      "eikonal_loss:  0.024229874834418297\n",
      "Epoch 704: loss = 0.2721513509750366\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12696334160864353 chamfer_loss_mesh:  0.15433355292771012\n",
      "eikonal_loss:  0.01654353179037571\n",
      "Epoch 705: loss = 0.29919978976249695\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12699636863544583 chamfer_loss_mesh:  0.1169140450656414\n",
      "eikonal_loss:  0.014825977385044098\n",
      "Epoch 706: loss = 0.2600964605808258\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.127142493147403 chamfer_loss_mesh:  0.11721508781192824\n",
      "eikonal_loss:  0.012684345245361328\n",
      "Epoch 707: loss = 0.2584017515182495\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12686755508184433 chamfer_loss_mesh:  0.11745325173251331\n",
      "eikonal_loss:  0.010582832619547844\n",
      "Epoch 708: loss = 0.25626513361930847\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1273748930543661 chamfer_loss_mesh:  0.11780388012994081\n",
      "eikonal_loss:  0.008935488760471344\n",
      "Epoch 709: loss = 0.25547537207603455\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12737491633743048 chamfer_loss_mesh:  0.1479349739383906\n",
      "eikonal_loss:  0.008371026255190372\n",
      "Epoch 710: loss = 0.28504127264022827\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12719810474663973 chamfer_loss_mesh:  0.11874636402353644\n",
      "eikonal_loss:  0.007898597978055477\n",
      "Epoch 711: loss = 0.255203515291214\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12661268701776862 chamfer_loss_mesh:  0.1185546352644451\n",
      "eikonal_loss:  0.014569646678864956\n",
      "Epoch 712: loss = 0.2610958516597748\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12714089825749397 chamfer_loss_mesh:  0.14790042769163847\n",
      "eikonal_loss:  0.014923635870218277\n",
      "Epoch 713: loss = 0.2913232147693634\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1268093241378665 chamfer_loss_mesh:  0.16165885608643293\n",
      "eikonal_loss:  0.013046813197433949\n",
      "Epoch 714: loss = 0.3028736412525177\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12622792273759842 chamfer_loss_mesh:  0.11753058061003685\n",
      "eikonal_loss:  0.014763973653316498\n",
      "Epoch 715: loss = 0.25988152623176575\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12626780662685633 chamfer_loss_mesh:  0.13603459228761494\n",
      "eikonal_loss:  0.013245051726698875\n",
      "Epoch 716: loss = 0.27690666913986206\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1270535751245916 chamfer_loss_mesh:  0.12832143693231046\n",
      "eikonal_loss:  0.011985842138528824\n",
      "Epoch 717: loss = 0.26871970295906067\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12655567843466997 chamfer_loss_mesh:  0.11841158266179264\n",
      "eikonal_loss:  0.011283030733466148\n",
      "Epoch 718: loss = 0.25760912895202637\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12689109425991774 chamfer_loss_mesh:  0.11836408521048725\n",
      "eikonal_loss:  0.010372824966907501\n",
      "Epoch 719: loss = 0.2569870948791504\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12667377013713121 chamfer_loss_mesh:  0.11781195644289255\n",
      "eikonal_loss:  0.009895361959934235\n",
      "Epoch 720: loss = 0.25573989748954773\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12658345513045788 chamfer_loss_mesh:  0.11843207175843418\n",
      "eikonal_loss:  0.00997210294008255\n",
      "Epoch 721: loss = 0.25634604692459106\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12631822610273957 chamfer_loss_mesh:  0.15246219118125737\n",
      "eikonal_loss:  0.009042752906680107\n",
      "Epoch 722: loss = 0.2891807556152344\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12647161493077874 chamfer_loss_mesh:  0.11912157788174227\n",
      "eikonal_loss:  0.00848663505166769\n",
      "Epoch 723: loss = 0.2554391920566559\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12661638902500272 chamfer_loss_mesh:  0.11875671043526381\n",
      "eikonal_loss:  0.008283717557787895\n",
      "Epoch 724: loss = 0.2550165355205536\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12669977732002735 chamfer_loss_mesh:  0.117436982691288\n",
      "eikonal_loss:  0.008106367662549019\n",
      "Epoch 725: loss = 0.25360190868377686\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12644658563658595 chamfer_loss_mesh:  0.11805009125964716\n",
      "eikonal_loss:  0.007914324291050434\n",
      "Epoch 726: loss = 0.25377029180526733\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12643998488783836 chamfer_loss_mesh:  0.11710840044543147\n",
      "eikonal_loss:  0.0077347531914711\n",
      "Epoch 727: loss = 0.2526441514492035\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.126059097237885 chamfer_loss_mesh:  0.11739191540982574\n",
      "eikonal_loss:  0.007817305624485016\n",
      "Epoch 728: loss = 0.25262919068336487\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12588794343173504 chamfer_loss_mesh:  0.16848254017531872\n",
      "eikonal_loss:  0.007501774933189154\n",
      "Epoch 729: loss = 0.30323266983032227\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12622540816664696 chamfer_loss_mesh:  0.11883294064318761\n",
      "eikonal_loss:  0.007264737505465746\n",
      "Epoch 730: loss = 0.2536851167678833\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12599749024957418 chamfer_loss_mesh:  0.11700514005497098\n",
      "eikonal_loss:  0.006986082531511784\n",
      "Epoch 731: loss = 0.2513504922389984\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1255103386938572 chamfer_loss_mesh:  0.11596227705013007\n",
      "eikonal_loss:  0.007162827532738447\n",
      "Epoch 732: loss = 0.24999649822711945\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12566415825858712 chamfer_loss_mesh:  0.11708765669027343\n",
      "eikonal_loss:  0.008721024729311466\n",
      "Epoch 733: loss = 0.25283563137054443\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12546522775664926 chamfer_loss_mesh:  0.11789613927248865\n",
      "eikonal_loss:  0.009924951009452343\n",
      "Epoch 734: loss = 0.25464919209480286\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12583956122398376 chamfer_loss_mesh:  0.1183219428639859\n",
      "eikonal_loss:  0.00656685046851635\n",
      "Epoch 735: loss = 0.25209054350852966\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12561624171212316 chamfer_loss_mesh:  0.11636818817351013\n",
      "eikonal_loss:  0.00674195121973753\n",
      "Epoch 736: loss = 0.2500891089439392\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1264540129341185 chamfer_loss_mesh:  0.11812440061476082\n",
      "eikonal_loss:  0.007402900606393814\n",
      "Epoch 737: loss = 0.2533450424671173\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12674840399995446 chamfer_loss_mesh:  0.17501763068139553\n",
      "eikonal_loss:  0.0072095962241292\n",
      "Epoch 738: loss = 0.31033897399902344\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12665935792028904 chamfer_loss_mesh:  0.1523704850114882\n",
      "eikonal_loss:  0.007229458540678024\n",
      "Epoch 739: loss = 0.2876221537590027\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12728354195132852 chamfer_loss_mesh:  0.11836901830974966\n",
      "eikonal_loss:  0.00792311504483223\n",
      "Epoch 740: loss = 0.2549391984939575\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1271431683562696 chamfer_loss_mesh:  0.11826948320958763\n",
      "eikonal_loss:  0.007618292234838009\n",
      "Epoch 741: loss = 0.2543960511684418\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12675467878580093 chamfer_loss_mesh:  0.1509052381152287\n",
      "eikonal_loss:  0.0077157048508524895\n",
      "Epoch 742: loss = 0.28674253821372986\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12714497279375792 chamfer_loss_mesh:  0.11639462900348008\n",
      "eikonal_loss:  0.007439459674060345\n",
      "Epoch 743: loss = 0.25234493613243103\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12666224502027035 chamfer_loss_mesh:  0.11807303235400468\n",
      "eikonal_loss:  0.007510552182793617\n",
      "Epoch 744: loss = 0.2536117732524872\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12661917135119438 chamfer_loss_mesh:  0.15667168190702796\n",
      "eikonal_loss:  0.007456750143319368\n",
      "Epoch 745: loss = 0.2921127378940582\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.127542729023844 chamfer_loss_mesh:  0.14950544573366642\n",
      "eikonal_loss:  0.006524790544062853\n",
      "Epoch 746: loss = 0.28493672609329224\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1276477938517928 chamfer_loss_mesh:  0.13189672608859837\n",
      "eikonal_loss:  0.005965816788375378\n",
      "Epoch 747: loss = 0.2668744921684265\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12757752556353807 chamfer_loss_mesh:  0.11725745571311563\n",
      "eikonal_loss:  0.006145061459392309\n",
      "Epoch 748: loss = 0.2523439824581146\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12720741797238588 chamfer_loss_mesh:  0.11717577581293881\n",
      "eikonal_loss:  0.005766158923506737\n",
      "Epoch 749: loss = 0.25151440501213074\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12705933768302202 chamfer_loss_mesh:  0.1160638639703393\n",
      "eikonal_loss:  0.005177263170480728\n",
      "Epoch 750: loss = 0.24966569244861603\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12745673302561045 chamfer_loss_mesh:  0.11687078222166747\n",
      "eikonal_loss:  0.005017570219933987\n",
      "Epoch 751: loss = 0.25071123242378235\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12729685986414552 chamfer_loss_mesh:  0.1170740433735773\n",
      "eikonal_loss:  0.004994106013327837\n",
      "Epoch 752: loss = 0.2507307827472687\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12700255028903484 chamfer_loss_mesh:  0.11703970085363835\n",
      "eikonal_loss:  0.0048942542634904385\n",
      "Epoch 753: loss = 0.250301718711853\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12610387057065964 chamfer_loss_mesh:  0.1170492178061977\n",
      "eikonal_loss:  0.004699508659541607\n",
      "Epoch 754: loss = 0.24921977519989014\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12580931652337313 chamfer_loss_mesh:  0.11826417176052928\n",
      "eikonal_loss:  0.005068501923233271\n",
      "Epoch 755: loss = 0.25050830841064453\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12578510213643312 chamfer_loss_mesh:  0.11573632946237922\n",
      "eikonal_loss:  0.00468669505789876\n",
      "Epoch 756: loss = 0.24757422506809235\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12584845535457134 chamfer_loss_mesh:  0.11701187759172171\n",
      "eikonal_loss:  0.004984655417501926\n",
      "Epoch 757: loss = 0.24921101331710815\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12553974520415068 chamfer_loss_mesh:  0.11555712262634188\n",
      "eikonal_loss:  0.00488374475389719\n",
      "Epoch 758: loss = 0.24734608829021454\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12645830865949392 chamfer_loss_mesh:  0.11556054232642055\n",
      "eikonal_loss:  0.004826652351766825\n",
      "Epoch 759: loss = 0.24821150302886963\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12718355283141136 chamfer_loss_mesh:  0.12878127745352685\n",
      "eikonal_loss:  0.0060373456217348576\n",
      "Epoch 760: loss = 0.2633693218231201\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1272497931495309 chamfer_loss_mesh:  0.11907592124771327\n",
      "eikonal_loss:  0.005552528891712427\n",
      "Epoch 761: loss = 0.2532461881637573\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12702916283160448 chamfer_loss_mesh:  0.13489149569068104\n",
      "eikonal_loss:  0.007069659419357777\n",
      "Epoch 762: loss = 0.2703581750392914\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12627497781068087 chamfer_loss_mesh:  0.11752776481444016\n",
      "eikonal_loss:  0.0053183273412287235\n",
      "Epoch 763: loss = 0.25049126148223877\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12759866658598185 chamfer_loss_mesh:  0.15274372708518058\n",
      "eikonal_loss:  0.005279967561364174\n",
      "Epoch 764: loss = 0.2869906723499298\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1276579569093883 chamfer_loss_mesh:  0.11786349932663143\n",
      "eikonal_loss:  0.005519380792975426\n",
      "Epoch 765: loss = 0.25241076946258545\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1276827068068087 chamfer_loss_mesh:  0.1639194379094988\n",
      "eikonal_loss:  0.004801529925316572\n",
      "Epoch 766: loss = 0.2977750897407532\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12784601422026753 chamfer_loss_mesh:  0.11709886894095689\n",
      "eikonal_loss:  0.004455901682376862\n",
      "Epoch 767: loss = 0.2507706880569458\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12754863128066063 chamfer_loss_mesh:  0.1511501905042678\n",
      "eikonal_loss:  0.006509642116725445\n",
      "Epoch 768: loss = 0.28657758235931396\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12723627733066678 chamfer_loss_mesh:  0.12775667710229754\n",
      "eikonal_loss:  0.010657990351319313\n",
      "Epoch 769: loss = 0.2670207917690277\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12744206469506025 chamfer_loss_mesh:  0.17053376359399408\n",
      "eikonal_loss:  0.004795402754098177\n",
      "Epoch 770: loss = 0.3041403591632843\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12723340187221766 chamfer_loss_mesh:  0.11557391553651541\n",
      "eikonal_loss:  0.004415199626237154\n",
      "Epoch 771: loss = 0.24859142303466797\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12706422712653875 chamfer_loss_mesh:  0.11969140905421227\n",
      "eikonal_loss:  0.004064465407282114\n",
      "Epoch 772: loss = 0.2521892488002777\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1271281624212861 chamfer_loss_mesh:  0.11672162509057671\n",
      "eikonal_loss:  0.00422682985663414\n",
      "Epoch 773: loss = 0.24944542348384857\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12776355724781752 chamfer_loss_mesh:  0.1471152063459158\n",
      "eikonal_loss:  0.004176746122539043\n",
      "Epoch 774: loss = 0.2804258465766907\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12711426243185997 chamfer_loss_mesh:  0.11887768050655723\n",
      "eikonal_loss:  0.005048281513154507\n",
      "Epoch 775: loss = 0.25241202116012573\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12717086356133223 chamfer_loss_mesh:  0.11605520558077842\n",
      "eikonal_loss:  0.005264901556074619\n",
      "Epoch 776: loss = 0.24986277520656586\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12773391790688038 chamfer_loss_mesh:  0.19614007032942027\n",
      "eikonal_loss:  0.0051165614277124405\n",
      "Epoch 777: loss = 0.3303636610507965\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1267440035007894 chamfer_loss_mesh:  0.11614731920417398\n",
      "eikonal_loss:  0.005252675153315067\n",
      "Epoch 778: loss = 0.24951741099357605\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12650196440517902 chamfer_loss_mesh:  0.11748734686989337\n",
      "eikonal_loss:  0.006017195992171764\n",
      "Epoch 779: loss = 0.25137999653816223\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12623919174075127 chamfer_loss_mesh:  0.1469558774260804\n",
      "eikonal_loss:  0.005809175781905651\n",
      "Epoch 780: loss = 0.2803792953491211\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1276169321499765 chamfer_loss_mesh:  0.11573595111258328\n",
      "eikonal_loss:  0.005334077402949333\n",
      "Epoch 781: loss = 0.25006192922592163\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.127501564566046 chamfer_loss_mesh:  0.1168286835309118\n",
      "eikonal_loss:  0.0048164501786231995\n",
      "Epoch 782: loss = 0.2505222260951996\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12914040125906467 chamfer_loss_mesh:  0.14983181608840823\n",
      "eikonal_loss:  0.004582457710057497\n",
      "Epoch 783: loss = 0.284930020570755\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12925020419061184 chamfer_loss_mesh:  0.11725572403520346\n",
      "eikonal_loss:  0.004501980263739824\n",
      "Epoch 784: loss = 0.2523827850818634\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12971909018233418 chamfer_loss_mesh:  0.14010511222295463\n",
      "eikonal_loss:  0.013590576127171516\n",
      "Epoch 785: loss = 0.2847888767719269\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1286510843783617 chamfer_loss_mesh:  0.11668453953461722\n",
      "eikonal_loss:  0.003996013198047876\n",
      "Epoch 786: loss = 0.25070542097091675\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12858124682679772 chamfer_loss_mesh:  0.14271415420807898\n",
      "eikonal_loss:  0.003772490657866001\n",
      "Epoch 787: loss = 0.2764423191547394\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12875505490228534 chamfer_loss_mesh:  0.11589072528295219\n",
      "eikonal_loss:  0.003524525323882699\n",
      "Epoch 788: loss = 0.24954596161842346\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12894312385469675 chamfer_loss_mesh:  0.11821359657915309\n",
      "eikonal_loss:  0.003176548285409808\n",
      "Epoch 789: loss = 0.2517109811306\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1283499295823276 chamfer_loss_mesh:  0.1170740433735773\n",
      "eikonal_loss:  0.0030212998390197754\n",
      "Epoch 790: loss = 0.2498224526643753\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1302103279158473 chamfer_loss_mesh:  0.14622535672970116\n",
      "eikonal_loss:  0.0030049660708755255\n",
      "Epoch 791: loss = 0.2808191180229187\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12916838750243187 chamfer_loss_mesh:  0.14636848936788738\n",
      "eikonal_loss:  0.0028173255268484354\n",
      "Epoch 792: loss = 0.2797331213951111\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12830934720113873 chamfer_loss_mesh:  0.13642932754009962\n",
      "eikonal_loss:  0.002689681015908718\n",
      "Epoch 793: loss = 0.2688080668449402\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1280226861126721 chamfer_loss_mesh:  0.1154676137957722\n",
      "eikonal_loss:  0.0026876693591475487\n",
      "Epoch 794: loss = 0.24755777418613434\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12785696890205145 chamfer_loss_mesh:  0.1334928529104218\n",
      "eikonal_loss:  0.002535009989514947\n",
      "Epoch 795: loss = 0.26526355743408203\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1282822689972818 chamfer_loss_mesh:  0.11605452164076269\n",
      "eikonal_loss:  0.0027368494775146246\n",
      "Epoch 796: loss = 0.24845150113105774\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12788395397365093 chamfer_loss_mesh:  0.14276319416239858\n",
      "eikonal_loss:  0.0025468829553574324\n",
      "Epoch 797: loss = 0.27457037568092346\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12768623419106007 chamfer_loss_mesh:  0.1331583334831521\n",
      "eikonal_loss:  0.0025031387340277433\n",
      "Epoch 798: loss = 0.2647237479686737\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1278152340091765 chamfer_loss_mesh:  0.13514913734979928\n",
      "eikonal_loss:  0.002414910588413477\n",
      "Epoch 799: loss = 0.2667551338672638\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "Estimated eps_H:  tensor(0.2159, device='cuda:0')\n",
      "cvt_loss:  0.12800812255591154 chamfer_loss_mesh:  0.11472622281871736\n",
      "eikonal_loss:  0.0023788479156792164\n",
      "Epoch 800: loss = 0.24648766219615936\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12766732834279537 chamfer_loss_mesh:  0.11463844566605985\n",
      "eikonal_loss:  0.0022971550934016705\n",
      "Epoch 801: loss = 0.24597753584384918\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12770055327564478 chamfer_loss_mesh:  0.1149470335803926\n",
      "eikonal_loss:  0.002182498574256897\n",
      "Epoch 802: loss = 0.24620571732521057\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12722492683678865 chamfer_loss_mesh:  0.13844420027453452\n",
      "eikonal_loss:  0.0022510068956762552\n",
      "Epoch 803: loss = 0.2692958414554596\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12741817627102137 chamfer_loss_mesh:  0.11527357855811715\n",
      "eikonal_loss:  0.002150237560272217\n",
      "Epoch 804: loss = 0.24621997773647308\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12776500079780817 chamfer_loss_mesh:  0.15725058619864285\n",
      "eikonal_loss:  0.002127458807080984\n",
      "Epoch 805: loss = 0.28852131962776184\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1275382237508893 chamfer_loss_mesh:  0.11585727042984217\n",
      "eikonal_loss:  0.0031063624192029238\n",
      "Epoch 806: loss = 0.2478809505701065\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12738251825794578 chamfer_loss_mesh:  0.11462681868579239\n",
      "eikonal_loss:  0.011154399253427982\n",
      "Epoch 807: loss = 0.25454163551330566\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12756604701280594 chamfer_loss_mesh:  0.11445484415162355\n",
      "eikonal_loss:  0.0066351816058158875\n",
      "Epoch 808: loss = 0.2500336468219757\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12720833765342832 chamfer_loss_mesh:  0.1167104855994694\n",
      "eikonal_loss:  0.015590888448059559\n",
      "Epoch 809: loss = 0.2608889937400818\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12706192210316658 chamfer_loss_mesh:  0.1416836748830974\n",
      "eikonal_loss:  0.01337264571338892\n",
      "Epoch 810: loss = 0.28349772095680237\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1268231077119708 chamfer_loss_mesh:  0.11538183025550097\n",
      "eikonal_loss:  0.013950897380709648\n",
      "Epoch 811: loss = 0.2575359344482422\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12719075893983245 chamfer_loss_mesh:  0.11502540291985497\n",
      "eikonal_loss:  0.012868852354586124\n",
      "Epoch 812: loss = 0.256466269493103\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12742963153868914 chamfer_loss_mesh:  0.11441023525549099\n",
      "eikonal_loss:  0.029013028368353844\n",
      "Epoch 813: loss = 0.2722344696521759\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12763459235429764 chamfer_loss_mesh:  0.11618598364293575\n",
      "eikonal_loss:  0.1923324167728424\n",
      "Epoch 814: loss = 0.43753430247306824\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12806069571524858 chamfer_loss_mesh:  0.11578125122468919\n",
      "eikonal_loss:  0.034069713205099106\n",
      "Epoch 815: loss = 0.2792937159538269\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12818232644349337 chamfer_loss_mesh:  0.17740242765285075\n",
      "eikonal_loss:  0.034033916890621185\n",
      "Epoch 816: loss = 0.3410012722015381\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1289532519876957 chamfer_loss_mesh:  0.16111049626488239\n",
      "eikonal_loss:  0.029886450618505478\n",
      "Epoch 817: loss = 0.32133254408836365\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12856523972004652 chamfer_loss_mesh:  0.15086628263816237\n",
      "eikonal_loss:  0.030298572033643723\n",
      "Epoch 818: loss = 0.31111133098602295\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12867250479757786 chamfer_loss_mesh:  0.11451370664872229\n",
      "eikonal_loss:  0.025660090148448944\n",
      "Epoch 819: loss = 0.27022796869277954\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1290359767153859 chamfer_loss_mesh:  0.12695876648649573\n",
      "eikonal_loss:  0.029172534123063087\n",
      "Epoch 820: loss = 0.2865484058856964\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12970119714736938 chamfer_loss_mesh:  0.11517715756781399\n",
      "eikonal_loss:  0.029514029622077942\n",
      "Epoch 821: loss = 0.27577391266822815\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1305394689552486 chamfer_loss_mesh:  0.11557545803952962\n",
      "eikonal_loss:  0.03325773403048515\n",
      "Epoch 822: loss = 0.28075459599494934\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13069704873487353 chamfer_loss_mesh:  0.11454064951976761\n",
      "eikonal_loss:  0.03417930752038956\n",
      "Epoch 823: loss = 0.28079989552497864\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13006937224417925 chamfer_loss_mesh:  0.11372505832696334\n",
      "eikonal_loss:  0.03388069570064545\n",
      "Epoch 824: loss = 0.2790561616420746\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1295875641517341 chamfer_loss_mesh:  0.13443233910948038\n",
      "eikonal_loss:  0.028138013556599617\n",
      "Epoch 825: loss = 0.2935391962528229\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12995187425985932 chamfer_loss_mesh:  0.11465506395325065\n",
      "eikonal_loss:  0.02613534964621067\n",
      "Epoch 826: loss = 0.2721220552921295\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12986385263502598 chamfer_loss_mesh:  0.11456134961917996\n",
      "eikonal_loss:  0.021457813680171967\n",
      "Epoch 827: loss = 0.2672618627548218\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12964579509571195 chamfer_loss_mesh:  0.1356218126602471\n",
      "eikonal_loss:  0.01879303902387619\n",
      "Epoch 828: loss = 0.28543949127197266\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1299282070249319 chamfer_loss_mesh:  0.13131358718965203\n",
      "eikonal_loss:  0.01746896654367447\n",
      "Epoch 829: loss = 0.28008928894996643\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12917446438223124 chamfer_loss_mesh:  0.11352280853316188\n",
      "eikonal_loss:  0.01722084917128086\n",
      "Epoch 830: loss = 0.26129767298698425\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12914553517475724 chamfer_loss_mesh:  0.11539681872818619\n",
      "eikonal_loss:  0.01697862148284912\n",
      "Epoch 831: loss = 0.262899786233902\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1288974075578153 chamfer_loss_mesh:  0.11471222387626767\n",
      "eikonal_loss:  0.015917325392365456\n",
      "Epoch 832: loss = 0.26090696454048157\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12864000163972378 chamfer_loss_mesh:  0.166355719557032\n",
      "eikonal_loss:  0.015879206359386444\n",
      "Epoch 833: loss = 0.31225675344467163\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.129140040371567 chamfer_loss_mesh:  0.1350331585854292\n",
      "eikonal_loss:  0.014708653092384338\n",
      "Epoch 834: loss = 0.2802610397338867\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12873017694801092 chamfer_loss_mesh:  0.11410879233153537\n",
      "eikonal_loss:  0.014134463854134083\n",
      "Epoch 835: loss = 0.25835415720939636\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1285146689042449 chamfer_loss_mesh:  0.11442261165939271\n",
      "eikonal_loss:  0.013591278344392776\n",
      "Epoch 836: loss = 0.2579096853733063\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12851576320827007 chamfer_loss_mesh:  0.11550744238775223\n",
      "eikonal_loss:  0.011572806164622307\n",
      "Epoch 837: loss = 0.2569754719734192\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12844160664826632 chamfer_loss_mesh:  0.1143787958426401\n",
      "eikonal_loss:  0.017033781856298447\n",
      "Epoch 838: loss = 0.2612341642379761\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12874845415353775 chamfer_loss_mesh:  0.11489284952403978\n",
      "eikonal_loss:  0.013776835054159164\n",
      "Epoch 839: loss = 0.2587990462779999\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1283265999518335 chamfer_loss_mesh:  0.1654533261898905\n",
      "eikonal_loss:  0.01312006451189518\n",
      "Epoch 840: loss = 0.3082810342311859\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1284867525100708 chamfer_loss_mesh:  0.11421116505516693\n",
      "eikonal_loss:  0.017894089221954346\n",
      "Epoch 841: loss = 0.26197350025177\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1290248241275549 chamfer_loss_mesh:  0.1156620928668417\n",
      "eikonal_loss:  0.014716852456331253\n",
      "Epoch 842: loss = 0.2607874572277069\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12910393998026848 chamfer_loss_mesh:  0.1551842433400452\n",
      "eikonal_loss:  0.012348394840955734\n",
      "Epoch 843: loss = 0.2980208098888397\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12987926602363586 chamfer_loss_mesh:  0.11411381274228916\n",
      "eikonal_loss:  0.011964097619056702\n",
      "Epoch 844: loss = 0.25734084844589233\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12888144701719284 chamfer_loss_mesh:  0.11423487012507394\n",
      "eikonal_loss:  0.009381374344229698\n",
      "Epoch 845: loss = 0.25388070940971375\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12793827336281538 chamfer_loss_mesh:  0.11372362496331334\n",
      "eikonal_loss:  0.011810226365923882\n",
      "Epoch 846: loss = 0.25485485792160034\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12866598553955555 chamfer_loss_mesh:  0.11357256153132766\n",
      "eikonal_loss:  0.007189424708485603\n",
      "Epoch 847: loss = 0.25081172585487366\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12898441636934876 chamfer_loss_mesh:  0.11412717867642641\n",
      "eikonal_loss:  0.0029499640222638845\n",
      "Epoch 848: loss = 0.24744540452957153\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1293860375881195 chamfer_loss_mesh:  0.13362194295041263\n",
      "eikonal_loss:  0.003070315346121788\n",
      "Epoch 849: loss = 0.2674611806869507\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12920504668727517 chamfer_loss_mesh:  0.1142597320722416\n",
      "eikonal_loss:  0.003341816132888198\n",
      "Epoch 850: loss = 0.2481878399848938\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12926305644214153 chamfer_loss_mesh:  0.11350278509780765\n",
      "eikonal_loss:  0.021088700741529465\n",
      "Epoch 851: loss = 0.2652357816696167\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12911295052617788 chamfer_loss_mesh:  0.1420064945705235\n",
      "eikonal_loss:  0.004229186102747917\n",
      "Epoch 852: loss = 0.27672988176345825\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12853695079684258 chamfer_loss_mesh:  0.1140065214713104\n",
      "eikonal_loss:  0.005306844133883715\n",
      "Epoch 853: loss = 0.2492327243089676\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1290895277634263 chamfer_loss_mesh:  0.16806507483124733\n",
      "eikonal_loss:  0.04069745913147926\n",
      "Epoch 854: loss = 0.33923429250717163\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12893659295514226 chamfer_loss_mesh:  0.11999713751720265\n",
      "eikonal_loss:  0.051217034459114075\n",
      "Epoch 855: loss = 0.30153214931488037\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12951819226145744 chamfer_loss_mesh:  0.11582529987208545\n",
      "eikonal_loss:  0.03403576463460922\n",
      "Epoch 856: loss = 0.2807598412036896\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12970680836588144 chamfer_loss_mesh:  0.1157665901700966\n",
      "eikonal_loss:  0.030331013724207878\n",
      "Epoch 857: loss = 0.2771836221218109\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1299894880503416 chamfer_loss_mesh:  0.15951422392390668\n",
      "eikonal_loss:  0.02779330313205719\n",
      "Epoch 858: loss = 0.3186781108379364\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12908392818644643 chamfer_loss_mesh:  0.1143217523349449\n",
      "eikonal_loss:  0.022099055349826813\n",
      "Epoch 859: loss = 0.26688718795776367\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12850762577727437 chamfer_loss_mesh:  0.11395630281185731\n",
      "eikonal_loss:  0.019001007080078125\n",
      "Epoch 860: loss = 0.26284754276275635\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12849662452936172 chamfer_loss_mesh:  0.11307936074445024\n",
      "eikonal_loss:  0.017496461048722267\n",
      "Epoch 861: loss = 0.2604551315307617\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12883394956588745 chamfer_loss_mesh:  0.13217265950515866\n",
      "eikonal_loss:  0.01688069850206375\n",
      "Epoch 862: loss = 0.27926960587501526\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1285748789086938 chamfer_loss_mesh:  0.11472578626126051\n",
      "eikonal_loss:  0.016420351341366768\n",
      "Epoch 863: loss = 0.2611043155193329\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12869928032159805 chamfer_loss_mesh:  0.16327796038240194\n",
      "eikonal_loss:  0.01936926692724228\n",
      "Epoch 864: loss = 0.3127293288707733\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1290824729949236 chamfer_loss_mesh:  0.113932546810247\n",
      "eikonal_loss:  0.018474861979484558\n",
      "Epoch 865: loss = 0.262872576713562\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12964962515980005 chamfer_loss_mesh:  0.1155239951913245\n",
      "eikonal_loss:  0.012587654404342175\n",
      "Epoch 866: loss = 0.25914475321769714\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.129248877055943 chamfer_loss_mesh:  0.11572931543923914\n",
      "eikonal_loss:  0.018549740314483643\n",
      "Epoch 867: loss = 0.2649116516113281\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12864009477198124 chamfer_loss_mesh:  0.12776133371517062\n",
      "eikonal_loss:  0.017462624236941338\n",
      "Epoch 868: loss = 0.27524638175964355\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12764011044055223 chamfer_loss_mesh:  0.11349540727678686\n",
      "eikonal_loss:  0.01620238460600376\n",
      "Epoch 869: loss = 0.25872164964675903\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1283261924982071 chamfer_loss_mesh:  0.15670435095671564\n",
      "eikonal_loss:  0.01571505516767502\n",
      "Epoch 870: loss = 0.302127867937088\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12941665481776 chamfer_loss_mesh:  0.17562438733875751\n",
      "eikonal_loss:  0.015365658327937126\n",
      "Epoch 871: loss = 0.32178807258605957\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1291644643060863 chamfer_loss_mesh:  0.11424452532082796\n",
      "eikonal_loss:  0.010243108496069908\n",
      "Epoch 872: loss = 0.25503548979759216\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12922806199640036 chamfer_loss_mesh:  0.11624499165918678\n",
      "eikonal_loss:  0.010018655098974705\n",
      "Epoch 873: loss = 0.2568763494491577\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12969817034900188 chamfer_loss_mesh:  0.11619926954153925\n",
      "eikonal_loss:  0.0093162190169096\n",
      "Epoch 874: loss = 0.25659629702568054\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12872222578153014 chamfer_loss_mesh:  0.11431236634962261\n",
      "eikonal_loss:  0.008890094235539436\n",
      "Epoch 875: loss = 0.25330838561058044\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12875536922365427 chamfer_loss_mesh:  0.13556229532696307\n",
      "eikonal_loss:  0.008114826865494251\n",
      "Epoch 876: loss = 0.27381661534309387\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12888070195913315 chamfer_loss_mesh:  0.23335707373917103\n",
      "eikonal_loss:  0.009704054333269596\n",
      "Epoch 877: loss = 0.37332457304000854\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1284460537135601 chamfer_loss_mesh:  0.1143243134720251\n",
      "eikonal_loss:  0.00941435806453228\n",
      "Epoch 878: loss = 0.2535673975944519\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12837749673053622 chamfer_loss_mesh:  0.11443278344813734\n",
      "eikonal_loss:  0.009727103635668755\n",
      "Epoch 879: loss = 0.2539200484752655\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12856600806117058 chamfer_loss_mesh:  0.12815490481443703\n",
      "eikonal_loss:  0.009469563141465187\n",
      "Epoch 880: loss = 0.26757490634918213\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12812291970476508 chamfer_loss_mesh:  0.1237526157638058\n",
      "eikonal_loss:  0.009385739453136921\n",
      "Epoch 881: loss = 0.2626451551914215\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12769517488777637 chamfer_loss_mesh:  0.11926503793802112\n",
      "eikonal_loss:  0.007975272834300995\n",
      "Epoch 882: loss = 0.2563209533691406\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12702320236712694 chamfer_loss_mesh:  0.11551375791896135\n",
      "eikonal_loss:  0.006477599497884512\n",
      "Epoch 883: loss = 0.250399112701416\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1268266118131578 chamfer_loss_mesh:  0.11451655882410705\n",
      "eikonal_loss:  0.006104660220444202\n",
      "Epoch 884: loss = 0.24883325397968292\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12709295842796564 chamfer_loss_mesh:  0.11422754323575646\n",
      "eikonal_loss:  0.006117499899119139\n",
      "Epoch 885: loss = 0.2488243132829666\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12734554475173354 chamfer_loss_mesh:  0.11443065159255639\n",
      "eikonal_loss:  0.006106954999268055\n",
      "Epoch 886: loss = 0.24926824867725372\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12718983925879002 chamfer_loss_mesh:  0.11384612298570573\n",
      "eikonal_loss:  0.005522355902940035\n",
      "Epoch 887: loss = 0.24794331192970276\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12711514718830585 chamfer_loss_mesh:  0.11387099220883101\n",
      "eikonal_loss:  0.005320197902619839\n",
      "Epoch 888: loss = 0.24769222736358643\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1291004940867424 chamfer_loss_mesh:  0.11374246969353408\n",
      "eikonal_loss:  0.005045197904109955\n",
      "Epoch 889: loss = 0.24927370250225067\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12826822930946946 chamfer_loss_mesh:  0.14211973757483065\n",
      "eikonal_loss:  0.01376707199960947\n",
      "Epoch 890: loss = 0.2855410575866699\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12765317223966122 chamfer_loss_mesh:  0.11478445958346128\n",
      "eikonal_loss:  0.010609016753733158\n",
      "Epoch 891: loss = 0.2544333040714264\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12715172488242388 chamfer_loss_mesh:  0.11337705655023456\n",
      "eikonal_loss:  0.011470047757029533\n",
      "Epoch 892: loss = 0.2533855140209198\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12679103529080749 chamfer_loss_mesh:  0.1145947608165443\n",
      "eikonal_loss:  0.010713552124798298\n",
      "Epoch 893: loss = 0.2534867525100708\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12718415819108486 chamfer_loss_mesh:  0.1267330371774733\n",
      "eikonal_loss:  0.010130518116056919\n",
      "Epoch 894: loss = 0.2654365003108978\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12653411831706762 chamfer_loss_mesh:  0.11395837645977736\n",
      "eikonal_loss:  0.00947448331862688\n",
      "Epoch 895: loss = 0.2513560354709625\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12634285958483815 chamfer_loss_mesh:  0.12774261995218694\n",
      "eikonal_loss:  0.009105389937758446\n",
      "Epoch 896: loss = 0.264579176902771\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12580127222463489 chamfer_loss_mesh:  0.11357969196978956\n",
      "eikonal_loss:  0.008463573642075062\n",
      "Epoch 897: loss = 0.24923288822174072\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12583916541188955 chamfer_loss_mesh:  0.11309933324810117\n",
      "eikonal_loss:  0.008399891667068005\n",
      "Epoch 898: loss = 0.24872836470603943\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12557224836200476 chamfer_loss_mesh:  0.11331385030644014\n",
      "eikonal_loss:  0.008116042241454124\n",
      "Epoch 899: loss = 0.24839238822460175\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1259314944036305 chamfer_loss_mesh:  0.11436370550654829\n",
      "eikonal_loss:  0.00783927645534277\n",
      "Epoch 900: loss = 0.24952246248722076\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12604322982952 chamfer_loss_mesh:  0.11546148743946105\n",
      "eikonal_loss:  0.0077437954023480415\n",
      "Epoch 901: loss = 0.2506380081176758\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12745063286274672 chamfer_loss_mesh:  0.11453544721007347\n",
      "eikonal_loss:  0.007580250967293978\n",
      "Epoch 902: loss = 0.250955194234848\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12727552093565464 chamfer_loss_mesh:  0.11427754361648113\n",
      "eikonal_loss:  0.007259875535964966\n",
      "Epoch 903: loss = 0.250201016664505\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12745452113449574 chamfer_loss_mesh:  0.13463402865454555\n",
      "eikonal_loss:  0.007428282406181097\n",
      "Epoch 904: loss = 0.2709044814109802\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12621688656508923 chamfer_loss_mesh:  0.11387720587663352\n",
      "eikonal_loss:  0.007535694167017937\n",
      "Epoch 905: loss = 0.24901710450649261\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12654857710003853 chamfer_loss_mesh:  0.11402666859794408\n",
      "eikonal_loss:  0.007325978484004736\n",
      "Epoch 906: loss = 0.24928902089595795\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1267684157937765 chamfer_loss_mesh:  0.13189873425289989\n",
      "eikonal_loss:  0.007422173395752907\n",
      "Epoch 907: loss = 0.2674778699874878\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12724902480840683 chamfer_loss_mesh:  0.11299752804916352\n",
      "eikonal_loss:  0.0071429782547056675\n",
      "Epoch 908: loss = 0.24877803027629852\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12617935426533222 chamfer_loss_mesh:  0.14021186507306993\n",
      "eikonal_loss:  0.007238921243697405\n",
      "Epoch 909: loss = 0.2750205397605896\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12643052032217383 chamfer_loss_mesh:  0.14040889800526202\n",
      "eikonal_loss:  0.007435712032020092\n",
      "Epoch 910: loss = 0.27566635608673096\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12602251954376698 chamfer_loss_mesh:  0.11346164683345705\n",
      "eikonal_loss:  0.007410845253616571\n",
      "Epoch 911: loss = 0.24828419089317322\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12745741987600923 chamfer_loss_mesh:  0.13744234456680715\n",
      "eikonal_loss:  0.007609953638166189\n",
      "Epoch 912: loss = 0.2738996744155884\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12655078899115324 chamfer_loss_mesh:  0.1127036230172962\n",
      "eikonal_loss:  0.007759395055472851\n",
      "Epoch 913: loss = 0.24840450286865234\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1271189423277974 chamfer_loss_mesh:  0.17662903701420873\n",
      "eikonal_loss:  0.0078062335960567\n",
      "Epoch 914: loss = 0.3129447400569916\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12669337447732687 chamfer_loss_mesh:  0.11382043885532767\n",
      "eikonal_loss:  0.007627702318131924\n",
      "Epoch 915: loss = 0.24953213334083557\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1270518871024251 chamfer_loss_mesh:  0.11268335219938308\n",
      "eikonal_loss:  0.007158779539167881\n",
      "Epoch 916: loss = 0.24828562140464783\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1270310254767537 chamfer_loss_mesh:  0.14752958668395877\n",
      "eikonal_loss:  0.007053070701658726\n",
      "Epoch 917: loss = 0.2830052077770233\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12727248249575496 chamfer_loss_mesh:  0.11383883247617632\n",
      "eikonal_loss:  0.006750402972102165\n",
      "Epoch 918: loss = 0.24925245344638824\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1278821611776948 chamfer_loss_mesh:  0.113495480036363\n",
      "eikonal_loss:  0.006479100324213505\n",
      "Epoch 919: loss = 0.2492474466562271\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12759009841829538 chamfer_loss_mesh:  0.11295705917291343\n",
      "eikonal_loss:  0.006131097208708525\n",
      "Epoch 920: loss = 0.24806928634643555\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12744111008942127 chamfer_loss_mesh:  0.11325049854349345\n",
      "eikonal_loss:  0.005582382436841726\n",
      "Epoch 921: loss = 0.24766398966312408\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12737922370433807 chamfer_loss_mesh:  0.11349008127581328\n",
      "eikonal_loss:  0.00572819821536541\n",
      "Epoch 922: loss = 0.24798886477947235\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12693636817857623 chamfer_loss_mesh:  0.11329488188493997\n",
      "eikonal_loss:  0.006002189591526985\n",
      "Epoch 923: loss = 0.24762365221977234\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1269543543457985 chamfer_loss_mesh:  0.11528932373039424\n",
      "eikonal_loss:  0.005616047885268927\n",
      "Epoch 924: loss = 0.2492513209581375\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12698235223069787 chamfer_loss_mesh:  0.1631533377803862\n",
      "eikonal_loss:  0.011722096242010593\n",
      "Epoch 925: loss = 0.3032498061656952\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12735447380691767 chamfer_loss_mesh:  0.11335617455188185\n",
      "eikonal_loss:  0.012252036482095718\n",
      "Epoch 926: loss = 0.2543538510799408\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1281175995245576 chamfer_loss_mesh:  0.1133401965489611\n",
      "eikonal_loss:  0.010586073622107506\n",
      "Epoch 927: loss = 0.253435343503952\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12823272263631225 chamfer_loss_mesh:  0.15531451208516955\n",
      "eikonal_loss:  0.0062719411216676235\n",
      "Epoch 928: loss = 0.291210412979126\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1290346379391849 chamfer_loss_mesh:  0.12666135444305837\n",
      "eikonal_loss:  0.005997758824378252\n",
      "Epoch 929: loss = 0.2630840241909027\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12853143271058798 chamfer_loss_mesh:  0.145670011988841\n",
      "eikonal_loss:  0.005418956745415926\n",
      "Epoch 930: loss = 0.2810123562812805\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1283667515963316 chamfer_loss_mesh:  0.11392717715352774\n",
      "eikonal_loss:  0.004464536905288696\n",
      "Epoch 931: loss = 0.2481497973203659\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1290915533900261 chamfer_loss_mesh:  0.11374035966582596\n",
      "eikonal_loss:  0.004271818790584803\n",
      "Epoch 932: loss = 0.24849532544612885\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12918325373902917 chamfer_loss_mesh:  0.16198067169170827\n",
      "eikonal_loss:  0.004211833700537682\n",
      "Epoch 933: loss = 0.2967674136161804\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1292722998186946 chamfer_loss_mesh:  0.11229408846702427\n",
      "eikonal_loss:  0.004457325674593449\n",
      "Epoch 934: loss = 0.2474149465560913\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12940249871462584 chamfer_loss_mesh:  0.1572211622260511\n",
      "eikonal_loss:  0.0047803302295506\n",
      "Epoch 935: loss = 0.2927961051464081\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12954954290762544 chamfer_loss_mesh:  0.13830856187269092\n",
      "eikonal_loss:  0.004089006222784519\n",
      "Epoch 936: loss = 0.2733384668827057\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1298480317927897 chamfer_loss_mesh:  0.11301492486381903\n",
      "eikonal_loss:  0.004347043111920357\n",
      "Epoch 937: loss = 0.24860218167304993\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13026014203205705 chamfer_loss_mesh:  0.13063711230643094\n",
      "eikonal_loss:  0.013445593416690826\n",
      "Epoch 938: loss = 0.2757345139980316\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1300445757806301 chamfer_loss_mesh:  0.11237400030950084\n",
      "eikonal_loss:  0.007224086672067642\n",
      "Epoch 939: loss = 0.2510360777378082\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1297337468713522 chamfer_loss_mesh:  0.11251706746406853\n",
      "eikonal_loss:  0.006398133933544159\n",
      "Epoch 940: loss = 0.2500421106815338\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1300134346820414 chamfer_loss_mesh:  0.14699950406793505\n",
      "eikonal_loss:  0.011351114138960838\n",
      "Epoch 941: loss = 0.28975793719291687\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12932494282722473 chamfer_loss_mesh:  0.11234110570512712\n",
      "eikonal_loss:  0.004069364629685879\n",
      "Epoch 942: loss = 0.24712920188903809\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13139366637915373 chamfer_loss_mesh:  0.11216076381970197\n",
      "eikonal_loss:  0.003741235937923193\n",
      "Epoch 943: loss = 0.2486894577741623\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13104036916047335 chamfer_loss_mesh:  0.11349367559887469\n",
      "eikonal_loss:  0.00351564958691597\n",
      "Epoch 944: loss = 0.24944405257701874\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13022046769037843 chamfer_loss_mesh:  0.19035785226151347\n",
      "eikonal_loss:  0.004178341012448072\n",
      "Epoch 945: loss = 0.32615187764167786\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12935653794556856 chamfer_loss_mesh:  0.11419558722991496\n",
      "eikonal_loss:  0.0066638002172112465\n",
      "Epoch 946: loss = 0.2516087591648102\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12977051082998514 chamfer_loss_mesh:  0.1336535788141191\n",
      "eikonal_loss:  0.006864569615572691\n",
      "Epoch 947: loss = 0.2716805040836334\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12996619334444404 chamfer_loss_mesh:  0.210585625609383\n",
      "eikonal_loss:  0.006805683486163616\n",
      "Epoch 948: loss = 0.348751038312912\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12969421222805977 chamfer_loss_mesh:  0.13034918811172247\n",
      "eikonal_loss:  0.006453283596783876\n",
      "Epoch 949: loss = 0.26789018511772156\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12938006548210979 chamfer_loss_mesh:  0.11308721150271595\n",
      "eikonal_loss:  0.005945370066910982\n",
      "Epoch 950: loss = 0.2498060017824173\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12978747254237533 chamfer_loss_mesh:  0.12431549839675426\n",
      "eikonal_loss:  0.005341626238077879\n",
      "Epoch 951: loss = 0.2608373463153839\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13041316997259855 chamfer_loss_mesh:  0.12744683772325516\n",
      "eikonal_loss:  0.0046515618450939655\n",
      "Epoch 952: loss = 0.263902872800827\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12979069724678993 chamfer_loss_mesh:  0.11385850666556507\n",
      "eikonal_loss:  0.031183233484625816\n",
      "Epoch 953: loss = 0.2762235105037689\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.131023651920259 chamfer_loss_mesh:  0.13372168177738786\n",
      "eikonal_loss:  0.027317095547914505\n",
      "Epoch 954: loss = 0.2934553027153015\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13093599118292332 chamfer_loss_mesh:  0.11306886153761297\n",
      "eikonal_loss:  0.018438344821333885\n",
      "Epoch 955: loss = 0.26383495330810547\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13092897133901715 chamfer_loss_mesh:  0.11401673691580072\n",
      "eikonal_loss:  0.0140915522351861\n",
      "Epoch 956: loss = 0.2604307234287262\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13073005247861147 chamfer_loss_mesh:  0.15576652367599308\n",
      "eikonal_loss:  0.014199326746165752\n",
      "Epoch 957: loss = 0.30208948254585266\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13037791941314936 chamfer_loss_mesh:  0.11489483586046845\n",
      "eikonal_loss:  0.012517588213086128\n",
      "Epoch 958: loss = 0.2591850757598877\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13034348376095295 chamfer_loss_mesh:  0.11307204840704799\n",
      "eikonal_loss:  0.010806749574840069\n",
      "Epoch 959: loss = 0.25561684370040894\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13080197386443615 chamfer_loss_mesh:  0.118414027383551\n",
      "eikonal_loss:  0.010222913697361946\n",
      "Epoch 960: loss = 0.2608332335948944\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1307182013988495 chamfer_loss_mesh:  0.11457686923677102\n",
      "eikonal_loss:  0.01083815935999155\n",
      "Epoch 961: loss = 0.25752541422843933\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1304470468312502 chamfer_loss_mesh:  0.12625177623704076\n",
      "eikonal_loss:  0.009504567831754684\n",
      "Epoch 962: loss = 0.26759618520736694\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.131816859357059 chamfer_loss_mesh:  0.15291654563043267\n",
      "eikonal_loss:  0.008963038213551044\n",
      "Epoch 963: loss = 0.2950870096683502\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1316535985097289 chamfer_loss_mesh:  0.14443378313444555\n",
      "eikonal_loss:  0.008904505521059036\n",
      "Epoch 964: loss = 0.2863832116127014\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1312720589339733 chamfer_loss_mesh:  0.11287996312603354\n",
      "eikonal_loss:  0.008158013224601746\n",
      "Epoch 965: loss = 0.2537018656730652\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13118390925228596 chamfer_loss_mesh:  0.11221088061574847\n",
      "eikonal_loss:  0.008320411667227745\n",
      "Epoch 966: loss = 0.25310781598091125\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1307667000219226 chamfer_loss_mesh:  0.1132172328652814\n",
      "eikonal_loss:  0.006472706329077482\n",
      "Epoch 967: loss = 0.2518514096736908\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13038456672802567 chamfer_loss_mesh:  0.15032851661089808\n",
      "eikonal_loss:  0.0072837392799556255\n",
      "Epoch 968: loss = 0.2893912196159363\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1303777564316988 chamfer_loss_mesh:  0.1151098549598828\n",
      "eikonal_loss:  0.0059505123645067215\n",
      "Epoch 969: loss = 0.2528318464756012\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13046360109001398 chamfer_loss_mesh:  0.11356962932040915\n",
      "eikonal_loss:  0.007968376390635967\n",
      "Epoch 970: loss = 0.253395140171051\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13018599711358547 chamfer_loss_mesh:  0.11327899119351059\n",
      "eikonal_loss:  0.007969985716044903\n",
      "Epoch 971: loss = 0.2528301775455475\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12978005688637495 chamfer_loss_mesh:  0.11542651918716729\n",
      "eikonal_loss:  0.007938043214380741\n",
      "Epoch 972: loss = 0.2545397877693176\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12973903212696314 chamfer_loss_mesh:  0.1592069020261988\n",
      "eikonal_loss:  0.007289377972483635\n",
      "Epoch 973: loss = 0.2976304888725281\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13008331879973412 chamfer_loss_mesh:  0.11571288632694632\n",
      "eikonal_loss:  0.01002327911555767\n",
      "Epoch 974: loss = 0.2572135627269745\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13041795464232564 chamfer_loss_mesh:  0.14060862304177135\n",
      "eikonal_loss:  0.006892576348036528\n",
      "Epoch 975: loss = 0.279313325881958\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13022703351452947 chamfer_loss_mesh:  0.11365726822987199\n",
      "eikonal_loss:  0.006909177638590336\n",
      "Epoch 976: loss = 0.25218671560287476\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.12997197918593884 chamfer_loss_mesh:  0.1580047101015225\n",
      "eikonal_loss:  0.006673418916761875\n",
      "Epoch 977: loss = 0.29604482650756836\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1296460977755487 chamfer_loss_mesh:  0.12359704123809934\n",
      "eikonal_loss:  0.007067631930112839\n",
      "Epoch 978: loss = 0.26170504093170166\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13035736046731472 chamfer_loss_mesh:  0.11457318760221824\n",
      "eikonal_loss:  0.0063114166259765625\n",
      "Epoch 979: loss = 0.25263673067092896\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13128239661455154 chamfer_loss_mesh:  0.12908849748782814\n",
      "eikonal_loss:  0.005779290106147528\n",
      "Epoch 980: loss = 0.2675449848175049\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13061078498139977 chamfer_loss_mesh:  0.11940453259740025\n",
      "eikonal_loss:  0.009212461300194263\n",
      "Epoch 981: loss = 0.2606213092803955\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1306143356487155 chamfer_loss_mesh:  0.1662180875428021\n",
      "eikonal_loss:  0.007658958900719881\n",
      "Epoch 982: loss = 0.30588555335998535\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13107266277074814 chamfer_loss_mesh:  0.11461415851954371\n",
      "eikonal_loss:  0.007086516823619604\n",
      "Epoch 983: loss = 0.2541673481464386\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13094614259898663 chamfer_loss_mesh:  0.15438398986589164\n",
      "eikonal_loss:  0.009126515127718449\n",
      "Epoch 984: loss = 0.2958526313304901\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13063813094049692 chamfer_loss_mesh:  0.14051658217795193\n",
      "eikonal_loss:  0.009016728028655052\n",
      "Epoch 985: loss = 0.2815678119659424\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1311025582253933 chamfer_loss_mesh:  0.11506200826261193\n",
      "eikonal_loss:  0.008600029163062572\n",
      "Epoch 986: loss = 0.25616219639778137\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1309920335188508 chamfer_loss_mesh:  0.14461064711213112\n",
      "eikonal_loss:  0.00813297275453806\n",
      "Epoch 987: loss = 0.2851342260837555\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13052904978394508 chamfer_loss_mesh:  0.11426722630858421\n",
      "eikonal_loss:  0.006306517869234085\n",
      "Epoch 988: loss = 0.25250163674354553\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13091787695884705 chamfer_loss_mesh:  0.13707656762562692\n",
      "eikonal_loss:  0.006704472005367279\n",
      "Epoch 989: loss = 0.27609968185424805\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.1309512066654861 chamfer_loss_mesh:  0.14907834702171385\n",
      "eikonal_loss:  0.006266648881137371\n",
      "Epoch 990: loss = 0.2876977026462555\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13080156641080976 chamfer_loss_mesh:  0.11469928722362965\n",
      "eikonal_loss:  0.00630531832575798\n",
      "Epoch 991: loss = 0.25320708751678467\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13094577006995678 chamfer_loss_mesh:  0.11365057434886694\n",
      "eikonal_loss:  0.006122882477939129\n",
      "Epoch 992: loss = 0.25211963057518005\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13093013549223542 chamfer_loss_mesh:  0.11420001101214439\n",
      "eikonal_loss:  0.005877223797142506\n",
      "Epoch 993: loss = 0.2524079382419586\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13137133792042732 chamfer_loss_mesh:  0.1145430578617379\n",
      "eikonal_loss:  0.005851346999406815\n",
      "Epoch 994: loss = 0.2531655430793762\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13112962478771806 chamfer_loss_mesh:  0.13735442189499736\n",
      "eikonal_loss:  0.005230933427810669\n",
      "Epoch 995: loss = 0.2751154601573944\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13083694502711296 chamfer_loss_mesh:  0.1408715033903718\n",
      "eikonal_loss:  0.005141068249940872\n",
      "Epoch 996: loss = 0.2782488763332367\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13074458111077547 chamfer_loss_mesh:  0.14479630044661462\n",
      "eikonal_loss:  0.005263136234134436\n",
      "Epoch 997: loss = 0.2822047770023346\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13112197630107403 chamfer_loss_mesh:  0.11262341286055744\n",
      "eikonal_loss:  0.003186551621183753\n",
      "Epoch 998: loss = 0.24833174049854279\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13041069032624364 chamfer_loss_mesh:  0.1130925738834776\n",
      "eikonal_loss:  0.003230836009606719\n",
      "Epoch 999: loss = 0.24813410639762878\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "cvt_loss:  0.13051307760179043 chamfer_loss_mesh:  0.11347993859089911\n",
      "eikonal_loss:  0.0029816064052283764\n",
      "Epoch 1000: loss = 0.2483738660812378\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "Sites length:  32768\n",
      "min sites:  tensor(-1.0542, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "max sites:  tensor(1.0395, device='cuda:0', grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "site_file_path = f\"{destination}{max_iter}_cvt_{lambda_cvt}_chamfer_{lambda_chamfer}_eikonal_{lambda_eikonal}.npy\"\n",
    "\n",
    "# Mkdir parent\n",
    "os.makedirs(os.path.dirname(site_file_path), exist_ok=True)\n",
    "\n",
    "voroloss_optim = False\n",
    "# check if optimized sites file exists\n",
    "if os.path.exists(site_file_path):\n",
    "    # import sites\n",
    "    print(\"Importing sites\")\n",
    "    sites = np.load(site_file_path)\n",
    "    sites = torch.from_numpy(sites).to(device).requires_grad_(True)\n",
    "else:\n",
    "    # import cProfile, pstats\n",
    "    # import time\n",
    "\n",
    "    # profiler = cProfile.Profile()\n",
    "    # profiler.enable()\n",
    "\n",
    "    # with torch.profiler.profile(\n",
    "    #     activities=[\n",
    "    #         torch.profiler.ProfilerActivity.CPU,\n",
    "    #         torch.profiler.ProfilerActivity.CUDA,\n",
    "    #     ],\n",
    "    #     record_shapes=False,\n",
    "    #     with_stack=True,  # Captures function calls\n",
    "    # ) as prof:\n",
    "    #     sites, optimized_sites_sdf = train_DCCVT(\n",
    "    #         sites, sdf0, max_iter=max_iter, upsampling=0, lambda_weights=lambda_weights\n",
    "    #     )\n",
    "\n",
    "    # print(prof.key_averages().table(sort_by=\"self_cuda_time_total\"))\n",
    "    # prof.export_chrome_trace(\"trace.json\")\n",
    "\n",
    "    sites, optimized_sites_sdf = train_DCCVT(\n",
    "        sites, sdf0, max_iter=max_iter, upsampling=0, lambda_weights=lambda_weights, voroloss_optim=voroloss_optim\n",
    "    )\n",
    "\n",
    "    sites_np = sites.detach().cpu().numpy()\n",
    "    np.save(site_file_path, sites_np)\n",
    "\n",
    "print(\"Sites length: \", len(sites))\n",
    "print(\"min sites: \", torch.min(sites))\n",
    "print(\"max sites: \", torch.max(sites))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0b7f7237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sdf torch.Size([32768])\n",
      "sites ./images/autograd/End2End_DCCVT_interpolSDF/gargoyle1000_1000_3d_sites_32768_chamfer1000.pth\n",
      "sites_np shape:  (32768, 3)\n"
     ]
    }
   ],
   "source": [
    "epoch = 1000\n",
    "\n",
    "# model_file_path = f'{destination}{mesh[0]}{max_iter}_{epoch}_3d_model_{num_centroids}_chamfer{lambda_chamfer}.pth'\n",
    "site_file_path = f\"{destination}{mesh[0]}{max_iter}_{epoch}_3d_sites_{num_centroids}_chamfer{lambda_chamfer}.pth\"\n",
    "sdf_file_path = f\"{destination}{mesh[0]}{max_iter}_{epoch}_3d_sdf_{num_centroids}_chamfer{lambda_chamfer}.pth\"\n",
    "\n",
    "\n",
    "sites = torch.load(site_file_path)\n",
    "sdf_v = torch.load(sdf_file_path)\n",
    "if voroloss_optim:\n",
    "    sdf_v = model(sites).squeeze(-1)\n",
    "\n",
    "\n",
    "sites_np = sites.detach().cpu().numpy()\n",
    "print(\"sdf\", sdf_v.shape)\n",
    "print(\"sites\", site_file_path)\n",
    "\n",
    "ps_cloud_f = ps.register_point_cloud(f\"{epoch} epoch_cvt_grid\", sites_np)\n",
    "ps_cloud_f.add_scalar_quantity(\n",
    "    \"vis_grid_pred\",\n",
    "    sdf_v.detach().cpu().numpy(),\n",
    "    enabled=True,\n",
    "    cmap=\"coolwarm\",\n",
    "    vminmax=(-0.15, 0.15),\n",
    ")\n",
    "\n",
    "print(\"sites_np shape: \", sites_np.shape)\n",
    "\n",
    "# print sites if Nan\n",
    "if np.isnan(sites_np).any():\n",
    "    print(\"sites_np contains NaN values\")\n",
    "    print(\"sites_np NaN values: \", np.isnan(sites_np).sum())\n",
    "# remove nan values from sites tensor\n",
    "sites_np = sites_np[~np.isnan(sites_np).any(axis=1)]\n",
    "sites = torch.from_numpy(sites_np).to(device).requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "82a1aa94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d3dsimplices, _ = pygdel3d.triangulate(sites_np)\n",
    "# d3dsimplices = torch.tensor(d3dsimplices, device=device)\n",
    "# b, f = su.NOT_mt_extraction(sites, sdf_v, d3dsimplices)\n",
    "# ps.register_surface_mesh(\n",
    "#     \"NOT_mt_extraction\",\n",
    "#     b,\n",
    "#     f,\n",
    "#     back_face_policy=\"identical\",\n",
    "#     enabled=False,\n",
    "# )\n",
    "# # ps.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0d0f86bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zc true_Sdf shape:  torch.Size([4430, 4])\n",
      "zc optimized sdf : torch.Size([4430, 4])\n",
      "sum of zc true Sdf:  46.82440185546875\n",
      "sum of zc opti Sdf:  35.70307922363281\n",
      "Diff   of   sum:  11.12132453918457\n",
      "Mean of zc true Sdf:  0.0006276142667047679\n"
     ]
    }
   ],
   "source": [
    "# metric between sites sdf values and their corresponding sdf values on hotspot model\n",
    "true_Sdf = model(sites).squeeze(-1)\n",
    "d3dsimplices, _ = pygdel3d.triangulate(sites_np)\n",
    "d3dsimplices = np.array(d3dsimplices)\n",
    "\n",
    "vertices_to_compute, bisectors_to_compute, used_tet = su.compute_zero_crossing_vertices_3d(\n",
    "    sites, None, None, d3dsimplices, sdf_v\n",
    ")\n",
    "d3dsimplices = torch.tensor(d3dsimplices, device=device)\n",
    "d3d = d3dsimplices[used_tet]\n",
    "zc_sdf = sdf_v[d3d]\n",
    "zc_truesdf = true_Sdf[d3d]\n",
    "print(\"zc true_Sdf shape: \", zc_truesdf.shape)\n",
    "print(\"zc optimized sdf :\", zc_sdf.shape)\n",
    "print(\"sum of zc true Sdf: \", torch.sum(zc_truesdf).item())\n",
    "print(\"sum of zc opti Sdf: \", torch.sum(zc_sdf).item())\n",
    "print(\"Diff   of   sum: \", torch.sum(zc_truesdf - zc_sdf).item())\n",
    "print(\"Mean of zc true Sdf: \", torch.mean(zc_truesdf - zc_sdf).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9772bb82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Delaunay simplices...\n",
      "Number of Delaunay simplices: 195681\n",
      "Delaunay simplices shape: [[   97     3    32    35]\n",
      " [22178 21155 21123 22147]\n",
      " [   64  2080    32  1152]\n",
      " ...\n",
      " [ 8589  8588  8556  7564]\n",
      " [ 8620  8589  8621  7565]\n",
      " [ 8589  8620  8621  8588]]\n",
      "Max vertex index in simplices: 32767\n",
      "Min vertex index in simplices: 0\n",
      "Site index range: 32768\n",
      "Computing Delaunay simplices...\n",
      "Number of Delaunay simplices: 195681\n",
      "Delaunay simplices shape: [[   97     3    32    35]\n",
      " [ 6995  6994  8018  6963]\n",
      " [ 2113  2145  2112  2144]\n",
      " ...\n",
      " [12867 11811 12866 12834]\n",
      " [11811 12867 12835 12834]\n",
      " [11811 12867 11812 12835]]\n",
      "Max vertex index in simplices: 32767\n",
      "Min vertex index in simplices: 0\n",
      "Site index range: 32768\n"
     ]
    }
   ],
   "source": [
    "# v_vect, f_vect = su.get_clipped_mesh_numba(sites, model, None, True)\n",
    "# ps.register_surface_mesh(\"model final clipped polygon mesh\", v_vect.detach().cpu().numpy(), f_vect)\n",
    "\n",
    "# v_vect, f_vect = su.get_clipped_mesh_numba(sites, model, None, False)\n",
    "# ps.register_surface_mesh(\"model final polygon mesh\", v_vect.detach().cpu().numpy(), f_vect)\n",
    "\n",
    "######################################################\n",
    "\n",
    "# if mesh[0] == \"sphere\":\n",
    "#     # generate sphere sdf\n",
    "#     print(\"Generating sphere SDF\")\n",
    "#     sdf_v = sphere_sdf(sites, torch.zeros(3).to(device), 0.50)\n",
    "\n",
    "(\n",
    "    v_vect,\n",
    "    f_vect,\n",
    "    _,\n",
    "    _,\n",
    "    _,\n",
    ") = su.get_clipped_mesh_numba(sites, None, None, False, sdf_v, True)\n",
    "\n",
    "# f_vect = [[f[0], f[i], f[i + 1]] for f in f_vect for i in range(1, len(f) - 1)]\n",
    "\n",
    "ps.register_surface_mesh(\n",
    "    \"sdf final unclipped polygon mesh\",\n",
    "    v_vect.detach().cpu().numpy(),\n",
    "    f_vect,\n",
    "    back_face_policy=\"identical\",\n",
    "    enabled=False,\n",
    ")\n",
    "\n",
    "if voroloss_optim:\n",
    "    ps.show()\n",
    "\n",
    "p, faces = su.cvt_extraction(sites, sdf_v, d3dsimplices.detach().cpu().numpy(), True)\n",
    "# ps.register_point_cloud(\"cvt extraction\", p.detach().cpu().numpy())\n",
    "ps.register_surface_mesh(\"cvt extraction final\", p.detach().cpu().numpy(), faces, back_face_policy=\"identical\")\n",
    "\n",
    "\n",
    "v_vect, f_vect, _, _, _ = su.get_clipped_mesh_numba(sites, None, None, True, sdf_v, True)\n",
    "# f_vect = [[f[0], f[i], f[i + 1]] for f in f_vect for i in range(1, len(f) - 1)]\n",
    "ps.register_surface_mesh(\n",
    "    \"sdf final clipped polygon mesh\", v_vect.detach().cpu().numpy(), f_vect, back_face_policy=\"identical\"\n",
    ")\n",
    "# f_vect = [[f[0], f[i], f[i + 1]] for f in f_vect for i in range(1, len(f) - 1)]\n",
    "\n",
    "d3dsimplices, _ = pygdel3d.triangulate(sites_np)\n",
    "d3dsimplices = torch.tensor(d3dsimplices, device=device)\n",
    "marching_tetrehedra_mesh = kaolin.ops.conversions.marching_tetrahedra(\n",
    "    sites.unsqueeze(0), d3dsimplices, sdf_v.unsqueeze(0), return_tet_idx=False\n",
    ")\n",
    "vertices_list, faces_list = marching_tetrehedra_mesh\n",
    "v_vect = vertices_list[0]\n",
    "faces = faces_list[0]\n",
    "\n",
    "ps.register_surface_mesh(\n",
    "    \"MTET\", v_vect.detach().cpu().numpy(), faces.detach().cpu().numpy(), back_face_policy=\"identical\"\n",
    ")\n",
    "\n",
    "# export obj file\n",
    "output_obj_file = (\n",
    "    f\"{destination}{mesh[0]}{max_iter}_{epoch}_3d_sites_{num_centroids}_chamfer{lambda_chamfer}_outputmesh.obj\"\n",
    ")\n",
    "output_ply_file = (\n",
    "    f\"{destination}{mesh[0]}{max_iter}_{epoch}_3d_sites_{num_centroids}_chamfer{lambda_chamfer}_targetpointcloud.ply\"\n",
    ")\n",
    "# su.save_obj(output_obj_file, v_vect.detach().cpu().numpy(), f_vect)\n",
    "# su.save_target_pc_ply(output_ply_file, mnfld_points.squeeze(0).detach().cpu().numpy())\n",
    "\n",
    "\n",
    "ps.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2a2308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sites, sdf = train_DCCVT(\n",
    "#     sites, sdf_v, max_iter=max_iter, upsampling=0, lambda_weights=lambda_weights, voroloss_optim=True\n",
    "# )\n",
    "# (\n",
    "#     v_vect,\n",
    "#     f_vect,\n",
    "#     _,\n",
    "#     _,\n",
    "#     _,\n",
    "# ) = su.get_clipped_mesh_numba(sites, None, None, False, sdf, True)\n",
    "# ps.register_surface_mesh(\"voromeh sdf final unclipped polygon mesh\", v_vect.detach().cpu().numpy(), f_vect)\n",
    "\n",
    "\n",
    "# v_vect, f_vect, _, _, _ = su.get_clipped_mesh_numba(sites, None, None, True, sdf, True)\n",
    "# ps.register_surface_mesh(\"voromeh sdf final clipped polygon mesh\", v_vect.detach().cpu().numpy(), f_vect)\n",
    "# # f_vect = [[f[0], f[i], f[i + 1]] for f in f_vect for i in range(1, len(f) - 1)]\n",
    "# ps.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a71d0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chamfer metric\n",
    "# add sampled points to polyscope and ground truth mesh to polyscope\n",
    "\n",
    "import trimesh\n",
    "\n",
    "\n",
    "def sample_points_on_mesh(mesh_path, n_points=100000):\n",
    "    mesh = trimesh.load(mesh_path)\n",
    "    # normalize mesh\n",
    "    mesh.apply_translation(-mesh.centroid)\n",
    "    mesh.apply_scale(1.0 / np.max(np.abs(mesh.vertices)))\n",
    "    # export mesh to obj file\n",
    "    mesh.export(mesh_path.replace(\".obj\", \".obj\"))\n",
    "    print(mesh_path)\n",
    "    points, _ = trimesh.sample.sample_surface(mesh, n_points)\n",
    "    return points, mesh\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "\n",
    "def chamfer_accuracy_completeness(ours_pts, gt_pts):\n",
    "    # Completeness: GT  Ours\n",
    "    dists_gt_to_ours = cKDTree(ours_pts).query(gt_pts, k=1)[0]\n",
    "    completeness = np.mean(dists_gt_to_ours**2)\n",
    "\n",
    "    # Accuracy: Ours  GT\n",
    "    dists_ours_to_gt = cKDTree(gt_pts).query(ours_pts, k=1)[0]\n",
    "    accuracy = np.mean(dists_ours_to_gt**2)\n",
    "\n",
    "    return accuracy, completeness\n",
    "\n",
    "\n",
    "ours_pts, _ = sample_points_on_mesh(output_obj_file, n_points=100000)\n",
    "m = mesh[1].replace(\"data\", \"mesh\")\n",
    "gt_pts, _ = sample_points_on_mesh(m + \".obj\", n_points=100000)\n",
    "\n",
    "acc, comp = chamfer_accuracy_completeness(ours_pts, gt_pts)\n",
    "\n",
    "print(f\"Chamfer Accuracy (Ours  GT): {acc:.6f}\")\n",
    "print(f\"Chamfer Completeness (GT  Ours): {comp:.6f}\")\n",
    "print(f\"Chamfer Distance (symmetric): {acc + comp:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910f8f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_points_on_mesh(mesh_path, n_points=100000):\n",
    "    mesh = trimesh.load(mesh_path)\n",
    "\n",
    "    # Normalize mesh (centered and scaled uniformly)\n",
    "    bbox = mesh.bounds\n",
    "    center = mesh.centroid\n",
    "    scale = np.linalg.norm(bbox[1] - bbox[0])\n",
    "    mesh.apply_translation(-center)\n",
    "    mesh.apply_scale(1.0 / scale)\n",
    "\n",
    "    # Export normalized mesh\n",
    "    mesh.export(mesh_path.replace(\".obj\", \".obj\"))\n",
    "\n",
    "    points, _ = trimesh.sample.sample_surface(mesh, n_points)\n",
    "    return points, mesh\n",
    "\n",
    "\n",
    "_, _ = sample_points_on_mesh(\n",
    "    \"/home/wylliam/dev/Kyushu_experiments/outputs/gargoyle_unconverged/cdp1000_v0_cvt100_clipTrue_buildFalse_upsampling0_num_centroids32_target_size32_final.obj\",\n",
    "    n_points=100000,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
