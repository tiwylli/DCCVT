{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f9796c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warp CUDA error: Failed to get driver entry point 'cuDeviceGetUuid' (CUDA error 1)\n",
      "Warp CUDA error: Function cuDeviceGetUuid_f: a suitable driver entry point was not found\n",
      "Warp CUDA error 36: API call is not supported in the installed CUDA driver (in function cuda_init, /builds/omniverse/warp/warp/native/warp.cu:284)\n",
      "Warp CUDA error: Function cuDeviceGetUuid_f: a suitable driver entry point was not found\n",
      "Warp CUDA error 36: API call is not supported in the installed CUDA driver (in function cuda_init, /builds/omniverse/warp/warp/native/warp.cu:284)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device:  NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "import kaolin\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import polyscope as ps\n",
    "\n",
    "# import diffvoronoi\n",
    "import pygdel3d\n",
    "import sdfpred_utils.sdfpred_utils as su\n",
    "import sdfpred_utils.loss_functions as lf\n",
    "from pytorch3d.loss import chamfer_distance\n",
    "from pytorch3d.ops import knn_points, knn_gather\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# cuda devices\n",
    "device = torch.device(\"cuda:0\")\n",
    "print(\"Using device: \", torch.cuda.get_device_name(device))\n",
    "\n",
    "# Improve reproducibility\n",
    "torch.manual_seed(69)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(69)\n",
    "\n",
    "input_dims = 3\n",
    "lr_sites = 0.005\n",
    "# lr_model = 0.00001\n",
    "destination = \"./images/autograd/End2End_DCCVT_interpolSDF/ball2bunny/\"\n",
    "model_trained_it = \"\"\n",
    "ROOT_DIR = \"/home/wylliam/dev/Kyushu_experiments\"\n",
    "\n",
    "# mesh = [\"sphere\"]\n",
    "\n",
    "# mesh = [\"hole_gargoyle\", \"/home/wylliam/dev/Kyushu_experiments/data/gargoyle\"]\n",
    "# trained_model_path = f\"/home/wylliam/dev/HotSpot/log/3D/pc/HotSpot-all-2025-04-24-18-16-03/gargoyle/gargoyle/trained_models/model{model_trained_it}.pth\"\n",
    "\n",
    "# mesh = [\n",
    "#     \"gargoyle\",\n",
    "#     f\"{ROOT_DIR}/mesh/thingi32/64764\",\n",
    "# ]\n",
    "# trained_model_path = f\"{ROOT_DIR}/hotspots_model/thingi32/64764.pth\"\n",
    "\n",
    "\n",
    "# mesh = [\"zombie\", f\"{ROOT_DIR}/mesh/thingi32_150k/398259\"]\n",
    "# trained_model_path = f\"{ROOT_DIR}/hotspots_model/thingi32_150k/398259.pth\"\n",
    "\n",
    "# mesh = [\"gargoyle_unconverged\", \"/home/wylliam/dev/Kyushu_experiments/mesh/gargoyle_unconverged\"]\n",
    "# trained_model_path = f\"/home/wylliam/dev/HotSpot/log/3D/pc/HotSpot-all-2025-04-24-18-16-03/gargoyle/gargoyle/trained_models/model_500.pth\"\n",
    "\n",
    "\n",
    "# mesh = [\"chair\", \"/home/wylliam/dev/Kyushu_experiments/data/chair\"]\n",
    "# trained_model_path = f\"/home/wylliam/dev/HotSpot/log/3D/pc/HotSpot-all-2025-05-02-17-56-25/chair/chair/trained_models/model{model_trained_it}.pth\"\n",
    "\n",
    "mesh = [\"bunny\", \"/home/wylliam/dev/Kyushu_experiments/data/bunny\"]\n",
    "trained_model_path = f\"/home/wylliam/dev/HotSpot/log/3D/pc/HotSpot-all-2025-04-25-17-32-49/bunny/bunny/trained_models/model{model_trained_it}.pth\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3f27a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new sites\n",
      "Sites shape:  torch.Size([4096, 3])\n",
      "Sites:  tensor([-1.0027, -1.0065, -0.9978], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "[polyscope] Backend: openGL3_glfw -- Loaded openGL version: 3.3.0 NVIDIA 580.76.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wylliam/dev/Kyushu_experiments-1/venv/lib/python3.12/site-packages/torch/functional.py:554: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:4314.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "num_centroids = 16**3\n",
    "grid = 64  # 128\n",
    "print(\"Creating new sites\")\n",
    "noise_scale = 0.005\n",
    "domain_limit = 1\n",
    "x = torch.linspace(-domain_limit, domain_limit, int(round(num_centroids ** (1 / 3))))\n",
    "y = torch.linspace(-domain_limit, domain_limit, int(round(num_centroids ** (1 / 3))))\n",
    "z = torch.linspace(-domain_limit, domain_limit, int(round(num_centroids ** (1 / 3))))\n",
    "meshgrid = torch.meshgrid(x, y, z)\n",
    "meshgrid = torch.stack(meshgrid, dim=3).view(-1, 3)\n",
    "\n",
    "# add noise to meshgrid\n",
    "meshgrid += torch.randn_like(meshgrid) * noise_scale\n",
    "\n",
    "\n",
    "sites = meshgrid.to(device, dtype=torch.float32).requires_grad_(True)\n",
    "\n",
    "print(\"Sites shape: \", sites.shape)\n",
    "print(\"Sites: \", sites[0])\n",
    "ps.init()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1ddd8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "\n",
    "# def z_axis_weights(points, mode=\"exp\", strength=3.0, percentile_clip=(0.02, 0.98), eps=1e-12):\n",
    "#     \"\"\"\n",
    "#     points: (N,3) or (1,N,3)\n",
    "#     \"\"\"\n",
    "#     # --- normalize shape ---\n",
    "#     if points.dim() == 3 and points.shape[0] == 1:\n",
    "#         points = points.squeeze(0)\n",
    "#     if not (points.dim() == 2 and points.shape[1] == 3):\n",
    "#         raise ValueError(f\"points must be (N,3) or (1,N,3); got {tuple(points.shape)}\")\n",
    "\n",
    "#     z = points[:, 2]\n",
    "\n",
    "#     # Robust min-max -> z_norm in [0,1]\n",
    "#     if percentile_clip is not None:\n",
    "#         lo, hi = percentile_clip\n",
    "#         z_lo = torch.quantile(z, lo)\n",
    "#         z_hi = torch.quantile(z, hi)\n",
    "#     else:\n",
    "#         z_lo, z_hi = z.min(), z.max()\n",
    "\n",
    "#     denom = (z_hi - z_lo).abs()\n",
    "#     if denom < 1e-12:\n",
    "#         # all z ~ equal -> uniform weights\n",
    "#         return torch.ones_like(z)\n",
    "\n",
    "#     z_norm = ((z - z_lo) / (denom + eps)).clamp(0.0, 1.0)\n",
    "\n",
    "#     if mode == \"linear\":\n",
    "#         w = 1.0 - z_norm\n",
    "#     elif mode == \"poly\":\n",
    "#         p = float(strength)\n",
    "#         w = (1.0 - z_norm).pow(p)\n",
    "#     elif mode == \"exp\":\n",
    "#         lam = float(strength)\n",
    "#         w = torch.exp(-lam * z_norm)\n",
    "#     elif mode == \"sigmoid\":\n",
    "#         k = float(strength)\n",
    "#         w = torch.sigmoid(-k * (z_norm - 0.5))\n",
    "#     else:\n",
    "#         raise ValueError(\"mode must be one of: linear | poly | exp | sigmoid\")\n",
    "\n",
    "#     return (w - w.min()).clamp_min(0) + eps\n",
    "\n",
    "\n",
    "# def weighted_subsample(points, M, weights, *, allow_replacement=None):\n",
    "#     \"\"\"\n",
    "#     points:   (N,3) or (1,N,3)\n",
    "#     weights:  (N,) or (1,N)\n",
    "#     If allow_replacement is None: auto True when M>N, else False.\n",
    "#     \"\"\"\n",
    "#     # --- normalize shapes ---\n",
    "#     if points.dim() == 3 and points.shape[0] == 1:\n",
    "#         points = points.squeeze(0)\n",
    "#     if not (points.dim() == 2 and points.shape[1] == 3):\n",
    "#         raise ValueError(f\"points must be (N,3) or (1,N,3); got {tuple(points.shape)}\")\n",
    "\n",
    "#     if weights.dim() == 2 and weights.shape[0] == 1:\n",
    "#         weights = weights.squeeze(0)\n",
    "#     if weights.dim() != 1 or weights.shape[0] != points.shape[0]:\n",
    "#         raise ValueError(f\"weights must be (N,) matching points; got {tuple(weights.shape)} vs N={points.shape[0]}\")\n",
    "\n",
    "#     N = points.shape[0]\n",
    "#     if allow_replacement is None:\n",
    "#         allow_replacement = M > N\n",
    "\n",
    "#     w = (weights.float() - weights.min()).clamp_min(0) + 1e-12\n",
    "#     M_eff = min(M, N) if not allow_replacement else M\n",
    "\n",
    "#     idx = torch.multinomial(w, M_eff, replacement=allow_replacement)\n",
    "#     return points[idx], idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2df77f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnfld_points shape:  torch.Size([1, 614400, 3])\n",
      "torch.float32\n",
      "torch.Size([4096, 3])\n",
      "Allocated: 16.825856 MB, Reserved: 85.983232 MB\n",
      "torch.Size([4096])\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# LOAD MODEL WITH HOTSPOT\n",
    "\n",
    "import sys\n",
    "\n",
    "if mesh[0] != \"sphere\":\n",
    "    sys.path.append(\"3rdparty/HotSpot\")\n",
    "    from dataset import shape_3d\n",
    "    import models.Net as Net\n",
    "\n",
    "    loss_type = \"igr_w_heat\"\n",
    "    loss_weights = [350, 0, 0, 1, 0, 0, 20]\n",
    "\n",
    "    train_set = shape_3d.ReconDataset(\n",
    "        file_path=mesh[1] + \".ply\",\n",
    "        n_points=grid * grid * 150,  # 15000, #args.n_points,\n",
    "        n_samples=10001,  # args.n_iterations,\n",
    "        grid_res=256,  # args.grid_res,\n",
    "        grid_range=1.1,  # args.grid_range,\n",
    "        sample_type=\"uniform_central_gaussian\",  # args.nonmnfld_sample_type,\n",
    "        sampling_std=0.5,  # args.nonmnfld_sample_std,\n",
    "        n_random_samples=7500,  # args.n_random_samples,\n",
    "        resample=True,\n",
    "        compute_sal_dist_gt=(True if \"sal\" in loss_type and loss_weights[5] > 0 else False),\n",
    "        scale_method=\"mean\",  # \"mean\" #args.pcd_scale_method,\n",
    "    )\n",
    "\n",
    "    model = Net.Network(\n",
    "        latent_size=0,  # args.latent_size,\n",
    "        in_dim=3,\n",
    "        decoder_hidden_dim=128,  # args.decoder_hidden_dim,\n",
    "        nl=\"sine\",  # args.nl,\n",
    "        encoder_type=\"none\",  # args.encoder_type,\n",
    "        decoder_n_hidden_layers=5,  # args.decoder_n_hidden_layers,\n",
    "        neuron_type=\"quadratic\",  # args.neuron_type,\n",
    "        init_type=\"mfgi\",  # args.init_type,\n",
    "        sphere_init_params=[1.6, 0.1],  # args.sphere_init_params,\n",
    "        n_repeat_period=30,  # args.n_repeat_period,\n",
    "    )\n",
    "    model.to(device)\n",
    "\n",
    "    ######\n",
    "    test_dataloader = torch.utils.data.DataLoader(\n",
    "        train_set, batch_size=1, shuffle=False, num_workers=0, pin_memory=False\n",
    "    )\n",
    "    test_data = next(iter(test_dataloader))\n",
    "    mnfld_points = test_data[\"mnfld_points\"].to(device)\n",
    "\n",
    "    # add noise to mnfld_points\n",
    "    # mnfld_points += torch.randn_like(mnfld_points) * (2 / 32) * (32 / 100)\n",
    "\n",
    "    mnfld_points.requires_grad_()\n",
    "    print(\"mnfld_points shape: \", mnfld_points.shape)\n",
    "    if torch.cuda.is_available():\n",
    "        map_location = torch.device(\"cuda\")\n",
    "    else:\n",
    "        map_location = torch.device(\"cpu\")\n",
    "    model.load_state_dict(torch.load(trained_model_path, weights_only=True, map_location=map_location))\n",
    "    sdf0 = model(sites)\n",
    "\n",
    "else:\n",
    "\n",
    "    def sphere_sdf(points: torch.Tensor, center: torch.Tensor, radius: float) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Compute the SDF of a sphere at given 3D points.\n",
    "\n",
    "        Args:\n",
    "            points: (N, 3) tensor of 3D query points\n",
    "            center: (3,) tensor specifying the center of the sphere\n",
    "            radius: float, radius of the sphere\n",
    "\n",
    "        Returns:\n",
    "            sdf: (N,) tensor of signed distances\n",
    "        \"\"\"\n",
    "        return torch.norm(points - center, dim=-1) - radius\n",
    "\n",
    "    def sphere_sdf_with_noise(\n",
    "        points: torch.Tensor, center: torch.Tensor, radius: float, noise_amplitude=0.05\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Sphere SDF with smooth directional noise added near the surface.\n",
    "\n",
    "        Args:\n",
    "            points: (N, 3)\n",
    "            center: (3,)\n",
    "            radius: float\n",
    "            noise_amplitude: float\n",
    "\n",
    "        Returns:\n",
    "            sdf: (N,)\n",
    "        \"\"\"\n",
    "        rel = points - center\n",
    "        norm = torch.norm(rel, dim=-1)  # (N,)\n",
    "        base_sdf = norm - radius  # (N,)\n",
    "\n",
    "        # Smooth periodic noise based on direction\n",
    "        unit_dir = rel / (norm.unsqueeze(-1) + 1e-9)  # (N,3)\n",
    "        noise = torch.sin(10 * unit_dir[:, 0]) * torch.sin(10 * unit_dir[:, 1]) * torch.sin(10 * unit_dir[:, 2])\n",
    "\n",
    "        # Weight noise so it mostly affects surface area\n",
    "        falloff = torch.exp(-20 * (base_sdf**2))  # (N,) ~1 near surface, ~0 far\n",
    "        sdf = base_sdf + noise_amplitude * noise * falloff\n",
    "\n",
    "        return sdf\n",
    "\n",
    "    # generate points on the sphere\n",
    "    mnfld_points = torch.randn(grid * grid * 150, 3, device=device)\n",
    "    mnfld_points = mnfld_points / torch.norm(mnfld_points, dim=-1, keepdim=True) * 0.5\n",
    "    mnfld_points = mnfld_points.unsqueeze(0).requires_grad_()\n",
    "    sdf0 = sphere_sdf(sites, torch.zeros(3).to(device), 0.50)\n",
    "    # sdf0 = sphere_sdf_with_noise(sites, torch.zeros(3).to(device), 0.50, noise_amplitude=0.1)\n",
    "\n",
    "\n",
    "# # add mnfld points with random noise to sites\n",
    "# N = mnfld_points.squeeze(0).shape[0]\n",
    "# num_samples = 18**3 - (num_centroids)\n",
    "# num_samples = 16**3\n",
    "# idx = torch.randint(0, N, (num_samples,))\n",
    "# sampled = mnfld_points.squeeze(0)[idx]\n",
    "# perturbed = sampled + (torch.rand_like(sampled) - 0.5) * noise_scale * 10\n",
    "\n",
    "\n",
    "# M = 16**3  # 4096\n",
    "# w = z_axis_weights(mnfld_points, mode=\"exp\", strength=4.0)\n",
    "\n",
    "# print(\"N =\", mnfld_points.squeeze(0).shape[0], \"M =\", M)  # sanity check\n",
    "\n",
    "# # Option A: keep unique samples only (if N<M, youâ€™ll just get N)\n",
    "# nonuni_pts, idx = weighted_subsample(mnfld_points, M, w, allow_replacement=False)\n",
    "\n",
    "# # (optional) add your jitter\n",
    "# perturbed = nonuni_pts + (torch.rand_like(nonuni_pts) - 0.5) * noise_scale\n",
    "\n",
    "\n",
    "# sites = torch.cat((sites, perturbed), dim=0)\n",
    "# sdf0 = model(sites)\n",
    "\n",
    "\n",
    "# START FROM SPHERE EXPERIMENTS\n",
    "sdf0 = torch.norm(sites - torch.zeros(3).to(device), dim=-1) - 0.50\n",
    "\n",
    "# make sites a leaf tensor\n",
    "sites = sites.detach().requires_grad_()\n",
    "print(sites.dtype)\n",
    "print(sites.shape)\n",
    "print(f\"Allocated: {torch.cuda.memory_allocated() / 1e6} MB, Reserved: {torch.cuda.memory_reserved() / 1e6} MB\")\n",
    "\n",
    "\n",
    "sdf0 = sdf0.detach().squeeze(-1).requires_grad_()\n",
    "print(sdf0.shape)\n",
    "print(sdf0.is_leaf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ba12786",
   "metadata": {},
   "outputs": [],
   "source": [
    "sites_np = sites.detach().cpu().numpy()\n",
    "d3dsimplices, _ = pygdel3d.triangulate(sites_np)\n",
    "d3dsimplices = np.array(d3dsimplices)\n",
    "# print(\"Delaunay simplices shape: \", d3dsimplices.shape)\n",
    "\n",
    "# print(\"sites shape: \", sites.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff63634a",
   "metadata": {},
   "outputs": [],
   "source": [
    "p, faces = su.cvt_extraction(sites, sdf0, d3dsimplices, True)\n",
    "ps.register_point_cloud(\"cvt extraction\", p.detach().cpu().numpy(), enabled=False)\n",
    "ps.register_surface_mesh(\"cvt extraction\", p.detach().cpu().numpy(), faces, back_face_policy=\"identical\", enabled=True)\n",
    "\n",
    "ps_cloud = ps.register_point_cloud(\"initial_cvt_grid+pc_gt\", sites.detach().cpu().numpy(), enabled=False)\n",
    "ps_cloud.add_scalar_quantity(\n",
    "    \"vis_grid_pred\",\n",
    "    sdf0.detach().cpu().numpy(),\n",
    "    enabled=True,\n",
    "    cmap=\"coolwarm\",\n",
    "    vminmax=(-0.00005, 0.00005),\n",
    ")\n",
    "mnf_cloud = ps.register_point_cloud(\"mnfld_points_pred\", mnfld_points.squeeze(0).detach().cpu().numpy(), enabled=False)\n",
    "\n",
    "v_vect, f_vect, sdf_verts, sdf_verts_grads, _ = su.get_clipped_mesh_numba(sites, None, d3dsimplices, False, sdf0, True)\n",
    "ps_mesh = ps.register_surface_mesh(\n",
    "    \"sdf unclipped initial mesh\",\n",
    "    v_vect.detach().cpu().numpy(),\n",
    "    f_vect,\n",
    "    back_face_policy=\"identical\",\n",
    "    enabled=False,\n",
    ")\n",
    "# ps_vert = ps.register_point_cloud(\"sdf unclipped initial verts\", v_vect.detach().cpu().numpy(), enabled=False)\n",
    "\n",
    "v_vect, f_vect, _, _, _ = su.get_clipped_mesh_numba(sites, None, d3dsimplices, True, sdf0, True)\n",
    "ps_mesh = ps.register_surface_mesh(\n",
    "    \"sdf clipped initial mesh\",\n",
    "    v_vect.detach().cpu().numpy(),\n",
    "    f_vect,\n",
    "    back_face_policy=\"identical\",\n",
    "    enabled=False,\n",
    ")\n",
    "\n",
    "d3dsimplices, _ = pygdel3d.triangulate(sites_np)\n",
    "d3dsimplices = torch.tensor(d3dsimplices, device=device)\n",
    "marching_tetrehedra_mesh = kaolin.ops.conversions.marching_tetrahedra(\n",
    "    sites.unsqueeze(0), d3dsimplices, sdf0.unsqueeze(0), return_tet_idx=False\n",
    ")\n",
    "vertices_list, faces_list = marching_tetrehedra_mesh\n",
    "v_vect = vertices_list[0]\n",
    "faces = faces_list[0]\n",
    "\n",
    "ps.register_surface_mesh(\n",
    "    \"init MTET\",\n",
    "    v_vect.detach().cpu().numpy(),\n",
    "    faces.detach().cpu().numpy(),\n",
    "    back_face_policy=\"identical\",\n",
    "    enabled=False,\n",
    ")\n",
    "\n",
    "\n",
    "# ps_cloud = ps.register_point_cloud(\"active sites\", tet_probs[2].reshape(-1, 3).detach().cpu().numpy(), enabled=False)\n",
    "# ps_cloud.add_vector_quantity(\"site step dir\", tet_probs[0].reshape(-1, 3).detach().cpu().numpy())\n",
    "# ps_vert.add_vector_quantity(\"verts step dir\", tet_probs[1].detach().cpu().numpy())\n",
    "\n",
    "\n",
    "ps.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52c1a4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SITES OPTIMISATION LOOP\n",
    "\n",
    "\n",
    "cvt_loss_values = []\n",
    "min_distance_loss_values = []\n",
    "chamfer_distance_loss_values = []\n",
    "eikonal_loss_values = []\n",
    "domain_restriction_loss_values = []\n",
    "sdf_loss_values = []\n",
    "div_loss_values = []\n",
    "loss_values = []\n",
    "\n",
    "voroloss = lf.Voroloss_opt().to(device)\n",
    "\n",
    "\n",
    "def train_DCCVT(\n",
    "    sites,\n",
    "    sites_sdf,\n",
    "    max_iter=100,\n",
    "    stop_train_threshold=1e-6,\n",
    "    upsampling=0,\n",
    "    lambda_weights=[0.1, 1.0, 0.1, 0.1, 1.0, 1.0, 0.1],\n",
    "    voroloss_optim=False,\n",
    "    Hotspot_model=None,\n",
    "):\n",
    "    if not voroloss_optim:\n",
    "        optimizer = torch.optim.Adam(\n",
    "            [\n",
    "                {\"params\": [sites], \"lr\": lr_sites * 0.1},\n",
    "                {\"params\": [sites_sdf], \"lr\": lr_sites * 0.1},\n",
    "            ],\n",
    "            betas=(0.8, 0.95),\n",
    "        )\n",
    "    else:\n",
    "        optimizer = torch.optim.Adam([{\"params\": [sites], \"lr\": lr_sites * 0.1}])\n",
    "\n",
    "    # scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "    # scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\n",
    "\n",
    "    # optimizer_sites = torch.optim.Adam([{'params': [sites], 'lr': lr_sites}])\n",
    "    # optimizer_sdf = torch.optim.SGD([{'params': [sites_sdf], 'lr': lr_sites}])\n",
    "    # scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[80, 150, 200, 250], gamma=0.5)\n",
    "\n",
    "    prev_loss = float(\"inf\")\n",
    "    best_loss = float(\"inf\")\n",
    "    upsampled = 0.0\n",
    "    epoch = 0\n",
    "    lambda_cvt = lambda_weights[0]\n",
    "    lambda_chamfer = lambda_weights[4]\n",
    "    lambda_shl = lambda_cvt / 10\n",
    "    best_sites = sites.clone()\n",
    "    best_sites.best_loss = best_loss\n",
    "    sites_sdf_grads = None\n",
    "\n",
    "    while epoch <= max_iter:\n",
    "        # if epoch == 990:\n",
    "        #     max_iter += 1000\n",
    "        optimizer.zero_grad()\n",
    "        # if mesh[0] == \"sphere\":\n",
    "        #     # generate sphere sdf\n",
    "        #     sites_sdf = sphere_sdf(sites, torch.zeros(3).to(device), 0.50)\n",
    "\n",
    "        if not voroloss_optim:\n",
    "            sites_np = sites.detach().cpu().numpy()\n",
    "            # d3dsimplices = diffvoronoi.get_delaunay_simplices(sites_np.reshape(input_dims * sites_np.shape[0]))\n",
    "            d3dsimplices, _ = pygdel3d.triangulate(sites_np)\n",
    "\n",
    "            d3dsimplices = np.array(d3dsimplices)\n",
    "\n",
    "            if epoch % 100 == 0 and epoch <= 500:\n",
    "                eps_H = lf.estimate_eps_H(sites, d3dsimplices, multiplier=1.5 * 5).detach()\n",
    "                print(\"Estimated eps_H: \", eps_H)\n",
    "            elif epoch % 100 == 0 and epoch <= 800:\n",
    "                eps_H = lf.estimate_eps_H(sites, d3dsimplices, multiplier=1.5 * 2).detach()\n",
    "                print(\"Estimated eps_H: \", eps_H)\n",
    "\n",
    "            build_mesh = False\n",
    "            clip = True\n",
    "            mtet = False\n",
    "            sites_sdf_grads = None\n",
    "            barycentric_weights = \"robust\"\n",
    "            ups_m = \"tet_frame\"\n",
    "            no_mp = False\n",
    "            video = False\n",
    "\n",
    "            if mtet:\n",
    "                print(\"Using MTET\")\n",
    "                d3dsimplices = torch.tensor(d3dsimplices, device=device)\n",
    "                marching_tetrehedra_mesh = kaolin.ops.conversions.marching_tetrahedra(\n",
    "                    sites.unsqueeze(0), d3dsimplices, sites_sdf.unsqueeze(0), return_tet_idx=False\n",
    "                )\n",
    "                vertices_list, faces_list = marching_tetrehedra_mesh\n",
    "                v_vect = vertices_list[0]\n",
    "                faces = faces_list[0]\n",
    "                print(\"v_vect shape: \", v_vect.shape)\n",
    "\n",
    "            else:\n",
    "                v_vect, faces_or_clippedvert, sites_sdf_grads, tets_sdf_grads, W = su.get_clipped_mesh_numba(\n",
    "                    sites, None, d3dsimplices, clip, sites_sdf, build_mesh, False, barycentric_weights, no_mp\n",
    "                )\n",
    "\n",
    "                # _, bisectors_to_compute, _ = su.compute_zero_crossing_vertices_3d(\n",
    "                #     sites, None, None, d3dsimplices, sites_sdf\n",
    "                # )\n",
    "                # bisectors = su.compute_all_bisectors_vectorized(sites, bisectors_to_compute)\n",
    "                # bisectors_sdf = (sites_sdf[bisectors_to_compute[:, 0]] + sites_sdf[bisectors_to_compute[:, 1]]) / 2\n",
    "                # bisectors_sdf_grad = (\n",
    "                #     sites_sdf_grads[bisectors_to_compute[:, 0]] + sites_sdf_grads[bisectors_to_compute[:, 1]]\n",
    "                # ) / 2\n",
    "                # proj_bisectors = su.newton_step_clipping(bisectors_sdf_grad, bisectors_sdf, bisectors)  # (M,3)\n",
    "\n",
    "            #  v_vect, faces_or_clippedvert = su.cvt_extraction(sites, sites_sdf, d3dsimplices, build_mesh)\n",
    "\n",
    "            if build_mesh:\n",
    "                triangle_faces = [[f[0], f[i], f[i + 1]] for f in faces_or_clippedvert for i in range(1, len(f) - 1)]\n",
    "                triangle_faces = torch.tensor(triangle_faces, device=device)\n",
    "                hs_p = su.sample_mesh_points_heitz(v_vect, triangle_faces, num_samples=mnfld_points.shape[0])\n",
    "                chamfer_loss_mesh, _ = chamfer_distance(mnfld_points.detach(), hs_p.unsqueeze(0))\n",
    "            else:\n",
    "                chamfer_loss_mesh, _ = chamfer_distance(mnfld_points.detach(), v_vect.unsqueeze(0))\n",
    "                # chamfer_loss_proj_bisect, _ = chamfer_distance(mnfld_points.detach(), proj_bisectors.unsqueeze(0))\n",
    "\n",
    "                # chamfer_loss_mesh = 0.9 * chamfer_loss_mesh + 0.1 * chamfer_loss_proj_bisect\n",
    "\n",
    "            if sites_sdf_grads is None:\n",
    "                sites_sdf_grads, tets_sdf_grads, W = su.sdf_space_grad_pytorch_diego_sites_tets(\n",
    "                    sites, sites_sdf, torch.tensor(d3dsimplices).to(device).detach()\n",
    "                )\n",
    "\n",
    "            # do cvt loss on the clipped voronoi vertices positions TODO\n",
    "            # cvt_loss = lf.compute_cvt_loss_vectorized_delaunay(sites, None, d3dsimplices)\n",
    "\n",
    "            # cvt_loss = lf.compute_cvt_loss_true(sites, d3dsimplices, faces_or_clippedvert)\n",
    "\n",
    "            eik_loss = lambda_cvt / 10 * lf.discrete_tet_volume_eikonal_loss(sites, sites_sdf_grads, d3dsimplices)\n",
    "            # shl = lambda_cvt / 0.1 * lf.smoothed_heaviside_loss(sites, sites_sdf, sites_sdf_grads, d3dsimplices)\n",
    "\n",
    "            # eik_loss = lambda_cvt / 1000 * lf.tet_sdf_grad_eikonal_loss(sites, tets_sdf_grads, d3dsimplices)\n",
    "\n",
    "            shl = lambda_cvt / 1 * lf.tet_sdf_motion_mean_curvature_loss(sites, sites_sdf, W, d3dsimplices, eps_H)\n",
    "            # print(\"smoothed_heaviside_loss: \", shl.item())\n",
    "\n",
    "            # sites_eik_loss = lambda_cvt * 0.5 * torch.mean(((sites_sdf_grads**2).sum(dim=1) - 1) ** 2)\n",
    "\n",
    "            sdf_loss = eik_loss + shl  # sites_eik_loss  # +\n",
    "\n",
    "            if not mtet:\n",
    "                cvt_loss = lf.compute_cvt_loss_CLIPPED_vertices(sites, None, None, d3dsimplices, faces_or_clippedvert)\n",
    "            else:\n",
    "                cvt_loss = torch.tensor(0)\n",
    "                eik_loss = torch.tensor(0)\n",
    "                shl = torch.tensor(0)\n",
    "\n",
    "            print(\n",
    "                \"eikonal_loss: \",\n",
    "                eik_loss.item(),\n",
    "                \"cvt_loss: \",\n",
    "                lambda_cvt / 1 * cvt_loss.item(),\n",
    "                \"chamfer_loss_mesh: \",\n",
    "                lambda_chamfer * chamfer_loss_mesh.item(),\n",
    "            )\n",
    "            sites_loss = lambda_cvt / 1 * cvt_loss + lambda_chamfer * chamfer_loss_mesh\n",
    "\n",
    "        else:\n",
    "            sdf_loss = 0\n",
    "            sites_np = sites.detach().cpu().numpy()\n",
    "            # d3dsimplices = diffvoronoi.get_delaunay_simplices(sites_np.reshape(input_dims * sites_np.shape[0]))\n",
    "            d3dsimplices, _ = pygdel3d.triangulate(sites_np)\n",
    "            d3dsimplices = np.array(d3dsimplices)\n",
    "            cvt_loss = lf.compute_cvt_loss_vectorized_delaunay(sites, None, d3dsimplices)\n",
    "\n",
    "            sites_loss = (\n",
    "                lambda_chamfer * voroloss(mnfld_points.squeeze(0), sites).mean()\n",
    "            ) + lambda_cvt / 10000 * cvt_loss\n",
    "\n",
    "        loss = sites_loss + sdf_loss\n",
    "        loss_values.append(loss.item())\n",
    "        print(f\"Epoch {epoch}: loss = {loss.item()}\")\n",
    "\n",
    "        # print(f\"before loss.backward(): Allocated: {torch.cuda.memory_allocated() / 1e6} MB, Reserved: {torch.cuda.memory_reserved() / 1e6} MB\")\n",
    "        loss.backward()\n",
    "        # print(f\"After loss.backward(): Allocated: {torch.cuda.memory_allocated() / 1e6} MB, Reserved: {torch.cuda.memory_reserved() / 1e6} MB\")\n",
    "        print(\"-----------------\")\n",
    "\n",
    "        # torch.nn.utils.clip_grad_norm_(sites_sdf, 1.0)\n",
    "        # torch.nn.utils.clip_grad_norm_(sites, 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        # sites_sdf += (sites_sdf_grads*(sites-sites_positions)).sum(dim=1)\n",
    "\n",
    "        # scheduler.step()\n",
    "        print(\"Learning rate: \", optimizer.param_groups[0][\"lr\"])\n",
    "        # if epoch>100 and (epoch // 100) == upsampled+1 and loss.item() < 0.5 and upsampled < upsampling:\n",
    "\n",
    "        # TODO: test epoch == 300 growthrate 300%\n",
    "        if upsampled < upsampling and epoch / (max_iter * 0.80) > upsampled / upsampling:\n",
    "            print(\"sites length BEFORE UPSAMPLING: \", len(sites))\n",
    "            if len(sites) * 1.09 > grid**3:\n",
    "                print(\"Skipping upsampling, too many sites, sites length: \", len(sites), \"grid size: \", grid**3)\n",
    "                upsampled = upsampling\n",
    "                sites = sites.detach().requires_grad_(True)\n",
    "                sites_sdf = sites_sdf.detach().requires_grad_(True)\n",
    "\n",
    "                optimizer = torch.optim.Adam(\n",
    "                    [\n",
    "                        {\"params\": [sites], \"lr\": lr_sites * 0.1},\n",
    "                        {\"params\": [sites_sdf], \"lr\": lr_sites * 0.1},\n",
    "                    ]\n",
    "                )\n",
    "                eps_H = lf.estimate_eps_H(sites, d3dsimplices, multiplier=1.5 * 3).detach()\n",
    "                print(\"Estimated eps_H: \", eps_H)\n",
    "                # scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.99)\n",
    "                continue\n",
    "            # sites, sites_sdf = su.upsampling_vectorized_sites_sites_sdf(sites, tri=None, vor=None, simplices=d3dsimplices, model=sites_sdf)\n",
    "            # sites, sites_sdf = su.upsampling_curvature_vectorized_sites_sites_sdf(sites, tri=None, vor=None, simplices=d3dsimplices, model=sites_sdf)\n",
    "            if sites_sdf_grads is None or sites_sdf_grads.shape[0] != sites.shape[0]:\n",
    "                sites_sdf_grads, tets_sdf_grads, W = su.sdf_space_grad_pytorch_diego_sites_tets(\n",
    "                    sites, sites_sdf, torch.tensor(d3dsimplices).to(device).detach()\n",
    "                )\n",
    "\n",
    "            sites, sites_sdf = su.upsampling_adaptive_vectorized_sites_sites_sdf(\n",
    "                sites,\n",
    "                simplices=d3dsimplices,\n",
    "                model=sites_sdf,\n",
    "                sites_sdf_grads=sites_sdf_grads,\n",
    "                ups_method=ups_m,\n",
    "                score=\"conservative\",\n",
    "            )\n",
    "            if voroloss_optim:\n",
    "                sites_sdf = Hotspot_model(sites)\n",
    "                sites_sdf = sites_sdf.detach().squeeze(-1).requires_grad_()\n",
    "\n",
    "            # sites, sites_sdf = su.upsampling_chamfer_vectorized_sites_sites_sdf(\n",
    "            #     sites, d3dsimplices, sites_sdf, mnfld_points\n",
    "            # )\n",
    "\n",
    "            sites = sites.detach().requires_grad_(True)\n",
    "            sites_sdf = sites_sdf.detach().requires_grad_(True)\n",
    "\n",
    "            optimizer = torch.optim.Adam(\n",
    "                [\n",
    "                    {\"params\": [sites], \"lr\": lr_sites * 0.1},\n",
    "                    {\"params\": [sites_sdf], \"lr\": lr_sites * 0.1},\n",
    "                ]\n",
    "            )\n",
    "            # scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.98)\n",
    "            eps_H = lf.estimate_eps_H(sites, d3dsimplices, multiplier=1.5 * 5).detach()\n",
    "            print(\"Estimated eps_H: \", eps_H)\n",
    "\n",
    "            upsampled += 1.0\n",
    "            print(\"sites shape AFTER: \", sites.shape)\n",
    "            print(\"sites sdf shape AFTER: \", sites_sdf.shape)\n",
    "\n",
    "        if epoch % (max_iter / 10) == 0 or epoch == max_iter:\n",
    "            # print(f\"Epoch {epoch}: loss = {loss.item()}\")\n",
    "            # print(f\"Best Epoch {best_epoch}: Best loss = {best_loss}\")\n",
    "            # save model and sites\n",
    "            # ps.register_surface_mesh(f\"{epoch} triangle clipped mesh\", v_vect.detach().cpu().numpy(), triangle_faces.detach().cpu().numpy())\n",
    "\n",
    "            # ps.register_point_cloud('sampled points end', hs_p.detach().cpu().numpy())\n",
    "            # ps.register_point_cloud(\"sampled points end\", v_vect.detach().cpu().numpy(), enabled=False)\n",
    "\n",
    "            # if f_vect is not None:\n",
    "            #     ps_mesh = ps.register_surface_mesh(\n",
    "            #         f\"{epoch} sdf clipped pmesh\",\n",
    "            #         v_vect.detach().cpu().numpy(),\n",
    "            #         f_vect,\n",
    "            #         back_face_policy=\"identical\",\n",
    "            #         enabled=False,\n",
    "            #     )\n",
    "            #     ps_mesh.add_vector_quantity(\n",
    "            #         f\"{epoch} sdf verts grads\",\n",
    "            #         sdf_verts_grads.detach().cpu().numpy(),\n",
    "            #         enabled=False,\n",
    "            #     )\n",
    "\n",
    "            site_file_path = (\n",
    "                f\"{destination}{mesh[0]}{max_iter}_{epoch}_3d_sites_{num_centroids}_chamfer{lambda_chamfer}.pth\"\n",
    "            )\n",
    "            # model_file_path = f'{destination}{mesh[0]}{max_iter}_{epoch}_3d_model_{num_centroids}_chamfer{lambda_chamfer}.pth'\n",
    "            sdf_file_path = (\n",
    "                f\"{destination}{mesh[0]}{max_iter}_{epoch}_3d_sdf_{num_centroids}_chamfer{lambda_chamfer}.pth\"\n",
    "            )\n",
    "            torch.save(sites_sdf, sdf_file_path)\n",
    "            torch.save(sites, site_file_path)\n",
    "\n",
    "        if video:\n",
    "            v_vect, f_vect = su.cvt_extraction(sites, sites_sdf, d3dsimplices, True)\n",
    "            su.save_obj(f\"{destination}{int(epoch)}.obj\", v_vect.detach().cpu().numpy(), f_vect)\n",
    "        epoch += 1\n",
    "\n",
    "    return sites, sites_sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "447548a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lambda_weights = [252,0,0,0,10.211111,0,100,0]\n",
    "# lambda_weights = [500,0,0,0,1000,0,100,0]\n",
    "lambda_weights = [100, 0, 0, 0, 1000, 0, 100, 0]\n",
    "\n",
    "\n",
    "lambda_cvt = lambda_weights[0]\n",
    "lambda_sdf = lambda_weights[1]\n",
    "lambda_min_distance = lambda_weights[2]\n",
    "lambda_laplace = lambda_weights[3]\n",
    "lambda_chamfer = lambda_weights[4]\n",
    "lambda_eikonal = lambda_weights[5]\n",
    "lambda_domain_restriction = lambda_weights[6]\n",
    "lambda_true_points = lambda_weights[7]\n",
    "\n",
    "max_iter = 1000\n",
    "voroloss_optim = False\n",
    "ups = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ccb5e968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated eps_H:  tensor(1.1722, device='cuda:0')\n",
      "eikonal_loss:  41.670284271240234 cvt_loss:  4.391663148999214 chamfer_loss_mesh:  40.45405611395836\n",
      "Epoch 0: loss = 86.53157043457031\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  46.544227600097656 cvt_loss:  4.452082887291908 chamfer_loss_mesh:  40.41123017668724\n",
      "Epoch 1: loss = 91.4231185913086\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "sites length BEFORE UPSAMPLING:  4096\n",
      "Sampled indices: 272 out of 446 candidates (M=409)\n",
      "Estimated eps_H:  tensor(1.1700, device='cuda:0')\n",
      "sites shape AFTER:  torch.Size([5184, 3])\n",
      "sites sdf shape AFTER:  torch.Size([5184])\n",
      "eikonal_loss:  62.32187271118164 cvt_loss:  3.8290705531835556 chamfer_loss_mesh:  41.825003921985626\n",
      "Epoch 2: loss = 107.98809051513672\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  49.727638244628906 cvt_loss:  3.758886456489563 chamfer_loss_mesh:  41.17835313081741\n",
      "Epoch 3: loss = 94.67709350585938\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  34.2254753112793 cvt_loss:  3.7412725389003754 chamfer_loss_mesh:  40.61619192361832\n",
      "Epoch 4: loss = 78.59518432617188\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  70.94585418701172 cvt_loss:  3.695658966898918 chamfer_loss_mesh:  39.833731949329376\n",
      "Epoch 5: loss = 114.48736572265625\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  87.2030029296875 cvt_loss:  3.6092519760131836 chamfer_loss_mesh:  39.444997906684875\n",
      "Epoch 6: loss = 130.2694091796875\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  82.2547607421875 cvt_loss:  3.606504201889038 chamfer_loss_mesh:  38.89063000679016\n",
      "Epoch 7: loss = 124.76398468017578\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  81.75421142578125 cvt_loss:  3.567986935377121 chamfer_loss_mesh:  38.42142969369888\n",
      "Epoch 8: loss = 123.75572204589844\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  78.83528900146484 cvt_loss:  3.486435115337372 chamfer_loss_mesh:  37.678733468055725\n",
      "Epoch 9: loss = 120.01252746582031\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  70.09196472167969 cvt_loss:  3.4932903945446014 chamfer_loss_mesh:  37.23614662885666\n",
      "Epoch 10: loss = 110.83348083496094\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  66.44236755371094 cvt_loss:  3.436587378382683 chamfer_loss_mesh:  36.965563893318176\n",
      "Epoch 11: loss = 106.85655212402344\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  56.19419479370117 cvt_loss:  3.4175321459770203 chamfer_loss_mesh:  36.26709431409836\n",
      "Epoch 12: loss = 95.89087677001953\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  39.23583221435547 cvt_loss:  3.414440155029297 chamfer_loss_mesh:  35.80136597156525\n",
      "Epoch 13: loss = 78.46365356445312\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  50.3138313293457 cvt_loss:  3.3657964318990707 chamfer_loss_mesh:  35.24285554885864\n",
      "Epoch 14: loss = 88.93450927734375\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  40.385498046875 cvt_loss:  3.333153575658798 chamfer_loss_mesh:  34.67319905757904\n",
      "Epoch 15: loss = 78.40400695800781\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  48.786460876464844 cvt_loss:  3.247959166765213 chamfer_loss_mesh:  33.83147716522217\n",
      "Epoch 16: loss = 85.87799072265625\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  44.72322463989258 cvt_loss:  3.2258108258247375 chamfer_loss_mesh:  33.35639834403992\n",
      "Epoch 17: loss = 81.31755828857422\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  40.2680778503418 cvt_loss:  3.2007932662963867 chamfer_loss_mesh:  32.82769024372101\n",
      "Epoch 18: loss = 76.30867004394531\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  37.25482177734375 cvt_loss:  3.1809519976377487 chamfer_loss_mesh:  32.08377584815025\n",
      "Epoch 19: loss = 72.53175354003906\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  35.06069564819336 cvt_loss:  3.180808946490288 chamfer_loss_mesh:  31.62563592195511\n",
      "Epoch 20: loss = 69.87926483154297\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  32.15534210205078 cvt_loss:  3.1478356570005417 chamfer_loss_mesh:  31.495675444602966\n",
      "Epoch 21: loss = 66.81098175048828\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  29.211502075195312 cvt_loss:  3.15963476896286 chamfer_loss_mesh:  30.97504749894142\n",
      "Epoch 22: loss = 63.358306884765625\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  26.7117977142334 cvt_loss:  3.1195102259516716 chamfer_loss_mesh:  30.296048149466515\n",
      "Epoch 23: loss = 60.13957977294922\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  25.133256912231445 cvt_loss:  3.128039836883545 chamfer_loss_mesh:  29.812652617692947\n",
      "Epoch 24: loss = 58.086143493652344\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  24.390714645385742 cvt_loss:  3.113221563398838 chamfer_loss_mesh:  29.519371688365936\n",
      "Epoch 25: loss = 57.035552978515625\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  23.16307830810547 cvt_loss:  3.0906064435839653 chamfer_loss_mesh:  29.28517758846283\n",
      "Epoch 26: loss = 55.55112838745117\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  22.106172561645508 cvt_loss:  3.042275458574295 chamfer_loss_mesh:  28.8320891559124\n",
      "Epoch 27: loss = 53.992767333984375\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  21.043319702148438 cvt_loss:  3.004186600446701 chamfer_loss_mesh:  28.53706106543541\n",
      "Epoch 28: loss = 52.59680938720703\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  20.502342224121094 cvt_loss:  2.963472343981266 chamfer_loss_mesh:  28.016075491905212\n",
      "Epoch 29: loss = 51.494144439697266\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  20.299602508544922 cvt_loss:  2.9373539611697197 chamfer_loss_mesh:  27.68835611641407\n",
      "Epoch 30: loss = 50.9376335144043\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  19.538677215576172 cvt_loss:  2.8878170996904373 chamfer_loss_mesh:  27.631063014268875\n",
      "Epoch 31: loss = 50.06991195678711\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  18.82479476928711 cvt_loss:  2.8479820117354393 chamfer_loss_mesh:  27.332521975040436\n",
      "Epoch 32: loss = 49.01766586303711\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  18.508588790893555 cvt_loss:  2.843734435737133 chamfer_loss_mesh:  26.896927505731583\n",
      "Epoch 33: loss = 48.261592864990234\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  17.060659408569336 cvt_loss:  2.820225805044174 chamfer_loss_mesh:  26.439448818564415\n",
      "Epoch 34: loss = 46.33260726928711\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  20.62408447265625 cvt_loss:  2.8096767142415047 chamfer_loss_mesh:  26.119060814380646\n",
      "Epoch 35: loss = 49.56520462036133\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  19.790876388549805 cvt_loss:  2.7767740190029144 chamfer_loss_mesh:  25.99325031042099\n",
      "Epoch 36: loss = 48.57329559326172\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  19.53244400024414 cvt_loss:  2.7646709233522415 chamfer_loss_mesh:  25.63612535595894\n",
      "Epoch 37: loss = 47.94566345214844\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  18.815296173095703 cvt_loss:  2.750599756836891 chamfer_loss_mesh:  25.346342474222183\n",
      "Epoch 38: loss = 46.92462921142578\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  18.11184310913086 cvt_loss:  2.752278745174408 chamfer_loss_mesh:  25.007054209709167\n",
      "Epoch 39: loss = 45.883567810058594\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  18.011260986328125 cvt_loss:  2.724757418036461 chamfer_loss_mesh:  24.738697335124016\n",
      "Epoch 40: loss = 45.48713684082031\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  17.970680236816406 cvt_loss:  2.765175513923168 chamfer_loss_mesh:  24.631477892398834\n",
      "Epoch 41: loss = 45.37977981567383\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  17.397666931152344 cvt_loss:  2.7624130249023438 chamfer_loss_mesh:  24.51535128057003\n",
      "Epoch 42: loss = 44.687904357910156\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  16.522647857666016 cvt_loss:  2.7244964614510536 chamfer_loss_mesh:  24.13817122578621\n",
      "Epoch 43: loss = 43.39777374267578\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  15.968718528747559 cvt_loss:  2.7276141569018364 chamfer_loss_mesh:  23.911524564027786\n",
      "Epoch 44: loss = 42.62034606933594\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  15.917254447937012 cvt_loss:  2.7247732505202293 chamfer_loss_mesh:  23.56826141476631\n",
      "Epoch 45: loss = 42.22283172607422\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  16.36021614074707 cvt_loss:  2.715545892715454 chamfer_loss_mesh:  23.444773629307747\n",
      "Epoch 46: loss = 42.533164978027344\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  17.299762725830078 cvt_loss:  2.7156099677085876 chamfer_loss_mesh:  23.256856948137283\n",
      "Epoch 47: loss = 43.28492736816406\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  12.606362342834473 cvt_loss:  2.7096619829535484 chamfer_loss_mesh:  23.102670907974243\n",
      "Epoch 48: loss = 38.431251525878906\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  13.161697387695312 cvt_loss:  2.7254128828644753 chamfer_loss_mesh:  22.893225774168968\n",
      "Epoch 49: loss = 38.79290008544922\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  12.104262351989746 cvt_loss:  2.7225352823734283 chamfer_loss_mesh:  22.57467806339264\n",
      "Epoch 50: loss = 37.4140625\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  12.252598762512207 cvt_loss:  2.6912981644272804 chamfer_loss_mesh:  22.336777299642563\n",
      "Epoch 51: loss = 37.293277740478516\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  12.480053901672363 cvt_loss:  2.6735106483101845 chamfer_loss_mesh:  21.882575005292892\n",
      "Epoch 52: loss = 37.04877853393555\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  23.58892059326172 cvt_loss:  2.6525361463427544 chamfer_loss_mesh:  21.533172577619553\n",
      "Epoch 53: loss = 47.78730392456055\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  19.709152221679688 cvt_loss:  2.6371337473392487 chamfer_loss_mesh:  21.265750750899315\n",
      "Epoch 54: loss = 43.624755859375\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  19.37160873413086 cvt_loss:  2.628360502421856 chamfer_loss_mesh:  21.050838753581047\n",
      "Epoch 55: loss = 43.06353759765625\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  17.346994400024414 cvt_loss:  2.6111768558621407 chamfer_loss_mesh:  20.915161818265915\n",
      "Epoch 56: loss = 40.88603210449219\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  20.10369300842285 cvt_loss:  2.5801172479987144 chamfer_loss_mesh:  20.674940198659897\n",
      "Epoch 57: loss = 43.37147903442383\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  19.72648811340332 cvt_loss:  2.571207471191883 chamfer_loss_mesh:  20.50725743174553\n",
      "Epoch 58: loss = 42.81771469116211\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  18.85858154296875 cvt_loss:  2.5560956448316574 chamfer_loss_mesh:  20.240547135472298\n",
      "Epoch 59: loss = 41.66801071166992\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  18.458147048950195 cvt_loss:  2.5355273857712746 chamfer_loss_mesh:  20.09957656264305\n",
      "Epoch 60: loss = 41.10602951049805\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  17.196088790893555 cvt_loss:  2.510399930179119 chamfer_loss_mesh:  20.042555406689644\n",
      "Epoch 61: loss = 39.76180648803711\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  15.756258010864258 cvt_loss:  2.503105439245701 chamfer_loss_mesh:  20.10190486907959\n",
      "Epoch 62: loss = 38.374046325683594\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  14.471163749694824 cvt_loss:  2.499418891966343 chamfer_loss_mesh:  19.904406741261482\n",
      "Epoch 63: loss = 36.887786865234375\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  13.40107536315918 cvt_loss:  2.489386685192585 chamfer_loss_mesh:  19.715068861842155\n",
      "Epoch 64: loss = 35.618370056152344\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  12.90621280670166 cvt_loss:  2.48055849224329 chamfer_loss_mesh:  19.590025767683983\n",
      "Epoch 65: loss = 34.98967742919922\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  13.367213249206543 cvt_loss:  2.456314116716385 chamfer_loss_mesh:  19.296351820230484\n",
      "Epoch 66: loss = 35.13277053833008\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  23.582592010498047 cvt_loss:  2.4559063836932182 chamfer_loss_mesh:  19.038939848542213\n",
      "Epoch 67: loss = 45.09032440185547\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  35.70103073120117 cvt_loss:  2.476941794157028 chamfer_loss_mesh:  18.75467039644718\n",
      "Epoch 68: loss = 56.945552825927734\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  20.86225700378418 cvt_loss:  2.4875376373529434 chamfer_loss_mesh:  18.649283796548843\n",
      "Epoch 69: loss = 42.011993408203125\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  19.78390884399414 cvt_loss:  2.4795938283205032 chamfer_loss_mesh:  18.56677606701851\n",
      "Epoch 70: loss = 40.84318161010742\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  18.691913604736328 cvt_loss:  2.4688178673386574 chamfer_loss_mesh:  18.32774467766285\n",
      "Epoch 71: loss = 39.501365661621094\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  14.505510330200195 cvt_loss:  2.468598261475563 chamfer_loss_mesh:  18.099118024110794\n",
      "Epoch 72: loss = 35.08613586425781\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  12.514570236206055 cvt_loss:  2.452905848622322 chamfer_loss_mesh:  17.92595162987709\n",
      "Epoch 73: loss = 32.9063720703125\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  11.968274116516113 cvt_loss:  2.45048850774765 chamfer_loss_mesh:  17.81938411295414\n",
      "Epoch 74: loss = 32.25111770629883\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  12.27218246459961 cvt_loss:  2.4433474987745285 chamfer_loss_mesh:  17.733534798026085\n",
      "Epoch 75: loss = 32.46204376220703\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  10.762633323669434 cvt_loss:  2.4334168061614037 chamfer_loss_mesh:  17.57054403424263\n",
      "Epoch 76: loss = 30.779537200927734\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  10.700249671936035 cvt_loss:  2.4071356281638145 chamfer_loss_mesh:  17.38223060965538\n",
      "Epoch 77: loss = 30.502559661865234\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  10.64409065246582 cvt_loss:  2.384396269917488 chamfer_loss_mesh:  17.238639295101166\n",
      "Epoch 78: loss = 30.280078887939453\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  10.381505966186523 cvt_loss:  2.3784490302205086 chamfer_loss_mesh:  17.214156687259674\n",
      "Epoch 79: loss = 29.987071990966797\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  10.206624984741211 cvt_loss:  2.3898033425211906 chamfer_loss_mesh:  17.023488879203796\n",
      "Epoch 80: loss = 29.632888793945312\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  10.08598804473877 cvt_loss:  2.3887746036052704 chamfer_loss_mesh:  16.801372170448303\n",
      "Epoch 81: loss = 29.289081573486328\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "sites length BEFORE UPSAMPLING:  5184\n",
      "Sampled indices: 402 out of 966 candidates (M=518)\n",
      "Estimated eps_H:  tensor(1.0019, device='cuda:0')\n",
      "sites shape AFTER:  torch.Size([6792, 3])\n",
      "sites sdf shape AFTER:  torch.Size([6792])\n",
      "eikonal_loss:  7.5652971267700195 cvt_loss:  2.2531116381287575 chamfer_loss_mesh:  16.155146062374115\n",
      "Epoch 82: loss = 25.983169555664062\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  7.0714921951293945 cvt_loss:  2.2352127358317375 chamfer_loss_mesh:  15.782956033945084\n",
      "Epoch 83: loss = 25.099266052246094\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  9.52580451965332 cvt_loss:  2.2150762379169464 chamfer_loss_mesh:  15.478918328881264\n",
      "Epoch 84: loss = 27.229400634765625\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  8.621846199035645 cvt_loss:  2.187192440032959 chamfer_loss_mesh:  15.387153252959251\n",
      "Epoch 85: loss = 26.20587158203125\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  7.25206184387207 cvt_loss:  2.155357040464878 chamfer_loss_mesh:  15.143957920372486\n",
      "Epoch 86: loss = 24.561019897460938\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  7.743432521820068 cvt_loss:  2.1513834595680237 chamfer_loss_mesh:  14.98015969991684\n",
      "Epoch 87: loss = 24.884607315063477\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  7.08587646484375 cvt_loss:  2.147163264453411 chamfer_loss_mesh:  14.731204137206078\n",
      "Epoch 88: loss = 23.973894119262695\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  9.399151802062988 cvt_loss:  2.1393144503235817 chamfer_loss_mesh:  14.622800052165985\n",
      "Epoch 89: loss = 26.17093276977539\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  8.948766708374023 cvt_loss:  2.130337804555893 chamfer_loss_mesh:  14.43476788699627\n",
      "Epoch 90: loss = 25.52349853515625\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  6.580708026885986 cvt_loss:  2.1312007680535316 chamfer_loss_mesh:  14.318104833364487\n",
      "Epoch 91: loss = 23.039642333984375\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  6.4972662925720215 cvt_loss:  2.1123046055436134 chamfer_loss_mesh:  14.1926109790802\n",
      "Epoch 92: loss = 22.81182098388672\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  6.401014804840088 cvt_loss:  2.106867730617523 chamfer_loss_mesh:  14.056581072509289\n",
      "Epoch 93: loss = 22.57407569885254\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  7.51063346862793 cvt_loss:  2.1080773323774338 chamfer_loss_mesh:  13.925698585808277\n",
      "Epoch 94: loss = 23.554004669189453\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  7.508911609649658 cvt_loss:  2.0996009930968285 chamfer_loss_mesh:  13.732794672250748\n",
      "Epoch 95: loss = 23.35088348388672\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  7.342333793640137 cvt_loss:  2.0870011299848557 chamfer_loss_mesh:  13.492440804839134\n",
      "Epoch 96: loss = 22.931352615356445\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  4.9921159744262695 cvt_loss:  2.0744258537888527 chamfer_loss_mesh:  13.22830282151699\n",
      "Epoch 97: loss = 20.304410934448242\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  6.078525066375732 cvt_loss:  2.066824585199356 chamfer_loss_mesh:  13.03753536194563\n",
      "Epoch 98: loss = 21.192440032958984\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  6.4850945472717285 cvt_loss:  2.053770236670971 chamfer_loss_mesh:  12.897830456495285\n",
      "Epoch 99: loss = 21.446285247802734\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "Estimated eps_H:  tensor(0.8415, device='cuda:0')\n",
      "eikonal_loss:  5.660582542419434 cvt_loss:  2.030697464942932 chamfer_loss_mesh:  12.828480452299118\n",
      "Epoch 100: loss = 20.52899169921875\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  5.506725788116455 cvt_loss:  2.024146355688572 chamfer_loss_mesh:  12.621909379959106\n",
      "Epoch 101: loss = 20.162015914916992\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  5.792572498321533 cvt_loss:  2.0036494359374046 chamfer_loss_mesh:  12.436446733772755\n",
      "Epoch 102: loss = 20.24189567565918\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  5.594209671020508 cvt_loss:  1.984461396932602 chamfer_loss_mesh:  12.309041805565357\n",
      "Epoch 103: loss = 19.896940231323242\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  5.389566898345947 cvt_loss:  1.9842388108372688 chamfer_loss_mesh:  12.155577540397644\n",
      "Epoch 104: loss = 19.538616180419922\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  3.9118492603302 cvt_loss:  1.9942527636885643 chamfer_loss_mesh:  12.077216990292072\n",
      "Epoch 105: loss = 17.99254608154297\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  3.6490800380706787 cvt_loss:  2.0041950047016144 chamfer_loss_mesh:  11.892765760421753\n",
      "Epoch 106: loss = 17.555286407470703\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  3.418689250946045 cvt_loss:  1.9926318898797035 chamfer_loss_mesh:  11.785169132053852\n",
      "Epoch 107: loss = 17.205730438232422\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  3.162647247314453 cvt_loss:  1.9769083708524704 chamfer_loss_mesh:  11.65895164012909\n",
      "Epoch 108: loss = 16.807758331298828\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  3.1476845741271973 cvt_loss:  1.9702296704053879 chamfer_loss_mesh:  11.58448401838541\n",
      "Epoch 109: loss = 16.71166229248047\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  2.9996824264526367 cvt_loss:  2.0006807520985603 chamfer_loss_mesh:  11.46266795694828\n",
      "Epoch 110: loss = 16.472299575805664\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  2.9231879711151123 cvt_loss:  1.993756927549839 chamfer_loss_mesh:  11.280759237706661\n",
      "Epoch 111: loss = 16.206974029541016\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  2.9740796089172363 cvt_loss:  1.9950365647673607 chamfer_loss_mesh:  11.16111222654581\n",
      "Epoch 112: loss = 16.13949203491211\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  2.8341710567474365 cvt_loss:  1.9733551889657974 chamfer_loss_mesh:  11.060504242777824\n",
      "Epoch 113: loss = 15.877304077148438\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  2.7223663330078125 cvt_loss:  1.981884054839611 chamfer_loss_mesh:  10.960627347230911\n",
      "Epoch 114: loss = 15.674160957336426\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  2.6182451248168945 cvt_loss:  1.9670426845550537 chamfer_loss_mesh:  10.806567966938019\n",
      "Epoch 115: loss = 15.401150703430176\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  2.5244665145874023 cvt_loss:  1.9588584080338478 chamfer_loss_mesh:  10.71866974234581\n",
      "Epoch 116: loss = 15.211292266845703\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  2.4894466400146484 cvt_loss:  1.9352264702320099 chamfer_loss_mesh:  10.599412955343723\n",
      "Epoch 117: loss = 15.033384323120117\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  2.4017772674560547 cvt_loss:  1.9288448616862297 chamfer_loss_mesh:  10.480365715920925\n",
      "Epoch 118: loss = 14.820289611816406\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  2.3109374046325684 cvt_loss:  1.9339745864272118 chamfer_loss_mesh:  10.354501195251942\n",
      "Epoch 119: loss = 14.608720779418945\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  2.31182861328125 cvt_loss:  1.9509198144078255 chamfer_loss_mesh:  10.26745792478323\n",
      "Epoch 120: loss = 14.539528846740723\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  2.237913131713867 cvt_loss:  1.9362147897481918 chamfer_loss_mesh:  10.122622363269329\n",
      "Epoch 121: loss = 14.306097030639648\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  2.274338722229004 cvt_loss:  1.9149567931890488 chamfer_loss_mesh:  10.036313906311989\n",
      "Epoch 122: loss = 14.234966278076172\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  2.2170910835266113 cvt_loss:  1.8977969884872437 chamfer_loss_mesh:  9.953944012522697\n",
      "Epoch 123: loss = 14.078179359436035\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  2.6296920776367188 cvt_loss:  1.908523216843605 chamfer_loss_mesh:  9.837066754698753\n",
      "Epoch 124: loss = 14.384613990783691\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  2.7090253829956055 cvt_loss:  1.9079305231571198 chamfer_loss_mesh:  9.752176702022552\n",
      "Epoch 125: loss = 14.378463745117188\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  2.8788983821868896 cvt_loss:  1.8922539427876472 chamfer_loss_mesh:  9.65434592217207\n",
      "Epoch 126: loss = 14.434849739074707\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  2.713186502456665 cvt_loss:  1.8765661865472794 chamfer_loss_mesh:  9.589813649654388\n",
      "Epoch 127: loss = 14.18891716003418\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  2.6839182376861572 cvt_loss:  1.8884086981415749 chamfer_loss_mesh:  9.664167650043964\n",
      "Epoch 128: loss = 14.245853424072266\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  4.127752780914307 cvt_loss:  1.8855024129152298 chamfer_loss_mesh:  9.518384002149105\n",
      "Epoch 129: loss = 15.541000366210938\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  3.8510384559631348 cvt_loss:  1.8676381558179855 chamfer_loss_mesh:  9.285605512559414\n",
      "Epoch 130: loss = 15.013664245605469\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  2.0326666831970215 cvt_loss:  1.866246573626995 chamfer_loss_mesh:  9.214786812663078\n",
      "Epoch 131: loss = 13.123088836669922\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  1.6947977542877197 cvt_loss:  1.8559183925390244 chamfer_loss_mesh:  9.141631424427032\n",
      "Epoch 132: loss = 12.701735496520996\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  1.6771013736724854 cvt_loss:  1.8459128215909004 chamfer_loss_mesh:  8.991392329335213\n",
      "Epoch 133: loss = 12.523797988891602\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  1.6770637035369873 cvt_loss:  1.8295984715223312 chamfer_loss_mesh:  8.889085613191128\n",
      "Epoch 134: loss = 12.405145645141602\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  1.6148738861083984 cvt_loss:  1.822500117123127 chamfer_loss_mesh:  8.804931305348873\n",
      "Epoch 135: loss = 12.251690864562988\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  1.1673909425735474 cvt_loss:  1.817086711525917 chamfer_loss_mesh:  8.701622486114502\n",
      "Epoch 136: loss = 11.695490837097168\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  1.1287546157836914 cvt_loss:  1.8138885498046875 chamfer_loss_mesh:  8.576793596148491\n",
      "Epoch 137: loss = 11.528838157653809\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  1.101833701133728 cvt_loss:  1.8120169639587402 chamfer_loss_mesh:  8.427025750279427\n",
      "Epoch 138: loss = 11.350281715393066\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  1.0770959854125977 cvt_loss:  1.7963070422410965 chamfer_loss_mesh:  8.423153311014175\n",
      "Epoch 139: loss = 11.305950164794922\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  1.0579060316085815 cvt_loss:  1.7992597073316574 chamfer_loss_mesh:  8.36552307009697\n",
      "Epoch 140: loss = 11.23209285736084\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  1.0361837148666382 cvt_loss:  1.78922601044178 chamfer_loss_mesh:  8.269410580396652\n",
      "Epoch 141: loss = 11.104232788085938\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  1.0291810035705566 cvt_loss:  1.7709625884890556 chamfer_loss_mesh:  8.18900391459465\n",
      "Epoch 142: loss = 10.998567581176758\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  1.0254783630371094 cvt_loss:  1.774097979068756 chamfer_loss_mesh:  8.146478794515133\n",
      "Epoch 143: loss = 10.955482482910156\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.9996367692947388 cvt_loss:  1.766008883714676 chamfer_loss_mesh:  8.115125820040703\n",
      "Epoch 144: loss = 10.8902006149292\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.9874864816665649 cvt_loss:  1.7668357118964195 chamfer_loss_mesh:  7.9902419820427895\n",
      "Epoch 145: loss = 10.753994941711426\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.9696018099784851 cvt_loss:  1.749887503683567 chamfer_loss_mesh:  7.8986696898937225\n",
      "Epoch 146: loss = 10.627595901489258\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.9506866931915283 cvt_loss:  1.753024198114872 chamfer_loss_mesh:  7.812639698386192\n",
      "Epoch 147: loss = 10.525789260864258\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.9370136260986328 cvt_loss:  1.7421938478946686 chamfer_loss_mesh:  7.740221451967955\n",
      "Epoch 148: loss = 10.428871154785156\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.9175234436988831 cvt_loss:  1.7426621168851852 chamfer_loss_mesh:  7.675150875002146\n",
      "Epoch 149: loss = 10.344788551330566\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.9061512351036072 cvt_loss:  1.730651594698429 chamfer_loss_mesh:  7.5822374783456326\n",
      "Epoch 150: loss = 10.228500366210938\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.8931040167808533 cvt_loss:  1.723526231944561 chamfer_loss_mesh:  7.490276359021664\n",
      "Epoch 151: loss = 10.116377830505371\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.8833193778991699 cvt_loss:  1.7100794240832329 chamfer_loss_mesh:  7.358528673648834\n",
      "Epoch 152: loss = 9.961409568786621\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.8791929483413696 cvt_loss:  1.693549007177353 chamfer_loss_mesh:  7.538983598351479\n",
      "Epoch 153: loss = 10.121210098266602\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.8689389228820801 cvt_loss:  1.6929036006331444 chamfer_loss_mesh:  7.4982247315347195\n",
      "Epoch 154: loss = 10.069568634033203\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.865187406539917 cvt_loss:  1.6835153102874756 chamfer_loss_mesh:  7.202807813882828\n",
      "Epoch 155: loss = 9.761022567749023\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.8474640846252441 cvt_loss:  1.6798978671431541 chamfer_loss_mesh:  7.127199321985245\n",
      "Epoch 156: loss = 9.664077758789062\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.8308607339859009 cvt_loss:  1.6781290993094444 chamfer_loss_mesh:  7.079595699906349\n",
      "Epoch 157: loss = 9.598114013671875\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.8235899209976196 cvt_loss:  1.6846541315317154 chamfer_loss_mesh:  7.02137453481555\n",
      "Epoch 158: loss = 9.539161682128906\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.8126081228256226 cvt_loss:  1.680305041372776 chamfer_loss_mesh:  6.952519062906504\n",
      "Epoch 159: loss = 9.454978942871094\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.7971057891845703 cvt_loss:  1.6693681478500366 chamfer_loss_mesh:  6.926367990672588\n",
      "Epoch 160: loss = 9.402392387390137\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.7877930998802185 cvt_loss:  1.6613569110631943 chamfer_loss_mesh:  6.860037799924612\n",
      "Epoch 161: loss = 9.318748474121094\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "sites length BEFORE UPSAMPLING:  6792\n",
      "Sampled indices: 555 out of 1762 candidates (M=679)\n",
      "Estimated eps_H:  tensor(0.8268, device='cuda:0')\n",
      "sites shape AFTER:  torch.Size([9012, 3])\n",
      "sites sdf shape AFTER:  torch.Size([9012])\n",
      "eikonal_loss:  0.5967692136764526 cvt_loss:  1.572149246931076 chamfer_loss_mesh:  6.4534395933151245\n",
      "Epoch 162: loss = 8.629401206970215\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.8565381169319153 cvt_loss:  1.5633175149559975 chamfer_loss_mesh:  6.339055486023426\n",
      "Epoch 163: loss = 8.765947341918945\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  1.6655927896499634 cvt_loss:  1.5456809662282467 chamfer_loss_mesh:  6.242504343390465\n",
      "Epoch 164: loss = 9.4608154296875\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  1.9087309837341309 cvt_loss:  1.52255455031991 chamfer_loss_mesh:  6.185481324791908\n",
      "Epoch 165: loss = 9.623804092407227\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  1.2987034320831299 cvt_loss:  1.521841622889042 chamfer_loss_mesh:  6.132719572633505\n",
      "Epoch 166: loss = 8.960309982299805\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  1.0655739307403564 cvt_loss:  1.4991708099842072 chamfer_loss_mesh:  6.059770006686449\n",
      "Epoch 167: loss = 8.631550788879395\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  1.0655310153961182 cvt_loss:  1.47965457290411 chamfer_loss_mesh:  6.089539732784033\n",
      "Epoch 168: loss = 8.641758918762207\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  1.1297701597213745 cvt_loss:  1.4795506373047829 chamfer_loss_mesh:  5.9836916625499725\n",
      "Epoch 169: loss = 8.600028038024902\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  1.0866339206695557 cvt_loss:  1.4578037895262241 chamfer_loss_mesh:  6.014089100062847\n",
      "Epoch 170: loss = 8.56553840637207\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  1.3633061647415161 cvt_loss:  1.456130761653185 chamfer_loss_mesh:  5.78228197991848\n",
      "Epoch 171: loss = 8.608731269836426\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  1.0742701292037964 cvt_loss:  1.44593957811594 chamfer_loss_mesh:  5.72411622852087\n",
      "Epoch 172: loss = 8.251346588134766\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  1.0366824865341187 cvt_loss:  1.4444860629737377 chamfer_loss_mesh:  5.660228431224823\n",
      "Epoch 173: loss = 8.148425102233887\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.9455162286758423 cvt_loss:  1.4313126914203167 chamfer_loss_mesh:  5.605651997029781\n",
      "Epoch 174: loss = 7.989506244659424\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.9084281921386719 cvt_loss:  1.4258737675845623 chamfer_loss_mesh:  5.521280225366354\n",
      "Epoch 175: loss = 7.862598419189453\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.8761327266693115 cvt_loss:  1.4210589230060577 chamfer_loss_mesh:  5.5309622548520565\n",
      "Epoch 176: loss = 7.835171222686768\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  1.494759440422058 cvt_loss:  1.4125925488770008 chamfer_loss_mesh:  5.596508271992207\n",
      "Epoch 177: loss = 8.51088809967041\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  1.3863645792007446 cvt_loss:  1.4150256291031837 chamfer_loss_mesh:  5.54540054872632\n",
      "Epoch 178: loss = 8.35382080078125\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  1.3047091960906982 cvt_loss:  1.40181016176939 chamfer_loss_mesh:  5.274670198559761\n",
      "Epoch 179: loss = 7.988225936889648\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  1.2846956253051758 cvt_loss:  1.400843821465969 chamfer_loss_mesh:  5.239440593868494\n",
      "Epoch 180: loss = 7.932015895843506\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  2.0595219135284424 cvt_loss:  1.397074293345213 chamfer_loss_mesh:  5.183096509426832\n",
      "Epoch 181: loss = 8.646735191345215\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  1.2394777536392212 cvt_loss:  1.3864417560398579 chamfer_loss_mesh:  5.137613974511623\n",
      "Epoch 182: loss = 7.770571708679199\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  1.2230278253555298 cvt_loss:  1.3854071497917175 chamfer_loss_mesh:  5.0798095762729645\n",
      "Epoch 183: loss = 7.695279121398926\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.7114778757095337 cvt_loss:  1.3714717701077461 chamfer_loss_mesh:  5.027150735259056\n",
      "Epoch 184: loss = 7.117122173309326\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.7446580529212952 cvt_loss:  1.3595580123364925 chamfer_loss_mesh:  4.927252884954214\n",
      "Epoch 185: loss = 7.038495063781738\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.7491061091423035 cvt_loss:  1.34904021397233 chamfer_loss_mesh:  4.875334445387125\n",
      "Epoch 186: loss = 6.980517387390137\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.44934603571891785 cvt_loss:  1.3495824299752712 chamfer_loss_mesh:  4.824865143746138\n",
      "Epoch 187: loss = 6.630830764770508\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.4339834749698639 cvt_loss:  1.3334796763956547 chamfer_loss_mesh:  4.773720167577267\n",
      "Epoch 188: loss = 6.548222064971924\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.4198494255542755 cvt_loss:  1.3262536376714706 chamfer_loss_mesh:  4.773017950356007\n",
      "Epoch 189: loss = 6.526162147521973\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.41084879636764526 cvt_loss:  1.3161074370145798 chamfer_loss_mesh:  4.704748280346394\n",
      "Epoch 190: loss = 6.438747406005859\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.5263549089431763 cvt_loss:  1.310777384787798 chamfer_loss_mesh:  4.679032601416111\n",
      "Epoch 191: loss = 6.52321195602417\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.5109237432479858 cvt_loss:  1.3127153739333153 chamfer_loss_mesh:  4.691012669354677\n",
      "Epoch 192: loss = 6.521700382232666\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.5034449100494385 cvt_loss:  1.298398058861494 chamfer_loss_mesh:  4.646257497370243\n",
      "Epoch 193: loss = 6.455166816711426\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.5174832940101624 cvt_loss:  1.2929720804095268 chamfer_loss_mesh:  4.607647657394409\n",
      "Epoch 194: loss = 6.4251790046691895\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.5392183065414429 cvt_loss:  1.2899668887257576 chamfer_loss_mesh:  4.560887813568115\n",
      "Epoch 195: loss = 6.397150993347168\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.6201188564300537 cvt_loss:  1.2918158434331417 chamfer_loss_mesh:  4.509408958256245\n",
      "Epoch 196: loss = 6.4284210205078125\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.6735789775848389 cvt_loss:  1.2882495298981667 chamfer_loss_mesh:  4.470445215702057\n",
      "Epoch 197: loss = 6.439351558685303\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.6579701900482178 cvt_loss:  1.2845953926444054 chamfer_loss_mesh:  4.402745980769396\n",
      "Epoch 198: loss = 6.3523993492126465\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.6922814249992371 cvt_loss:  1.2882372364401817 chamfer_loss_mesh:  4.351940006017685\n",
      "Epoch 199: loss = 6.339558124542236\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "Estimated eps_H:  tensor(0.6721, device='cuda:0')\n",
      "eikonal_loss:  1.049028754234314 cvt_loss:  1.2768789194524288 chamfer_loss_mesh:  4.2866733856499195\n",
      "Epoch 200: loss = 6.619510650634766\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.9827762842178345 cvt_loss:  1.2565976940095425 chamfer_loss_mesh:  4.275635816156864\n",
      "Epoch 201: loss = 6.521949768066406\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.9918845891952515 cvt_loss:  1.245433185249567 chamfer_loss_mesh:  4.2415279895067215\n",
      "Epoch 202: loss = 6.4857869148254395\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  1.034148097038269 cvt_loss:  1.244036853313446 chamfer_loss_mesh:  4.159804899245501\n",
      "Epoch 203: loss = 6.444940090179443\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.9417276978492737 cvt_loss:  1.2439919635653496 chamfer_loss_mesh:  4.147658124566078\n",
      "Epoch 204: loss = 6.340333938598633\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.9286490082740784 cvt_loss:  1.2282075360417366 chamfer_loss_mesh:  4.098914097994566\n",
      "Epoch 205: loss = 6.262731552124023\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.792357325553894 cvt_loss:  1.2200609780848026 chamfer_loss_mesh:  4.137357696890831\n",
      "Epoch 206: loss = 6.15674352645874\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.7619712352752686 cvt_loss:  1.2139220722019672 chamfer_loss_mesh:  4.056411795318127\n",
      "Epoch 207: loss = 6.039272785186768\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.7341519594192505 cvt_loss:  1.2094834819436073 chamfer_loss_mesh:  4.00884123519063\n",
      "Epoch 208: loss = 5.9594502449035645\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.6890830993652344 cvt_loss:  1.2095547281205654 chamfer_loss_mesh:  4.013405181467533\n",
      "Epoch 209: loss = 5.919027328491211\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  3.891707420349121 cvt_loss:  1.206169556826353 chamfer_loss_mesh:  3.9966865442693233\n",
      "Epoch 210: loss = 9.101556777954102\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  3.924041986465454 cvt_loss:  1.203607488423586 chamfer_loss_mesh:  3.9503448642790318\n",
      "Epoch 211: loss = 9.084993362426758\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  3.791743755340576 cvt_loss:  1.2011047452688217 chamfer_loss_mesh:  3.891099477186799\n",
      "Epoch 212: loss = 8.890959739685059\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  4.186607360839844 cvt_loss:  1.1955619789659977 chamfer_loss_mesh:  3.8514183834195137\n",
      "Epoch 213: loss = 9.240604400634766\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  3.7317097187042236 cvt_loss:  1.1913861148059368 chamfer_loss_mesh:  3.826543688774109\n",
      "Epoch 214: loss = 8.756658554077148\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  3.609961986541748 cvt_loss:  1.1965947225689888 chamfer_loss_mesh:  3.7990824785083532\n",
      "Epoch 215: loss = 8.61265754699707\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  1.021141529083252 cvt_loss:  1.1864840984344482 chamfer_loss_mesh:  3.7726187147200108\n",
      "Epoch 216: loss = 5.987269878387451\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.9853483438491821 cvt_loss:  1.1805493384599686 chamfer_loss_mesh:  3.7620363291352987\n",
      "Epoch 217: loss = 5.934970855712891\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  1.4703593254089355 cvt_loss:  1.1744585819542408 chamfer_loss_mesh:  3.724298905581236\n",
      "Epoch 218: loss = 6.376156806945801\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  1.3749021291732788 cvt_loss:  1.185515709221363 chamfer_loss_mesh:  3.6970300134271383\n",
      "Epoch 219: loss = 6.264496803283691\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  1.7955023050308228 cvt_loss:  1.1865699663758278 chamfer_loss_mesh:  3.6583112087100744\n",
      "Epoch 220: loss = 6.647434234619141\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  1.6894450187683105 cvt_loss:  1.185084879398346 chamfer_loss_mesh:  3.6435932852327824\n",
      "Epoch 221: loss = 6.525178909301758\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  1.604758620262146 cvt_loss:  1.1787252500653267 chamfer_loss_mesh:  3.652772167697549\n",
      "Epoch 222: loss = 6.443314075469971\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  1.514385461807251 cvt_loss:  1.1707023717463017 chamfer_loss_mesh:  3.6123772151768208\n",
      "Epoch 223: loss = 6.304525375366211\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  1.424102783203125 cvt_loss:  1.165967620909214 chamfer_loss_mesh:  3.599944058805704\n",
      "Epoch 224: loss = 6.197082042694092\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  1.3736002445220947 cvt_loss:  1.1578291654586792 chamfer_loss_mesh:  3.5686050541698933\n",
      "Epoch 225: loss = 6.1071062088012695\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  1.301404356956482 cvt_loss:  1.1582587845623493 chamfer_loss_mesh:  3.527758177369833\n",
      "Epoch 226: loss = 5.9944987297058105\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  1.2149275541305542 cvt_loss:  1.1561731807887554 chamfer_loss_mesh:  3.49954841658473\n",
      "Epoch 227: loss = 5.877730846405029\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  1.1495411396026611 cvt_loss:  1.1428437195718288 chamfer_loss_mesh:  3.460794920101762\n",
      "Epoch 228: loss = 5.760266304016113\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  1.1012029647827148 cvt_loss:  1.1362007819116116 chamfer_loss_mesh:  3.4037104342132807\n",
      "Epoch 229: loss = 5.648208141326904\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  1.0520479679107666 cvt_loss:  1.1463562957942486 chamfer_loss_mesh:  3.354741260409355\n",
      "Epoch 230: loss = 5.560240268707275\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.9415786266326904 cvt_loss:  1.154256146401167 chamfer_loss_mesh:  3.3120953012257814\n",
      "Epoch 231: loss = 5.4150309562683105\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.9051443338394165 cvt_loss:  1.1468246579170227 chamfer_loss_mesh:  3.2668604981154203\n",
      "Epoch 232: loss = 5.325934886932373\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.8713511228561401 cvt_loss:  1.1403915472328663 chamfer_loss_mesh:  3.2469267025589943\n",
      "Epoch 233: loss = 5.26577615737915\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.842764675617218 cvt_loss:  1.1335439048707485 chamfer_loss_mesh:  3.2412814907729626\n",
      "Epoch 234: loss = 5.224694728851318\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  1.210254192352295 cvt_loss:  1.1264464817941189 chamfer_loss_mesh:  3.2218643464148045\n",
      "Epoch 235: loss = 5.565675735473633\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  1.2301849126815796 cvt_loss:  1.119866780936718 chamfer_loss_mesh:  3.1938704196363688\n",
      "Epoch 236: loss = 5.551033020019531\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  1.2581747770309448 cvt_loss:  1.1139492504298687 chamfer_loss_mesh:  3.2003317028284073\n",
      "Epoch 237: loss = 5.579568862915039\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.8960990905761719 cvt_loss:  1.1178499087691307 chamfer_loss_mesh:  3.1655027996748686\n",
      "Epoch 238: loss = 5.186567306518555\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.8549516201019287 cvt_loss:  1.110792439430952 chamfer_loss_mesh:  3.135105362161994\n",
      "Epoch 239: loss = 5.107970237731934\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.86328125 cvt_loss:  1.120590791106224 chamfer_loss_mesh:  3.1219408847391605\n",
      "Epoch 240: loss = 5.112936973571777\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.8383380770683289 cvt_loss:  1.121390052139759 chamfer_loss_mesh:  3.105681389570236\n",
      "Epoch 241: loss = 5.07253360748291\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "sites length BEFORE UPSAMPLING:  9012\n",
      "Sampled indices: 741 out of 3012 candidates (M=901)\n",
      "Estimated eps_H:  tensor(0.6688, device='cuda:0')\n",
      "sites shape AFTER:  torch.Size([11976, 3])\n",
      "sites sdf shape AFTER:  torch.Size([11976])\n",
      "eikonal_loss:  0.6314533352851868 cvt_loss:  1.0932124219834805 chamfer_loss_mesh:  2.9943417757749557\n",
      "Epoch 242: loss = 4.724262237548828\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.5194858908653259 cvt_loss:  1.0860313661396503 chamfer_loss_mesh:  3.022132907062769\n",
      "Epoch 243: loss = 4.632908344268799\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.5937369465827942 cvt_loss:  1.0633721947669983 chamfer_loss_mesh:  2.9095595236867666\n",
      "Epoch 244: loss = 4.5719313621521\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.5565413236618042 cvt_loss:  1.050153374671936 chamfer_loss_mesh:  2.8671994805336\n",
      "Epoch 245: loss = 4.479160785675049\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.5079270601272583 cvt_loss:  1.044009905308485 chamfer_loss_mesh:  2.820280846208334\n",
      "Epoch 246: loss = 4.377480983734131\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.4985122084617615 cvt_loss:  1.0310495272278786 chamfer_loss_mesh:  2.7851874474436045\n",
      "Epoch 247: loss = 4.32000732421875\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.4101838171482086 cvt_loss:  1.023931335657835 chamfer_loss_mesh:  2.7209450490772724\n",
      "Epoch 248: loss = 4.160314083099365\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.41780468821525574 cvt_loss:  1.0167263448238373 chamfer_loss_mesh:  2.678022487089038\n",
      "Epoch 249: loss = 4.117808818817139\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.4033372402191162 cvt_loss:  1.0057794861495495 chamfer_loss_mesh:  2.637360244989395\n",
      "Epoch 250: loss = 4.051730155944824\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.398088663816452 cvt_loss:  1.00003806874156 chamfer_loss_mesh:  2.610632684081793\n",
      "Epoch 251: loss = 4.01400899887085\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.3789502680301666 cvt_loss:  0.9934823028743267 chamfer_loss_mesh:  2.578742802143097\n",
      "Epoch 252: loss = 3.9564199447631836\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.3594319820404053 cvt_loss:  0.9920562617480755 chamfer_loss_mesh:  2.567397430539131\n",
      "Epoch 253: loss = 3.9241323471069336\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.34148338437080383 cvt_loss:  0.9874390438199043 chamfer_loss_mesh:  2.522839466109872\n",
      "Epoch 254: loss = 3.8570034503936768\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.32572057843208313 cvt_loss:  0.9773244149982929 chamfer_loss_mesh:  2.492852509021759\n",
      "Epoch 255: loss = 3.801142454147339\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.30893975496292114 cvt_loss:  0.9705740958452225 chamfer_loss_mesh:  2.4754272308200598\n",
      "Epoch 256: loss = 3.7601892948150635\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.2986920475959778 cvt_loss:  0.9661477990448475 chamfer_loss_mesh:  2.5159772485494614\n",
      "Epoch 257: loss = 3.7860653400421143\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.28727251291275024 cvt_loss:  0.961790420114994 chamfer_loss_mesh:  2.4967193603515625\n",
      "Epoch 258: loss = 3.751033067703247\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.2773280143737793 cvt_loss:  0.9529490955173969 chamfer_loss_mesh:  2.4397994857281446\n",
      "Epoch 259: loss = 3.675337314605713\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.2648067772388458 cvt_loss:  0.9485731832683086 chamfer_loss_mesh:  2.425366546958685\n",
      "Epoch 260: loss = 3.6440083980560303\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.23984256386756897 cvt_loss:  0.94857607036829 chamfer_loss_mesh:  2.3409142158925533\n",
      "Epoch 261: loss = 3.5345945358276367\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.22566331923007965 cvt_loss:  0.947758462280035 chamfer_loss_mesh:  2.322078449651599\n",
      "Epoch 262: loss = 3.5007598400115967\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.2600575089454651 cvt_loss:  0.9385847486555576 chamfer_loss_mesh:  2.2918693721294403\n",
      "Epoch 263: loss = 3.495774030685425\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.2658693194389343 cvt_loss:  0.9335475042462349 chamfer_loss_mesh:  2.2868644446134567\n",
      "Epoch 264: loss = 3.4915452003479004\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.25688743591308594 cvt_loss:  0.9302763268351555 chamfer_loss_mesh:  2.252548700198531\n",
      "Epoch 265: loss = 3.4449822902679443\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.26479122042655945 cvt_loss:  0.9337778203189373 chamfer_loss_mesh:  2.2321364376693964\n",
      "Epoch 266: loss = 3.435978412628174\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.2596960961818695 cvt_loss:  0.9299215860664845 chamfer_loss_mesh:  2.208095043897629\n",
      "Epoch 267: loss = 3.4029884338378906\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.21774254739284515 cvt_loss:  0.9287501685321331 chamfer_loss_mesh:  2.2142729721963406\n",
      "Epoch 268: loss = 3.366041898727417\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.2498067021369934 cvt_loss:  0.9294693358242512 chamfer_loss_mesh:  2.189760096371174\n",
      "Epoch 269: loss = 3.3743133544921875\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.25833529233932495 cvt_loss:  0.9232334792613983 chamfer_loss_mesh:  2.154745627194643\n",
      "Epoch 270: loss = 3.341594934463501\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.24762806296348572 cvt_loss:  0.9152675978839397 chamfer_loss_mesh:  2.1456722170114517\n",
      "Epoch 271: loss = 3.3138508796691895\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.237113356590271 cvt_loss:  0.9112393483519554 chamfer_loss_mesh:  2.1206780802458525\n",
      "Epoch 272: loss = 3.27431583404541\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.23935897648334503 cvt_loss:  0.9082913398742676 chamfer_loss_mesh:  2.1004737354815006\n",
      "Epoch 273: loss = 3.253415107727051\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.22818385064601898 cvt_loss:  0.9011615999042988 chamfer_loss_mesh:  2.076977165415883\n",
      "Epoch 274: loss = 3.211616277694702\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.2289220690727234 cvt_loss:  0.8932326920330524 chamfer_loss_mesh:  2.0592110231518745\n",
      "Epoch 275: loss = 3.1866610050201416\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.2799679934978485 cvt_loss:  0.8860655128955841 chamfer_loss_mesh:  2.0423943642526865\n",
      "Epoch 276: loss = 3.213724374771118\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.24282139539718628 cvt_loss:  0.880018062889576 chamfer_loss_mesh:  2.019996289163828\n",
      "Epoch 277: loss = 3.148134469985962\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.23913247883319855 cvt_loss:  0.8808789774775505 chamfer_loss_mesh:  1.9999747164547443\n",
      "Epoch 278: loss = 3.12528395652771\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.1912531852722168 cvt_loss:  0.874208752065897 chamfer_loss_mesh:  1.9800430163741112\n",
      "Epoch 279: loss = 3.050808906555176\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.18653704226016998 cvt_loss:  0.8698856458067894 chamfer_loss_mesh:  1.9987802952528\n",
      "Epoch 280: loss = 3.060513734817505\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.18224963545799255 cvt_loss:  0.8630990982055664 chamfer_loss_mesh:  1.9730334170162678\n",
      "Epoch 281: loss = 3.0236942768096924\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.17735391855239868 cvt_loss:  0.8622286841273308 chamfer_loss_mesh:  1.9540307112038136\n",
      "Epoch 282: loss = 2.998932361602783\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.17594732344150543 cvt_loss:  0.8616586215794086 chamfer_loss_mesh:  1.9236888037994504\n",
      "Epoch 283: loss = 2.966611623764038\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.17292864620685577 cvt_loss:  0.8555138483643532 chamfer_loss_mesh:  1.9035624573007226\n",
      "Epoch 284: loss = 2.937328577041626\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.1702473759651184 cvt_loss:  0.8537190966308117 chamfer_loss_mesh:  1.8908806378021836\n",
      "Epoch 285: loss = 2.9201767444610596\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.13730867207050323 cvt_loss:  0.8479738608002663 chamfer_loss_mesh:  1.870962092652917\n",
      "Epoch 286: loss = 2.861579179763794\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.1351352035999298 cvt_loss:  0.8405090309679508 chamfer_loss_mesh:  1.8482031300663948\n",
      "Epoch 287: loss = 2.8291852474212646\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.13135692477226257 cvt_loss:  0.83647221326828 chamfer_loss_mesh:  1.848418265581131\n",
      "Epoch 288: loss = 2.8215885162353516\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.1298583745956421 cvt_loss:  0.8347989059984684 chamfer_loss_mesh:  1.8342952243983746\n",
      "Epoch 289: loss = 2.8042960166931152\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.12689638137817383 cvt_loss:  0.8329589851200581 chamfer_loss_mesh:  1.8200089689344168\n",
      "Epoch 290: loss = 2.7852113246917725\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.13390353322029114 cvt_loss:  0.8268903009593487 chamfer_loss_mesh:  1.795462565496564\n",
      "Epoch 291: loss = 2.7616050243377686\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.13256557285785675 cvt_loss:  0.8392367511987686 chamfer_loss_mesh:  1.7710583051666617\n",
      "Epoch 292: loss = 2.74821400642395\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.13060860335826874 cvt_loss:  0.8317040279507637 chamfer_loss_mesh:  1.7513404600322247\n",
      "Epoch 293: loss = 2.7190001010894775\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.1284686028957367 cvt_loss:  0.8207114413380623 chamfer_loss_mesh:  1.736744656227529\n",
      "Epoch 294: loss = 2.691269874572754\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.12674543261528015 cvt_loss:  0.819897186011076 chamfer_loss_mesh:  1.7208547797054052\n",
      "Epoch 295: loss = 2.672849178314209\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.12446053326129913 cvt_loss:  0.8145084604620934 chamfer_loss_mesh:  1.7160644056275487\n",
      "Epoch 296: loss = 2.6603848934173584\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.12237799167633057 cvt_loss:  0.8082703687250614 chamfer_loss_mesh:  1.7023957334458828\n",
      "Epoch 297: loss = 2.6383988857269287\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.12054009735584259 cvt_loss:  0.8034409955143929 chamfer_loss_mesh:  1.6762842424213886\n",
      "Epoch 298: loss = 2.605621576309204\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.11895386874675751 cvt_loss:  0.8054451085627079 chamfer_loss_mesh:  1.6585743287578225\n",
      "Epoch 299: loss = 2.5883331298828125\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "Estimated eps_H:  tensor(0.5413, device='cuda:0')\n",
      "eikonal_loss:  0.11721707880496979 cvt_loss:  0.8011181838810444 chamfer_loss_mesh:  1.6470428090542555\n",
      "Epoch 300: loss = 2.57075834274292\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.11511921882629395 cvt_loss:  0.8003724738955498 chamfer_loss_mesh:  1.699801068753004\n",
      "Epoch 301: loss = 2.6206729412078857\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.11361326277256012 cvt_loss:  0.797358900308609 chamfer_loss_mesh:  1.6388131771236658\n",
      "Epoch 302: loss = 2.5551705360412598\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.1117996945977211 cvt_loss:  0.7912031374871731 chamfer_loss_mesh:  1.6337251290678978\n",
      "Epoch 303: loss = 2.5421142578125\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.11036588996648788 cvt_loss:  0.7876300252974033 chamfer_loss_mesh:  1.6337521374225616\n",
      "Epoch 304: loss = 2.5371334552764893\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.10902845859527588 cvt_loss:  0.7821466773748398 chamfer_loss_mesh:  1.6487016109749675\n",
      "Epoch 305: loss = 2.5452628135681152\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.10697844624519348 cvt_loss:  0.7785571739077568 chamfer_loss_mesh:  1.6187860164791346\n",
      "Epoch 306: loss = 2.50970721244812\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.10729598999023438 cvt_loss:  0.774331483989954 chamfer_loss_mesh:  1.5993493143469095\n",
      "Epoch 307: loss = 2.4863643646240234\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.10426894575357437 cvt_loss:  0.7748570293188095 chamfer_loss_mesh:  1.5845942543819547\n",
      "Epoch 308: loss = 2.4691131114959717\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.1026996374130249 cvt_loss:  0.7750577293336391 chamfer_loss_mesh:  1.5692595625296235\n",
      "Epoch 309: loss = 2.4524130821228027\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.10007503628730774 cvt_loss:  0.7745308801531792 chamfer_loss_mesh:  1.5547277871519327\n",
      "Epoch 310: loss = 2.4347357749938965\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.09822903573513031 cvt_loss:  0.773692037910223 chamfer_loss_mesh:  1.5339485835283995\n",
      "Epoch 311: loss = 2.4112727642059326\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.09621155261993408 cvt_loss:  0.7733367849141359 chamfer_loss_mesh:  1.5179701149463654\n",
      "Epoch 312: loss = 2.3929240703582764\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0957069844007492 cvt_loss:  0.7720660883933306 chamfer_loss_mesh:  1.510930247604847\n",
      "Epoch 313: loss = 2.3841090202331543\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.09430080652236938 cvt_loss:  0.7675123400986195 chamfer_loss_mesh:  1.49682501796633\n",
      "Epoch 314: loss = 2.364043951034546\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.11516216397285461 cvt_loss:  0.763803580775857 chamfer_loss_mesh:  1.4931733021512628\n",
      "Epoch 315: loss = 2.377547025680542\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.11325553059577942 cvt_loss:  0.7640782743692398 chamfer_loss_mesh:  1.473411568440497\n",
      "Epoch 316: loss = 2.356154203414917\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.11119551211595535 cvt_loss:  0.7648193277418613 chamfer_loss_mesh:  1.4726370573043823\n",
      "Epoch 317: loss = 2.354057550430298\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.12753567099571228 cvt_loss:  0.7646402809768915 chamfer_loss_mesh:  1.4540657866746187\n",
      "Epoch 318: loss = 2.3516523838043213\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.10200163722038269 cvt_loss:  0.7606855593621731 chamfer_loss_mesh:  1.4499749522656202\n",
      "Epoch 319: loss = 2.3180782794952393\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.10337569564580917 cvt_loss:  0.7560786791145802 chamfer_loss_mesh:  1.4306826051324606\n",
      "Epoch 320: loss = 2.2955563068389893\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.09954846650362015 cvt_loss:  0.7515949197113514 chamfer_loss_mesh:  1.420001732185483\n",
      "Epoch 321: loss = 2.276566743850708\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "sites length BEFORE UPSAMPLING:  11976\n",
      "Sampled indices: 1033 out of 4718 candidates (M=1197)\n",
      "Estimated eps_H:  tensor(0.5412, device='cuda:0')\n",
      "sites shape AFTER:  torch.Size([16108, 3])\n",
      "sites sdf shape AFTER:  torch.Size([16108])\n",
      "eikonal_loss:  0.07520098984241486 cvt_loss:  0.7700032088905573 chamfer_loss_mesh:  1.413102843798697\n",
      "Epoch 322: loss = 2.262263774871826\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.08656437695026398 cvt_loss:  0.763603113591671 chamfer_loss_mesh:  1.4090860495343804\n",
      "Epoch 323: loss = 2.2632076740264893\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0712834969162941 cvt_loss:  0.7456602063030005 chamfer_loss_mesh:  1.383054768666625\n",
      "Epoch 324: loss = 2.203950881958008\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.06724830716848373 cvt_loss:  0.7324052043259144 chamfer_loss_mesh:  1.4010102022439241\n",
      "Epoch 325: loss = 2.2046151161193848\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.06540699303150177 cvt_loss:  0.7188668940216303 chamfer_loss_mesh:  1.329403487034142\n",
      "Epoch 326: loss = 2.117623805999756\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.060279663652181625 cvt_loss:  0.7092391606420279 chamfer_loss_mesh:  1.3248773757368326\n",
      "Epoch 327: loss = 2.09834361076355\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.051831573247909546 cvt_loss:  0.7081290241330862 chamfer_loss_mesh:  1.3074021553620696\n",
      "Epoch 328: loss = 2.0713095664978027\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.06644199788570404 cvt_loss:  0.6994729395955801 chamfer_loss_mesh:  1.285820035263896\n",
      "Epoch 329: loss = 2.0556812286376953\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.06562942266464233 cvt_loss:  0.6919954903423786 chamfer_loss_mesh:  1.2826285092160106\n",
      "Epoch 330: loss = 2.0441956520080566\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.06409027427434921 cvt_loss:  0.6839004810899496 chamfer_loss_mesh:  1.2593467254191637\n",
      "Epoch 331: loss = 2.011277914047241\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.07413554191589355 cvt_loss:  0.6770434323698282 chamfer_loss_mesh:  1.2509701773524284\n",
      "Epoch 332: loss = 2.0060906410217285\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.07372216880321503 cvt_loss:  0.6773489527404308 chamfer_loss_mesh:  1.227141823619604\n",
      "Epoch 333: loss = 1.9821501970291138\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0675581768155098 cvt_loss:  0.6713712587952614 chamfer_loss_mesh:  1.2179347686469555\n",
      "Epoch 334: loss = 1.960801124572754\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.06723200529813766 cvt_loss:  0.6691426038742065 chamfer_loss_mesh:  1.202731509692967\n",
      "Epoch 335: loss = 1.9430477619171143\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0651111751794815 cvt_loss:  0.6666294764727354 chamfer_loss_mesh:  1.1932456400245428\n",
      "Epoch 336: loss = 1.928925633430481\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.06337444484233856 cvt_loss:  0.6606653332710266 chamfer_loss_mesh:  1.182754640467465\n",
      "Epoch 337: loss = 1.9107352495193481\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.06588634848594666 cvt_loss:  0.6551780737936497 chamfer_loss_mesh:  1.1634391266852617\n",
      "Epoch 338: loss = 1.8884477615356445\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.07889452576637268 cvt_loss:  0.6492102984338999 chamfer_loss_mesh:  1.1444929987192154\n",
      "Epoch 339: loss = 1.876541256904602\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.07734738290309906 cvt_loss:  0.6463858764618635 chamfer_loss_mesh:  1.1421910021454096\n",
      "Epoch 340: loss = 1.8698681592941284\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.07549914717674255 cvt_loss:  0.6422258913516998 chamfer_loss_mesh:  1.138088060542941\n",
      "Epoch 341: loss = 1.8597551584243774\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.049669329077005386 cvt_loss:  0.6373530253767967 chamfer_loss_mesh:  1.1305809020996094\n",
      "Epoch 342: loss = 1.8215432167053223\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.04892466589808464 cvt_loss:  0.6341236177831888 chamfer_loss_mesh:  1.1200405424460769\n",
      "Epoch 343: loss = 1.807030439376831\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.04836296662688255 cvt_loss:  0.6290305871516466 chamfer_loss_mesh:  1.1251555988565087\n",
      "Epoch 344: loss = 1.8064912557601929\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.059108465909957886 cvt_loss:  0.6238238420337439 chamfer_loss_mesh:  1.1205802438780665\n",
      "Epoch 345: loss = 1.8074620962142944\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.05853595584630966 cvt_loss:  0.6223216187208891 chamfer_loss_mesh:  1.1065356666222215\n",
      "Epoch 346: loss = 1.7913453578948975\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.060909487307071686 cvt_loss:  0.6181726697832346 chamfer_loss_mesh:  1.0996744967997074\n",
      "Epoch 347: loss = 1.7827086448669434\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.06367582082748413 cvt_loss:  0.6170934997498989 chamfer_loss_mesh:  1.0866953525692225\n",
      "Epoch 348: loss = 1.7714152336120605\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.06572072952985764 cvt_loss:  0.6112887989729643 chamfer_loss_mesh:  1.0696286335587502\n",
      "Epoch 349: loss = 1.7505900859832764\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.06429378688335419 cvt_loss:  0.6094770506024361 chamfer_loss_mesh:  1.0639404645189643\n",
      "Epoch 350: loss = 1.7416623830795288\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.07131773233413696 cvt_loss:  0.6052312441170216 chamfer_loss_mesh:  1.0522711090743542\n",
      "Epoch 351: loss = 1.732770323753357\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.07006624341011047 cvt_loss:  0.6014005281031132 chamfer_loss_mesh:  1.0355806443840265\n",
      "Epoch 352: loss = 1.7110008001327515\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.08166470378637314 cvt_loss:  0.6007162854075432 chamfer_loss_mesh:  1.0278469417244196\n",
      "Epoch 353: loss = 1.7141796350479126\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.05902118608355522 cvt_loss:  0.6008215248584747 chamfer_loss_mesh:  1.0167051805183291\n",
      "Epoch 354: loss = 1.6805036067962646\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.058271341025829315 cvt_loss:  0.5960444919764996 chamfer_loss_mesh:  1.0059868218377233\n",
      "Epoch 355: loss = 1.6642612218856812\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.05602322891354561 cvt_loss:  0.5920258350670338 chamfer_loss_mesh:  0.9832121431827545\n",
      "Epoch 356: loss = 1.6352189779281616\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.054226718842983246 cvt_loss:  0.5891667678952217 chamfer_loss_mesh:  0.975597882643342\n",
      "Epoch 357: loss = 1.6229472160339355\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.05268726497888565 cvt_loss:  0.5855286493897438 chamfer_loss_mesh:  0.965184299275279\n",
      "Epoch 358: loss = 1.6073552370071411\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.05106443911790848 cvt_loss:  0.5839170422405005 chamfer_loss_mesh:  0.9505592752248049\n",
      "Epoch 359: loss = 1.5894951820373535\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.049298882484436035 cvt_loss:  0.5799210164695978 chamfer_loss_mesh:  0.9435501415282488\n",
      "Epoch 360: loss = 1.5767205953598022\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.04826422408223152 cvt_loss:  0.5757445469498634 chamfer_loss_mesh:  0.9259775979444385\n",
      "Epoch 361: loss = 1.55393648147583\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.04607541859149933 cvt_loss:  0.5723245907574892 chamfer_loss_mesh:  0.9141218615695834\n",
      "Epoch 362: loss = 1.536472201347351\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.039698198437690735 cvt_loss:  0.5680046044290066 chamfer_loss_mesh:  0.9080725139938295\n",
      "Epoch 363: loss = 1.5197243690490723\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.05730820447206497 cvt_loss:  0.5652574356645346 chamfer_loss_mesh:  0.9041877929121256\n",
      "Epoch 364: loss = 1.5307053327560425\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0584704615175724 cvt_loss:  0.5618526134639978 chamfer_loss_mesh:  0.8976308163255453\n",
      "Epoch 365: loss = 1.521905779838562\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.05509020760655403 cvt_loss:  0.5584002006798983 chamfer_loss_mesh:  0.8858796791173518\n",
      "Epoch 366: loss = 1.5033199787139893\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.05399896949529648 cvt_loss:  0.5563635844737291 chamfer_loss_mesh:  0.8754860027693212\n",
      "Epoch 367: loss = 1.4898004531860352\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.04858773574233055 cvt_loss:  0.5537118762731552 chamfer_loss_mesh:  0.86958147585392\n",
      "Epoch 368: loss = 1.4758327007293701\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.036899179220199585 cvt_loss:  0.5516908597201109 chamfer_loss_mesh:  0.8568280027247965\n",
      "Epoch 369: loss = 1.449371099472046\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.030825434252619743 cvt_loss:  0.5474684294313192 chamfer_loss_mesh:  0.8668250520713627\n",
      "Epoch 370: loss = 1.4490717649459839\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.042720403522253036 cvt_loss:  0.5441579036414623 chamfer_loss_mesh:  0.8587725460529327\n",
      "Epoch 371: loss = 1.4496018886566162\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0405663400888443 cvt_loss:  0.541519420221448 chamfer_loss_mesh:  0.8497602539137006\n",
      "Epoch 372: loss = 1.4357963800430298\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.03990289196372032 cvt_loss:  0.5392036866396666 chamfer_loss_mesh:  0.8460846729576588\n",
      "Epoch 373: loss = 1.4291408061981201\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.039199214428663254 cvt_loss:  0.5365917924791574 chamfer_loss_mesh:  0.8434875053353608\n",
      "Epoch 374: loss = 1.423227071762085\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.03882580250501633 cvt_loss:  0.5335664376616478 chamfer_loss_mesh:  0.8495577494613826\n",
      "Epoch 375: loss = 1.425898790359497\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.03761409595608711 cvt_loss:  0.5313101690262556 chamfer_loss_mesh:  0.8362894877791405\n",
      "Epoch 376: loss = 1.4091647863388062\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.03708529844880104 cvt_loss:  0.528253149241209 chamfer_loss_mesh:  0.8451818721368909\n",
      "Epoch 377: loss = 1.4144715070724487\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.036339230835437775 cvt_loss:  0.5289952270686626 chamfer_loss_mesh:  0.8332391153089702\n",
      "Epoch 378: loss = 1.4025273323059082\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.03583940491080284 cvt_loss:  0.5259718280285597 chamfer_loss_mesh:  0.8286670199595392\n",
      "Epoch 379: loss = 1.394431710243225\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.03526034206151962 cvt_loss:  0.5240521393716335 chamfer_loss_mesh:  0.8248036028817296\n",
      "Epoch 380: loss = 1.3880733251571655\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.03285086899995804 cvt_loss:  0.5229240749031305 chamfer_loss_mesh:  0.8263422059826553\n",
      "Epoch 381: loss = 1.3860766887664795\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.03394057974219322 cvt_loss:  0.5197275895625353 chamfer_loss_mesh:  0.8174774702638388\n",
      "Epoch 382: loss = 1.3751052618026733\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.03497445210814476 cvt_loss:  0.5168994888663292 chamfer_loss_mesh:  0.8035262580960989\n",
      "Epoch 383: loss = 1.359358549118042\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.03425450623035431 cvt_loss:  0.5148226860910654 chamfer_loss_mesh:  0.8033921476453543\n",
      "Epoch 384: loss = 1.3564273118972778\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.033739540725946426 cvt_loss:  0.5134947597980499 chamfer_loss_mesh:  0.7994582410901785\n",
      "Epoch 385: loss = 1.3506500720977783\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.032734643667936325 cvt_loss:  0.5113447550684214 chamfer_loss_mesh:  0.7857846794649959\n",
      "Epoch 386: loss = 1.333820104598999\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0321299247443676 cvt_loss:  0.5099167115986347 chamfer_loss_mesh:  0.7820137543603778\n",
      "Epoch 387: loss = 1.3280184268951416\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.031637128442525864 cvt_loss:  0.507941422984004 chamfer_loss_mesh:  0.780015776399523\n",
      "Epoch 388: loss = 1.3235516548156738\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.03152262791991234 cvt_loss:  0.5052169784903526 chamfer_loss_mesh:  0.7781176245771348\n",
      "Epoch 389: loss = 1.3188130855560303\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.03248972073197365 cvt_loss:  0.5039377603679895 chamfer_loss_mesh:  0.7713499944657087\n",
      "Epoch 390: loss = 1.3117340803146362\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.032055024057626724 cvt_loss:  0.5030812229961157 chamfer_loss_mesh:  0.7730850484222174\n",
      "Epoch 391: loss = 1.3121803998947144\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.031227536499500275 cvt_loss:  0.50044902600348 chamfer_loss_mesh:  0.7601459510624409\n",
      "Epoch 392: loss = 1.2957818508148193\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.03038332611322403 cvt_loss:  0.4979217890650034 chamfer_loss_mesh:  0.7511525182053447\n",
      "Epoch 393: loss = 1.2834157943725586\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.02981063723564148 cvt_loss:  0.4960712045431137 chamfer_loss_mesh:  0.7454078877344728\n",
      "Epoch 394: loss = 1.2752504348754883\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.028931718319654465 cvt_loss:  0.49396753311157227 chamfer_loss_mesh:  0.7385062053799629\n",
      "Epoch 395: loss = 1.2653650045394897\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.028301697224378586 cvt_loss:  0.4923943430185318 chamfer_loss_mesh:  0.7324896869249642\n",
      "Epoch 396: loss = 1.257145643234253\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.027889102697372437 cvt_loss:  0.4904741421341896 chamfer_loss_mesh:  0.732279964722693\n",
      "Epoch 397: loss = 1.2546043395996094\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.028458107262849808 cvt_loss:  0.48902942799031734 chamfer_loss_mesh:  0.7207627641037107\n",
      "Epoch 398: loss = 1.2422103881835938\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.027928194031119347 cvt_loss:  0.48746545799076557 chamfer_loss_mesh:  0.7116732303984463\n",
      "Epoch 399: loss = 1.2310245037078857\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "Estimated eps_H:  tensor(0.4355, device='cuda:0')\n",
      "eikonal_loss:  0.027373284101486206 cvt_loss:  0.4866852890700102 chamfer_loss_mesh:  0.7054541492834687\n",
      "Epoch 400: loss = 1.2235283851623535\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.026818038895726204 cvt_loss:  0.48643904738128185 chamfer_loss_mesh:  0.6996356532908976\n",
      "Epoch 401: loss = 1.2169103622436523\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "sites length BEFORE UPSAMPLING:  16108\n",
      "Sampled indices: 1389 out of 7304 candidates (M=1610)\n",
      "Estimated eps_H:  tensor(0.4355, device='cuda:0')\n",
      "sites shape AFTER:  torch.Size([21664, 3])\n",
      "sites sdf shape AFTER:  torch.Size([21664])\n",
      "eikonal_loss:  0.017216475680470467 cvt_loss:  0.5435764789581299 chamfer_loss_mesh:  0.6920628948137164\n",
      "Epoch 402: loss = 1.2558181285858154\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.016963079571723938 cvt_loss:  0.5336496513336897 chamfer_loss_mesh:  0.6890158401802182\n",
      "Epoch 403: loss = 1.2425875663757324\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.01607614755630493 cvt_loss:  0.515224551782012 chamfer_loss_mesh:  0.6740692188031971\n",
      "Epoch 404: loss = 1.208326816558838\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.015179910697042942 cvt_loss:  0.5028353538364172 chamfer_loss_mesh:  0.6749965832568705\n",
      "Epoch 405: loss = 1.1959664821624756\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.014639087952673435 cvt_loss:  0.49497708678245544 chamfer_loss_mesh:  0.6680071819573641\n",
      "Epoch 406: loss = 1.1805813312530518\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.020779486745595932 cvt_loss:  0.4871788900345564 chamfer_loss_mesh:  0.6585388910025358\n",
      "Epoch 407: loss = 1.1694507598876953\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.03388358652591705 cvt_loss:  0.4796740598976612 chamfer_loss_mesh:  0.6434278329834342\n",
      "Epoch 408: loss = 1.1599359512329102\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.019813239574432373 cvt_loss:  0.47293263487517834 chamfer_loss_mesh:  0.6363987340591848\n",
      "Epoch 409: loss = 1.1320884227752686\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.02104068361222744 cvt_loss:  0.4677764605730772 chamfer_loss_mesh:  0.6205159006640315\n",
      "Epoch 410: loss = 1.1122735738754272\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.020194269716739655 cvt_loss:  0.46378769911825657 chamfer_loss_mesh:  0.6125138024799526\n",
      "Epoch 411: loss = 1.099434494972229\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.018860433250665665 cvt_loss:  0.458754226565361 chamfer_loss_mesh:  0.606959976721555\n",
      "Epoch 412: loss = 1.087510585784912\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.017636151984333992 cvt_loss:  0.45358166098594666 chamfer_loss_mesh:  0.5994383245706558\n",
      "Epoch 413: loss = 1.0735915899276733\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.018394378945231438 cvt_loss:  0.4489848390221596 chamfer_loss_mesh:  0.5840848316438496\n",
      "Epoch 414: loss = 1.054399013519287\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.017932916060090065 cvt_loss:  0.4449521657079458 chamfer_loss_mesh:  0.5765993264503777\n",
      "Epoch 415: loss = 1.04241943359375\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.01748737320303917 cvt_loss:  0.44185565784573555 chamfer_loss_mesh:  0.5716643063351512\n",
      "Epoch 416: loss = 1.0339405536651611\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.017405986785888672 cvt_loss:  0.43838624842464924 chamfer_loss_mesh:  0.5662005860358477\n",
      "Epoch 417: loss = 1.0249238014221191\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.01707492582499981 cvt_loss:  0.43481807224452496 chamfer_loss_mesh:  0.5574336973950267\n",
      "Epoch 418: loss = 1.01225745677948\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.01672619767487049 cvt_loss:  0.4318769555538893 chamfer_loss_mesh:  0.550696044228971\n",
      "Epoch 419: loss = 1.0022279024124146\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.01659344509243965 cvt_loss:  0.4314814228564501 chamfer_loss_mesh:  0.5448877927847207\n",
      "Epoch 420: loss = 0.9958906769752502\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.016291974112391472 cvt_loss:  0.42836302891373634 chamfer_loss_mesh:  0.5365168326534331\n",
      "Epoch 421: loss = 0.9840998649597168\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.015905873849987984 cvt_loss:  0.42602955363690853 chamfer_loss_mesh:  0.5308797117322683\n",
      "Epoch 422: loss = 0.9757436513900757\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.015259424224495888 cvt_loss:  0.42537455447018147 chamfer_loss_mesh:  0.5252438713796437\n",
      "Epoch 423: loss = 0.9688047170639038\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.014606820419430733 cvt_loss:  0.4222582560032606 chamfer_loss_mesh:  0.5204833578318357\n",
      "Epoch 424: loss = 0.9602770209312439\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.01521403156220913 cvt_loss:  0.4193457309156656 chamfer_loss_mesh:  0.5197967402637005\n",
      "Epoch 425: loss = 0.9572859406471252\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.013394434005022049 cvt_loss:  0.4161903169006109 chamfer_loss_mesh:  0.5146003095433116\n",
      "Epoch 426: loss = 0.9471117854118347\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.016576454043388367 cvt_loss:  0.4139208234846592 chamfer_loss_mesh:  0.5091902567073703\n",
      "Epoch 427: loss = 0.9426126480102539\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.01534094288945198 cvt_loss:  0.4140659235417843 chamfer_loss_mesh:  0.5053561762906611\n",
      "Epoch 428: loss = 0.9376877546310425\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.01487265806645155 cvt_loss:  0.4111217800527811 chamfer_loss_mesh:  0.4980522789992392\n",
      "Epoch 429: loss = 0.9269711375236511\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.014755653217434883 cvt_loss:  0.4105175379663706 chamfer_loss_mesh:  0.49222150119021535\n",
      "Epoch 430: loss = 0.9204180836677551\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.013399221934378147 cvt_loss:  0.4073473159223795 chamfer_loss_mesh:  0.4840148030780256\n",
      "Epoch 431: loss = 0.9076833128929138\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.014617117121815681 cvt_loss:  0.40534138679504395 chamfer_loss_mesh:  0.4802652692887932\n",
      "Epoch 432: loss = 0.903145968914032\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.015487628057599068 cvt_loss:  0.4023789893835783 chamfer_loss_mesh:  0.4905249224975705\n",
      "Epoch 433: loss = 0.9113135933876038\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.014710163697600365 cvt_loss:  0.4025062546133995 chamfer_loss_mesh:  0.4761886957567185\n",
      "Epoch 434: loss = 0.8963261246681213\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.015330576337873936 cvt_loss:  0.40042069740593433 chamfer_loss_mesh:  0.46564923832193017\n",
      "Epoch 435: loss = 0.8843199014663696\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.015128500759601593 cvt_loss:  0.39787841960787773 chamfer_loss_mesh:  0.46079058665782213\n",
      "Epoch 436: loss = 0.8767142295837402\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.014257421717047691 cvt_loss:  0.39471867494285107 chamfer_loss_mesh:  0.4573213227558881\n",
      "Epoch 437: loss = 0.8692132234573364\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.01468619517982006 cvt_loss:  0.39215171709656715 chamfer_loss_mesh:  0.4584832349792123\n",
      "Epoch 438: loss = 0.8682354688644409\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.014859966933727264 cvt_loss:  0.3891431260854006 chamfer_loss_mesh:  0.4521100199781358\n",
      "Epoch 439: loss = 0.859025239944458\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.01453728973865509 cvt_loss:  0.3876572009176016 chamfer_loss_mesh:  0.4458768817130476\n",
      "Epoch 440: loss = 0.8509837985038757\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.01758827269077301 cvt_loss:  0.385116646066308 chamfer_loss_mesh:  0.4461395146790892\n",
      "Epoch 441: loss = 0.8517574667930603\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.011783222667872906 cvt_loss:  0.38246994372457266 chamfer_loss_mesh:  0.4432670248206705\n",
      "Epoch 442: loss = 0.8404309749603271\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.011881153099238873 cvt_loss:  0.37979702465236187 chamfer_loss_mesh:  0.43533596908673644\n",
      "Epoch 443: loss = 0.8299197554588318\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.015414535067975521 cvt_loss:  0.37837717682123184 chamfer_loss_mesh:  0.42858190136030316\n",
      "Epoch 444: loss = 0.8252773880958557\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.015038389712572098 cvt_loss:  0.37575128953903913 chamfer_loss_mesh:  0.4269784549251199\n",
      "Epoch 445: loss = 0.8206705451011658\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.014562780037522316 cvt_loss:  0.3747459268197417 chamfer_loss_mesh:  0.4241960996296257\n",
      "Epoch 446: loss = 0.8164063692092896\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.014021423645317554 cvt_loss:  0.3726702416315675 chamfer_loss_mesh:  0.4202398704364896\n",
      "Epoch 447: loss = 0.8098321557044983\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.013728668913245201 cvt_loss:  0.3713424317538738 chamfer_loss_mesh:  0.4158004012424499\n",
      "Epoch 448: loss = 0.803771436214447\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.01280116941779852 cvt_loss:  0.3701078938320279 chamfer_loss_mesh:  0.4115022602491081\n",
      "Epoch 449: loss = 0.7973096370697021\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.012707088142633438 cvt_loss:  0.3685199189931154 chamfer_loss_mesh:  0.4055163008160889\n",
      "Epoch 450: loss = 0.7896401286125183\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.01234503835439682 cvt_loss:  0.36684642545878887 chamfer_loss_mesh:  0.40325633017346263\n",
      "Epoch 451: loss = 0.7853437066078186\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.012159358710050583 cvt_loss:  0.3670324105769396 chamfer_loss_mesh:  0.40188702405430377\n",
      "Epoch 452: loss = 0.783974289894104\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.011902080848813057 cvt_loss:  0.3683200106024742 chamfer_loss_mesh:  0.3968402452301234\n",
      "Epoch 453: loss = 0.7799564599990845\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.011783762834966183 cvt_loss:  0.3696164349094033 chamfer_loss_mesh:  0.3923728072550148\n",
      "Epoch 454: loss = 0.7766668796539307\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.01130685769021511 cvt_loss:  0.3672451479360461 chamfer_loss_mesh:  0.3910775121767074\n",
      "Epoch 455: loss = 0.7725200653076172\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.011152881197631359 cvt_loss:  0.36667315289378166 chamfer_loss_mesh:  0.3847232146654278\n",
      "Epoch 456: loss = 0.7654379606246948\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.008906504139304161 cvt_loss:  0.3642603289335966 chamfer_loss_mesh:  0.3846943727694452\n",
      "Epoch 457: loss = 0.7607492804527283\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.00854645948857069 cvt_loss:  0.3620601259171963 chamfer_loss_mesh:  0.384476559702307\n",
      "Epoch 458: loss = 0.7579696178436279\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.008268941193819046 cvt_loss:  0.36032027564942837 chamfer_loss_mesh:  0.3757004742510617\n",
      "Epoch 459: loss = 0.7471759915351868\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.007853690534830093 cvt_loss:  0.3597758710384369 chamfer_loss_mesh:  0.37200417136773467\n",
      "Epoch 460: loss = 0.7425177097320557\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.01408308558166027 cvt_loss:  0.3576640272513032 chamfer_loss_mesh:  0.37213214091025293\n",
      "Epoch 461: loss = 0.7467618584632874\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.014246338047087193 cvt_loss:  0.3562767989933491 chamfer_loss_mesh:  0.3676877240650356\n",
      "Epoch 462: loss = 0.741091787815094\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.07269489765167236 cvt_loss:  0.35415252204984426 chamfer_loss_mesh:  0.3630215360317379\n",
      "Epoch 463: loss = 0.7927490472793579\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.07253167778253555 cvt_loss:  0.35362911876291037 chamfer_loss_mesh:  0.35881897201761603\n",
      "Epoch 464: loss = 0.7878556251525879\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.06410972028970718 cvt_loss:  0.352554302662611 chamfer_loss_mesh:  0.3627411788329482\n",
      "Epoch 465: loss = 0.7822793126106262\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.05833720788359642 cvt_loss:  0.3513078670948744 chamfer_loss_mesh:  0.3605959063861519\n",
      "Epoch 466: loss = 0.7731155753135681\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.051859911531209946 cvt_loss:  0.35004850942641497 chamfer_loss_mesh:  0.36025134613737464\n",
      "Epoch 467: loss = 0.7650312185287476\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.05014549568295479 cvt_loss:  0.3486513392999768 chamfer_loss_mesh:  0.35618114634417\n",
      "Epoch 468: loss = 0.7578495144844055\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.047335442155599594 cvt_loss:  0.3475069999694824 chamfer_loss_mesh:  0.35724532790482044\n",
      "Epoch 469: loss = 0.754957377910614\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.042836740612983704 cvt_loss:  0.3455733647570014 chamfer_loss_mesh:  0.34595918259583414\n",
      "Epoch 470: loss = 0.7372379899024963\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.03874824568629265 cvt_loss:  0.34451945684850216 chamfer_loss_mesh:  0.34237169893458486\n",
      "Epoch 471: loss = 0.7285076379776001\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.036313414573669434 cvt_loss:  0.34338077530264854 chamfer_loss_mesh:  0.3396587853785604\n",
      "Epoch 472: loss = 0.7222198247909546\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.03425585851073265 cvt_loss:  0.34246472641825676 chamfer_loss_mesh:  0.3370598133187741\n",
      "Epoch 473: loss = 0.7166463136672974\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.032506413757801056 cvt_loss:  0.3422854235395789 chamfer_loss_mesh:  0.3378309484105557\n",
      "Epoch 474: loss = 0.7154879570007324\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.030622605234384537 cvt_loss:  0.3410463221371174 chamfer_loss_mesh:  0.338795012794435\n",
      "Epoch 475: loss = 0.7133250832557678\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.01903298683464527 cvt_loss:  0.33945199102163315 chamfer_loss_mesh:  0.3400007262825966\n",
      "Epoch 476: loss = 0.7013476490974426\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.016512848436832428 cvt_loss:  0.3382730297744274 chamfer_loss_mesh:  0.339505379088223\n",
      "Epoch 477: loss = 0.6971506476402283\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.015914442017674446 cvt_loss:  0.33665879163891077 chamfer_loss_mesh:  0.3345033328514546\n",
      "Epoch 478: loss = 0.6899343729019165\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.01716863550245762 cvt_loss:  0.335455103777349 chamfer_loss_mesh:  0.3312087501399219\n",
      "Epoch 479: loss = 0.6866883039474487\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.02711549773812294 cvt_loss:  0.33462957944720984 chamfer_loss_mesh:  0.335209391778335\n",
      "Epoch 480: loss = 0.6998101472854614\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0264300387352705 cvt_loss:  0.33371299505233765 chamfer_loss_mesh:  0.3310584870632738\n",
      "Epoch 481: loss = 0.6940571665763855\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "sites length BEFORE UPSAMPLING:  21664\n",
      "Sampled indices: 1884 out of 10825 candidates (M=2166)\n",
      "Estimated eps_H:  tensor(0.3504, device='cuda:0')\n",
      "sites shape AFTER:  torch.Size([29200, 3])\n",
      "sites sdf shape AFTER:  torch.Size([29200])\n",
      "eikonal_loss:  0.019647400826215744 cvt_loss:  0.40944311767816544 chamfer_loss_mesh:  0.3665091935545206\n",
      "Epoch 482: loss = 0.7977392673492432\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.011662721633911133 cvt_loss:  0.40056826546788216 chamfer_loss_mesh:  0.3643716627266258\n",
      "Epoch 483: loss = 0.7787384986877441\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.009554672054946423 cvt_loss:  0.38283043541014194 chamfer_loss_mesh:  0.35946303978562355\n",
      "Epoch 484: loss = 0.753984272480011\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.008625773712992668 cvt_loss:  0.37156762555241585 chamfer_loss_mesh:  0.35311278770677745\n",
      "Epoch 485: loss = 0.7354390621185303\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.00786248967051506 cvt_loss:  0.368690537288785 chamfer_loss_mesh:  0.3478165599517524\n",
      "Epoch 486: loss = 0.7265002131462097\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.008259778842329979 cvt_loss:  0.36299731582403183 chamfer_loss_mesh:  0.34183423849754035\n",
      "Epoch 487: loss = 0.715218186378479\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0074381097219884396 cvt_loss:  0.3588761202991009 chamfer_loss_mesh:  0.3365529119037092\n",
      "Epoch 488: loss = 0.7049921751022339\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.008571638725697994 cvt_loss:  0.35316350404173136 chamfer_loss_mesh:  0.3289944725111127\n",
      "Epoch 489: loss = 0.6928530335426331\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.007973870262503624 cvt_loss:  0.34915979485958815 chamfer_loss_mesh:  0.32328563975170255\n",
      "Epoch 490: loss = 0.6825408339500427\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0075219240970909595 cvt_loss:  0.34430953674018383 chamfer_loss_mesh:  0.3195617173332721\n",
      "Epoch 491: loss = 0.6735141277313232\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.007376211695373058 cvt_loss:  0.34151780419051647 chamfer_loss_mesh:  0.3167715622112155\n",
      "Epoch 492: loss = 0.6677845120429993\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0115923210978508 cvt_loss:  0.33813712652772665 chamfer_loss_mesh:  0.3127939999103546\n",
      "Epoch 493: loss = 0.6646411418914795\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.011673398315906525 cvt_loss:  0.33467304892838 chamfer_loss_mesh:  0.3138121101073921\n",
      "Epoch 494: loss = 0.6622758507728577\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.007315680384635925 cvt_loss:  0.3306496422737837 chamfer_loss_mesh:  0.3075786225963384\n",
      "Epoch 495: loss = 0.6476610898971558\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.008202120661735535 cvt_loss:  0.32755923457443714 chamfer_loss_mesh:  0.30445930315181613\n",
      "Epoch 496: loss = 0.642336905002594\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.008779380470514297 cvt_loss:  0.3249281318858266 chamfer_loss_mesh:  0.30212002457119524\n",
      "Epoch 497: loss = 0.6379436254501343\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.01247948408126831 cvt_loss:  0.32397639006376266 chamfer_loss_mesh:  0.29793911380693316\n",
      "Epoch 498: loss = 0.6365102529525757\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.011805592104792595 cvt_loss:  0.32122228294610977 chamfer_loss_mesh:  0.2951777714770287\n",
      "Epoch 499: loss = 0.6303175091743469\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "Estimated eps_H:  tensor(0.2786, device='cuda:0')\n",
      "eikonal_loss:  0.012016354128718376 cvt_loss:  0.3185767913237214 chamfer_loss_mesh:  0.2908634196501225\n",
      "Epoch 500: loss = 0.6236019730567932\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.012052631005644798 cvt_loss:  0.3169511677697301 chamfer_loss_mesh:  0.28797268169000745\n",
      "Epoch 501: loss = 0.6191211342811584\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.011696289293467999 cvt_loss:  0.31431533861905336 chamfer_loss_mesh:  0.2859107917174697\n",
      "Epoch 502: loss = 0.6140670776367188\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.010296887718141079 cvt_loss:  0.31359465792775154 chamfer_loss_mesh:  0.28109928825870156\n",
      "Epoch 503: loss = 0.6071329712867737\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.010372460819780827 cvt_loss:  0.311343721114099 chamfer_loss_mesh:  0.27737783966585994\n",
      "Epoch 504: loss = 0.6012365818023682\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.010407754220068455 cvt_loss:  0.30876961536705494 chamfer_loss_mesh:  0.2745854144450277\n",
      "Epoch 505: loss = 0.5959044098854065\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.010315142571926117 cvt_loss:  0.30728583224117756 chamfer_loss_mesh:  0.2711897250264883\n",
      "Epoch 506: loss = 0.5909309983253479\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.01012477558106184 cvt_loss:  0.3049249527975917 chamfer_loss_mesh:  0.2684950304683298\n",
      "Epoch 507: loss = 0.5856839418411255\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.01053826417773962 cvt_loss:  0.30304647516459227 chamfer_loss_mesh:  0.2670849207788706\n",
      "Epoch 508: loss = 0.5828076004981995\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.008247279562056065 cvt_loss:  0.30058822594583035 chamfer_loss_mesh:  0.2694353461265564\n",
      "Epoch 509: loss = 0.5804070830345154\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.008164300583302975 cvt_loss:  0.3016203176230192 chamfer_loss_mesh:  0.26547780726104975\n",
      "Epoch 510: loss = 0.5773980617523193\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.008095849305391312 cvt_loss:  0.30036596581339836 chamfer_loss_mesh:  0.2636048011481762\n",
      "Epoch 511: loss = 0.5742008686065674\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.008053809404373169 cvt_loss:  0.2998594893142581 chamfer_loss_mesh:  0.2628368674777448\n",
      "Epoch 512: loss = 0.5728827714920044\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.008197946473956108 cvt_loss:  0.2979535376653075 chamfer_loss_mesh:  0.2591910306364298\n",
      "Epoch 513: loss = 0.5674731731414795\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.007164807058870792 cvt_loss:  0.29521603137254715 chamfer_loss_mesh:  0.2582562156021595\n",
      "Epoch 514: loss = 0.5627649426460266\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.007613802328705788 cvt_loss:  0.29336498118937016 chamfer_loss_mesh:  0.25596219347789884\n",
      "Epoch 515: loss = 0.5590674877166748\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.007437871769070625 cvt_loss:  0.29185269959270954 chamfer_loss_mesh:  0.25216848007403314\n",
      "Epoch 516: loss = 0.5535838603973389\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0066789728589355946 cvt_loss:  0.2902485430240631 chamfer_loss_mesh:  0.2488013415131718\n",
      "Epoch 517: loss = 0.5478515028953552\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.00674265855923295 cvt_loss:  0.2881461288779974 chamfer_loss_mesh:  0.24646727251820266\n",
      "Epoch 518: loss = 0.5434784889221191\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.00638880068436265 cvt_loss:  0.28679887764155865 chamfer_loss_mesh:  0.24697036133147776\n",
      "Epoch 519: loss = 0.5422796607017517\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.006194017827510834 cvt_loss:  0.2856051316484809 chamfer_loss_mesh:  0.24651800049468875\n",
      "Epoch 520: loss = 0.5404380559921265\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.006755249574780464 cvt_loss:  0.28386248741298914 chamfer_loss_mesh:  0.24480829597450793\n",
      "Epoch 521: loss = 0.5375459790229797\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.007160527165979147 cvt_loss:  0.28286571614444256 chamfer_loss_mesh:  0.24110042431857437\n",
      "Epoch 522: loss = 0.5332460999488831\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.007085841149091721 cvt_loss:  0.283252727240324 chamfer_loss_mesh:  0.24296779884025455\n",
      "Epoch 523: loss = 0.5354251265525818\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.00707382895052433 cvt_loss:  0.2819974208250642 chamfer_loss_mesh:  0.2399539080215618\n",
      "Epoch 524: loss = 0.5311442017555237\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.007317115552723408 cvt_loss:  0.2805976429954171 chamfer_loss_mesh:  0.23753462301101536\n",
      "Epoch 525: loss = 0.5275683403015137\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.007547691930085421 cvt_loss:  0.27981249149888754 chamfer_loss_mesh:  0.2389851724728942\n",
      "Epoch 526: loss = 0.5284636616706848\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.006893970537930727 cvt_loss:  0.27849453035742044 chamfer_loss_mesh:  0.2363250096095726\n",
      "Epoch 527: loss = 0.5238299369812012\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.00679636187851429 cvt_loss:  0.27744241524487734 chamfer_loss_mesh:  0.23371529823634773\n",
      "Epoch 528: loss = 0.5200697183609009\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.006826629862189293 cvt_loss:  0.2765809651464224 chamfer_loss_mesh:  0.23085995053406805\n",
      "Epoch 529: loss = 0.5163838863372803\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.006916155107319355 cvt_loss:  0.27508900966495275 chamfer_loss_mesh:  0.22906290541868657\n",
      "Epoch 530: loss = 0.5131845474243164\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.007349965628236532 cvt_loss:  0.2740785013884306 chamfer_loss_mesh:  0.22723425354342908\n",
      "Epoch 531: loss = 0.51077800989151\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.009291994385421276 cvt_loss:  0.2731901127845049 chamfer_loss_mesh:  0.22494276345241815\n",
      "Epoch 532: loss = 0.5095383524894714\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.008989264257252216 cvt_loss:  0.2723115961998701 chamfer_loss_mesh:  0.22413599072024226\n",
      "Epoch 533: loss = 0.5075507164001465\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.008246451616287231 cvt_loss:  0.2731945598497987 chamfer_loss_mesh:  0.2224636118626222\n",
      "Epoch 534: loss = 0.5060194730758667\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.008375773206353188 cvt_loss:  0.27217441238462925 chamfer_loss_mesh:  0.22079498739913106\n",
      "Epoch 535: loss = 0.5034579634666443\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.008136695250868797 cvt_loss:  0.2710469998419285 chamfer_loss_mesh:  0.21986976207699627\n",
      "Epoch 536: loss = 0.5011662840843201\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.00840301439166069 cvt_loss:  0.2701855031773448 chamfer_loss_mesh:  0.2184874756494537\n",
      "Epoch 537: loss = 0.4991881251335144\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.008506829850375652 cvt_loss:  0.26879177894443274 chamfer_loss_mesh:  0.2165411424357444\n",
      "Epoch 538: loss = 0.49595126509666443\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.009062394499778748 cvt_loss:  0.26808527763932943 chamfer_loss_mesh:  0.21634934819303453\n",
      "Epoch 539: loss = 0.4956066906452179\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.00893706176429987 cvt_loss:  0.26679777074605227 chamfer_loss_mesh:  0.21417824609670788\n",
      "Epoch 540: loss = 0.4920223355293274\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.010417783632874489 cvt_loss:  0.2663832623511553 chamfer_loss_mesh:  0.2123656595358625\n",
      "Epoch 541: loss = 0.4912745952606201\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.010121846571564674 cvt_loss:  0.2659132471308112 chamfer_loss_mesh:  0.21186878439038992\n",
      "Epoch 542: loss = 0.4900093376636505\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.010976508259773254 cvt_loss:  0.2648911206051707 chamfer_loss_mesh:  0.21289975848048925\n",
      "Epoch 543: loss = 0.4908716082572937\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.009762578643858433 cvt_loss:  0.2639117417857051 chamfer_loss_mesh:  0.21148475934751332\n",
      "Epoch 544: loss = 0.4872604310512543\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.009316784329712391 cvt_loss:  0.26343115605413914 chamfer_loss_mesh:  0.20934274652972817\n",
      "Epoch 545: loss = 0.48419129848480225\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.00807732529938221 cvt_loss:  0.26280072052031755 chamfer_loss_mesh:  0.20935955399181694\n",
      "Epoch 546: loss = 0.48233723640441895\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.00743158208206296 cvt_loss:  0.2631347859278321 chamfer_loss_mesh:  0.20807077817153186\n",
      "Epoch 547: loss = 0.48073530197143555\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.007314505986869335 cvt_loss:  0.2628682879731059 chamfer_loss_mesh:  0.2082807623082772\n",
      "Epoch 548: loss = 0.48056119680404663\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0071222810074687 cvt_loss:  0.262152892537415 chamfer_loss_mesh:  0.2077733661280945\n",
      "Epoch 549: loss = 0.47914454340934753\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.006996734067797661 cvt_loss:  0.26153719518333673 chamfer_loss_mesh:  0.20540936384350061\n",
      "Epoch 550: loss = 0.4760372042655945\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.007627140264958143 cvt_loss:  0.26036370545625687 chamfer_loss_mesh:  0.20297380979172885\n",
      "Epoch 551: loss = 0.4730578362941742\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.00829689297825098 cvt_loss:  0.25923894718289375 chamfer_loss_mesh:  0.201841103262268\n",
      "Epoch 552: loss = 0.47146886587142944\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0077072735875844955 cvt_loss:  0.25871223770081997 chamfer_loss_mesh:  0.2000302483793348\n",
      "Epoch 553: loss = 0.4685411751270294\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.00770860118791461 cvt_loss:  0.2578932559117675 chamfer_loss_mesh:  0.19946746760979295\n",
      "Epoch 554: loss = 0.4671602249145508\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.007453585974872112 cvt_loss:  0.25751686189323664 chamfer_loss_mesh:  0.19864461501128972\n",
      "Epoch 555: loss = 0.46570461988449097\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0073823933489620686 cvt_loss:  0.2570349723100662 chamfer_loss_mesh:  0.19662734121084213\n",
      "Epoch 556: loss = 0.46313339471817017\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.007350843399763107 cvt_loss:  0.2565862610936165 chamfer_loss_mesh:  0.1961290108738467\n",
      "Epoch 557: loss = 0.46215343475341797\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.008178526535630226 cvt_loss:  0.2568037947639823 chamfer_loss_mesh:  0.1950499863596633\n",
      "Epoch 558: loss = 0.4621189534664154\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.007827877067029476 cvt_loss:  0.25623717810958624 chamfer_loss_mesh:  0.1957577042048797\n",
      "Epoch 559: loss = 0.4619079530239105\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.007627546321600676 cvt_loss:  0.25547100231051445 chamfer_loss_mesh:  0.19519831403158605\n",
      "Epoch 560: loss = 0.4603811800479889\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.007747923955321312 cvt_loss:  0.2565452363342047 chamfer_loss_mesh:  0.1939578796736896\n",
      "Epoch 561: loss = 0.46033400297164917\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "sites length BEFORE UPSAMPLING:  29200\n",
      "Sampled indices: 2593 out of 15690 candidates (M=2920)\n",
      "Estimated eps_H:  tensor(0.2818, device='cuda:0')\n",
      "sites shape AFTER:  torch.Size([39572, 3])\n",
      "sites sdf shape AFTER:  torch.Size([39572])\n",
      "eikonal_loss:  0.00779705960303545 cvt_loss:  0.3252255264669657 chamfer_loss_mesh:  0.22247937158681452\n",
      "Epoch 562: loss = 0.5570366382598877\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0072496989741921425 cvt_loss:  0.3187383757904172 chamfer_loss_mesh:  0.22238785459194332\n",
      "Epoch 563: loss = 0.5499072670936584\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.008425730280578136 cvt_loss:  0.30236856546252966 chamfer_loss_mesh:  0.21510460646823049\n",
      "Epoch 564: loss = 0.5274280309677124\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.007714122533798218 cvt_loss:  0.29386524111032486 chamfer_loss_mesh:  0.21216498862486333\n",
      "Epoch 565: loss = 0.5152703523635864\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.007852482609450817 cvt_loss:  0.2867433475330472 chamfer_loss_mesh:  0.21208799444139004\n",
      "Epoch 566: loss = 0.5082066655158997\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.00776316225528717 cvt_loss:  0.28201998211443424 chamfer_loss_mesh:  0.21038948034401983\n",
      "Epoch 567: loss = 0.5016931891441345\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.007601911202073097 cvt_loss:  0.27723803650587797 chamfer_loss_mesh:  0.21007272880524397\n",
      "Epoch 568: loss = 0.496431827545166\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.007556145545095205 cvt_loss:  0.27474050875753164 chamfer_loss_mesh:  0.20837655756622553\n",
      "Epoch 569: loss = 0.4921905994415283\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.007581675425171852 cvt_loss:  0.27135948184877634 chamfer_loss_mesh:  0.2057600358966738\n",
      "Epoch 570: loss = 0.4862176179885864\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.00826453696936369 cvt_loss:  0.2679122146219015 chamfer_loss_mesh:  0.20190590294077992\n",
      "Epoch 571: loss = 0.4795975089073181\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.008161948062479496 cvt_loss:  0.26532430201768875 chamfer_loss_mesh:  0.19821664318442345\n",
      "Epoch 572: loss = 0.47321605682373047\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.008189001120626926 cvt_loss:  0.26289690285921097 chamfer_loss_mesh:  0.19483306095935404\n",
      "Epoch 573: loss = 0.46743088960647583\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.007582695689052343 cvt_loss:  0.2615434117615223 chamfer_loss_mesh:  0.19280496053397655\n",
      "Epoch 574: loss = 0.4634418785572052\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.007394964806735516 cvt_loss:  0.25877112057060003 chamfer_loss_mesh:  0.19065136439166963\n",
      "Epoch 575: loss = 0.4583275318145752\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.007349526509642601 cvt_loss:  0.2579017775133252 chamfer_loss_mesh:  0.18844238366000354\n",
      "Epoch 576: loss = 0.45520347356796265\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.007321850396692753 cvt_loss:  0.2557400381192565 chamfer_loss_mesh:  0.1859331241576001\n",
      "Epoch 577: loss = 0.4505033493041992\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0076758526265621185 cvt_loss:  0.25429169181734324 chamfer_loss_mesh:  0.18409088079351932\n",
      "Epoch 578: loss = 0.44756558537483215\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.008098959922790527 cvt_loss:  0.2527049044147134 chamfer_loss_mesh:  0.1861241617007181\n",
      "Epoch 579: loss = 0.44843411445617676\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.007372634019702673 cvt_loss:  0.2504828618839383 chamfer_loss_mesh:  0.18237309996038675\n",
      "Epoch 580: loss = 0.441733717918396\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.006912066601216793 cvt_loss:  0.24857872631400824 chamfer_loss_mesh:  0.18238065240439028\n",
      "Epoch 581: loss = 0.43937626481056213\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.006708213593810797 cvt_loss:  0.24700025096535683 chamfer_loss_mesh:  0.1827885425882414\n",
      "Epoch 582: loss = 0.4380020797252655\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.00695628160610795 cvt_loss:  0.24610753171145916 chamfer_loss_mesh:  0.1810819812817499\n",
      "Epoch 583: loss = 0.4356497526168823\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.007185079623013735 cvt_loss:  0.24660953786224127 chamfer_loss_mesh:  0.17968261090572923\n",
      "Epoch 584: loss = 0.43498027324676514\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.007064515259116888 cvt_loss:  0.24481567088514566 chamfer_loss_mesh:  0.1781197206582874\n",
      "Epoch 585: loss = 0.43150249123573303\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.006916818208992481 cvt_loss:  0.24382290430366993 chamfer_loss_mesh:  0.17811261932365596\n",
      "Epoch 586: loss = 0.4303555488586426\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0068159098736941814 cvt_loss:  0.2424121368676424 chamfer_loss_mesh:  0.17715757712721825\n",
      "Epoch 587: loss = 0.4278881847858429\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.006458813324570656 cvt_loss:  0.24089638609439135 chamfer_loss_mesh:  0.17427770944777876\n",
      "Epoch 588: loss = 0.42313453555107117\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0063247280195355415 cvt_loss:  0.2398163778707385 chamfer_loss_mesh:  0.17253051919396967\n",
      "Epoch 589: loss = 0.4201720356941223\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.006360938772559166 cvt_loss:  0.2383924089372158 chamfer_loss_mesh:  0.1701327710179612\n",
      "Epoch 590: loss = 0.4163854718208313\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.006274559535086155 cvt_loss:  0.2368387533351779 chamfer_loss_mesh:  0.1680537243373692\n",
      "Epoch 591: loss = 0.4126657247543335\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0062009720131754875 cvt_loss:  0.23580819834023714 chamfer_loss_mesh:  0.16693599172867835\n",
      "Epoch 592: loss = 0.410444438457489\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.006338919512927532 cvt_loss:  0.23444946855306625 chamfer_loss_mesh:  0.1661559654166922\n",
      "Epoch 593: loss = 0.4084421992301941\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.006724362261593342 cvt_loss:  0.2334774937480688 chamfer_loss_mesh:  0.16445500659756362\n",
      "Epoch 594: loss = 0.4061529338359833\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.007114713080227375 cvt_loss:  0.23220316506922245 chamfer_loss_mesh:  0.1643595314817503\n",
      "Epoch 595: loss = 0.4051726758480072\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.009968861937522888 cvt_loss:  0.23138634860515594 chamfer_loss_mesh:  0.1631200866540894\n",
      "Epoch 596: loss = 0.4059702157974243\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.007432699203491211 cvt_loss:  0.2307089976966381 chamfer_loss_mesh:  0.16178069927264005\n",
      "Epoch 597: loss = 0.4014167785644531\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.007258955389261246 cvt_loss:  0.2288409974426031 chamfer_loss_mesh:  0.16023269563447684\n",
      "Epoch 598: loss = 0.3978257477283478\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.007011804264038801 cvt_loss:  0.22723348811268806 chamfer_loss_mesh:  0.15829122276045382\n",
      "Epoch 599: loss = 0.39402928948402405\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "Estimated eps_H:  tensor(0.0893, device='cuda:0')\n",
      "eikonal_loss:  0.006906919181346893 cvt_loss:  0.22579822689294815 chamfer_loss_mesh:  0.15748011355753988\n",
      "Epoch 600: loss = 0.3917953372001648\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.006881373003125191 cvt_loss:  0.22520110942423344 chamfer_loss_mesh:  0.15600371989421546\n",
      "Epoch 601: loss = 0.38969627022743225\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.006968132685869932 cvt_loss:  0.2242117654532194 chamfer_loss_mesh:  0.1556388015160337\n",
      "Epoch 602: loss = 0.3884291350841522\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.006889688782393932 cvt_loss:  0.22288209293037653 chamfer_loss_mesh:  0.15461933799088\n",
      "Epoch 603: loss = 0.3860005736351013\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0069222040474414825 cvt_loss:  0.22189223673194647 chamfer_loss_mesh:  0.15373635687865317\n",
      "Epoch 604: loss = 0.3841587007045746\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.006980797275900841 cvt_loss:  0.22119339555501938 chamfer_loss_mesh:  0.1515802287030965\n",
      "Epoch 605: loss = 0.3813613951206207\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.008779606781899929 cvt_loss:  0.2198242349550128 chamfer_loss_mesh:  0.15038391575217247\n",
      "Epoch 606: loss = 0.38059496879577637\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.008085462264716625 cvt_loss:  0.21976556163281202 chamfer_loss_mesh:  0.14941795961931348\n",
      "Epoch 607: loss = 0.37887388467788696\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.007858514785766602 cvt_loss:  0.2185432007536292 chamfer_loss_mesh:  0.14916302461642772\n",
      "Epoch 608: loss = 0.3771691918373108\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.007386407814919949 cvt_loss:  0.21766265854239464 chamfer_loss_mesh:  0.14738115714862943\n",
      "Epoch 609: loss = 0.37403392791748047\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0072252945974469185 cvt_loss:  0.21688819397240877 chamfer_loss_mesh:  0.14825366088189185\n",
      "Epoch 610: loss = 0.3739699125289917\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.007042472716420889 cvt_loss:  0.21682982333004475 chamfer_loss_mesh:  0.14811519940849394\n",
      "Epoch 611: loss = 0.37358948588371277\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.009738152846693993 cvt_loss:  0.21543728653341532 chamfer_loss_mesh:  0.14744997315574437\n",
      "Epoch 612: loss = 0.3742261826992035\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.009424420073628426 cvt_loss:  0.21460633724927902 chamfer_loss_mesh:  0.14642217138316482\n",
      "Epoch 613: loss = 0.37205344438552856\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.00945782195776701 cvt_loss:  0.21412582136690617 chamfer_loss_mesh:  0.14603463932871819\n",
      "Epoch 614: loss = 0.3712177574634552\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.009690845385193825 cvt_loss:  0.21311219315975904 chamfer_loss_mesh:  0.14854848268441856\n",
      "Epoch 615: loss = 0.37295088171958923\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.015982208773493767 cvt_loss:  0.21234198939055204 chamfer_loss_mesh:  0.14756475866306573\n",
      "Epoch 616: loss = 0.3774878680706024\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.020252082496881485 cvt_loss:  0.2115603070706129 chamfer_loss_mesh:  0.14748296234756708\n",
      "Epoch 617: loss = 0.3808944821357727\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.01906784437596798 cvt_loss:  0.21131082903593779 chamfer_loss_mesh:  0.14718799502588809\n",
      "Epoch 618: loss = 0.37916550040245056\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.018941059708595276 cvt_loss:  0.21059282589703798 chamfer_loss_mesh:  0.14577951515093446\n",
      "Epoch 619: loss = 0.3769114017486572\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.017887769266963005 cvt_loss:  0.21034337114542723 chamfer_loss_mesh:  0.14372053556144238\n",
      "Epoch 620: loss = 0.37355080246925354\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.01566142588853836 cvt_loss:  0.2098349155858159 chamfer_loss_mesh:  0.143585741170682\n",
      "Epoch 621: loss = 0.37067997455596924\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.01687128283083439 cvt_loss:  0.20992928184568882 chamfer_loss_mesh:  0.14256697613745928\n",
      "Epoch 622: loss = 0.3709651827812195\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.018175199627876282 cvt_loss:  0.2098999684676528 chamfer_loss_mesh:  0.14220461889635772\n",
      "Epoch 623: loss = 0.37187692523002625\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.015022093430161476 cvt_loss:  0.20908666774630547 chamfer_loss_mesh:  0.14153514348436147\n",
      "Epoch 624: loss = 0.3672407865524292\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.01381506398320198 cvt_loss:  0.20842074882239103 chamfer_loss_mesh:  0.14048340381123126\n",
      "Epoch 625: loss = 0.36431577801704407\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.013064044527709484 cvt_loss:  0.20811725407838821 chamfer_loss_mesh:  0.1401955814799294\n",
      "Epoch 626: loss = 0.3629716634750366\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.012369325384497643 cvt_loss:  0.20722933113574982 chamfer_loss_mesh:  0.13843431952409446\n",
      "Epoch 627: loss = 0.35962751507759094\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.01131362747400999 cvt_loss:  0.206395098939538 chamfer_loss_mesh:  0.1377027074340731\n",
      "Epoch 628: loss = 0.35700616240501404\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.011037812568247318 cvt_loss:  0.2060256665572524 chamfer_loss_mesh:  0.13779955042991787\n",
      "Epoch 629: loss = 0.35645774006843567\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.010272407904267311 cvt_loss:  0.20537388045340776 chamfer_loss_mesh:  0.13676239177584648\n",
      "Epoch 630: loss = 0.35400229692459106\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.008662601932883263 cvt_loss:  0.20461981184780598 chamfer_loss_mesh:  0.1363113260595128\n",
      "Epoch 631: loss = 0.3511863648891449\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.00846779067069292 cvt_loss:  0.20462856628000736 chamfer_loss_mesh:  0.13384423800744116\n",
      "Epoch 632: loss = 0.3485317826271057\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.008071014657616615 cvt_loss:  0.20384285598993301 chamfer_loss_mesh:  0.13313873205333948\n",
      "Epoch 633: loss = 0.3466433584690094\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.008324867114424706 cvt_loss:  0.2040503779426217 chamfer_loss_mesh:  0.1330967788817361\n",
      "Epoch 634: loss = 0.34706228971481323\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.006692723836749792 cvt_loss:  0.20325873047113419 chamfer_loss_mesh:  0.13276237586978823\n",
      "Epoch 635: loss = 0.34430330991744995\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.006606982089579105 cvt_loss:  0.2024431712925434 chamfer_loss_mesh:  0.1333823602180928\n",
      "Epoch 636: loss = 0.3440224230289459\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.006505219265818596 cvt_loss:  0.20170214120298624 chamfer_loss_mesh:  0.13262561697047204\n",
      "Epoch 637: loss = 0.3424224853515625\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.006288091652095318 cvt_loss:  0.2015191363170743 chamfer_loss_mesh:  0.1307080965489149\n",
      "Epoch 638: loss = 0.3401041328907013\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.006331435404717922 cvt_loss:  0.20105976145714521 chamfer_loss_mesh:  0.1298281567869708\n",
      "Epoch 639: loss = 0.33880725502967834\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.006246699020266533 cvt_loss:  0.20067570731043816 chamfer_loss_mesh:  0.1295250840485096\n",
      "Epoch 640: loss = 0.3380354344844818\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0067633455619215965 cvt_loss:  0.20003544632345438 chamfer_loss_mesh:  0.1285836478928104\n",
      "Epoch 641: loss = 0.33696940541267395\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "sites length BEFORE UPSAMPLING:  39572\n",
      "Sampled indices: 3520 out of 22620 candidates (M=3957)\n",
      "Estimated eps_H:  tensor(0.2251, device='cuda:0')\n",
      "sites shape AFTER:  torch.Size([53652, 3])\n",
      "sites sdf shape AFTER:  torch.Size([53652])\n",
      "eikonal_loss:  0.006871539633721113 cvt_loss:  0.2690366702154279 chamfer_loss_mesh:  0.15485729090869427\n",
      "Epoch 642: loss = 0.43188196420669556\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.006501981522887945 cvt_loss:  0.26233564130961895 chamfer_loss_mesh:  0.15310737944673747\n",
      "Epoch 643: loss = 0.42305788397789\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.006547083146870136 cvt_loss:  0.24721247609704733 chamfer_loss_mesh:  0.15166013326961547\n",
      "Epoch 644: loss = 0.4065301716327667\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.006364841945469379 cvt_loss:  0.2381897997111082 chamfer_loss_mesh:  0.14838436618447304\n",
      "Epoch 645: loss = 0.3940467834472656\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.006400663871318102 cvt_loss:  0.2326861023902893 chamfer_loss_mesh:  0.14626946358475834\n",
      "Epoch 646: loss = 0.38646119832992554\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.006305754650384188 cvt_loss:  0.22851454559713602 chamfer_loss_mesh:  0.14456023927778006\n",
      "Epoch 647: loss = 0.3804830312728882\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.006462635938078165 cvt_loss:  0.22480175830423832 chamfer_loss_mesh:  0.1428477989975363\n",
      "Epoch 648: loss = 0.375213086605072\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.006455995608121157 cvt_loss:  0.22158392239362001 chamfer_loss_mesh:  0.14153969823382795\n",
      "Epoch 649: loss = 0.37067911028862\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0065985736437141895 cvt_loss:  0.21859090775251389 chamfer_loss_mesh:  0.13972973101772368\n",
      "Epoch 650: loss = 0.36601799726486206\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.006468081381171942 cvt_loss:  0.21540499292314053 chamfer_loss_mesh:  0.13790803495794535\n",
      "Epoch 651: loss = 0.3608790636062622\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.006138177588582039 cvt_loss:  0.21314513869583607 chamfer_loss_mesh:  0.13686410966329277\n",
      "Epoch 652: loss = 0.35724490880966187\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.006180398166179657 cvt_loss:  0.21161080803722143 chamfer_loss_mesh:  0.1376326399622485\n",
      "Epoch 653: loss = 0.35652056336402893\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.00631640013307333 cvt_loss:  0.21081729792058468 chamfer_loss_mesh:  0.13540776853915304\n",
      "Epoch 654: loss = 0.3536369502544403\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.00628188531845808 cvt_loss:  0.2096424112096429 chamfer_loss_mesh:  0.13455965381581336\n",
      "Epoch 655: loss = 0.3515785038471222\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.006359659135341644 cvt_loss:  0.20764123182743788 chamfer_loss_mesh:  0.1334555126959458\n",
      "Epoch 656: loss = 0.3485504984855652\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.006142164580523968 cvt_loss:  0.20600538700819016 chamfer_loss_mesh:  0.1343495532637462\n",
      "Epoch 657: loss = 0.34759077429771423\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.00613437732681632 cvt_loss:  0.20444905385375023 chamfer_loss_mesh:  0.13375435082707554\n",
      "Epoch 658: loss = 0.3454304039478302\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.006160333752632141 cvt_loss:  0.2029783558100462 chamfer_loss_mesh:  0.13309756468515843\n",
      "Epoch 659: loss = 0.3433275818824768\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0060724192298948765 cvt_loss:  0.20259490702301264 chamfer_loss_mesh:  0.13116400805301964\n",
      "Epoch 660: loss = 0.3409218490123749\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0061541153118014336 cvt_loss:  0.20062902476638556 chamfer_loss_mesh:  0.13002521882299334\n",
      "Epoch 661: loss = 0.33789780735969543\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.006093395873904228 cvt_loss:  0.1989350188523531 chamfer_loss_mesh:  0.1291046355618164\n",
      "Epoch 662: loss = 0.33522212505340576\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.006160805933177471 cvt_loss:  0.19755938556045294 chamfer_loss_mesh:  0.12860196875408292\n",
      "Epoch 663: loss = 0.3334105312824249\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.006172805093228817 cvt_loss:  0.19646375440061092 chamfer_loss_mesh:  0.1277656847378239\n",
      "Epoch 664: loss = 0.3314898610115051\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.006222795695066452 cvt_loss:  0.19497834146022797 chamfer_loss_mesh:  0.12658645573537797\n",
      "Epoch 665: loss = 0.32887449860572815\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.006176238413900137 cvt_loss:  0.19355459371581674 chamfer_loss_mesh:  0.12598875036928803\n",
      "Epoch 666: loss = 0.326805979013443\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.006098534911870956 cvt_loss:  0.1929307822138071 chamfer_loss_mesh:  0.12550412793643773\n",
      "Epoch 667: loss = 0.32561954855918884\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.00615732092410326 cvt_loss:  0.19188682781532407 chamfer_loss_mesh:  0.12388647883199155\n",
      "Epoch 668: loss = 0.32301610708236694\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.006153681315481663 cvt_loss:  0.19058716716244817 chamfer_loss_mesh:  0.12355286162346601\n",
      "Epoch 669: loss = 0.32137900590896606\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.006096196360886097 cvt_loss:  0.18935425905510783 chamfer_loss_mesh:  0.12245475954841822\n",
      "Epoch 670: loss = 0.31898972392082214\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.006076199002563953 cvt_loss:  0.18871212378144264 chamfer_loss_mesh:  0.1215997981489636\n",
      "Epoch 671: loss = 0.3174724578857422\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.006027256604284048 cvt_loss:  0.18753419863060117 chamfer_loss_mesh:  0.12086231436114758\n",
      "Epoch 672: loss = 0.31550711393356323\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.006018908694386482 cvt_loss:  0.18651599530130625 chamfer_loss_mesh:  0.11995395470876247\n",
      "Epoch 673: loss = 0.3135714530944824\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005925851874053478 cvt_loss:  0.18522907048463821 chamfer_loss_mesh:  0.11986837489530444\n",
      "Epoch 674: loss = 0.3121054768562317\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005935387685894966 cvt_loss:  0.18458501435816288 chamfer_loss_mesh:  0.11951778287766501\n",
      "Epoch 675: loss = 0.31111952662467957\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005877852439880371 cvt_loss:  0.18395722145214677 chamfer_loss_mesh:  0.11899061064468697\n",
      "Epoch 676: loss = 0.3099063038825989\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005876678973436356 cvt_loss:  0.18321463139727712 chamfer_loss_mesh:  0.11985058517893776\n",
      "Epoch 677: loss = 0.3100217282772064\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005869872402399778 cvt_loss:  0.18206273671239614 chamfer_loss_mesh:  0.11959979019593447\n",
      "Epoch 678: loss = 0.30861127376556396\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005870708730071783 cvt_loss:  0.18128205556422472 chamfer_loss_mesh:  0.11751463898690417\n",
      "Epoch 679: loss = 0.3057454824447632\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0058029647916555405 cvt_loss:  0.18093553371727467 chamfer_loss_mesh:  0.11706284567480907\n",
      "Epoch 680: loss = 0.3048790991306305\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0057724881917238235 cvt_loss:  0.1804303959943354 chamfer_loss_mesh:  0.11691652616718784\n",
      "Epoch 681: loss = 0.30419716238975525\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005805899389088154 cvt_loss:  0.17992613138630986 chamfer_loss_mesh:  0.1161945256171748\n",
      "Epoch 682: loss = 0.3030036389827728\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.00582515774294734 cvt_loss:  0.17841256922110915 chamfer_loss_mesh:  0.11542245920281857\n",
      "Epoch 683: loss = 0.30073678493499756\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005789407528936863 cvt_loss:  0.1776196644641459 chamfer_loss_mesh:  0.11544905282789841\n",
      "Epoch 684: loss = 0.2999345362186432\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.00578894792124629 cvt_loss:  0.17698786687105894 chamfer_loss_mesh:  0.11478134547360241\n",
      "Epoch 685: loss = 0.2986341714859009\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005769751034677029 cvt_loss:  0.17612387891858816 chamfer_loss_mesh:  0.11338098556734622\n",
      "Epoch 686: loss = 0.2963496148586273\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005749222822487354 cvt_loss:  0.17569900956004858 chamfer_loss_mesh:  0.11294772411929443\n",
      "Epoch 687: loss = 0.29547008872032166\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005751802120357752 cvt_loss:  0.1747660804539919 chamfer_loss_mesh:  0.11188528151251376\n",
      "Epoch 688: loss = 0.2934761643409729\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005703735165297985 cvt_loss:  0.17534018261358142 chamfer_loss_mesh:  0.11134951637359336\n",
      "Epoch 689: loss = 0.29346632957458496\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005670236423611641 cvt_loss:  0.17445693956688046 chamfer_loss_mesh:  0.10930463031399995\n",
      "Epoch 690: loss = 0.2905038893222809\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0056668841280043125 cvt_loss:  0.17383511876687407 chamfer_loss_mesh:  0.10904247756116092\n",
      "Epoch 691: loss = 0.2896169424057007\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005670394282788038 cvt_loss:  0.1743305241689086 chamfer_loss_mesh:  0.10852740524569526\n",
      "Epoch 692: loss = 0.2896004915237427\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005695428233593702 cvt_loss:  0.17463110852986574 chamfer_loss_mesh:  0.10839389869943261\n",
      "Epoch 693: loss = 0.28979161381721497\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005673930048942566 cvt_loss:  0.1738140475936234 chamfer_loss_mesh:  0.10804212070070207\n",
      "Epoch 694: loss = 0.28860074281692505\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005562286823987961 cvt_loss:  0.1734368153847754 chamfer_loss_mesh:  0.10743359598563984\n",
      "Epoch 695: loss = 0.2875029742717743\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005518937949091196 cvt_loss:  0.1722958986647427 chamfer_loss_mesh:  0.1070046637323685\n",
      "Epoch 696: loss = 0.28588923811912537\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005483236163854599 cvt_loss:  0.17097677337005734 chamfer_loss_mesh:  0.10758686403278261\n",
      "Epoch 697: loss = 0.2851163148880005\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005479589104652405 cvt_loss:  0.1702858367934823 chamfer_loss_mesh:  0.10707080946303904\n",
      "Epoch 698: loss = 0.28390511870384216\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0055262502282857895 cvt_loss:  0.1702080713585019 chamfer_loss_mesh:  0.10682544962037355\n",
      "Epoch 699: loss = 0.2836281657218933\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "Estimated eps_H:  tensor(0.0717, device='cuda:0')\n",
      "eikonal_loss:  0.005535580217838287 cvt_loss:  0.1699337735772133 chamfer_loss_mesh:  0.10672127245925367\n",
      "Epoch 700: loss = 0.28337061405181885\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005500502418726683 cvt_loss:  0.16918870387598872 chamfer_loss_mesh:  0.10584303527139127\n",
      "Epoch 701: loss = 0.2817123234272003\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.00545098539441824 cvt_loss:  0.16880669863894582 chamfer_loss_mesh:  0.10734670649981126\n",
      "Epoch 702: loss = 0.28278499841690063\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005420180037617683 cvt_loss:  0.16781430458649993 chamfer_loss_mesh:  0.10649640171322972\n",
      "Epoch 703: loss = 0.28091055154800415\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0053892056457698345 cvt_loss:  0.16742597799748182 chamfer_loss_mesh:  0.10571246093604714\n",
      "Epoch 704: loss = 0.2797068953514099\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005354804918169975 cvt_loss:  0.1670102239586413 chamfer_loss_mesh:  0.10403578926343471\n",
      "Epoch 705: loss = 0.2775789797306061\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005366573575884104 cvt_loss:  0.16655216459184885 chamfer_loss_mesh:  0.10344335896661505\n",
      "Epoch 706: loss = 0.27653977274894714\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005379972979426384 cvt_loss:  0.1659799017943442 chamfer_loss_mesh:  0.10324914910597727\n",
      "Epoch 707: loss = 0.27578625082969666\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005374461878091097 cvt_loss:  0.1650874619372189 chamfer_loss_mesh:  0.10258775000693277\n",
      "Epoch 708: loss = 0.27422603964805603\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005384764634072781 cvt_loss:  0.1648691133596003 chamfer_loss_mesh:  0.10194985225098208\n",
      "Epoch 709: loss = 0.2733796536922455\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005332112777978182 cvt_loss:  0.16469383845105767 chamfer_loss_mesh:  0.10116936755366623\n",
      "Epoch 710: loss = 0.27237069606781006\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005284263286739588 cvt_loss:  0.16462778439745307 chamfer_loss_mesh:  0.10050469427369535\n",
      "Epoch 711: loss = 0.2715909481048584\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005305013619363308 cvt_loss:  0.16412073746323586 chamfer_loss_mesh:  0.10185364226344973\n",
      "Epoch 712: loss = 0.2724525034427643\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005279840435832739 cvt_loss:  0.16361776506528258 chamfer_loss_mesh:  0.10167845175601542\n",
      "Epoch 713: loss = 0.2717483937740326\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005272764712572098 cvt_loss:  0.1630912534892559 chamfer_loss_mesh:  0.1009625630103983\n",
      "Epoch 714: loss = 0.270498126745224\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005286699626594782 cvt_loss:  0.16295474488288164 chamfer_loss_mesh:  0.10192905028816313\n",
      "Epoch 715: loss = 0.2713412940502167\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005244417581707239 cvt_loss:  0.1631722552701831 chamfer_loss_mesh:  0.10186544386669993\n",
      "Epoch 716: loss = 0.2714526951313019\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005195107776671648 cvt_loss:  0.1626646495424211 chamfer_loss_mesh:  0.10218695388175547\n",
      "Epoch 717: loss = 0.271215558052063\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005182432010769844 cvt_loss:  0.16239896649494767 chamfer_loss_mesh:  0.1009664119919762\n",
      "Epoch 718: loss = 0.2697162330150604\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005161650944501162 cvt_loss:  0.16209492459893227 chamfer_loss_mesh:  0.1019064147840254\n",
      "Epoch 719: loss = 0.2703310251235962\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005122039467096329 cvt_loss:  0.1616078894585371 chamfer_loss_mesh:  0.10193447087658569\n",
      "Epoch 720: loss = 0.26983219385147095\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005130732897669077 cvt_loss:  0.16203728737309575 chamfer_loss_mesh:  0.10160102101508528\n",
      "Epoch 721: loss = 0.2699365019798279\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "sites length BEFORE UPSAMPLING:  53652\n",
      "Sampled indices: 4801 out of 31513 candidates (M=5365)\n",
      "Estimated eps_H:  tensor(0.1801, device='cuda:0')\n",
      "sites shape AFTER:  torch.Size([72856, 3])\n",
      "sites sdf shape AFTER:  torch.Size([72856])\n",
      "eikonal_loss:  0.005752977449446917 cvt_loss:  0.22088256664574146 chamfer_loss_mesh:  0.12316665379330516\n",
      "Epoch 722: loss = 0.3506004810333252\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005714427214115858 cvt_loss:  0.21564236376434565 chamfer_loss_mesh:  0.12145916844019666\n",
      "Epoch 723: loss = 0.3436119258403778\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005769801326096058 cvt_loss:  0.20194877870380878 chamfer_loss_mesh:  0.11622205056482926\n",
      "Epoch 724: loss = 0.32473430037498474\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005752332974225283 cvt_loss:  0.19327409099787474 chamfer_loss_mesh:  0.1138246661867015\n",
      "Epoch 725: loss = 0.31364256143569946\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005788507405668497 cvt_loss:  0.18911465303972363 chamfer_loss_mesh:  0.11223075853195041\n",
      "Epoch 726: loss = 0.30792367458343506\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005802317522466183 cvt_loss:  0.18531389068812132 chamfer_loss_mesh:  0.11190830264240503\n",
      "Epoch 727: loss = 0.3038131594657898\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005759350024163723 cvt_loss:  0.1818637945689261 chamfer_loss_mesh:  0.11070795881096274\n",
      "Epoch 728: loss = 0.2991189956665039\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005716065876185894 cvt_loss:  0.17949803732335567 chamfer_loss_mesh:  0.10941497021121904\n",
      "Epoch 729: loss = 0.29541683197021484\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005729548167437315 cvt_loss:  0.17727166414260864 chamfer_loss_mesh:  0.10805498459376395\n",
      "Epoch 730: loss = 0.2918437719345093\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005775935016572475 cvt_loss:  0.17516419757157564 chamfer_loss_mesh:  0.10780115553643554\n",
      "Epoch 731: loss = 0.28952884674072266\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.00574348121881485 cvt_loss:  0.1733339624479413 chamfer_loss_mesh:  0.10641792323440313\n",
      "Epoch 732: loss = 0.28628283739089966\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005762315820902586 cvt_loss:  0.1714193494990468 chamfer_loss_mesh:  0.10584860865492374\n",
      "Epoch 733: loss = 0.2838178277015686\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005757598206400871 cvt_loss:  0.17011319287121296 chamfer_loss_mesh:  0.10512136213947088\n",
      "Epoch 734: loss = 0.2817797064781189\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005733340512961149 cvt_loss:  0.16870631370693445 chamfer_loss_mesh:  0.10457789176143706\n",
      "Epoch 735: loss = 0.27980494499206543\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005759557709097862 cvt_loss:  0.16726601170375943 chamfer_loss_mesh:  0.10395526624051854\n",
      "Epoch 736: loss = 0.27776819467544556\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005723560228943825 cvt_loss:  0.16660895198583603 chamfer_loss_mesh:  0.10283562005497515\n",
      "Epoch 737: loss = 0.2759554386138916\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005733459256589413 cvt_loss:  0.16510487766936421 chamfer_loss_mesh:  0.1022138458210975\n",
      "Epoch 738: loss = 0.27383947372436523\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005805119406431913 cvt_loss:  0.16402562614530325 chamfer_loss_mesh:  0.10091378499055281\n",
      "Epoch 739: loss = 0.27153098583221436\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0057433173060417175 cvt_loss:  0.16316755209118128 chamfer_loss_mesh:  0.10074531746795401\n",
      "Epoch 740: loss = 0.27044227719306946\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005709468387067318 cvt_loss:  0.16246510203927755 chamfer_loss_mesh:  0.10042331268778071\n",
      "Epoch 741: loss = 0.26938363909721375\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005683287978172302 cvt_loss:  0.16148330178111792 chamfer_loss_mesh:  0.09928629151545465\n",
      "Epoch 742: loss = 0.2672387361526489\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.00570834893733263 cvt_loss:  0.16027343226596713 chamfer_loss_mesh:  0.09884966857498512\n",
      "Epoch 743: loss = 0.265617311000824\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005639031995087862 cvt_loss:  0.1594638917595148 chamfer_loss_mesh:  0.09825875167734921\n",
      "Epoch 744: loss = 0.2641473114490509\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005609083455055952 cvt_loss:  0.15795454382896423 chamfer_loss_mesh:  0.09795503865461797\n",
      "Epoch 745: loss = 0.26230379939079285\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0055570704862475395 cvt_loss:  0.15705203404650092 chamfer_loss_mesh:  0.09778729872778058\n",
      "Epoch 746: loss = 0.2611813247203827\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0055842651054263115 cvt_loss:  0.15575048746541142 chamfer_loss_mesh:  0.09751634206622839\n",
      "Epoch 747: loss = 0.25963589549064636\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005568184424191713 cvt_loss:  0.15476337866857648 chamfer_loss_mesh:  0.09716349450172856\n",
      "Epoch 748: loss = 0.2582794427871704\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005543963052332401 cvt_loss:  0.15414089430123568 chamfer_loss_mesh:  0.09649364073993638\n",
      "Epoch 749: loss = 0.25696253776550293\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.00552701810374856 cvt_loss:  0.153729144949466 chamfer_loss_mesh:  0.09652421431383118\n",
      "Epoch 750: loss = 0.2565644383430481\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005541427526623011 cvt_loss:  0.15308154979720712 chamfer_loss_mesh:  0.09563920320942998\n",
      "Epoch 751: loss = 0.255046010017395\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005540071055293083 cvt_loss:  0.15256138285622 chamfer_loss_mesh:  0.0960117467911914\n",
      "Epoch 752: loss = 0.2548968195915222\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.00553998164832592 cvt_loss:  0.1520225196145475 chamfer_loss_mesh:  0.09614667214918882\n",
      "Epoch 753: loss = 0.25449231266975403\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005524070467799902 cvt_loss:  0.15130640240386128 chamfer_loss_mesh:  0.09568842506268993\n",
      "Epoch 754: loss = 0.2533020079135895\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0054866960272192955 cvt_loss:  0.15038943383842707 chamfer_loss_mesh:  0.09541798499412835\n",
      "Epoch 755: loss = 0.2520769238471985\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005448984447866678 cvt_loss:  0.14988620532676578 chamfer_loss_mesh:  0.09463840979151428\n",
      "Epoch 756: loss = 0.25075605511665344\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005423363298177719 cvt_loss:  0.14927536249160767 chamfer_loss_mesh:  0.09380011033499613\n",
      "Epoch 757: loss = 0.24928094446659088\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005414380691945553 cvt_loss:  0.1486180815845728 chamfer_loss_mesh:  0.09259275975637138\n",
      "Epoch 758: loss = 0.24740684032440186\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005403163377195597 cvt_loss:  0.14780601486563683 chamfer_loss_mesh:  0.09223539382219315\n",
      "Epoch 759: loss = 0.2462259829044342\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005382932722568512 cvt_loss:  0.14724582433700562 chamfer_loss_mesh:  0.09228770795743912\n",
      "Epoch 760: loss = 0.24569764733314514\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005363923497498035 cvt_loss:  0.14653895050287247 chamfer_loss_mesh:  0.09197858162224293\n",
      "Epoch 761: loss = 0.24466218054294586\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005370292346924543 cvt_loss:  0.1460077823139727 chamfer_loss_mesh:  0.09223843517247587\n",
      "Epoch 762: loss = 0.2443971037864685\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005398334935307503 cvt_loss:  0.14514572685584426 chamfer_loss_mesh:  0.0926101638469845\n",
      "Epoch 763: loss = 0.2439344823360443\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005366146564483643 cvt_loss:  0.14460142701864243 chamfer_loss_mesh:  0.09182714711641893\n",
      "Epoch 764: loss = 0.24257533252239227\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0053266845643520355 cvt_loss:  0.14396526385098696 chamfer_loss_mesh:  0.09164834045805037\n",
      "Epoch 765: loss = 0.24172063171863556\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005338169634342194 cvt_loss:  0.14387976843863726 chamfer_loss_mesh:  0.0915180571610108\n",
      "Epoch 766: loss = 0.24151600897312164\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005330173764377832 cvt_loss:  0.1435234909877181 chamfer_loss_mesh:  0.09241594671038911\n",
      "Epoch 767: loss = 0.24204958975315094\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005315850488841534 cvt_loss:  0.14297689776867628 chamfer_loss_mesh:  0.09210549615090713\n",
      "Epoch 768: loss = 0.2411779910326004\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.00539933517575264 cvt_loss:  0.14241335447877645 chamfer_loss_mesh:  0.09229405259247869\n",
      "Epoch 769: loss = 0.2408861666917801\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005285861901938915 cvt_loss:  0.1419064006768167 chamfer_loss_mesh:  0.09115500870393589\n",
      "Epoch 770: loss = 0.23912681639194489\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005247269291430712 cvt_loss:  0.14139809645712376 chamfer_loss_mesh:  0.0900713712326251\n",
      "Epoch 771: loss = 0.23749621212482452\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005221423227339983 cvt_loss:  0.14086849987506866 chamfer_loss_mesh:  0.08916172373574227\n",
      "Epoch 772: loss = 0.23603112995624542\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005203161854296923 cvt_loss:  0.14034566702321172 chamfer_loss_mesh:  0.08887816511560231\n",
      "Epoch 773: loss = 0.23520593345165253\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.00516737112775445 cvt_loss:  0.13957860646769404 chamfer_loss_mesh:  0.08854125189827755\n",
      "Epoch 774: loss = 0.23406657576560974\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0051564620807766914 cvt_loss:  0.13916746247559786 chamfer_loss_mesh:  0.08893148333299905\n",
      "Epoch 775: loss = 0.234034463763237\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005123909097164869 cvt_loss:  0.13836920261383057 chamfer_loss_mesh:  0.08861548849381506\n",
      "Epoch 776: loss = 0.23288734257221222\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005097877699881792 cvt_loss:  0.1379684079438448 chamfer_loss_mesh:  0.08823977259453386\n",
      "Epoch 777: loss = 0.23208452761173248\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005081837996840477 cvt_loss:  0.1375485910102725 chamfer_loss_mesh:  0.08768198313191533\n",
      "Epoch 778: loss = 0.23109066486358643\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.00509925652295351 cvt_loss:  0.13689500046893954 chamfer_loss_mesh:  0.08754406007938087\n",
      "Epoch 779: loss = 0.23031629621982574\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005094821564853191 cvt_loss:  0.13655087677761912 chamfer_loss_mesh:  0.08800199429970235\n",
      "Epoch 780: loss = 0.2304254025220871\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005057027563452721 cvt_loss:  0.1360867521725595 chamfer_loss_mesh:  0.08842100214678794\n",
      "Epoch 781: loss = 0.23034216463565826\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005027228966355324 cvt_loss:  0.13610287569463253 chamfer_loss_mesh:  0.08758174953982234\n",
      "Epoch 782: loss = 0.22948913276195526\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005023959558457136 cvt_loss:  0.13583919499069452 chamfer_loss_mesh:  0.0875752666615881\n",
      "Epoch 783: loss = 0.22921507060527802\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.005039125215262175 cvt_loss:  0.13555132318288088 chamfer_loss_mesh:  0.0870200019562617\n",
      "Epoch 784: loss = 0.2283869981765747\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.004993381444364786 cvt_loss:  0.13516222825273871 chamfer_loss_mesh:  0.0871561496751383\n",
      "Epoch 785: loss = 0.2280883640050888\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.004953243304044008 cvt_loss:  0.13462149072438478 chamfer_loss_mesh:  0.08689266542205587\n",
      "Epoch 786: loss = 0.22724378108978271\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.004928313195705414 cvt_loss:  0.13411282561719418 chamfer_loss_mesh:  0.08708472887519747\n",
      "Epoch 787: loss = 0.22690217196941376\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.004943350795656443 cvt_loss:  0.13375632697716355 chamfer_loss_mesh:  0.08671423711348325\n",
      "Epoch 788: loss = 0.22618994116783142\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.004921525251120329 cvt_loss:  0.1334585715085268 chamfer_loss_mesh:  0.08629291551187634\n",
      "Epoch 789: loss = 0.22544872760772705\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.004892542492598295 cvt_loss:  0.1331921317614615 chamfer_loss_mesh:  0.08584863098803908\n",
      "Epoch 790: loss = 0.22470903396606445\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.004949614405632019 cvt_loss:  0.13283173320814967 chamfer_loss_mesh:  0.08551670907763764\n",
      "Epoch 791: loss = 0.224073588848114\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0048796795308589935 cvt_loss:  0.13263823930174112 chamfer_loss_mesh:  0.0849642456159927\n",
      "Epoch 792: loss = 0.22325773537158966\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0048502166755497456 cvt_loss:  0.1322903553955257 chamfer_loss_mesh:  0.08528878242941573\n",
      "Epoch 793: loss = 0.22320468723773956\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.004835845902562141 cvt_loss:  0.13188510201871395 chamfer_loss_mesh:  0.08445684943581\n",
      "Epoch 794: loss = 0.22195270657539368\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.004825206473469734 cvt_loss:  0.13166897697374225 chamfer_loss_mesh:  0.08463060657959431\n",
      "Epoch 795: loss = 0.22189967334270477\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.004789281636476517 cvt_loss:  0.13142586685717106 chamfer_loss_mesh:  0.08395838085561991\n",
      "Epoch 796: loss = 0.22094814479351044\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.004761580377817154 cvt_loss:  0.13117730850353837 chamfer_loss_mesh:  0.08415564661845565\n",
      "Epoch 797: loss = 0.22086922824382782\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.004739419557154179 cvt_loss:  0.1307050115428865 chamfer_loss_mesh:  0.08386018453165889\n",
      "Epoch 798: loss = 0.22007915377616882\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.004732704721391201 cvt_loss:  0.13063191436231136 chamfer_loss_mesh:  0.0839147760416381\n",
      "Epoch 799: loss = 0.22005349397659302\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "Estimated eps_H:  tensor(0.0576, device='cuda:0')\n",
      "eikonal_loss:  0.004716648254543543 cvt_loss:  0.13018883764743805 chamfer_loss_mesh:  0.08380359213333577\n",
      "Epoch 800: loss = 0.2195793092250824\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.004718859679996967 cvt_loss:  0.1298833405598998 chamfer_loss_mesh:  0.08340468048118055\n",
      "Epoch 801: loss = 0.2188769429922104\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.004725223407149315 cvt_loss:  0.12946438509970903 chamfer_loss_mesh:  0.0833751619211398\n",
      "Epoch 802: loss = 0.2184348851442337\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.004702361300587654 cvt_loss:  0.1289891079068184 chamfer_loss_mesh:  0.0828619668027386\n",
      "Epoch 803: loss = 0.21742357313632965\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.004648654256016016 cvt_loss:  0.12884337920695543 chamfer_loss_mesh:  0.08220392192015424\n",
      "Epoch 804: loss = 0.21656633913516998\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.004613980185240507 cvt_loss:  0.12860766146332026 chamfer_loss_mesh:  0.08167415944626555\n",
      "Epoch 805: loss = 0.21576586365699768\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.00459921732544899 cvt_loss:  0.1282427809201181 chamfer_loss_mesh:  0.08167907799361274\n",
      "Epoch 806: loss = 0.2153911292552948\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.004615931771695614 cvt_loss:  0.12827657628804445 chamfer_loss_mesh:  0.08143799641402438\n",
      "Epoch 807: loss = 0.21520015597343445\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.004613851197063923 cvt_loss:  0.12812886852771044 chamfer_loss_mesh:  0.08199970034183934\n",
      "Epoch 808: loss = 0.21561118960380554\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.004589025862514973 cvt_loss:  0.12796432711184025 chamfer_loss_mesh:  0.08180818986147642\n",
      "Epoch 809: loss = 0.2152300477027893\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.004568185657262802 cvt_loss:  0.12751150643453002 chamfer_loss_mesh:  0.0812470680102706\n",
      "Epoch 810: loss = 0.2141943722963333\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0045591131784021854 cvt_loss:  0.12735335621982813 chamfer_loss_mesh:  0.08098935359157622\n",
      "Epoch 811: loss = 0.21376876533031464\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.004525606520473957 cvt_loss:  0.12706503039225936 chamfer_loss_mesh:  0.0804639421403408\n",
      "Epoch 812: loss = 0.21292130649089813\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.004517276771366596 cvt_loss:  0.12709139846265316 chamfer_loss_mesh:  0.07996935164555907\n",
      "Epoch 813: loss = 0.2124442458152771\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.004498851951211691 cvt_loss:  0.12707848800346255 chamfer_loss_mesh:  0.07976219785632566\n",
      "Epoch 814: loss = 0.2122049629688263\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.004485348239541054 cvt_loss:  0.12695485493168235 chamfer_loss_mesh:  0.07964403630467132\n",
      "Epoch 815: loss = 0.21194954216480255\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.004460148513317108 cvt_loss:  0.12666198890656233 chamfer_loss_mesh:  0.08008501026779413\n",
      "Epoch 816: loss = 0.2120717316865921\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.004460690077394247 cvt_loss:  0.1264758058823645 chamfer_loss_mesh:  0.07966914563439786\n",
      "Epoch 817: loss = 0.21146947145462036\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0044485642574727535 cvt_loss:  0.12634018203243613 chamfer_loss_mesh:  0.07997604552656412\n",
      "Epoch 818: loss = 0.21162858605384827\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.004423061385750771 cvt_loss:  0.1262029749341309 chamfer_loss_mesh:  0.08032268669921905\n",
      "Epoch 819: loss = 0.21181239187717438\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0044106487184762955 cvt_loss:  0.12606153031811118 chamfer_loss_mesh:  0.07983017712831497\n",
      "Epoch 820: loss = 0.21116578578948975\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.004405200481414795 cvt_loss:  0.12584695359691978 chamfer_loss_mesh:  0.08019850793061778\n",
      "Epoch 821: loss = 0.2113139033317566\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.00440397672355175 cvt_loss:  0.12551030376926064 chamfer_loss_mesh:  0.07965222175698727\n",
      "Epoch 822: loss = 0.21042998135089874\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.004397276323288679 cvt_loss:  0.1252551912330091 chamfer_loss_mesh:  0.0809987832326442\n",
      "Epoch 823: loss = 0.2115139663219452\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0043831877410411835 cvt_loss:  0.1251758192665875 chamfer_loss_mesh:  0.08029877790249884\n",
      "Epoch 824: loss = 0.2107199877500534\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.004370533395558596 cvt_loss:  0.12481427984312177 chamfer_loss_mesh:  0.08016637730179355\n",
      "Epoch 825: loss = 0.21021334826946259\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.004338344559073448 cvt_loss:  0.12480339501053095 chamfer_loss_mesh:  0.08046774019021541\n",
      "Epoch 826: loss = 0.21047155559062958\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.004319685511291027 cvt_loss:  0.12448598863556981 chamfer_loss_mesh:  0.07988125435076654\n",
      "Epoch 827: loss = 0.20954836905002594\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.004299703054130077 cvt_loss:  0.1243688864633441 chamfer_loss_mesh:  0.07942014781292528\n",
      "Epoch 828: loss = 0.20894986391067505\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.004290528129786253 cvt_loss:  0.12430470669642091 chamfer_loss_mesh:  0.07863616337999701\n",
      "Epoch 829: loss = 0.20809215307235718\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0042907665483653545 cvt_loss:  0.12384220026433468 chamfer_loss_mesh:  0.07834356802050024\n",
      "Epoch 830: loss = 0.20733724534511566\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.004270974546670914 cvt_loss:  0.12372286291792989 chamfer_loss_mesh:  0.07840224134270102\n",
      "Epoch 831: loss = 0.2072565257549286\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0042492700740695 cvt_loss:  0.1238518743775785 chamfer_loss_mesh:  0.07786332571413368\n",
      "Epoch 832: loss = 0.20682477951049805\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0042528873309493065 cvt_loss:  0.12347315205261111 chamfer_loss_mesh:  0.07758456922601908\n",
      "Epoch 833: loss = 0.20617017149925232\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.004256817512214184 cvt_loss:  0.12328494340181351 chamfer_loss_mesh:  0.07690865459153429\n",
      "Epoch 834: loss = 0.20530948042869568\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0042136600241065025 cvt_loss:  0.12316987849771976 chamfer_loss_mesh:  0.07754238322377205\n",
      "Epoch 835: loss = 0.2057846039533615\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.004175627138465643 cvt_loss:  0.12291086604818702 chamfer_loss_mesh:  0.07708945486228913\n",
      "Epoch 836: loss = 0.20503486692905426\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0041548158042132854 cvt_loss:  0.1228672219440341 chamfer_loss_mesh:  0.07665455632377416\n",
      "Epoch 837: loss = 0.20453506708145142\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.004105505533516407 cvt_loss:  0.12268568389117718 chamfer_loss_mesh:  0.07665771408937871\n",
      "Epoch 838: loss = 0.20430681109428406\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.004082122351974249 cvt_loss:  0.12250291183590889 chamfer_loss_mesh:  0.07616014045197517\n",
      "Epoch 839: loss = 0.20360322296619415\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.00406931946054101 cvt_loss:  0.12200850760564208 chamfer_loss_mesh:  0.07609304157085717\n",
      "Epoch 840: loss = 0.2030280977487564\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.004063853062689304 cvt_loss:  0.12206918327137828 chamfer_loss_mesh:  0.07613410707563162\n",
      "Epoch 841: loss = 0.20312388241291046\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0040462748147547245 cvt_loss:  0.12201076606288552 chamfer_loss_mesh:  0.07608818123117089\n",
      "Epoch 842: loss = 0.20300133526325226\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.004055212251842022 cvt_loss:  0.1217644545249641 chamfer_loss_mesh:  0.07562884275102988\n",
      "Epoch 843: loss = 0.2023046314716339\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.004031880293041468 cvt_loss:  0.1219850848428905 chamfer_loss_mesh:  0.07535963231930509\n",
      "Epoch 844: loss = 0.20223262906074524\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.003994473721832037 cvt_loss:  0.12185514206066728 chamfer_loss_mesh:  0.0756419831304811\n",
      "Epoch 845: loss = 0.20234738290309906\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.00398500170558691 cvt_loss:  0.121547922026366 chamfer_loss_mesh:  0.07543666288256645\n",
      "Epoch 846: loss = 0.2018248289823532\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.00397986825555563 cvt_loss:  0.12158355675637722 chamfer_loss_mesh:  0.07485007517971098\n",
      "Epoch 847: loss = 0.20126838982105255\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.003967768978327513 cvt_loss:  0.12160340556874871 chamfer_loss_mesh:  0.07497388287447393\n",
      "Epoch 848: loss = 0.2013997584581375\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0039741406217217445 cvt_loss:  0.12165755033493042 chamfer_loss_mesh:  0.07497435581171885\n",
      "Epoch 849: loss = 0.2014608383178711\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.003971748985350132 cvt_loss:  0.12143171625211835 chamfer_loss_mesh:  0.0745928700780496\n",
      "Epoch 850: loss = 0.2008504718542099\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.003970914985984564 cvt_loss:  0.12107662623748183 chamfer_loss_mesh:  0.07423343777190894\n",
      "Epoch 851: loss = 0.20013494789600372\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.00399793591350317 cvt_loss:  0.12161459308117628 chamfer_loss_mesh:  0.07405762153211981\n",
      "Epoch 852: loss = 0.20052368938922882\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.003980704583227634 cvt_loss:  0.12118320446461439 chamfer_loss_mesh:  0.07381674367934465\n",
      "Epoch 853: loss = 0.19983398914337158\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.003976671025156975 cvt_loss:  0.12084509944543242 chamfer_loss_mesh:  0.07400012691505253\n",
      "Epoch 854: loss = 0.199674591422081\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.003969788085669279 cvt_loss:  0.12082990724593401 chamfer_loss_mesh:  0.07377342990366742\n",
      "Epoch 855: loss = 0.19942516088485718\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.003937121480703354 cvt_loss:  0.12063032481819391 chamfer_loss_mesh:  0.0737683440092951\n",
      "Epoch 856: loss = 0.19918788969516754\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.003928768448531628 cvt_loss:  0.1205596374347806 chamfer_loss_mesh:  0.0742435731808655\n",
      "Epoch 857: loss = 0.19958394765853882\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.003930091857910156 cvt_loss:  0.1204879954457283 chamfer_loss_mesh:  0.07387153891613707\n",
      "Epoch 858: loss = 0.1991412341594696\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0039164163172245026 cvt_loss:  0.12008922640234232 chamfer_loss_mesh:  0.07399229070870206\n",
      "Epoch 859: loss = 0.1988498419523239\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.003889265935868025 cvt_loss:  0.11992556974291801 chamfer_loss_mesh:  0.07409196405205876\n",
      "Epoch 860: loss = 0.1987585723400116\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0038880601059645414 cvt_loss:  0.1197469187900424 chamfer_loss_mesh:  0.0739022289053537\n",
      "Epoch 861: loss = 0.1983882486820221\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0038668003398925066 cvt_loss:  0.12000617571175098 chamfer_loss_mesh:  0.073604955105111\n",
      "Epoch 862: loss = 0.1983288824558258\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0038455610629171133 cvt_loss:  0.11989326449111104 chamfer_loss_mesh:  0.07354999252129346\n",
      "Epoch 863: loss = 0.1981397122144699\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0038499017246067524 cvt_loss:  0.11971704661846161 chamfer_loss_mesh:  0.07313831883948296\n",
      "Epoch 864: loss = 0.19755613803863525\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0038340885657817125 cvt_loss:  0.11975119123235345 chamfer_loss_mesh:  0.07306501356652007\n",
      "Epoch 865: loss = 0.19750091433525085\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0038176970556378365 cvt_loss:  0.1199838356114924 chamfer_loss_mesh:  0.07306301267817616\n",
      "Epoch 866: loss = 0.19771520793437958\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0038079703226685524 cvt_loss:  0.12020173016935587 chamfer_loss_mesh:  0.07298658601939678\n",
      "Epoch 867: loss = 0.19784650206565857\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0038135084323585033 cvt_loss:  0.11994534870609641 chamfer_loss_mesh:  0.07278489647433162\n",
      "Epoch 868: loss = 0.19739364087581635\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0037927322555333376 cvt_loss:  0.12068059295415878 chamfer_loss_mesh:  0.07294289389392361\n",
      "Epoch 869: loss = 0.1982661336660385\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.003791394177824259 cvt_loss:  0.12034475803375244 chamfer_loss_mesh:  0.07221067789942026\n",
      "Epoch 870: loss = 0.19719652831554413\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.00379343144595623 cvt_loss:  0.11943826684728265 chamfer_loss_mesh:  0.07234152872115374\n",
      "Epoch 871: loss = 0.19642266631126404\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0037954687140882015 cvt_loss:  0.11943000135943294 chamfer_loss_mesh:  0.07332621316891164\n",
      "Epoch 872: loss = 0.19740092754364014\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.003776202443987131 cvt_loss:  0.1193694886751473 chamfer_loss_mesh:  0.0731251566321589\n",
      "Epoch 873: loss = 0.1971200406551361\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0037601732183247805 cvt_loss:  0.11934245703741908 chamfer_loss_mesh:  0.07258039840962738\n",
      "Epoch 874: loss = 0.19653242826461792\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0037386836484074593 cvt_loss:  0.11968077160418034 chamfer_loss_mesh:  0.07234502118080854\n",
      "Epoch 875: loss = 0.19661399722099304\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.00369905773550272 cvt_loss:  0.11924123391509056 chamfer_loss_mesh:  0.07191469194367528\n",
      "Epoch 876: loss = 0.1957046538591385\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0036916183307766914 cvt_loss:  0.11884511914104223 chamfer_loss_mesh:  0.07148774602683261\n",
      "Epoch 877: loss = 0.19487395882606506\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.003654723521322012 cvt_loss:  0.11999077396467328 chamfer_loss_mesh:  0.07151902536861598\n",
      "Epoch 878: loss = 0.1960138976573944\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0036327759735286236 cvt_loss:  0.11987994657829404 chamfer_loss_mesh:  0.07222143904073164\n",
      "Epoch 879: loss = 0.19658342003822327\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0036153579130768776 cvt_loss:  0.11990673374384642 chamfer_loss_mesh:  0.07210071635199711\n",
      "Epoch 880: loss = 0.19647172093391418\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0035920205991715193 cvt_loss:  0.11954952497035265 chamfer_loss_mesh:  0.0720593670848757\n",
      "Epoch 881: loss = 0.19604937732219696\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0035805590450763702 cvt_loss:  0.11950773186981678 chamfer_loss_mesh:  0.07185130380094051\n",
      "Epoch 882: loss = 0.19578781723976135\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0035664134193211794 cvt_loss:  0.11992657091468573 chamfer_loss_mesh:  0.07154860941227525\n",
      "Epoch 883: loss = 0.1958896815776825\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.003564790589734912 cvt_loss:  0.11994758388027549 chamfer_loss_mesh:  0.0715545829734765\n",
      "Epoch 884: loss = 0.19591520726680756\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.003551843110471964 cvt_loss:  0.11986910831183195 chamfer_loss_mesh:  0.07123040268197656\n",
      "Epoch 885: loss = 0.1954995095729828\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.003539922647178173 cvt_loss:  0.12039127759635448 chamfer_loss_mesh:  0.07139259832911193\n",
      "Epoch 886: loss = 0.1961718052625656\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0035512391477823257 cvt_loss:  0.12011328944936395 chamfer_loss_mesh:  0.0708519437466748\n",
      "Epoch 887: loss = 0.1953640729188919\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0035373386926949024 cvt_loss:  0.11988610494881868 chamfer_loss_mesh:  0.0703260739101097\n",
      "Epoch 888: loss = 0.19459672272205353\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0035239013377577066 cvt_loss:  0.1193809206597507 chamfer_loss_mesh:  0.06962500629015267\n",
      "Epoch 889: loss = 0.1933770328760147\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.003527361201122403 cvt_loss:  0.11941978009417653 chamfer_loss_mesh:  0.0696724746376276\n",
      "Epoch 890: loss = 0.19346657395362854\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0035197739489376545 cvt_loss:  0.11997396359220147 chamfer_loss_mesh:  0.06939561717445031\n",
      "Epoch 891: loss = 0.1937362402677536\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0035178293474018574 cvt_loss:  0.11977541726082563 chamfer_loss_mesh:  0.06920933083165437\n",
      "Epoch 892: loss = 0.19334891438484192\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0035036823246628046 cvt_loss:  0.11945738224312663 chamfer_loss_mesh:  0.06996655429247767\n",
      "Epoch 893: loss = 0.19377359747886658\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0035000243224203587 cvt_loss:  0.11932913912460208 chamfer_loss_mesh:  0.06977061275392771\n",
      "Epoch 894: loss = 0.1934453547000885\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.003495498327538371 cvt_loss:  0.11900848476216197 chamfer_loss_mesh:  0.069766967499163\n",
      "Epoch 895: loss = 0.19311615824699402\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.003464548848569393 cvt_loss:  0.11901026591658592 chamfer_loss_mesh:  0.06928312359377742\n",
      "Epoch 896: loss = 0.19260331988334656\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.003451751545071602 cvt_loss:  0.11884935665875673 chamfer_loss_mesh:  0.06929749361006543\n",
      "Epoch 897: loss = 0.19244344532489777\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.003441861364990473 cvt_loss:  0.1184303080663085 chamfer_loss_mesh:  0.06940370803931728\n",
      "Epoch 898: loss = 0.19212014973163605\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0034436481073498726 cvt_loss:  0.11809543939307332 chamfer_loss_mesh:  0.06870798824820668\n",
      "Epoch 899: loss = 0.19109071791172028\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.003445852780714631 cvt_loss:  0.11800887295976281 chamfer_loss_mesh:  0.06917254358995706\n",
      "Epoch 900: loss = 0.19147071242332458\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.003440552856773138 cvt_loss:  0.11774582089856267 chamfer_loss_mesh:  0.06940529419807717\n",
      "Epoch 901: loss = 0.19143518805503845\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0034359365236014128 cvt_loss:  0.11752359569072723 chamfer_loss_mesh:  0.06946570647414774\n",
      "Epoch 902: loss = 0.19126875698566437\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0034336328972131014 cvt_loss:  0.1174263539724052 chamfer_loss_mesh:  0.0691189561621286\n",
      "Epoch 903: loss = 0.1908220797777176\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.003409475553780794 cvt_loss:  0.11805646354332566 chamfer_loss_mesh:  0.06937808211660013\n",
      "Epoch 904: loss = 0.1916874498128891\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.003407879499718547 cvt_loss:  0.11787220137193799 chamfer_loss_mesh:  0.06970442336751148\n",
      "Epoch 905: loss = 0.19182752072811127\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0033916046377271414 cvt_loss:  0.1178851816803217 chamfer_loss_mesh:  0.06962918996578082\n",
      "Epoch 906: loss = 0.19174893200397491\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0033717360347509384 cvt_loss:  0.11767942924052477 chamfer_loss_mesh:  0.06924762419657782\n",
      "Epoch 907: loss = 0.19114159047603607\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.003366838674992323 cvt_loss:  0.11804846581071615 chamfer_loss_mesh:  0.06877556734252721\n",
      "Epoch 908: loss = 0.19103319942951202\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0033670382108539343 cvt_loss:  0.1178457634523511 chamfer_loss_mesh:  0.06892891542520374\n",
      "Epoch 909: loss = 0.1909838318824768\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.003356311470270157 cvt_loss:  0.11770839337259531 chamfer_loss_mesh:  0.06911753735039383\n",
      "Epoch 910: loss = 0.19102436304092407\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0033668449614197016 cvt_loss:  0.1174945617094636 chamfer_loss_mesh:  0.06867698539281264\n",
      "Epoch 911: loss = 0.19038036465644836\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0033609967213124037 cvt_loss:  0.11814020108431578 chamfer_loss_mesh:  0.06833227962488309\n",
      "Epoch 912: loss = 0.19067518413066864\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.003338487586006522 cvt_loss:  0.11811269214376807 chamfer_loss_mesh:  0.06856304389657453\n",
      "Epoch 913: loss = 0.1908564269542694\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.003328781807795167 cvt_loss:  0.11804739478975534 chamfer_loss_mesh:  0.06792684871470556\n",
      "Epoch 914: loss = 0.1901450753211975\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.003306821221485734 cvt_loss:  0.11761566856876016 chamfer_loss_mesh:  0.06805771408835426\n",
      "Epoch 915: loss = 0.18982209265232086\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0032850992865860462 cvt_loss:  0.11758391046896577 chamfer_loss_mesh:  0.06814816879341379\n",
      "Epoch 916: loss = 0.18985877931118011\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0032779572065919638 cvt_loss:  0.11738947359845042 chamfer_loss_mesh:  0.06797919195378199\n",
      "Epoch 917: loss = 0.18948759138584137\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0032778328750282526 cvt_loss:  0.11698710732161999 chamfer_loss_mesh:  0.06779794784961268\n",
      "Epoch 918: loss = 0.18890362977981567\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0032757294829934835 cvt_loss:  0.1177122350782156 chamfer_loss_mesh:  0.06768677121726796\n",
      "Epoch 919: loss = 0.18951527774333954\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.003265505423769355 cvt_loss:  0.11704748030751944 chamfer_loss_mesh:  0.067492677771952\n",
      "Epoch 920: loss = 0.18864615261554718\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0032635238021612167 cvt_loss:  0.11724799405783415 chamfer_loss_mesh:  0.06749379099346697\n",
      "Epoch 921: loss = 0.18884587287902832\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0032536082435399294 cvt_loss:  0.11715859873220325 chamfer_loss_mesh:  0.06809423939557746\n",
      "Epoch 922: loss = 0.18934710323810577\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0032451448496431112 cvt_loss:  0.11686640791594982 chamfer_loss_mesh:  0.06790440966142341\n",
      "Epoch 923: loss = 0.18885625898838043\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0032437830232083797 cvt_loss:  0.11679682647809386 chamfer_loss_mesh:  0.06764404679415748\n",
      "Epoch 924: loss = 0.18852466344833374\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.003220523241907358 cvt_loss:  0.11630909284576774 chamfer_loss_mesh:  0.06668637797702104\n",
      "Epoch 925: loss = 0.1870555430650711\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.003240139689296484 cvt_loss:  0.1162566477432847 chamfer_loss_mesh:  0.06684381514787674\n",
      "Epoch 926: loss = 0.1871802806854248\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0032206580508500338 cvt_loss:  0.11632404057309031 chamfer_loss_mesh:  0.06634411693084985\n",
      "Epoch 927: loss = 0.18672771751880646\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.003211300354450941 cvt_loss:  0.11670981766656041 chamfer_loss_mesh:  0.06704497354803607\n",
      "Epoch 928: loss = 0.1878049522638321\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0032207434996962547 cvt_loss:  0.11658177245408297 chamfer_loss_mesh:  0.06724611739628017\n",
      "Epoch 929: loss = 0.1878870129585266\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0031971230637282133 cvt_loss:  0.11654526460915804 chamfer_loss_mesh:  0.06734630733262748\n",
      "Epoch 930: loss = 0.18792760372161865\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0031877390574663877 cvt_loss:  0.11642568279057741 chamfer_loss_mesh:  0.06710230081807822\n",
      "Epoch 931: loss = 0.18755482137203217\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0031796146649867296 cvt_loss:  0.11618924327194691 chamfer_loss_mesh:  0.06665743421763182\n",
      "Epoch 932: loss = 0.18686524033546448\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0031779997516423464 cvt_loss:  0.11584878666326404 chamfer_loss_mesh:  0.06656620098510757\n",
      "Epoch 933: loss = 0.18643176555633545\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0031604638788849115 cvt_loss:  0.11631284141913056 chamfer_loss_mesh:  0.06614938320126384\n",
      "Epoch 934: loss = 0.1864611953496933\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0031557069160044193 cvt_loss:  0.11612675152719021 chamfer_loss_mesh:  0.06568078242707998\n",
      "Epoch 935: loss = 0.18580177426338196\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0031427177600562572 cvt_loss:  0.11538610560819507 chamfer_loss_mesh:  0.06549851968884468\n",
      "Epoch 936: loss = 0.1848652958869934\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0031225921120494604 cvt_loss:  0.11518961982801557 chamfer_loss_mesh:  0.06529391976073384\n",
      "Epoch 937: loss = 0.1844441443681717\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0031270766630768776 cvt_loss:  0.11515357764437795 chamfer_loss_mesh:  0.06516167195513844\n",
      "Epoch 938: loss = 0.18428045511245728\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.003102859016507864 cvt_loss:  0.11493912898004055 chamfer_loss_mesh:  0.06530682003358379\n",
      "Epoch 939: loss = 0.18418638408184052\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0031242903787642717 cvt_loss:  0.11503424029797316 chamfer_loss_mesh:  0.06528445373987779\n",
      "Epoch 940: loss = 0.1842803657054901\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.003157953266054392 cvt_loss:  0.11501809349283576 chamfer_loss_mesh:  0.06518811278510839\n",
      "Epoch 941: loss = 0.18420101702213287\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.00307800923474133 cvt_loss:  0.1146651222370565 chamfer_loss_mesh:  0.06465394835686311\n",
      "Epoch 942: loss = 0.1832336038351059\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0030872831121087074 cvt_loss:  0.11463254923000932 chamfer_loss_mesh:  0.0646256230538711\n",
      "Epoch 943: loss = 0.1831817328929901\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0030601252801716328 cvt_loss:  0.11444151168689132 chamfer_loss_mesh:  0.06461810698965564\n",
      "Epoch 944: loss = 0.1829562485218048\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.003068117657676339 cvt_loss:  0.11430690065026283 chamfer_loss_mesh:  0.06456630217144266\n",
      "Epoch 945: loss = 0.1827773153781891\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.00305599020794034 cvt_loss:  0.11422927491366863 chamfer_loss_mesh:  0.0646733824396506\n",
      "Epoch 946: loss = 0.18279461562633514\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0030189957469701767 cvt_loss:  0.11407790007069707 chamfer_loss_mesh:  0.06432165537262335\n",
      "Epoch 947: loss = 0.18225429952144623\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.003040977753698826 cvt_loss:  0.11401792289689183 chamfer_loss_mesh:  0.06417953409254551\n",
      "Epoch 948: loss = 0.1820739060640335\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.003104096045717597 cvt_loss:  0.11408927384763956 chamfer_loss_mesh:  0.06359448889270425\n",
      "Epoch 949: loss = 0.1816229373216629\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.003099684836342931 cvt_loss:  0.11451212922111154 chamfer_loss_mesh:  0.06336878141155466\n",
      "Epoch 950: loss = 0.1818152219057083\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0030755845364183187 cvt_loss:  0.11442607501521707 chamfer_loss_mesh:  0.06296314677456394\n",
      "Epoch 951: loss = 0.18129923939704895\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0030270288698375225 cvt_loss:  0.11423805262893438 chamfer_loss_mesh:  0.06293053593253717\n",
      "Epoch 952: loss = 0.18102984130382538\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.002976766787469387 cvt_loss:  0.11434337357059121 chamfer_loss_mesh:  0.06299968663370237\n",
      "Epoch 953: loss = 0.18115384876728058\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0029668796341866255 cvt_loss:  0.11424652766436338 chamfer_loss_mesh:  0.063213417888619\n",
      "Epoch 954: loss = 0.18126066029071808\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0029702589381486177 cvt_loss:  0.11415326735004783 chamfer_loss_mesh:  0.06277493957895786\n",
      "Epoch 955: loss = 0.18073183298110962\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.002958154072985053 cvt_loss:  0.11391016887500882 chamfer_loss_mesh:  0.06236951594473794\n",
      "Epoch 956: loss = 0.18007084727287292\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.002949676476418972 cvt_loss:  0.11370719876140356 chamfer_loss_mesh:  0.06255244807107374\n",
      "Epoch 957: loss = 0.18004226684570312\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0029402899090200663 cvt_loss:  0.11334109585732222 chamfer_loss_mesh:  0.06284237315412611\n",
      "Epoch 958: loss = 0.1799563318490982\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0029351399280130863 cvt_loss:  0.11334882583469152 chamfer_loss_mesh:  0.0628392881480977\n",
      "Epoch 959: loss = 0.1799556463956833\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.002919976133853197 cvt_loss:  0.11337898904457688 chamfer_loss_mesh:  0.06279962690314278\n",
      "Epoch 960: loss = 0.1799304187297821\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0029112098272889853 cvt_loss:  0.11315549490973353 chamfer_loss_mesh:  0.06276912608882412\n",
      "Epoch 961: loss = 0.1796671748161316\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0029098649974912405 cvt_loss:  0.11305365478619933 chamfer_loss_mesh:  0.062185426941141486\n",
      "Epoch 962: loss = 0.17898018658161163\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0029215612448751926 cvt_loss:  0.11300803162157536 chamfer_loss_mesh:  0.0638174096820876\n",
      "Epoch 963: loss = 0.18057751655578613\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0028871605172753334 cvt_loss:  0.11278004385530949 chamfer_loss_mesh:  0.06348648457787931\n",
      "Epoch 964: loss = 0.17998409271240234\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0028701159171760082 cvt_loss:  0.11266301153227687 chamfer_loss_mesh:  0.06378914986271411\n",
      "Epoch 965: loss = 0.1801525503396988\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0028665182180702686 cvt_loss:  0.11265287175774574 chamfer_loss_mesh:  0.06360415136441588\n",
      "Epoch 966: loss = 0.17995361983776093\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.002847623312845826 cvt_loss:  0.11256512952968478 chamfer_loss_mesh:  0.0640193247818388\n",
      "Epoch 967: loss = 0.18026180565357208\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.002832298167049885 cvt_loss:  0.11204004986211658 chamfer_loss_mesh:  0.0637536941212602\n",
      "Epoch 968: loss = 0.17945566773414612\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0028262881096452475 cvt_loss:  0.11202400783076882 chamfer_loss_mesh:  0.06382253195624799\n",
      "Epoch 969: loss = 0.1795019805431366\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0028091203421354294 cvt_loss:  0.11171409860253334 chamfer_loss_mesh:  0.0635700998827815\n",
      "Epoch 970: loss = 0.17892229557037354\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.002794815693050623 cvt_loss:  0.11155441170558333 chamfer_loss_mesh:  0.06356879748636857\n",
      "Epoch 971: loss = 0.17874665558338165\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0027930689975619316 cvt_loss:  0.11142062721773982 chamfer_loss_mesh:  0.0631350849289447\n",
      "Epoch 972: loss = 0.17817720770835876\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0027846279554069042 cvt_loss:  0.11111147468909621 chamfer_loss_mesh:  0.06281334208324552\n",
      "Epoch 973: loss = 0.17753741145133972\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.002758293179795146 cvt_loss:  0.11122081195935607 chamfer_loss_mesh:  0.06352405034704134\n",
      "Epoch 974: loss = 0.17833170294761658\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.002760525792837143 cvt_loss:  0.11156232794746757 chamfer_loss_mesh:  0.06281431706156582\n",
      "Epoch 975: loss = 0.17796531319618225\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.002747117541730404 cvt_loss:  0.11138523695990443 chamfer_loss_mesh:  0.06226775440154597\n",
      "Epoch 976: loss = 0.17722809314727783\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0027384296990931034 cvt_loss:  0.11118995025753975 chamfer_loss_mesh:  0.062267223256640136\n",
      "Epoch 977: loss = 0.17702366411685944\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.002719078678637743 cvt_loss:  0.11103739961981773 chamfer_loss_mesh:  0.06219525675987825\n",
      "Epoch 978: loss = 0.17677971720695496\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.002704886719584465 cvt_loss:  0.11106497840955853 chamfer_loss_mesh:  0.062081657233648\n",
      "Epoch 979: loss = 0.17667944729328156\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0026963790878653526 cvt_loss:  0.11247441871091723 chamfer_loss_mesh:  0.062009276007302105\n",
      "Epoch 980: loss = 0.17800816893577576\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.002695427043363452 cvt_loss:  0.1122663845308125 chamfer_loss_mesh:  0.06197983748279512\n",
      "Epoch 981: loss = 0.1777699887752533\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.00268727308139205 cvt_loss:  0.11205341434106231 chamfer_loss_mesh:  0.061342485423665494\n",
      "Epoch 982: loss = 0.17691120505332947\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.002670034533366561 cvt_loss:  0.11165391188114882 chamfer_loss_mesh:  0.0612300937063992\n",
      "Epoch 983: loss = 0.17638182640075684\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.00265946751460433 cvt_loss:  0.11162844020873308 chamfer_loss_mesh:  0.06155113806016743\n",
      "Epoch 984: loss = 0.17666706442832947\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0026426827535033226 cvt_loss:  0.11155371321365237 chamfer_loss_mesh:  0.06142452184576541\n",
      "Epoch 985: loss = 0.17644931375980377\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0026263846084475517 cvt_loss:  0.11140374699607491 chamfer_loss_mesh:  0.061023027228657156\n",
      "Epoch 986: loss = 0.17588110268115997\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0026205419562757015 cvt_loss:  0.1110507408156991 chamfer_loss_mesh:  0.060911035689059645\n",
      "Epoch 987: loss = 0.17541007697582245\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.002609717193990946 cvt_loss:  0.11096459347754717 chamfer_loss_mesh:  0.06116976146586239\n",
      "Epoch 988: loss = 0.1755717396736145\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.002610991010442376 cvt_loss:  0.11053858324885368 chamfer_loss_mesh:  0.060900914832018316\n",
      "Epoch 989: loss = 0.1748775988817215\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0026138387620449066 cvt_loss:  0.11040286626666784 chamfer_loss_mesh:  0.06076513454900123\n",
      "Epoch 990: loss = 0.1746087521314621\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0026048778090626 cvt_loss:  0.11043708072975278 chamfer_loss_mesh:  0.061035825638100505\n",
      "Epoch 991: loss = 0.1749044805765152\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.002592249307781458 cvt_loss:  0.11038685915991664 chamfer_loss_mesh:  0.06155728624435142\n",
      "Epoch 992: loss = 0.17536316812038422\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0025883151683956385 cvt_loss:  0.1102132722735405 chamfer_loss_mesh:  0.06138673052191734\n",
      "Epoch 993: loss = 0.17501509189605713\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.002574979793280363 cvt_loss:  0.11020103702321649 chamfer_loss_mesh:  0.06163717625895515\n",
      "Epoch 994: loss = 0.17523960769176483\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.002571211662143469 cvt_loss:  0.1100563327781856 chamfer_loss_mesh:  0.06150417902972549\n",
      "Epoch 995: loss = 0.17495760321617126\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0025731120258569717 cvt_loss:  0.10998452780768275 chamfer_loss_mesh:  0.06118015153333545\n",
      "Epoch 996: loss = 0.17456364631652832\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.002564998809248209 cvt_loss:  0.11001595994457603 chamfer_loss_mesh:  0.06094815762480721\n",
      "Epoch 997: loss = 0.17435482144355774\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0025625014677643776 cvt_loss:  0.10979106882587075 chamfer_loss_mesh:  0.060809561546193436\n",
      "Epoch 998: loss = 0.17398867011070251\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.002554862294346094 cvt_loss:  0.10960075305774808 chamfer_loss_mesh:  0.06073660188121721\n",
      "Epoch 999: loss = 0.17371755838394165\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "eikonal_loss:  0.0025544227100908756 cvt_loss:  0.10955410543829203 chamfer_loss_mesh:  0.060529160691658035\n",
      "Epoch 1000: loss = 0.17346274852752686\n",
      "-----------------\n",
      "Learning rate:  0.0005\n",
      "Sites length:  72856\n",
      "min sites:  tensor(-1.1116, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "max sites:  tensor(1.0917, device='cuda:0', grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "site_file_path = f\"{destination}{max_iter}_cvt_{lambda_cvt}_chamfer_{lambda_chamfer}_eikonal_{lambda_eikonal}.npy\"\n",
    "\n",
    "# check if optimized sites file exists\n",
    "if os.path.exists(site_file_path):\n",
    "    # import sites\n",
    "    print(\"Importing sites\")\n",
    "    sites = np.load(site_file_path)\n",
    "    sites = torch.from_numpy(sites).to(device).requires_grad_(True)\n",
    "else:\n",
    "    # import cProfile, pstats\n",
    "    # import time\n",
    "\n",
    "    # profiler = cProfile.Profile()\n",
    "    # profiler.enable()\n",
    "\n",
    "    # with torch.profiler.profile(\n",
    "    #     activities=[\n",
    "    #         torch.profiler.ProfilerActivity.CPU,\n",
    "    #         torch.profiler.ProfilerActivity.CUDA,\n",
    "    #     ],\n",
    "    #     record_shapes=False,\n",
    "    #     with_stack=True,  # Captures function calls\n",
    "    # ) as prof:\n",
    "    #     sites, optimized_sites_sdf = train_DCCVT(\n",
    "    #         sites, sdf0, max_iter=max_iter, upsampling=0, lambda_weights=lambda_weights\n",
    "    #     )\n",
    "\n",
    "    # print(prof.key_averages().table(sort_by=\"self_cuda_time_total\"))\n",
    "    # prof.export_chrome_trace(\"trace.json\")\n",
    "\n",
    "    sites, optimized_sites_sdf = train_DCCVT(\n",
    "        sites,\n",
    "        sdf0,\n",
    "        max_iter=max_iter,\n",
    "        upsampling=ups,\n",
    "        lambda_weights=lambda_weights,\n",
    "        voroloss_optim=voroloss_optim,\n",
    "        Hotspot_model=model if voroloss_optim else None,\n",
    "    )\n",
    "\n",
    "    sites_np = sites.detach().cpu().numpy()\n",
    "    np.save(site_file_path, sites_np)\n",
    "\n",
    "print(\"Sites length: \", len(sites))\n",
    "print(\"min sites: \", torch.min(sites))\n",
    "print(\"max sites: \", torch.max(sites))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b7f7237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sdf torch.Size([72856])\n",
      "sites ./images/autograd/End2End_DCCVT_interpolSDF/ball2bunny/bunny1000_1000_3d_sites_4096_chamfer1000.pth\n",
      "sites_np shape:  (72856, 3)\n"
     ]
    }
   ],
   "source": [
    "epoch = 1000\n",
    "\n",
    "# model_file_path = f'{destination}{mesh[0]}{max_iter}_{epoch}_3d_model_{num_centroids}_chamfer{lambda_chamfer}.pth'\n",
    "site_file_path = f\"{destination}{mesh[0]}{max_iter}_{epoch}_3d_sites_{num_centroids}_chamfer{lambda_chamfer}.pth\"\n",
    "sdf_file_path = f\"{destination}{mesh[0]}{max_iter}_{epoch}_3d_sdf_{num_centroids}_chamfer{lambda_chamfer}.pth\"\n",
    "\n",
    "\n",
    "sites = torch.load(site_file_path)\n",
    "sdf_v = torch.load(sdf_file_path)\n",
    "if voroloss_optim:\n",
    "    sdf_v = model(sites).squeeze(-1)\n",
    "\n",
    "\n",
    "sites_np = sites.detach().cpu().numpy()\n",
    "print(\"sdf\", sdf_v.shape)\n",
    "print(\"sites\", site_file_path)\n",
    "\n",
    "ps_cloud_f = ps.register_point_cloud(f\"{epoch} epoch_cvt_grid\", sites_np)\n",
    "ps_cloud_f.add_scalar_quantity(\n",
    "    \"vis_grid_pred\",\n",
    "    sdf_v.detach().cpu().numpy(),\n",
    "    enabled=True,\n",
    "    cmap=\"coolwarm\",\n",
    "    vminmax=(-0.15, 0.15),\n",
    ")\n",
    "\n",
    "print(\"sites_np shape: \", sites_np.shape)\n",
    "\n",
    "# print sites if Nan\n",
    "if np.isnan(sites_np).any():\n",
    "    print(\"sites_np contains NaN values\")\n",
    "    print(\"sites_np NaN values: \", np.isnan(sites_np).sum())\n",
    "# remove nan values from sites tensor\n",
    "sites_np = sites_np[~np.isnan(sites_np).any(axis=1)]\n",
    "sites = torch.from_numpy(sites_np).to(device).requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a1aa94",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d0f86bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric between sites sdf values and their corresponding sdf values on hotspot model\n",
    "# true_Sdf = model(sites).squeeze(-1)\n",
    "d3dsimplices, _ = pygdel3d.triangulate(sites_np)\n",
    "d3dsimplices = torch.tensor(d3dsimplices, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9772bb82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Delaunay simplices...\n",
      "Number of Delaunay simplices: 440559\n",
      "Delaunay simplices shape: [[   18     3   257   259]\n",
      " [ 1292  2569  1547  2316]\n",
      " [    6   260   517   516]\n",
      " ...\n",
      " [71916 16322 30742 63104]\n",
      " [71916 70892 16322 63104]\n",
      " [71916 16322 70892 70175]]\n",
      "Max vertex index in simplices: 72855\n",
      "Min vertex index in simplices: 0\n",
      "Site index range: 72856\n",
      "Computing Delaunay simplices...\n",
      "Number of Delaunay simplices: 440559\n",
      "Delaunay simplices shape: [[   18     3   257   259]\n",
      " [    3     6     0   514]\n",
      " [ 1798  1286  1797  1799]\n",
      " ...\n",
      " [71916 70892 16322 63104]\n",
      " [71916 30742 69382 63104]\n",
      " [71916 16322 70892 70175]]\n",
      "Max vertex index in simplices: 72855\n",
      "Min vertex index in simplices: 0\n",
      "Site index range: 72856\n"
     ]
    }
   ],
   "source": [
    "# v_vect, f_vect = su.get_clipped_mesh_numba(sites, model, None, True)\n",
    "# ps.register_surface_mesh(\"model final clipped polygon mesh\", v_vect.detach().cpu().numpy(), f_vect)\n",
    "\n",
    "# v_vect, f_vect = su.get_clipped_mesh_numba(sites, model, None, False)\n",
    "# ps.register_surface_mesh(\"model final polygon mesh\", v_vect.detach().cpu().numpy(), f_vect)\n",
    "\n",
    "######################################################\n",
    "\n",
    "# if mesh[0] == \"sphere\":\n",
    "#     # generate sphere sdf\n",
    "#     print(\"Generating sphere SDF\")\n",
    "#     sdf_v = sphere_sdf(sites, torch.zeros(3).to(device), 0.50)\n",
    "\n",
    "(\n",
    "    v_vect,\n",
    "    f_vect,\n",
    "    _,\n",
    "    _,\n",
    "    _,\n",
    ") = su.get_clipped_mesh_numba(sites, None, None, False, sdf_v, True)\n",
    "\n",
    "output_obj_file = f\"{destination}{mesh[0]}_unclipped.obj\"\n",
    "su.save_obj(output_obj_file, v_vect.detach().cpu().numpy(), f_vect)\n",
    "\n",
    "\n",
    "# f_vect = [[f[0], f[i], f[i + 1]] for f in f_vect for i in range(1, len(f) - 1)]\n",
    "\n",
    "ps.register_surface_mesh(\n",
    "    \"sdf final unclipped polygon mesh\",\n",
    "    v_vect.detach().cpu().numpy(),\n",
    "    f_vect,\n",
    "    back_face_policy=\"identical\",\n",
    "    enabled=False,\n",
    ")\n",
    "\n",
    "if voroloss_optim:\n",
    "    ps.show()\n",
    "\n",
    "p, faces = su.cvt_extraction(sites, sdf_v, d3dsimplices.detach().cpu().numpy(), True)\n",
    "output_obj_file = f\"{destination}{mesh[0]}_interpol_extract.obj\"\n",
    "su.save_obj(output_obj_file, p.detach().cpu().numpy(), faces)\n",
    "# ps.register_point_cloud(\"cvt extraction\", p.detach().cpu().numpy())\n",
    "ps.register_surface_mesh(\"cvt extraction final\", p.detach().cpu().numpy(), faces, back_face_policy=\"identical\")\n",
    "\n",
    "\n",
    "v_vect, f_vect, _, _, _ = su.get_clipped_mesh_numba(sites, None, None, True, sdf_v, True)\n",
    "output_obj_file = f\"{destination}{mesh[0]}_proj_extract.obj\"\n",
    "su.save_obj(output_obj_file, v_vect.detach().cpu().numpy(), f_vect)\n",
    "# f_vect = [[f[0], f[i], f[i + 1]] for f in f_vect for i in range(1, len(f) - 1)]\n",
    "ps.register_surface_mesh(\n",
    "    \"sdf final clipped polygon mesh\", v_vect.detach().cpu().numpy(), f_vect, back_face_policy=\"identical\"\n",
    ")\n",
    "# f_vect = [[f[0], f[i], f[i + 1]] for f in f_vect for i in range(1, len(f) - 1)]\n",
    "\n",
    "d3dsimplices, _ = pygdel3d.triangulate(sites_np)\n",
    "d3dsimplices = torch.tensor(d3dsimplices, device=device)\n",
    "marching_tetrehedra_mesh = kaolin.ops.conversions.marching_tetrahedra(\n",
    "    sites.unsqueeze(0), d3dsimplices, sdf_v.unsqueeze(0), return_tet_idx=False\n",
    ")\n",
    "vertices_list, faces_list = marching_tetrehedra_mesh\n",
    "v_vect = vertices_list[0]\n",
    "faces = faces_list[0]\n",
    "\n",
    "ps.register_surface_mesh(\n",
    "    \"MTET\", v_vect.detach().cpu().numpy(), faces.detach().cpu().numpy(), back_face_policy=\"identical\"\n",
    ")\n",
    "\n",
    "# export obj file\n",
    "output_obj_file = f\"{destination}{mesh[0]}_MT.obj\"\n",
    "output_ply_file = (\n",
    "    f\"{destination}{mesh[0]}{max_iter}_{epoch}_3d_sites_{num_centroids}_chamfer{lambda_chamfer}_targetpointcloud.ply\"\n",
    ")\n",
    "su.save_obj(output_obj_file, v_vect.detach().cpu().numpy(), faces)\n",
    "# su.save_target_pc_ply(output_ply_file, mnfld_points.squeeze(0).detach().cpu().numpy())\n",
    "\n",
    "\n",
    "ps.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ece9872",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'obj_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvoronoiaccel\u001b[39;00m\n\u001b[32m      3\u001b[39m ERROR_SCALE = \u001b[32m1e5\u001b[39m  \u001b[38;5;66;03m# Scale the error metrics to match the unit of the model (e.g., if model is in cm, scale by 100)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m obj_pts, obj_normals, obj_mesh = su.sample_points_on_mesh(\u001b[43mobj_path\u001b[49m, n_points=N_POINTS, GT=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m      5\u001b[39m gt_mesh, gt_normals, gt_mesh = su.sample_points_on_mesh(obj_path, GT=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      6\u001b[39m cd1, cd2, f1, nc, recall, precision, completeness1, completeness2, accuracy1, accuracy2 = (\n\u001b[32m      7\u001b[39m     voronoiaccel.compute_error_fcpw(\n\u001b[32m      8\u001b[39m         np.array(gt_mesh.vertices),\n\u001b[32m   (...)\u001b[39m\u001b[32m     18\u001b[39m     )\n\u001b[32m     19\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'obj_path' is not defined"
     ]
    }
   ],
   "source": [
    "import voronoiaccel\n",
    "\n",
    "ERROR_SCALE = 1e5  # Scale the error metrics to match the unit of the model (e.g., if model is in cm, scale by 100)\n",
    "obj_pts, obj_normals, obj_mesh = su.sample_points_on_mesh(obj_path, n_points=N_POINTS, GT=False)\n",
    "gt_mesh, gt_normals, gt_mesh = su.sample_points_on_mesh(obj_path, GT=True)\n",
    "cd1, cd2, f1, nc, recall, precision, completeness1, completeness2, accuracy1, accuracy2 = (\n",
    "    voronoiaccel.compute_error_fcpw(\n",
    "        np.array(gt_mesh.vertices),\n",
    "        np.array(gt_mesh.faces).astype(np.int32),\n",
    "        np.array(gt_pts),\n",
    "        np.array(gt_normals),\n",
    "        np.array(obj_mesh.vertices),\n",
    "        np.array(obj_mesh.faces).astype(np.int32),\n",
    "        np.array(obj_pts),\n",
    "        np.array(obj_normals),\n",
    "        0.003,\n",
    "        0.45,\n",
    "    )\n",
    ")\n",
    "cd2 = cd2 * ERROR_SCALE  # Scale the Chamfer distance\n",
    "cd1 = cd1 * ERROR_SCALE  # Scale the Chamfer distance\n",
    "completeness1 = completeness1 * ERROR_SCALE  # Scale the completeness\n",
    "completeness2 = completeness2 * ERROR_SCALE  # Scale the completeness\n",
    "accuracy1 = accuracy1 * ERROR_SCALE  # Scale the accuracy\n",
    "accuracy2 = accuracy2 * ERROR_SCALE  # Scale the accuracy\n",
    "\n",
    "errors[obj_path] = {\n",
    "    \"cd1\": cd1,\n",
    "    \"cd2\": cd2,\n",
    "    \"f1\": f1,\n",
    "    \"nc\": nc,\n",
    "    \"recall\": recall,\n",
    "    \"precision\": precision,\n",
    "    \"completeness1\": completeness1,\n",
    "    \"completeness2\": completeness2,\n",
    "    \"accuracy1\": accuracy1,\n",
    "    \"accuracy2\": accuracy2,\n",
    "}\n",
    "print(\n",
    "    f\"  CD: {cd2:.4f},\\t F1: {f1:.4f},\\t NC: {nc:.4f},\\t Recall: {recall:.4f},\\t Precision: {precision:.4f},\\t Completeness2: {completeness2:.4f},\\t Accuracy2: {accuracy2:.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2a2308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sites, sdf = train_DCCVT(\n",
    "#     sites, sdf_v, max_iter=max_iter, upsampling=0, lambda_weights=lambda_weights, voroloss_optim=True\n",
    "# )\n",
    "# (\n",
    "#     v_vect,\n",
    "#     f_vect,\n",
    "#     _,\n",
    "#     _,\n",
    "#     _,\n",
    "# ) = su.get_clipped_mesh_numba(sites, None, None, False, sdf, True)\n",
    "# ps.register_surface_mesh(\"voromeh sdf final unclipped polygon mesh\", v_vect.detach().cpu().numpy(), f_vect)\n",
    "\n",
    "\n",
    "# v_vect, f_vect, _, _, _ = su.get_clipped_mesh_numba(sites, None, None, True, sdf, True)\n",
    "# ps.register_surface_mesh(\"voromeh sdf final clipped polygon mesh\", v_vect.detach().cpu().numpy(), f_vect)\n",
    "# # f_vect = [[f[0], f[i], f[i + 1]] for f in f_vect for i in range(1, len(f) - 1)]\n",
    "# ps.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a71d0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wylliam/dev/Kyushu_experiments-1/venv/lib/python3.12/site-packages/trimesh/base.py:605: RuntimeWarning: Mean of empty slice.\n",
      "  centroid = self.triangles_center.mean(axis=0)\n",
      "/home/wylliam/dev/Kyushu_experiments-1/venv/lib/python3.12/site-packages/numpy/_core/_methods.py:145: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Translation must be (3,) or (2,)!",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 35\u001b[39m\n\u001b[32m     30\u001b[39m     accuracy = np.mean(dists_ours_to_gt**\u001b[32m2\u001b[39m)\n\u001b[32m     32\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m accuracy, completeness\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m ours_pts, _ = \u001b[43msample_points_on_mesh\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_obj_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_points\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m m = mesh[\u001b[32m1\u001b[39m].replace(\u001b[33m\"\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmesh\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     37\u001b[39m gt_pts, _ = sample_points_on_mesh(m + \u001b[33m\"\u001b[39m\u001b[33m.obj\u001b[39m\u001b[33m\"\u001b[39m, n_points=\u001b[32m100000\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36msample_points_on_mesh\u001b[39m\u001b[34m(mesh_path, n_points)\u001b[39m\n\u001b[32m      8\u001b[39m mesh = trimesh.load(mesh_path)\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# normalize mesh\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[43mmesh\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply_translation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m-\u001b[49m\u001b[43mmesh\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcentroid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m mesh.apply_scale(\u001b[32m1.0\u001b[39m / np.max(np.abs(mesh.vertices)))\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# export mesh to obj file\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/Kyushu_experiments-1/venv/lib/python3.12/site-packages/trimesh/parent.py:192\u001b[39m, in \u001b[36mGeometry.apply_translation\u001b[39m\u001b[34m(self, translation)\u001b[39m\n\u001b[32m    190\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply_transform(tf.planar_matrix(offset=translation))\n\u001b[32m    191\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m translation.shape != (\u001b[32m3\u001b[39m,):\n\u001b[32m--> \u001b[39m\u001b[32m192\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mTranslation must be (3,) or (2,)!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    194\u001b[39m \u001b[38;5;66;03m# manually create a translation matrix\u001b[39;00m\n\u001b[32m    195\u001b[39m matrix = np.eye(\u001b[32m4\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: Translation must be (3,) or (2,)!"
     ]
    }
   ],
   "source": [
    "# chamfer metric\n",
    "# add sampled points to polyscope and ground truth mesh to polyscope\n",
    "\n",
    "import trimesh\n",
    "\n",
    "\n",
    "def sample_points_on_mesh(mesh_path, n_points=100000):\n",
    "    mesh = trimesh.load(mesh_path)\n",
    "    # normalize mesh\n",
    "    mesh.apply_translation(-mesh.centroid)\n",
    "    mesh.apply_scale(1.0 / np.max(np.abs(mesh.vertices)))\n",
    "    # export mesh to obj file\n",
    "    mesh.export(mesh_path.replace(\".obj\", \".obj\"))\n",
    "    print(mesh_path)\n",
    "    points, _ = trimesh.sample.sample_surface(mesh, n_points)\n",
    "    return points, mesh\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "\n",
    "def chamfer_accuracy_completeness(ours_pts, gt_pts):\n",
    "    # Completeness: GT â†’ Ours\n",
    "    dists_gt_to_ours = cKDTree(ours_pts).query(gt_pts, k=1)[0]\n",
    "    completeness = np.mean(dists_gt_to_ours**2)\n",
    "\n",
    "    # Accuracy: Ours â†’ GT\n",
    "    dists_ours_to_gt = cKDTree(gt_pts).query(ours_pts, k=1)[0]\n",
    "    accuracy = np.mean(dists_ours_to_gt**2)\n",
    "\n",
    "    return accuracy, completeness\n",
    "\n",
    "\n",
    "ours_pts, _ = sample_points_on_mesh(output_obj_file, n_points=100000)\n",
    "m = mesh[1].replace(\"data\", \"mesh\")\n",
    "gt_pts, _ = sample_points_on_mesh(m + \".obj\", n_points=100000)\n",
    "\n",
    "acc, comp = chamfer_accuracy_completeness(ours_pts, gt_pts)\n",
    "\n",
    "print(f\"Chamfer Accuracy (Ours â†’ GT): {acc:.6f}\")\n",
    "print(f\"Chamfer Completeness (GT â†’ Ours): {comp:.6f}\")\n",
    "print(f\"Chamfer Distance (symmetric): {acc + comp:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910f8f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing mesh:  68381.obj\n",
      "Sampled points shape:  (153600, 3)\n",
      "Sampled normals shape:  (153600, 3)\n",
      "Normalized mesh saved to:  /home/wylliam/dev/Kyushu_experiments/mesh/thingi32_150k/68381_norm.obj\n",
      "Sampled points saved to:  /home/wylliam/dev/Kyushu_experiments/mesh/thingi32_150k/68381.ply\n",
      "Processing mesh:  79241.obj\n",
      "Sampled points shape:  (153600, 3)\n",
      "Sampled normals shape:  (153600, 3)\n",
      "Normalized mesh saved to:  /home/wylliam/dev/Kyushu_experiments/mesh/thingi32_150k/79241_norm.obj\n",
      "Sampled points saved to:  /home/wylliam/dev/Kyushu_experiments/mesh/thingi32_150k/79241.ply\n",
      "Processing mesh:  68380.obj\n",
      "Sampled points shape:  (153600, 3)\n",
      "Sampled normals shape:  (153600, 3)\n",
      "Normalized mesh saved to:  /home/wylliam/dev/Kyushu_experiments/mesh/thingi32_150k/68380_norm.obj\n",
      "Sampled points saved to:  /home/wylliam/dev/Kyushu_experiments/mesh/thingi32_150k/68380.ply\n",
      "Processing mesh:  72870.obj\n",
      "Sampled points shape:  (153600, 3)\n",
      "Sampled normals shape:  (153600, 3)\n",
      "Normalized mesh saved to:  /home/wylliam/dev/Kyushu_experiments/mesh/thingi32_150k/72870_norm.obj\n",
      "Sampled points saved to:  /home/wylliam/dev/Kyushu_experiments/mesh/thingi32_150k/72870.ply\n",
      "Processing mesh:  64764.obj\n",
      "Sampled points shape:  (153600, 3)\n",
      "Sampled normals shape:  (153600, 3)\n",
      "Normalized mesh saved to:  /home/wylliam/dev/Kyushu_experiments/mesh/thingi32_150k/64764_norm.obj\n",
      "Sampled points saved to:  /home/wylliam/dev/Kyushu_experiments/mesh/thingi32_150k/64764.ply\n",
      "Processing mesh:  75662.obj\n",
      "Sampled points shape:  (153600, 3)\n",
      "Sampled normals shape:  (153600, 3)\n",
      "Normalized mesh saved to:  /home/wylliam/dev/Kyushu_experiments/mesh/thingi32_150k/75662_norm.obj\n",
      "Sampled points saved to:  /home/wylliam/dev/Kyushu_experiments/mesh/thingi32_150k/75662.ply\n",
      "Processing mesh:  47984.obj\n",
      "Sampled points shape:  (153600, 3)\n",
      "Sampled normals shape:  (153600, 3)\n",
      "Normalized mesh saved to:  /home/wylliam/dev/Kyushu_experiments/mesh/thingi32_150k/47984_norm.obj\n",
      "Sampled points saved to:  /home/wylliam/dev/Kyushu_experiments/mesh/thingi32_150k/47984.ply\n",
      "Processing mesh:  77245.obj\n",
      "Sampled points shape:  (153600, 3)\n",
      "Sampled normals shape:  (153600, 3)\n",
      "Normalized mesh saved to:  /home/wylliam/dev/Kyushu_experiments/mesh/thingi32_150k/77245_norm.obj\n",
      "Sampled points saved to:  /home/wylliam/dev/Kyushu_experiments/mesh/thingi32_150k/77245.ply\n",
      "Processing mesh:  75656.obj\n",
      "Sampled points shape:  (153600, 3)\n",
      "Sampled normals shape:  (153600, 3)\n",
      "Normalized mesh saved to:  /home/wylliam/dev/Kyushu_experiments/mesh/thingi32_150k/75656_norm.obj\n",
      "Sampled points saved to:  /home/wylliam/dev/Kyushu_experiments/mesh/thingi32_150k/75656.ply\n",
      "Processing mesh:  76277.obj\n",
      "Sampled points shape:  (153600, 3)\n",
      "Sampled normals shape:  (153600, 3)\n",
      "Normalized mesh saved to:  /home/wylliam/dev/Kyushu_experiments/mesh/thingi32_150k/76277_norm.obj\n",
      "Sampled points saved to:  /home/wylliam/dev/Kyushu_experiments/mesh/thingi32_150k/76277.ply\n",
      "Processing mesh:  398259.obj\n",
      "Sampled points shape:  (153600, 3)\n",
      "Sampled normals shape:  (153600, 3)\n",
      "Normalized mesh saved to:  /home/wylliam/dev/Kyushu_experiments/mesh/thingi32_150k/398259_norm.obj\n",
      "Sampled points saved to:  /home/wylliam/dev/Kyushu_experiments/mesh/thingi32_150k/398259.ply\n",
      "Processing mesh:  90889.obj\n",
      "Sampled points shape:  (153600, 3)\n",
      "Sampled normals shape:  (153600, 3)\n",
      "Normalized mesh saved to:  /home/wylliam/dev/Kyushu_experiments/mesh/thingi32_150k/90889_norm.obj\n",
      "Sampled points saved to:  /home/wylliam/dev/Kyushu_experiments/mesh/thingi32_150k/90889.ply\n",
      "Processing mesh:  75496.obj\n",
      "Sampled points shape:  (153600, 3)\n",
      "Sampled normals shape:  (153600, 3)\n",
      "Normalized mesh saved to:  /home/wylliam/dev/Kyushu_experiments/mesh/thingi32_150k/75496_norm.obj\n",
      "Sampled points saved to:  /home/wylliam/dev/Kyushu_experiments/mesh/thingi32_150k/75496.ply\n",
      "Processing mesh:  44234.obj\n",
      "Sampled points shape:  (153600, 3)\n",
      "Sampled normals shape:  (153600, 3)\n",
      "Normalized mesh saved to:  /home/wylliam/dev/Kyushu_experiments/mesh/thingi32_150k/44234_norm.obj\n",
      "Sampled points saved to:  /home/wylliam/dev/Kyushu_experiments/mesh/thingi32_150k/44234.ply\n",
      "Processing mesh:  354371.obj\n",
      "Sampled points shape:  (153600, 3)\n",
      "Sampled normals shape:  (153600, 3)\n",
      "Normalized mesh saved to:  /home/wylliam/dev/Kyushu_experiments/mesh/thingi32_150k/354371_norm.obj\n",
      "Sampled points saved to:  /home/wylliam/dev/Kyushu_experiments/mesh/thingi32_150k/354371.ply\n",
      "Processing mesh:  92880.obj\n",
      "Sampled points shape:  (153600, 3)\n",
      "Sampled normals shape:  (153600, 3)\n",
      "Normalized mesh saved to:  /home/wylliam/dev/Kyushu_experiments/mesh/thingi32_150k/92880_norm.obj\n",
      "Sampled points saved to:  /home/wylliam/dev/Kyushu_experiments/mesh/thingi32_150k/92880.ply\n",
      "Processing mesh:  316358.obj\n",
      "Sampled points shape:  (153600, 3)\n",
      "Sampled normals shape:  (153600, 3)\n",
      "Normalized mesh saved to:  /home/wylliam/dev/Kyushu_experiments/mesh/thingi32_150k/316358_norm.obj\n",
      "Sampled points saved to:  /home/wylliam/dev/Kyushu_experiments/mesh/thingi32_150k/316358.ply\n",
      "Processing mesh:  64444.obj\n",
      "Sampled points shape:  (153600, 3)\n",
      "Sampled normals shape:  (153600, 3)\n",
      "Normalized mesh saved to:  /home/wylliam/dev/Kyushu_experiments/mesh/thingi32_150k/64444_norm.obj\n",
      "Sampled points saved to:  /home/wylliam/dev/Kyushu_experiments/mesh/thingi32_150k/64444.ply\n",
      "Processing mesh:  72960.obj\n",
      "Sampled points shape:  (153600, 3)\n",
      "Sampled normals shape:  (153600, 3)\n",
      "Normalized mesh saved to:  /home/wylliam/dev/Kyushu_experiments/mesh/thingi32_150k/72960_norm.obj\n",
      "Sampled points saved to:  /home/wylliam/dev/Kyushu_experiments/mesh/thingi32_150k/72960.ply\n",
      "Processing mesh:  313444.obj\n",
      "Sampled points shape:  (153600, 3)\n",
      "Sampled normals shape:  (153600, 3)\n",
      "Normalized mesh saved to:  /home/wylliam/dev/Kyushu_experiments/mesh/thingi32_150k/313444_norm.obj\n",
      "Sampled points saved to:  /home/wylliam/dev/Kyushu_experiments/mesh/thingi32_150k/313444.ply\n",
      "Processing mesh:  78671.obj\n",
      "Sampled points shape:  (153600, 3)\n",
      "Sampled normals shape:  (153600, 3)\n",
      "Normalized mesh saved to:  /home/wylliam/dev/Kyushu_experiments/mesh/thingi32_150k/78671_norm.obj\n",
      "Sampled points saved to:  /home/wylliam/dev/Kyushu_experiments/mesh/thingi32_150k/78671.ply\n",
      "Processing mesh:  75665.obj\n",
      "Sampled points shape:  (153600, 3)\n",
      "Sampled normals shape:  (153600, 3)\n",
      "Normalized mesh saved to:  /home/wylliam/dev/Kyushu_experiments/mesh/thingi32_150k/75665_norm.obj\n",
      "Sampled points saved to:  /home/wylliam/dev/Kyushu_experiments/mesh/thingi32_150k/75665.ply\n",
      "Processing mesh:  96481.obj\n",
      "Sampled points shape:  (153600, 3)\n",
      "Sampled normals shape:  (153600, 3)\n",
      "Normalized mesh saved to:  /home/wylliam/dev/Kyushu_experiments/mesh/thingi32_150k/96481_norm.obj\n",
      "Sampled points saved to:  /home/wylliam/dev/Kyushu_experiments/mesh/thingi32_150k/96481.ply\n",
      "Processing mesh:  441708_150k.obj\n",
      "Sampled points shape:  (153600, 3)\n",
      "Sampled normals shape:  (153600, 3)\n",
      "Normalized mesh saved to:  /home/wylliam/dev/Kyushu_experiments/mesh/thingi32_150k/441708_150k_norm.obj\n",
      "Sampled points saved to:  /home/wylliam/dev/Kyushu_experiments/mesh/thingi32_150k/441708_150k.ply\n",
      "Processing mesh:  58168.obj\n",
      "Sampled points shape:  (153600, 3)\n",
      "Sampled normals shape:  (153600, 3)\n",
      "Normalized mesh saved to:  /home/wylliam/dev/Kyushu_experiments/mesh/thingi32_150k/58168_norm.obj\n",
      "Sampled points saved to:  /home/wylliam/dev/Kyushu_experiments/mesh/thingi32_150k/58168.ply\n",
      "Processing mesh:  75655.obj\n",
      "Sampled points shape:  (153600, 3)\n",
      "Sampled normals shape:  (153600, 3)\n",
      "Normalized mesh saved to:  /home/wylliam/dev/Kyushu_experiments/mesh/thingi32_150k/75655_norm.obj\n",
      "Sampled points saved to:  /home/wylliam/dev/Kyushu_experiments/mesh/thingi32_150k/75655.ply\n",
      "Processing mesh:  92763.obj\n",
      "Sampled points shape:  (153600, 3)\n",
      "Sampled normals shape:  (153600, 3)\n",
      "Normalized mesh saved to:  /home/wylliam/dev/Kyushu_experiments/mesh/thingi32_150k/92763_norm.obj\n",
      "Sampled points saved to:  /home/wylliam/dev/Kyushu_experiments/mesh/thingi32_150k/92763.ply\n",
      "Processing mesh:  252119.obj\n",
      "Sampled points shape:  (153600, 3)\n",
      "Sampled normals shape:  (153600, 3)\n",
      "Normalized mesh saved to:  /home/wylliam/dev/Kyushu_experiments/mesh/thingi32_150k/252119_norm.obj\n",
      "Sampled points saved to:  /home/wylliam/dev/Kyushu_experiments/mesh/thingi32_150k/252119.ply\n",
      "Processing mesh:  527631.obj\n",
      "Sampled points shape:  (153600, 3)\n",
      "Sampled normals shape:  (153600, 3)\n",
      "Normalized mesh saved to:  /home/wylliam/dev/Kyushu_experiments/mesh/thingi32_150k/527631_norm.obj\n",
      "Sampled points saved to:  /home/wylliam/dev/Kyushu_experiments/mesh/thingi32_150k/527631.ply\n",
      "Processing mesh:  53159.obj\n",
      "Sampled points shape:  (153600, 3)\n",
      "Sampled normals shape:  (153600, 3)\n",
      "Normalized mesh saved to:  /home/wylliam/dev/Kyushu_experiments/mesh/thingi32_150k/53159_norm.obj\n",
      "Sampled points saved to:  /home/wylliam/dev/Kyushu_experiments/mesh/thingi32_150k/53159.ply\n",
      "Processing mesh:  95444.obj\n",
      "Sampled points shape:  (153600, 3)\n",
      "Sampled normals shape:  (153600, 3)\n",
      "Normalized mesh saved to:  /home/wylliam/dev/Kyushu_experiments/mesh/thingi32_150k/95444_norm.obj\n",
      "Sampled points saved to:  /home/wylliam/dev/Kyushu_experiments/mesh/thingi32_150k/95444.ply\n",
      "Processing mesh:  441708.obj\n",
      "Sampled points shape:  (153600, 3)\n",
      "Sampled normals shape:  (153600, 3)\n",
      "Normalized mesh saved to:  /home/wylliam/dev/Kyushu_experiments/mesh/thingi32_150k/441708_norm.obj\n",
      "Sampled points saved to:  /home/wylliam/dev/Kyushu_experiments/mesh/thingi32_150k/441708.ply\n",
      "Processing mesh:  73075.obj\n",
      "Sampled points shape:  (153600, 3)\n",
      "Sampled normals shape:  (153600, 3)\n",
      "Normalized mesh saved to:  /home/wylliam/dev/Kyushu_experiments/mesh/thingi32_150k/73075_norm.obj\n",
      "Sampled points saved to:  /home/wylliam/dev/Kyushu_experiments/mesh/thingi32_150k/73075.ply\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import trimesh\n",
    "# import numpy as np\n",
    "\n",
    "\n",
    "# def sample_points_on_mesh(mesh_path, n_points=32 * 32 * 150, GT=True):\n",
    "#     mesh = trimesh.load(mesh_path)\n",
    "#     points, idx = trimesh.sample.sample_surface(mesh, n_points)\n",
    "#     normals = mesh.face_normals[idx]  # Get normals at sampled points\n",
    "\n",
    "#     if GT:\n",
    "#         # Center the point cloud\n",
    "#         points = np.asarray(points, dtype=np.float32)\n",
    "#         center = points.mean(axis=0)\n",
    "#         points -= center\n",
    "\n",
    "#         # Compute scale factor (same as HotSpot)\n",
    "#         scale = np.percentile(np.linalg.norm(points, axis=-1), 70) / 0.45\n",
    "#         scale = max(scale, np.abs(points).max())\n",
    "#         points /= scale\n",
    "\n",
    "#         # Apply same normalization to mesh vertices\n",
    "#         mesh.vertices = (mesh.vertices - center) / scale\n",
    "\n",
    "#         mesh.export(mesh_path.replace(\".obj\", \".obj\"))\n",
    "#         # Save sampled points as a .ply file using trimesh\n",
    "#         pc = trimesh.PointCloud(points)\n",
    "#         pc.export(mesh_path.replace(\".obj\", \".ply\"))\n",
    "\n",
    "#     return points, normals, mesh\n",
    "\n",
    "\n",
    "# thingi32_150k_dir = \"/home/wylliam/dev/Kyushu_experiments/mesh/thingi32_150k/\"\n",
    "# all_mesh = [m for m in os.listdir(thingi32_150k_dir) if m.endswith(\".obj\")]\n",
    "# for mesh in all_mesh:\n",
    "#     print(\"Processing mesh: \", mesh)\n",
    "#     m = thingi32_150k_dir + mesh\n",
    "#     points, normals, mesh = sample_points_on_mesh(m)\n",
    "#     print(\"Sampled points shape: \", points.shape)\n",
    "#     print(\"Sampled normals shape: \", normals.shape)\n",
    "#     print(\"Normalized mesh saved to: \", m.replace(\".obj\", \"_norm.obj\"))\n",
    "#     print(\"Sampled points saved to: \", m.replace(\".obj\", \".ply\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0080741f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import polyscope as ps\n",
    "\n",
    "\n",
    "def ellipsoid_mesh(mean, cov, k=1.0, res_u=48, res_v=24):\n",
    "    \"\"\"\n",
    "    Build a triangle mesh for the k-sigma ellipsoid of N(mu, cov).\n",
    "\n",
    "    mean: (3,) array-like\n",
    "    cov:  (3,3) SPD matrix\n",
    "    k:    sigma scale (1.0 for 1Ïƒ, 2.0 for 2Ïƒ, ...)\n",
    "    res_u,res_v: sphere grid resolution (longitude/latitude)\n",
    "    Returns: V (nV,3), F (nF,3)\n",
    "    \"\"\"\n",
    "    mean = np.asarray(mean, dtype=float).reshape(3)\n",
    "    cov = np.asarray(cov, dtype=float).reshape(3, 3)\n",
    "\n",
    "    # eigendecomposition: cov = Q diag(Î») Q^T\n",
    "    # eigh ensures sorted eigenvalues; guard small negatives due to numerics\n",
    "    lam, Q = np.linalg.eigh(cov)\n",
    "    lam = np.maximum(lam, 0.0)\n",
    "    radii = k * np.sqrt(lam)  # axis lengths (Ïƒ-scaled)\n",
    "    A = Q @ np.diag(radii)  # linear transform from unit sphere to ellipsoid\n",
    "\n",
    "    # unit sphere parameterization\n",
    "    u = np.linspace(0.0, 2.0 * np.pi, res_u, endpoint=False)\n",
    "    v = np.linspace(0.0, np.pi, res_v, endpoint=True)\n",
    "    uu, vv = np.meshgrid(u, v, indexing=\"xy\")\n",
    "\n",
    "    x = np.cos(uu) * np.sin(vv)\n",
    "    y = np.sin(uu) * np.sin(vv)\n",
    "    z = np.cos(vv)\n",
    "    S = np.stack([x, y, z], axis=-1)  # (res_v, res_u, 3)\n",
    "    S = S.reshape(-1, 3)  # (res_v*res_u, 3)\n",
    "\n",
    "    # transform to ellipsoid\n",
    "    V = (S @ A.T) + mean  # (nV, 3)\n",
    "\n",
    "    # faces (two triangles per quad strip in (v,u) grid)\n",
    "    def idx(i, j):\n",
    "        return (i % res_v) * res_u + (j % res_u)\n",
    "\n",
    "    faces = []\n",
    "    for i in range(res_v - 1):  # latitude strips (exclude poles row)\n",
    "        for j in range(res_u):  # wrap around longitude\n",
    "            a = idx(i, j)\n",
    "            b = idx(i, j + 1)\n",
    "            c = idx(i + 1, j)\n",
    "            d = idx(i + 1, j + 1)\n",
    "            faces.append([a, c, b])\n",
    "            faces.append([b, c, d])\n",
    "\n",
    "    # collapse top/bottom fans (optional; current grid includes poles already cleanly)\n",
    "    F = np.asarray(faces, dtype=int)\n",
    "    return V, F\n",
    "\n",
    "\n",
    "def register_gaussian_ellipsoids(name, mean, cov, ks=(1.0,), colors=None, alphas=None, res_u=64, res_v=32):\n",
    "    \"\"\"\n",
    "    Register one or more k-sigma ellipsoids in Polyscope as surface meshes.\n",
    "    \"\"\"\n",
    "    if colors is None:\n",
    "        # default grayscale tones for up to 3 shells\n",
    "        colors = [(0.80, 0.80, 0.80), (0.55, 0.55, 0.55), (0.35, 0.35, 0.35)]\n",
    "    if alphas is None:\n",
    "        alphas = [0.65, 0.35, 0.20]\n",
    "\n",
    "    for i, k in enumerate(ks):\n",
    "        V, F = ellipsoid_mesh(mean, cov, k=k, res_u=res_u, res_v=res_v)\n",
    "        m = ps.register_surface_mesh(f\"{name}_{k:.1f}Ïƒ\", V, F, smooth_shade=True)\n",
    "        # style\n",
    "        c = colors[i % len(colors)]\n",
    "        a = alphas[i % len(alphas)]\n",
    "        m.set_color(c)\n",
    "        m.set_transparency(a)\n",
    "        m.set_edge_width(1.0)  # thin wireframe overlay\n",
    "        m.set_edge_color((0.1, 0.1, 0.1))\n",
    "\n",
    "\n",
    "# -------------------- example usage --------------------\n",
    "if __name__ == \"__main__\":\n",
    "    ps.init()\n",
    "\n",
    "    mu = np.array([0.0, 0.0, 0.0])\n",
    "    cov = np.array([[0.09, 0.00, 0.00], [0.00, 0.04, 0.02], [0.00, 0.02, 0.16]])  # SPD\n",
    "\n",
    "    # draw 1Ïƒ, 2Ïƒ shells\n",
    "    register_gaussian_ellipsoids(\"GaussianA\", mu, cov, ks=(1.0, 2.0))\n",
    "\n",
    "    # a second Gaussian to compare\n",
    "    mu2 = np.array([0.6, -0.3, 0.2])\n",
    "    cov2 = np.array([[0.02, 0.01, 0.00], [0.01, 0.05, 0.01], [0.00, 0.01, 0.03]])\n",
    "    register_gaussian_ellipsoids(\"GaussianB\", mu2, cov2, ks=(1.0,))\n",
    "\n",
    "    ps.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
