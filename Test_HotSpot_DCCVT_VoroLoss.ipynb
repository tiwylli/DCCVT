{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed71bbfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "Using device:  NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "import kaolin\n",
    "import torch\n",
    "import math\n",
    "import matplotlib\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import polyscope as ps\n",
    "import trimesh\n",
    "import diffvoronoi\n",
    "\n",
    "from scipy.spatial import Voronoi, voronoi_plot_2d, Delaunay\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import sdfpred_utils.sdfpred_utils as su\n",
    "import sdfpred_utils.sdf_MLP as mlp\n",
    "import sdfpred_utils.sdf_functions as sdf\n",
    "import sdfpred_utils.loss_functions as lf\n",
    "import sdfpred_utils.Steik_data3d as sd3d\n",
    "import sdfpred_utils.Steik_Loss as sl\n",
    "import sdfpred_utils.Steik_utils as Stu \n",
    "import open3d as o3d\n",
    "\n",
    "#cuda devices\n",
    "device = torch.device(\"cuda:0\")\n",
    "print(\"Using device: \", torch.cuda.get_device_name(device))\n",
    "\n",
    "#default tensor types\n",
    "#torch.set_default_tensor_type(torch.cuda.DoubleTensor)\n",
    "\n",
    "multires = 2\n",
    "input_dims = 3\n",
    "lr_sites = 0.005\n",
    "#lr_model = 0.00005*2\n",
    "destination = \"./images/autograd/HotSpot/\"\n",
    "model_trained_it = \"\"\n",
    "\n",
    "# mesh = [\"gargoyle\",\"/home/wylliam/dev/Kyushu_experiments/data/gargoyle\"]\n",
    "# trained_model_path = f\"/home/wylliam/dev/HotSpot/log/3D/pc/HotSpot-all-2025-04-24-18-16-03/gargoyle/gargoyle/trained_models/model{model_trained_it}.pth\"\n",
    "\n",
    "# mesh = [\"chair\",\"/home/wylliam/dev/Kyushu_experiments/data/chair\"]\n",
    "# trained_model_path = f\"/home/wylliam/dev/HotSpot/log/3D/pc/HotSpot-all-2025-05-02-17-56-25/chair/chair/trained_models/model{model_trained_it}.pth\"\n",
    "\n",
    "\n",
    "mesh = [\"bunny\",\"/home/wylliam/dev/Kyushu_experiments/data/bunny\"]\n",
    "trained_model_path = f\"/home/wylliam/dev/HotSpot/log/3D/pc/HotSpot-all-2025-04-25-17-32-49/bunny/bunny/trained_models/model{model_trained_it}.pth\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96ddcc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch3d.ops import knn_points, knn_gather\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class Voroloss_opt(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Voroloss_opt, self).__init__()\n",
    "        self.knn = 16\n",
    "\n",
    "    def __call__(self, points, spoints):\n",
    "        \"\"\"points, self.points\"\"\"\n",
    "        # WARNING: fecthing for knn\n",
    "        with torch.no_grad():\n",
    "            indices = knn_points(points, spoints, K=self.knn).idx\n",
    "\n",
    "        points_knn = knn_gather(spoints, indices)\n",
    "        points_to_voronoi_center = points - points_knn[:, :, 0]\n",
    "\n",
    "        voronoi_edge = points_knn[:, :, 1:] - points_knn[:, :, 0].unsqueeze(2)\n",
    "        voronoi_edge_l = torch.sqrt(((voronoi_edge**2).sum(-1)))\n",
    "        vector_length = (points_to_voronoi_center.unsqueeze(2) * voronoi_edge).sum(\n",
    "            -1\n",
    "        ) / voronoi_edge_l\n",
    "        sq_dist = (vector_length - voronoi_edge_l / 2) ** 2\n",
    "        return sq_dist.min(-1)[0]\n",
    "    \n",
    "voroloss = Voroloss_opt().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95a49d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sites_spread_loss(sites):\n",
    "#     with torch.no_grad():\n",
    "#         indices = knn_points(sites, sites, K=).idx\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a4b4e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new sites\n",
      "Sites shape:  torch.Size([512, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wylliam/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1678402412426/work/aten/src/ATen/native/TensorShape.cpp:3483.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[polyscope] Backend: openGL3_glfw -- Loaded openGL version: 3.3.0 NVIDIA 570.144\n"
     ]
    }
   ],
   "source": [
    "num_centroids = 8**3\n",
    "\n",
    "print(\"Creating new sites\")\n",
    "noise_scale = 0.1\n",
    "domain_limit = 1\n",
    "x = torch.linspace(-domain_limit, domain_limit, int(round(num_centroids**(1/3))))\n",
    "y = torch.linspace(-domain_limit, domain_limit, int(round(num_centroids**(1/3))))\n",
    "z = torch.linspace(-domain_limit, domain_limit, int(round(num_centroids**(1/3))))\n",
    "meshgrid = torch.meshgrid(x, y, z)\n",
    "meshgrid = torch.stack(meshgrid, dim=3).view(-1, 3)\n",
    "#add noise to meshgrid\n",
    "meshgrid += torch.randn_like(meshgrid) * noise_scale\n",
    "sites = meshgrid.to(device, dtype=torch.float32).requires_grad_(True)\n",
    "\n",
    "print(\"Sites shape: \", sites.shape)\n",
    "ps.init()\n",
    "#ps.register_point_cloud(\"initial_cvt_grid\",sites.detach().cpu().numpy())\n",
    "\n",
    "# # load pointcloud used for sdf training\n",
    "# pointcloud = o3d.io.read_point_cloud(mesh[1]+\".ply\")\n",
    "# print(\"Pointcloud shape: \", np.asarray(pointcloud.points).shape)\n",
    "# # sample pointcloud to 150*32*32\n",
    "# chamfer_distance_pc_gt = pointcloud.uniform_down_sample(int((128**3)/(150*32*32)))\n",
    "# chamfer_distance_pc_gt = np.asarray(chamfer_distance_pc_gt.points)\n",
    "# print(\"Chamfer distance pointcloud shape: \", chamfer_distance_pc_gt.shape)\n",
    "\n",
    "\n",
    "# ps.register_point_cloud(\"pointcloud_gt\", chamfer_distance_pc_gt)\n",
    "# chamfer_distance_pc_gt = torch.tensor(chamfer_distance_pc_gt, device=device, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe96048f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnfld_points shape:  torch.Size([1, 153600, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wylliam/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LOAD MODEL WITH HOTSPOT\n",
    "import sys\n",
    "sys.path.append(\"3rdparty/HotSpot\")\n",
    "from dataset import shape_3d\n",
    "import models.Net as Net\n",
    "\n",
    "loss_type = \"igr_w_heat\"\n",
    "loss_weights = [350, 0, 0, 1, 0, 0, 20]\n",
    "\n",
    "train_set = shape_3d.ReconDataset(\n",
    "    file_path = mesh[1]+\".ply\",\n",
    "    n_points=32*32*150,#15000, #args.n_points,\n",
    "    n_samples=10001, #args.n_iterations,\n",
    "    grid_res=256, #args.grid_res,\n",
    "    grid_range=1.1, #args.grid_range,\n",
    "    sample_type=\"uniform_central_gaussian\", #args.nonmnfld_sample_type,\n",
    "    sampling_std=0.5, #args.nonmnfld_sample_std,\n",
    "    n_random_samples=7500, #args.n_random_samples,\n",
    "    resample=True,\n",
    "    compute_sal_dist_gt=(\n",
    "        True if \"sal\" in loss_type and loss_weights[5] > 0 else False\n",
    "    ),\n",
    "    scale_method=\"mean\"#\"mean\" #args.pcd_scale_method,\n",
    ")\n",
    "\n",
    "model = Net.Network(\n",
    "    latent_size=0,#args.latent_size,\n",
    "    in_dim=3,\n",
    "    decoder_hidden_dim=128,#args.decoder_hidden_dim,\n",
    "    nl=\"sine\",#args.nl,\n",
    "    encoder_type=\"none\",#args.encoder_type,\n",
    "    decoder_n_hidden_layers=5,#args.decoder_n_hidden_layers,\n",
    "    neuron_type=\"quadratic\",#args.neuron_type,\n",
    "    init_type=\"mfgi\",#args.init_type,\n",
    "    sphere_init_params=[1.6, 0.1],#args.sphere_init_params,\n",
    "    n_repeat_period=30#args.n_repeat_period,\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "######       \n",
    "test_dataloader = torch.utils.data.DataLoader(train_set, batch_size=1, shuffle=False, num_workers=0, pin_memory=False)   \n",
    "test_data = next(iter(test_dataloader))\n",
    "mnfld_points = test_data[\"mnfld_points\"].to(device)\n",
    "mnfld_points.requires_grad_()\n",
    "print(\"mnfld_points shape: \", mnfld_points.shape)\n",
    "if torch.cuda.is_available():\n",
    "    map_location = torch.device(\"cuda\")\n",
    "else:\n",
    "    map_location = torch.device(\"cpu\")\n",
    "model.load_state_dict(torch.load(trained_model_path, weights_only=True, map_location=map_location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5753400f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #add mnfld points with random noise to sites \n",
    "N = mnfld_points.squeeze(0).shape[0]\n",
    "num_samples = 32**3\n",
    "idx = torch.randint(0, N, (num_samples,))\n",
    "sampled = mnfld_points.squeeze(0)[idx]\n",
    "perturbed = sampled + (torch.rand_like(sampled)-0.5)*0.1\n",
    "sites = torch.cat((sites, perturbed), dim=0)\n",
    "\n",
    "# make sites a leaf tensor\n",
    "sites = sites.detach().requires_grad_()\n",
    "\n",
    "sites_pred = model(sites)#[\"nonmanifold_pnts_pred\"]\n",
    "#mnfld_preds = model(mnfld_points)#[\"nonmanifold_pnts_pred\"]\n",
    "\n",
    "ps_cloud = ps.register_point_cloud(\"initial_cvt_grid+pc_gt\",sites.detach().cpu().numpy())\n",
    "mnf_cloud = ps.register_point_cloud(\"mnfld_points_pred\",mnfld_points.squeeze(0).detach().cpu().numpy())\n",
    "#mnf_cloud.add_scalar_quantity(\"mnfld_points_pred\", mnfld_preds.reshape(-1).detach().cpu().numpy(), enabled=True)\n",
    "ps_cloud.add_scalar_quantity(\"vis_grid_pred\", sites_pred.reshape(-1).detach().cpu().numpy(), enabled=True)\n",
    "\n",
    "initial_mesh = su.get_zero_crossing_mesh_3d(sites, model)\n",
    "ps.register_surface_mesh(\"initial Zero-Crossing faces\", initial_mesh[0], initial_mesh[1])\n",
    "\n",
    "ps.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "460a316b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SITES OPTIMISATION LOOP\n",
    "cvt_loss_values = []\n",
    "min_distance_loss_values = []\n",
    "chamfer_distance_loss_values = []\n",
    "eikonal_loss_values = []\n",
    "domain_restriction_loss_values = []\n",
    "sdf_loss_values = []\n",
    "div_loss_values = []\n",
    "loss_values = []\n",
    "\n",
    "\n",
    "\n",
    "def autograd(sites, model, max_iter=100, stop_train_threshold=1e-6, upsampling=0, lambda_weights = [0.1,1.0,0.1,0.1,1.0,1.0,0.1]):\n",
    "    optimizer = torch.optim.Adam([\n",
    "    {'params': [sites], 'lr': lr_sites}\n",
    "], betas=(0.9, 0.999))\n",
    "\n",
    "    prev_loss = float(\"inf\")\n",
    "    best_loss = float(\"inf\")\n",
    "    upsampled = 0.0\n",
    "    epoch = 0\n",
    "    lambda_cvt = lambda_weights[0]\n",
    "    # lambda_pc = lambda_weights[1]\n",
    "    lambda_min_distance = lambda_weights[2]\n",
    "    # lambda_laplace = lambda_weights[3]\n",
    "    lambda_chamfer = lambda_weights[4]\n",
    "    lambda_eikonal = lambda_weights[5]\n",
    "    lambda_domain_restriction = lambda_weights[6]\n",
    "    # lambda_target_points = lambda_weights[7]\n",
    "    lambda_sdf = 5e3\n",
    "    lambda_div = 1e2\n",
    "    lambda_eikonal = 5e1\n",
    "    best_sites = sites.clone()\n",
    "    best_sites.best_loss = best_loss\n",
    "    \n",
    "    while epoch <= max_iter:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # compute voronoi and delaunay once for each epoch and pass it around\n",
    "        # Compute Voronoi diagram\n",
    "        sites_np = sites.detach().cpu().numpy()\n",
    "        #vor = Voronoi(sites_np)\n",
    "        #tri = Delaunay(sites_np)\n",
    "      \n",
    "      \n",
    "        d3dsimplices = diffvoronoi.get_delaunay_simplices(sites_np.reshape(input_dims*sites_np.shape[0]))\n",
    "        d3dsimplices = np.array(d3dsimplices)\n",
    "        #print(\"Delaunay simplices shape: \", d3dsimplices.shape)\n",
    "        \n",
    "        vertices_to_compute, bisectors_to_compute = su.compute_zero_crossing_vertices_3d(sites, None, None, d3dsimplices, model)\n",
    "                \n",
    "        #vertices_to_compute, bisectors_to_compute = su.compute_zero_crossing_vertices_3d(sites, None, tri, None, model)\n",
    "        #vertices_to_compute, bisectors_to_compute = su.compute_zero_crossing_vertices_3d(sites, vor, tri, None, model)\n",
    "        \n",
    "        vertices = su.compute_vertices_3d_vectorized(sites, vertices_to_compute)    \n",
    "        bisectors = su.compute_all_bisectors_vectorized(sites, bisectors_to_compute)\n",
    "        points = torch.cat((vertices, bisectors), 0)\n",
    "        print(\"points\", points.shape) \n",
    "\n",
    "        # Compute losses       \n",
    "        #cvt_loss = lf.compute_cvt_loss_vectorized_voronoi(sites, vor)\n",
    "        #cvt_loss = lf.compute_cvt_loss_vectorized_delaunay(sites, tri)\n",
    "    \n",
    "        cvt_loss = lf.compute_cvt_loss_vectorized_delaunay(sites, None, d3dsimplices)\n",
    "        print(\"CVT loss: \", cvt_loss, \"weighted: \", lambda_cvt*cvt_loss)\n",
    "        #min_distance_loss = lf.sdf_weighted_min_distance_loss(model, sites)\n",
    "        \n",
    "        from pytorch3d.loss import chamfer_distance\n",
    "        chamfer_loss, _ = chamfer_distance(mnfld_points.detach(), points.unsqueeze(0))\n",
    "        print(f\"Chamfer loss PYTORCH3D {chamfer_loss} weighted: {lambda_chamfer*chamfer_loss} : Allocated: {torch.cuda.memory_allocated() / 1e6} MB, Reserved: {torch.cuda.memory_reserved() / 1e6} MB\")\n",
    "\n",
    "\n",
    "        # voroloss_loss = voroloss(points.unsqueeze(0), mnfld_points)\n",
    "        # #voroloss_loss = voroloss(sites.unsqueeze(0), mnfld_points)\n",
    "        # voroloss_loss = voroloss_loss.mean()\n",
    "        # print(f\"After Voronoi loss: {voroloss_loss} : Allocated: {torch.cuda.memory_allocated() / 1e6} MB, Reserved: {torch.cuda.memory_reserved() / 1e6} MB\")\n",
    "        \n",
    "        #SDF loss\n",
    "        sdf_loss = torch.mean(model(points)**2) + torch.maximum((model(sites).abs() - 0.05), torch.tensor(0.0)).mean()\n",
    "        #sdf_loss = torch.maximum((model(sites).abs() - 0.01), torch.tensor(0.0)).mean()\n",
    "        #sdf_loss = torch.maximum((model(sites).abs() - 0.05), torch.tensor(0.0)).mean()\n",
    "        print(\"SDF loss: \", sdf_loss, \"weighted: \", lambda_chamfer*sdf_loss)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        sites_loss = (\n",
    "            lambda_cvt * cvt_loss +\n",
    "            #lambda_chamfer * chamfer_loss \n",
    "            #lambda_chamfer * voroloss_loss\n",
    "            + lambda_chamfer * sdf_loss\n",
    "        )\n",
    "            \n",
    "        loss = sites_loss\n",
    "        loss_values.append(loss.item())\n",
    "        print(f\"Epoch {epoch}: loss = {loss.item()}\")\n",
    "        print(f\"before loss.backward(): Allocated: {torch.cuda.memory_allocated() / 1e6} MB, Reserved: {torch.cuda.memory_reserved() / 1e6} MB\")\n",
    "\n",
    "        loss.backward()\n",
    "        print(f\"After loss.backward(): Allocated: {torch.cuda.memory_allocated() / 1e6} MB, Reserved: {torch.cuda.memory_reserved() / 1e6} MB\")\n",
    "        print(\"-----------------\")\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        if loss.item() < best_loss:\n",
    "            best_loss = loss.item()\n",
    "            best_epoch = epoch\n",
    "            best_sites = sites.clone()\n",
    "            best_sites.best_loss = best_loss\n",
    "            #if upsampled > 0:\n",
    "                #print(f\"UPSAMPLED {upsampled} Best Epoch {best_epoch}: Best loss = {best_loss}\")\n",
    "                #return best_sites\n",
    "        \n",
    "        if abs(prev_loss - loss.item()) < stop_train_threshold:\n",
    "            print(f\"Converged at epoch {epoch} with loss {loss.item()}\")\n",
    "            #break\n",
    "        \n",
    "        prev_loss = loss.item() \n",
    "        \n",
    "        # if epoch>100 and (epoch // 100) == upsampled+1 and loss.item() < 0.5 and upsampled < upsampling:\n",
    "        if epoch/max_iter > (upsampled+1)/(upsampling+1) and upsampled < upsampling:\n",
    "            print(\"sites length BEFORE UPSAMPLING: \",len(sites))\n",
    "            sites = su.upsampling_vectorized(sites, tri=None, vor=None, simplices=d3dsimplices, model=model)\n",
    "            sites = sites.detach().requires_grad_(True)\n",
    "            optimizer = torch.optim.Adam([{'params': [sites], 'lr': lr_sites}])\n",
    "            upsampled += 1.0\n",
    "            print(\"sites length AFTER: \",len(sites))\n",
    "            \n",
    "          \n",
    "        if epoch % (max_iter/50) == 0:\n",
    "            #print(f\"Epoch {epoch}: loss = {loss.item()}\")\n",
    "            #print(f\"Best Epoch {best_epoch}: Best loss = {best_loss}\")\n",
    "            #save model and sites\n",
    "            site_file_path = f'{destination}{mesh[0]}{max_iter}_{epoch}_3d_sites_{num_centroids}_chamfer{lambda_chamfer}.pth'\n",
    "            model_file_path = f'{destination}{mesh[0]}{max_iter}_{epoch}_3d_model_{num_centroids}_chamfer{lambda_chamfer}.pth'\n",
    "            torch.save(model.state_dict(), model_file_path)\n",
    "            torch.save(sites, site_file_path)\n",
    "            \n",
    "        epoch += 1           \n",
    "    \n",
    "    #Export the sites, their sdf values, the gradients of the sdf values and the hessian\n",
    "    sdf_values = model(sites)\n",
    "\n",
    "    sdf_gradients = torch.autograd.grad(outputs=sdf_values, inputs=sites, grad_outputs=torch.ones_like(sdf_values), create_graph=True, retain_graph=True,)[0] # (N, 3)\n",
    "\n",
    "    N, D = sites.shape\n",
    "    hess_sdf = torch.zeros(N, D, D, device=sites.device)\n",
    "    for i in range(D):\n",
    "        grad2 = torch.autograd.grad(outputs=sdf_gradients[:, i], inputs=sites, grad_outputs=torch.ones_like(sdf_gradients[:, i]), create_graph=False, retain_graph=True,)[0] # (N, 3)\n",
    "        hess_sdf[:, i, :] = grad2 # fill row i of each 3Ã—3 Hessian\n",
    "    \n",
    "    np.savez(f'{mesh[0]}voroloss_to_clip{model_trained_it}.npz', sites=sites.detach().cpu().numpy(), sdf_values=sdf_values.detach().cpu().numpy(), sdf_gradients=sdf_gradients.detach().cpu().numpy(), sdf_hessians=hess_sdf.detach().cpu().numpy())\n",
    "    print(f\"Saved to {mesh[0]}voroloss_to_clip{model_trained_it}.npz\")\n",
    "    return best_sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7e96773",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lambda_weights = [252,0,0,0,10.211111,0,100,0]\n",
    "#lambda_weights = [500,0,0,0,1000,0,100,0]\n",
    "lambda_weights = [100,0,0,0,1000,0,100,0]\n",
    "\n",
    "\n",
    "lambda_cvt = lambda_weights[0]\n",
    "lambda_sdf = lambda_weights[1]\n",
    "lambda_min_distance = lambda_weights[2]\n",
    "lambda_laplace = lambda_weights[3]\n",
    "lambda_chamfer = lambda_weights[4]\n",
    "lambda_eikonal = lambda_weights[5]\n",
    "lambda_domain_restriction = lambda_weights[6]\n",
    "lambda_true_points = lambda_weights[7]\n",
    "\n",
    "max_iter = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fb2cefd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "points torch.Size([87395, 3])\n",
      "CVT loss:  tensor(0.0101, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(1.0129, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 6.70510416966863e-05 weighted: 0.06705103814601898 : Allocated: 482.37568 MB, Reserved: 1050.673152 MB\n",
      "SDF loss:  tensor(0.0098, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(9.7658, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0: loss = 10.778693199157715\n",
      "before loss.backward(): Allocated: 2032.32 MB, Reserved: 2206.203904 MB\n",
      "After loss.backward(): Allocated: 457.467904 MB, Reserved: 2483.027968 MB\n",
      "-----------------\n",
      "points torch.Size([86882, 3])\n",
      "CVT loss:  tensor(0.0074, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.7403, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 4.3200856453040615e-05 weighted: 0.04320085793733597 : Allocated: 492.464128 MB, Reserved: 2485.12512 MB\n",
      "SDF loss:  tensor(0.0094, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(9.4146, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1: loss = 10.154898643493652\n",
      "before loss.backward(): Allocated: 2035.478528 MB, Reserved: 2487.222272 MB\n",
      "After loss.backward(): Allocated: 457.466368 MB, Reserved: 2489.319424 MB\n",
      "-----------------\n",
      "points torch.Size([86051, 3])\n",
      "CVT loss:  tensor(0.0081, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.8092, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 3.9342688978649676e-05 weighted: 0.039342690259218216 : Allocated: 492.145152 MB, Reserved: 2489.319424 MB\n",
      "SDF loss:  tensor(0.0092, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(9.1610, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2: loss = 9.97023868560791\n",
      "before loss.backward(): Allocated: 2024.491008 MB, Reserved: 2489.319424 MB\n",
      "After loss.backward(): Allocated: 457.43616 MB, Reserved: 2489.319424 MB\n",
      "-----------------\n",
      "points torch.Size([85646, 3])\n",
      "CVT loss:  tensor(0.0082, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.8216, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 3.6467594327405095e-05 weighted: 0.03646759316325188 : Allocated: 492.017664 MB, Reserved: 2489.319424 MB\n",
      "SDF loss:  tensor(0.0090, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(8.9656, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3: loss = 9.787211418151855\n",
      "before loss.backward(): Allocated: 2019.16416 MB, Reserved: 2489.319424 MB\n",
      "After loss.backward(): Allocated: 457.421312 MB, Reserved: 2489.319424 MB\n",
      "-----------------\n",
      "points torch.Size([85575, 3])\n",
      "CVT loss:  tensor(0.0083, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.8272, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 3.3937347325263545e-05 weighted: 0.03393734619021416 : Allocated: 491.99104 MB, Reserved: 2489.319424 MB\n",
      "SDF loss:  tensor(0.0088, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(8.8168, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 4: loss = 9.643917083740234\n",
      "before loss.backward(): Allocated: 2018.224128 MB, Reserved: 2489.319424 MB\n",
      "After loss.backward(): Allocated: 457.41824 MB, Reserved: 2489.319424 MB\n",
      "-----------------\n",
      "points torch.Size([85862, 3])\n",
      "CVT loss:  tensor(0.0094, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.9371, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 3.313349589006975e-05 weighted: 0.03313349559903145 : Allocated: 492.057088 MB, Reserved: 2489.319424 MB\n",
      "SDF loss:  tensor(0.0087, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(8.6847, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5: loss = 9.621835708618164\n",
      "before loss.backward(): Allocated: 2021.974528 MB, Reserved: 2489.319424 MB\n",
      "After loss.backward(): Allocated: 457.430016 MB, Reserved: 2489.319424 MB\n",
      "-----------------\n",
      "points torch.Size([87111, 3])\n",
      "CVT loss:  tensor(0.0065, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.6492, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 3.0716088076587766e-05 weighted: 0.03071608766913414 : Allocated: 492.439552 MB, Reserved: 2489.319424 MB\n",
      "SDF loss:  tensor(0.0086, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(8.5675, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6: loss = 9.216712951660156\n",
      "before loss.backward(): Allocated: 2038.39488 MB, Reserved: 2489.319424 MB\n",
      "After loss.backward(): Allocated: 457.478656 MB, Reserved: 2489.319424 MB\n",
      "-----------------\n",
      "points torch.Size([87760, 3])\n",
      "CVT loss:  tensor(0.0073, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.7278, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.8652801120188087e-05 weighted: 0.028652800247073174 : Allocated: 493.42976 MB, Reserved: 2489.319424 MB\n",
      "SDF loss:  tensor(0.0085, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(8.4622, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 7: loss = 9.18993854522705\n",
      "before loss.backward(): Allocated: 2047.868928 MB, Reserved: 2489.319424 MB\n",
      "After loss.backward(): Allocated: 458.284544 MB, Reserved: 2489.319424 MB\n",
      "-----------------\n",
      "points torch.Size([88467, 3])\n",
      "CVT loss:  tensor(0.0078, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.7760, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.751143983914517e-05 weighted: 0.027511440217494965 : Allocated: 493.627392 MB, Reserved: 2489.319424 MB\n",
      "SDF loss:  tensor(0.0084, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(8.3539, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8: loss = 9.129899024963379\n",
      "before loss.backward(): Allocated: 2078.824448 MB, Reserved: 2489.319424 MB\n",
      "After loss.backward(): Allocated: 458.304 MB, Reserved: 2489.319424 MB\n",
      "-----------------\n",
      "points torch.Size([89599, 3])\n",
      "CVT loss:  tensor(0.0045, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4491, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.6813351723831147e-05 weighted: 0.02681335248053074 : Allocated: 493.961728 MB, Reserved: 2489.319424 MB\n",
      "SDF loss:  tensor(0.0082, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(8.2499, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9: loss = 8.698970794677734\n",
      "before loss.backward(): Allocated: 2079.187456 MB, Reserved: 2489.319424 MB\n",
      "After loss.backward(): Allocated: 458.334208 MB, Reserved: 2489.319424 MB\n",
      "-----------------\n",
      "points torch.Size([90652, 3])\n",
      "CVT loss:  tensor(0.0063, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.6347, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.5920911866705865e-05 weighted: 0.025920912623405457 : Allocated: 494.249472 MB, Reserved: 2489.319424 MB\n",
      "SDF loss:  tensor(0.0081, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(8.1466, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 10: loss = 8.78128433227539\n",
      "before loss.backward(): Allocated: 2086.40512 MB, Reserved: 3646.947328 MB\n",
      "After loss.backward(): Allocated: 458.363904 MB, Reserved: 3856.662528 MB\n",
      "-----------------\n",
      "points torch.Size([91938, 3])\n",
      "CVT loss:  tensor(0.0070, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.6968, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.5524859665893018e-05 weighted: 0.025524860247969627 : Allocated: 494.652416 MB, Reserved: 3856.662528 MB\n",
      "SDF loss:  tensor(0.0080, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(8.0422, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11: loss = 8.73907470703125\n",
      "before loss.backward(): Allocated: 2102.646272 MB, Reserved: 3856.662528 MB\n",
      "After loss.backward(): Allocated: 458.397184 MB, Reserved: 3856.662528 MB\n",
      "-----------------\n",
      "points torch.Size([93058, 3])\n",
      "CVT loss:  tensor(0.0069, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.6945, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.555447463237215e-05 weighted: 0.02555447444319725 : Allocated: 495.054336 MB, Reserved: 3856.662528 MB\n",
      "SDF loss:  tensor(0.0079, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(7.9392, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12: loss = 8.633687973022461\n",
      "before loss.backward(): Allocated: 2132.809216 MB, Reserved: 3856.662528 MB\n",
      "After loss.backward(): Allocated: 458.420224 MB, Reserved: 3856.662528 MB\n",
      "-----------------\n",
      "points torch.Size([93625, 3])\n",
      "CVT loss:  tensor(0.0049, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4870, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.4643144570291042e-05 weighted: 0.024643145501613617 : Allocated: 496.347136 MB, Reserved: 3856.662528 MB\n",
      "SDF loss:  tensor(0.0078, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(7.8346, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 13: loss = 8.32165813446045\n",
      "before loss.backward(): Allocated: 2134.116352 MB, Reserved: 3856.662528 MB\n",
      "After loss.backward(): Allocated: 458.441728 MB, Reserved: 3856.662528 MB\n",
      "-----------------\n",
      "points torch.Size([94098, 3])\n",
      "CVT loss:  tensor(0.0049, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4940, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.3802245777915232e-05 weighted: 0.023802245035767555 : Allocated: 495.326208 MB, Reserved: 3856.662528 MB\n",
      "SDF loss:  tensor(0.0077, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(7.7343, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14: loss = 8.22838020324707\n",
      "before loss.backward(): Allocated: 2133.10976 MB, Reserved: 3856.662528 MB\n",
      "After loss.backward(): Allocated: 458.331648 MB, Reserved: 3856.662528 MB\n",
      "-----------------\n",
      "points torch.Size([95075, 3])\n",
      "CVT loss:  tensor(0.0047, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4678, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.330080678802915e-05 weighted: 0.023300806060433388 : Allocated: 496.608768 MB, Reserved: 3856.662528 MB\n",
      "SDF loss:  tensor(0.0076, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(7.6321, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15: loss = 8.099928855895996\n",
      "before loss.backward(): Allocated: 2145.333248 MB, Reserved: 5014.290432 MB\n",
      "After loss.backward(): Allocated: 458.481664 MB, Reserved: 5230.297088 MB\n",
      "-----------------\n",
      "points torch.Size([95514, 3])\n",
      "CVT loss:  tensor(0.0044, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4401, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.311319622094743e-05 weighted: 0.023113196715712547 : Allocated: 495.697408 MB, Reserved: 5230.297088 MB\n",
      "SDF loss:  tensor(0.0075, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(7.5311, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16: loss = 7.97117805480957\n",
      "before loss.backward(): Allocated: 2149.830656 MB, Reserved: 5230.297088 MB\n",
      "After loss.backward(): Allocated: 458.207232 MB, Reserved: 5230.297088 MB\n",
      "-----------------\n",
      "points torch.Size([96376, 3])\n",
      "CVT loss:  tensor(0.0083, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.8311, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.2885476937517524e-05 weighted: 0.022885477170348167 : Allocated: 496.84224 MB, Reserved: 5230.297088 MB\n",
      "SDF loss:  tensor(0.0074, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(7.4339, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17: loss = 8.2649564743042\n",
      "before loss.backward(): Allocated: 2187.11552 MB, Reserved: 5230.297088 MB\n",
      "After loss.backward(): Allocated: 458.515968 MB, Reserved: 5230.297088 MB\n",
      "-----------------\n",
      "points torch.Size([96690, 3])\n",
      "CVT loss:  tensor(0.0048, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4767, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.2854201233712956e-05 weighted: 0.02285420149564743 : Allocated: 496.244224 MB, Reserved: 5230.297088 MB\n",
      "SDF loss:  tensor(0.0073, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(7.3332, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18: loss = 7.809930324554443\n",
      "before loss.backward(): Allocated: 2186.528256 MB, Reserved: 5230.297088 MB\n",
      "After loss.backward(): Allocated: 458.366976 MB, Reserved: 5230.297088 MB\n",
      "-----------------\n",
      "points torch.Size([97260, 3])\n",
      "CVT loss:  tensor(0.0045, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4487, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.3384858650388196e-05 weighted: 0.023384857922792435 : Allocated: 496.61696 MB, Reserved: 5230.297088 MB\n",
      "SDF loss:  tensor(0.0072, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(7.2357, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19: loss = 7.68440055847168\n",
      "before loss.backward(): Allocated: 2186.915328 MB, Reserved: 5230.297088 MB\n",
      "After loss.backward(): Allocated: 458.243072 MB, Reserved: 5230.297088 MB\n",
      "-----------------\n",
      "points torch.Size([97732, 3])\n",
      "CVT loss:  tensor(0.0059, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.5853, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.2874426576890983e-05 weighted: 0.02287442609667778 : Allocated: 496.413184 MB, Reserved: 5230.297088 MB\n",
      "SDF loss:  tensor(0.0071, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(7.1390, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20: loss = 7.724326133728027\n",
      "before loss.backward(): Allocated: 2186.725888 MB, Reserved: 5230.297088 MB\n",
      "After loss.backward(): Allocated: 458.276352 MB, Reserved: 5230.297088 MB\n",
      "-----------------\n",
      "points torch.Size([98431, 3])\n",
      "CVT loss:  tensor(0.0099, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.9936, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.240806134068407e-05 weighted: 0.02240806072950363 : Allocated: 496.793088 MB, Reserved: 5230.297088 MB\n",
      "SDF loss:  tensor(0.0070, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(7.0416, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21: loss = 8.035253524780273\n",
      "before loss.backward(): Allocated: 2188.749312 MB, Reserved: 6383.730688 MB\n",
      "After loss.backward(): Allocated: 458.273792 MB, Reserved: 6606.0288 MB\n",
      "-----------------\n",
      "points torch.Size([98835, 3])\n",
      "CVT loss:  tensor(0.0080, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.7994, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.237531225546263e-05 weighted: 0.022375311702489853 : Allocated: 497.302016 MB, Reserved: 6606.0288 MB\n",
      "SDF loss:  tensor(0.0069, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(6.9424, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 22: loss = 7.7418107986450195\n",
      "before loss.backward(): Allocated: 2194.434048 MB, Reserved: 6606.0288 MB\n",
      "After loss.backward(): Allocated: 458.83648 MB, Reserved: 6606.0288 MB\n",
      "-----------------\n",
      "points torch.Size([99487, 3])\n",
      "CVT loss:  tensor(0.0069, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.6875, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.2227523004403338e-05 weighted: 0.02222752384841442 : Allocated: 496.96768 MB, Reserved: 6606.0288 MB\n",
      "SDF loss:  tensor(0.0068, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(6.8484, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 23: loss = 7.535834312438965\n",
      "before loss.backward(): Allocated: 2202.129408 MB, Reserved: 6606.0288 MB\n",
      "After loss.backward(): Allocated: 458.302976 MB, Reserved: 6606.0288 MB\n",
      "-----------------\n",
      "points torch.Size([99949, 3])\n",
      "CVT loss:  tensor(0.0074, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.7353, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.2123647795524448e-05 weighted: 0.02212364785373211 : Allocated: 497.678848 MB, Reserved: 6606.0288 MB\n",
      "SDF loss:  tensor(0.0068, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(6.7511, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 24: loss = 7.486398696899414\n",
      "before loss.backward(): Allocated: 2208.528384 MB, Reserved: 6606.0288 MB\n",
      "After loss.backward(): Allocated: 458.866176 MB, Reserved: 6606.0288 MB\n",
      "-----------------\n",
      "points torch.Size([100731, 3])\n",
      "CVT loss:  tensor(0.0071, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.7129, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.18760542338714e-05 weighted: 0.021876053884625435 : Allocated: 498.351616 MB, Reserved: 6606.0288 MB\n",
      "SDF loss:  tensor(0.0067, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(6.6552, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 25: loss = 7.368068218231201\n",
      "before loss.backward(): Allocated: 2241.175552 MB, Reserved: 6606.0288 MB\n",
      "After loss.backward(): Allocated: 458.336256 MB, Reserved: 6606.0288 MB\n",
      "-----------------\n",
      "points torch.Size([100939, 3])\n",
      "CVT loss:  tensor(0.0035, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3536, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.1690899302484468e-05 weighted: 0.02169089950621128 : Allocated: 498.951168 MB, Reserved: 6606.0288 MB\n",
      "SDF loss:  tensor(0.0066, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(6.5620, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 26: loss = 6.9156670570373535\n",
      "before loss.backward(): Allocated: 2241.782272 MB, Reserved: 6606.0288 MB\n",
      "After loss.backward(): Allocated: 458.8928 MB, Reserved: 6606.0288 MB\n",
      "-----------------\n",
      "points torch.Size([101691, 3])\n",
      "CVT loss:  tensor(0.0037, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3671, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.1052721422165632e-05 weighted: 0.02105272188782692 : Allocated: 498.573824 MB, Reserved: 6606.0288 MB\n",
      "SDF loss:  tensor(0.0065, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(6.4680, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 27: loss = 6.83501672744751\n",
      "before loss.backward(): Allocated: 2241.426432 MB, Reserved: 6606.0288 MB\n",
      "After loss.backward(): Allocated: 458.361856 MB, Reserved: 6606.0288 MB\n",
      "-----------------\n",
      "points torch.Size([102183, 3])\n",
      "CVT loss:  tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2964, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.1142735931789503e-05 weighted: 0.021142736077308655 : Allocated: 499.229696 MB, Reserved: 6606.0288 MB\n",
      "SDF loss:  tensor(0.0064, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(6.3751, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 28: loss = 6.671466827392578\n",
      "before loss.backward(): Allocated: 2242.09664 MB, Reserved: 6606.0288 MB\n",
      "After loss.backward(): Allocated: 458.925568 MB, Reserved: 6606.0288 MB\n",
      "-----------------\n",
      "points torch.Size([102843, 3])\n",
      "CVT loss:  tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3102, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.1031613869126886e-05 weighted: 0.021031614392995834 : Allocated: 498.827776 MB, Reserved: 6606.0288 MB\n",
      "SDF loss:  tensor(0.0063, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(6.2835, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 29: loss = 6.593666076660156\n",
      "before loss.backward(): Allocated: 2247.38304 MB, Reserved: 7751.073792 MB\n",
      "After loss.backward(): Allocated: 458.392576 MB, Reserved: 7979.66336 MB\n",
      "-----------------\n",
      "points torch.Size([102991, 3])\n",
      "CVT loss:  tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2775, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.084339939756319e-05 weighted: 0.020843399688601494 : Allocated: 499.410944 MB, Reserved: 7979.66336 MB\n",
      "SDF loss:  tensor(0.0062, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(6.1888, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 30: loss = 6.466338157653809\n",
      "before loss.backward(): Allocated: 2249.823744 MB, Reserved: 7979.66336 MB\n",
      "After loss.backward(): Allocated: 458.947072 MB, Reserved: 7979.66336 MB\n",
      "-----------------\n",
      "points torch.Size([103621, 3])\n",
      "CVT loss:  tensor(0.0063, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.6289, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.077669523714576e-05 weighted: 0.020776694640517235 : Allocated: 498.99008 MB, Reserved: 7979.66336 MB\n",
      "SDF loss:  tensor(0.0061, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(6.0985, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 31: loss = 6.727442264556885\n",
      "before loss.backward(): Allocated: 2257.16224 MB, Reserved: 7979.66336 MB\n",
      "After loss.backward(): Allocated: 458.413568 MB, Reserved: 7979.66336 MB\n",
      "-----------------\n",
      "points torch.Size([104208, 3])\n",
      "CVT loss:  tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2365, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.104354280163534e-05 weighted: 0.02104354277253151 : Allocated: 499.669504 MB, Reserved: 7979.66336 MB\n",
      "SDF loss:  tensor(0.0060, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(6.0069, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 32: loss = 6.243351936340332\n",
      "before loss.backward(): Allocated: 2265.736192 MB, Reserved: 7979.66336 MB\n",
      "After loss.backward(): Allocated: 458.980352 MB, Reserved: 7979.66336 MB\n",
      "-----------------\n",
      "points torch.Size([104416, 3])\n",
      "CVT loss:  tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2341, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.0944378775311634e-05 weighted: 0.02094437927007675 : Allocated: 499.16672 MB, Reserved: 7979.66336 MB\n",
      "SDF loss:  tensor(0.0059, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(5.9156, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 33: loss = 6.149750232696533\n",
      "before loss.backward(): Allocated: 2267.899392 MB, Reserved: 7979.66336 MB\n",
      "After loss.backward(): Allocated: 458.43456 MB, Reserved: 7979.66336 MB\n",
      "-----------------\n",
      "points torch.Size([105014, 3])\n",
      "CVT loss:  tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2387, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.1144154743524268e-05 weighted: 0.02114415541291237 : Allocated: 499.843072 MB, Reserved: 7979.66336 MB\n",
      "SDF loss:  tensor(0.0058, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(5.8268, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 34: loss = 6.065491199493408\n",
      "before loss.backward(): Allocated: 2294.45888 MB, Reserved: 7979.66336 MB\n",
      "After loss.backward(): Allocated: 459.002368 MB, Reserved: 7979.66336 MB\n",
      "-----------------\n",
      "points torch.Size([105108, 3])\n",
      "CVT loss:  tensor(0.0051, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.5106, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.1181027477723546e-05 weighted: 0.021181028336286545 : Allocated: 499.309056 MB, Reserved: 7979.66336 MB\n",
      "SDF loss:  tensor(0.0057, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(5.7344, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 35: loss = 6.245045185089111\n",
      "before loss.backward(): Allocated: 2293.976576 MB, Reserved: 7979.66336 MB\n",
      "After loss.backward(): Allocated: 458.454016 MB, Reserved: 7979.66336 MB\n",
      "-----------------\n",
      "points torch.Size([105646, 3])\n",
      "CVT loss:  tensor(0.0037, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3677, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.1117040887475014e-05 weighted: 0.021117040887475014 : Allocated: 500.007936 MB, Reserved: 7979.66336 MB\n",
      "SDF loss:  tensor(0.0056, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(5.6465, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 36: loss = 6.014194488525391\n",
      "before loss.backward(): Allocated: 2294.965248 MB, Reserved: 7979.66336 MB\n",
      "After loss.backward(): Allocated: 459.018752 MB, Reserved: 7979.66336 MB\n",
      "-----------------\n",
      "points torch.Size([105700, 3])\n",
      "CVT loss:  tensor(0.0040, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4004, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.0729181414935738e-05 weighted: 0.02072918228805065 : Allocated: 499.471872 MB, Reserved: 7979.66336 MB\n",
      "SDF loss:  tensor(0.0056, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(5.5586, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 37: loss = 5.959011554718018\n",
      "before loss.backward(): Allocated: 2294.456832 MB, Reserved: 7979.66336 MB\n",
      "After loss.backward(): Allocated: 458.469376 MB, Reserved: 7979.66336 MB\n",
      "-----------------\n",
      "points torch.Size([105846, 3])\n",
      "CVT loss:  tensor(0.0038, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3775, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.0737135855597444e-05 weighted: 0.020737135782837868 : Allocated: 500.06528 MB, Reserved: 7979.66336 MB\n",
      "SDF loss:  tensor(0.0055, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(5.4704, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 38: loss = 5.847840785980225\n",
      "before loss.backward(): Allocated: 2295.128576 MB, Reserved: 7979.66336 MB\n",
      "After loss.backward(): Allocated: 459.024384 MB, Reserved: 7979.66336 MB\n",
      "-----------------\n",
      "points torch.Size([106297, 3])\n",
      "CVT loss:  tensor(0.0032, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3189, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.0617657355614938e-05 weighted: 0.020617658272385597 : Allocated: 499.636224 MB, Reserved: 7979.66336 MB\n",
      "SDF loss:  tensor(0.0054, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(5.3814, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 39: loss = 5.700344085693359\n",
      "before loss.backward(): Allocated: 2294.944768 MB, Reserved: 7979.66336 MB\n",
      "After loss.backward(): Allocated: 458.48576 MB, Reserved: 7979.66336 MB\n",
      "-----------------\n",
      "points torch.Size([106819, 3])\n",
      "CVT loss:  tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3096, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.2614443878410384e-05 weighted: 0.02261444367468357 : Allocated: 500.342784 MB, Reserved: 7979.66336 MB\n",
      "SDF loss:  tensor(0.0053, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(5.3005, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 40: loss = 5.610109329223633\n",
      "before loss.backward(): Allocated: 2299.901952 MB, Reserved: 9112.12544 MB\n",
      "After loss.backward(): Allocated: 459.051008 MB, Reserved: 9347.006464 MB\n",
      "-----------------\n",
      "points torch.Size([107281, 3])\n",
      "CVT loss:  tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2641, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.0184825189062394e-05 weighted: 0.020184826105833054 : Allocated: 499.916288 MB, Reserved: 9347.006464 MB\n",
      "SDF loss:  tensor(0.0052, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(5.2081, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 41: loss = 5.4721999168396\n",
      "before loss.backward(): Allocated: 2305.263616 MB, Reserved: 9347.006464 MB\n",
      "After loss.backward(): Allocated: 458.512896 MB, Reserved: 9347.006464 MB\n",
      "-----------------\n",
      "points torch.Size([107494, 3])\n",
      "CVT loss:  tensor(0.0053, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.5334, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.0227071217959747e-05 weighted: 0.02022707089781761 : Allocated: 500.527104 MB, Reserved: 9347.006464 MB\n",
      "SDF loss:  tensor(0.0051, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(5.1200, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 42: loss = 5.653380393981934\n",
      "before loss.backward(): Allocated: 2308.49536 MB, Reserved: 9347.006464 MB\n",
      "After loss.backward(): Allocated: 459.068928 MB, Reserved: 9347.006464 MB\n",
      "-----------------\n",
      "points torch.Size([108004, 3])\n",
      "CVT loss:  tensor(0.0047, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4678, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.0171082724118605e-05 weighted: 0.020171083509922028 : Allocated: 500.12416 MB, Reserved: 9347.006464 MB\n",
      "SDF loss:  tensor(0.0050, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(5.0357, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 43: loss = 5.503518581390381\n",
      "before loss.backward(): Allocated: 2314.373632 MB, Reserved: 9347.006464 MB\n",
      "After loss.backward(): Allocated: 458.53184 MB, Reserved: 9347.006464 MB\n",
      "-----------------\n",
      "points torch.Size([108681, 3])\n",
      "CVT loss:  tensor(0.0038, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3772, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.986879578907974e-05 weighted: 0.019868796691298485 : Allocated: 500.865536 MB, Reserved: 9347.006464 MB\n",
      "SDF loss:  tensor(0.0049, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(4.9498, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 44: loss = 5.3269476890563965\n",
      "before loss.backward(): Allocated: 2346.816 MB, Reserved: 9347.006464 MB\n",
      "After loss.backward(): Allocated: 459.100672 MB, Reserved: 9347.006464 MB\n",
      "-----------------\n",
      "points torch.Size([108771, 3])\n",
      "CVT loss:  tensor(0.0045, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4464, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.9904158762074076e-05 weighted: 0.019904159009456635 : Allocated: 500.33408 MB, Reserved: 9347.006464 MB\n",
      "SDF loss:  tensor(0.0049, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(4.8633, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 45: loss = 5.309691429138184\n",
      "before loss.backward(): Allocated: 2346.376704 MB, Reserved: 9347.006464 MB\n",
      "After loss.backward(): Allocated: 458.552832 MB, Reserved: 9347.006464 MB\n",
      "-----------------\n",
      "points torch.Size([108882, 3])\n",
      "CVT loss:  tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2944, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.013732955674641e-05 weighted: 0.020137328654527664 : Allocated: 500.912128 MB, Reserved: 9347.006464 MB\n",
      "SDF loss:  tensor(0.0048, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(4.7795, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 46: loss = 5.0738935470581055\n",
      "before loss.backward(): Allocated: 2347.072 MB, Reserved: 9347.006464 MB\n",
      "After loss.backward(): Allocated: 459.106816 MB, Reserved: 9347.006464 MB\n",
      "-----------------\n",
      "points torch.Size([109147, 3])\n",
      "CVT loss:  tensor(0.0045, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4527, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.985840208362788e-05 weighted: 0.019858401268720627 : Allocated: 500.44416 MB, Reserved: 9347.006464 MB\n",
      "SDF loss:  tensor(0.0047, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(4.6939, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 47: loss = 5.146546840667725\n",
      "before loss.backward(): Allocated: 2346.88256 MB, Reserved: 9347.006464 MB\n",
      "After loss.backward(): Allocated: 458.562048 MB, Reserved: 9347.006464 MB\n",
      "-----------------\n",
      "points torch.Size([109294, 3])\n",
      "CVT loss:  tensor(0.0037, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3744, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.9648259694804437e-05 weighted: 0.01964825950562954 : Allocated: 501.037056 MB, Reserved: 9347.006464 MB\n",
      "SDF loss:  tensor(0.0046, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(4.6083, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 48: loss = 4.982701778411865\n",
      "before loss.backward(): Allocated: 2347.629568 MB, Reserved: 9347.006464 MB\n",
      "After loss.backward(): Allocated: 459.117568 MB, Reserved: 9347.006464 MB\n",
      "-----------------\n",
      "points torch.Size([109771, 3])\n",
      "CVT loss:  tensor(0.0057, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.5731, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.971698657143861e-05 weighted: 0.019716987386345863 : Allocated: 500.649472 MB, Reserved: 9347.006464 MB\n",
      "SDF loss:  tensor(0.0045, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(4.5247, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 49: loss = 5.097761631011963\n",
      "before loss.backward(): Allocated: 2347.744768 MB, Reserved: 9347.006464 MB\n",
      "After loss.backward(): Allocated: 458.578944 MB, Reserved: 9347.006464 MB\n",
      "-----------------\n",
      "points torch.Size([110458, 3])\n",
      "CVT loss:  tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2707, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.971265737665817e-05 weighted: 0.0197126567363739 : Allocated: 501.456384 MB, Reserved: 9347.006464 MB\n",
      "SDF loss:  tensor(0.0044, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(4.4392, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 50: loss = 4.709811210632324\n",
      "before loss.backward(): Allocated: 2349.273088 MB, Reserved: 9347.006464 MB\n",
      "After loss.backward(): Allocated: 459.149312 MB, Reserved: 9347.006464 MB\n",
      "-----------------\n",
      "points torch.Size([110758, 3])\n",
      "CVT loss:  tensor(0.0035, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3525, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.9641860490082763e-05 weighted: 0.01964186131954193 : Allocated: 501.02272 MB, Reserved: 9347.006464 MB\n",
      "SDF loss:  tensor(0.0044, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(4.3555, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 51: loss = 4.707973957061768\n",
      "before loss.backward(): Allocated: 2351.112192 MB, Reserved: 10462.691328 MB\n",
      "After loss.backward(): Allocated: 458.605056 MB, Reserved: 10703.863808 MB\n",
      "-----------------\n",
      "points torch.Size([111029, 3])\n",
      "CVT loss:  tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3426, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.9526793039403856e-05 weighted: 0.01952679269015789 : Allocated: 504.833024 MB, Reserved: 10703.863808 MB\n",
      "SDF loss:  tensor(0.0043, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(4.2729, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 52: loss = 4.615518093109131\n",
      "before loss.backward(): Allocated: 2358.398464 MB, Reserved: 10703.863808 MB\n",
      "After loss.backward(): Allocated: 459.175936 MB, Reserved: 10703.863808 MB\n",
      "-----------------\n",
      "points torch.Size([111562, 3])\n",
      "CVT loss:  tensor(0.0045, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4518, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.9219682144466788e-05 weighted: 0.01921968162059784 : Allocated: 504.448 MB, Reserved: 10703.863808 MB\n",
      "SDF loss:  tensor(0.0042, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(4.1886, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 53: loss = 4.6403937339782715\n",
      "before loss.backward(): Allocated: 2364.61568 MB, Reserved: 10703.863808 MB\n",
      "After loss.backward(): Allocated: 458.627584 MB, Reserved: 10703.863808 MB\n",
      "-----------------\n",
      "points torch.Size([111808, 3])\n",
      "CVT loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1896, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.948311364685651e-05 weighted: 0.019483113661408424 : Allocated: 505.108992 MB, Reserved: 10703.863808 MB\n",
      "SDF loss:  tensor(0.0041, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(4.1096, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 54: loss = 4.299243450164795\n",
      "before loss.backward(): Allocated: 2368.306688 MB, Reserved: 10703.863808 MB\n",
      "After loss.backward(): Allocated: 459.21024 MB, Reserved: 10703.863808 MB\n",
      "-----------------\n",
      "points torch.Size([112303, 3])\n",
      "CVT loss:  tensor(0.0046, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4565, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.0148676412645727e-05 weighted: 0.02014867588877678 : Allocated: 504.702464 MB, Reserved: 10703.863808 MB\n",
      "SDF loss:  tensor(0.0040, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(4.0278, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 55: loss = 4.484311580657959\n",
      "before loss.backward(): Allocated: 2374.610944 MB, Reserved: 10703.863808 MB\n",
      "After loss.backward(): Allocated: 458.647552 MB, Reserved: 10703.863808 MB\n",
      "-----------------\n",
      "points torch.Size([112760, 3])\n",
      "CVT loss:  tensor(0.0039, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3873, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.0630679500754923e-05 weighted: 0.02063068002462387 : Allocated: 505.404416 MB, Reserved: 10703.863808 MB\n",
      "SDF loss:  tensor(0.0039, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(3.9482, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 56: loss = 4.335548400878906\n",
      "before loss.backward(): Allocated: 2402.89024 MB, Reserved: 10703.863808 MB\n",
      "After loss.backward(): Allocated: 459.252736 MB, Reserved: 10703.863808 MB\n",
      "-----------------\n",
      "points torch.Size([112717, 3])\n",
      "CVT loss:  tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2229, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.954681647475809e-05 weighted: 0.019546816125512123 : Allocated: 504.843776 MB, Reserved: 10703.863808 MB\n",
      "SDF loss:  tensor(0.0039, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(3.8654, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 57: loss = 4.088309288024902\n",
      "before loss.backward(): Allocated: 2402.263552 MB, Reserved: 10703.863808 MB\n",
      "After loss.backward(): Allocated: 458.659328 MB, Reserved: 10703.863808 MB\n",
      "-----------------\n",
      "points torch.Size([112777, 3])\n",
      "CVT loss:  tensor(0.0041, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4122, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.2144813556224108e-05 weighted: 0.02214481309056282 : Allocated: 505.41312 MB, Reserved: 10703.863808 MB\n",
      "SDF loss:  tensor(0.0038, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(3.7916, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 58: loss = 4.203817844390869\n",
      "before loss.backward(): Allocated: 2402.92864 MB, Reserved: 10703.863808 MB\n",
      "After loss.backward(): Allocated: 459.254272 MB, Reserved: 10703.863808 MB\n",
      "-----------------\n",
      "points torch.Size([113170, 3])\n",
      "CVT loss:  tensor(0.0032, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3168, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.986207462323364e-05 weighted: 0.01986207440495491 : Allocated: 504.94976 MB, Reserved: 10703.863808 MB\n",
      "SDF loss:  tensor(0.0037, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(3.7098, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 59: loss = 4.026637554168701\n",
      "before loss.backward(): Allocated: 2403.07968 MB, Reserved: 10703.863808 MB\n",
      "After loss.backward(): Allocated: 458.670592 MB, Reserved: 10703.863808 MB\n",
      "-----------------\n",
      "points torch.Size([113805, 3])\n",
      "CVT loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2039, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.911361323436722e-05 weighted: 0.019113613292574883 : Allocated: 505.552384 MB, Reserved: 10703.863808 MB\n",
      "SDF loss:  tensor(0.0036, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(3.6304, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 60: loss = 3.8343424797058105\n",
      "before loss.backward(): Allocated: 2404.675584 MB, Reserved: 10703.863808 MB\n",
      "After loss.backward(): Allocated: 459.300352 MB, Reserved: 10703.863808 MB\n",
      "-----------------\n",
      "points torch.Size([114251, 3])\n",
      "CVT loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1784, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.8792983610183e-05 weighted: 0.018792983144521713 : Allocated: 505.802752 MB, Reserved: 10703.863808 MB\n",
      "SDF loss:  tensor(0.0036, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(3.5543, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 61: loss = 3.732775926589966\n",
      "before loss.backward(): Allocated: 2405.62176 MB, Reserved: 10703.863808 MB\n",
      "After loss.backward(): Allocated: 459.321344 MB, Reserved: 10703.863808 MB\n",
      "-----------------\n",
      "points torch.Size([114322, 3])\n",
      "CVT loss:  tensor(0.0042, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4219, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.876886199170258e-05 weighted: 0.018768861889839172 : Allocated: 505.759744 MB, Reserved: 10703.863808 MB\n",
      "SDF loss:  tensor(0.0035, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(3.4789, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 62: loss = 3.900801658630371\n",
      "before loss.backward(): Allocated: 2405.691392 MB, Reserved: 10703.863808 MB\n",
      "After loss.backward(): Allocated: 459.324928 MB, Reserved: 10703.863808 MB\n",
      "-----------------\n",
      "points torch.Size([114802, 3])\n",
      "CVT loss:  tensor(0.0047, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4741, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.887056350824423e-05 weighted: 0.018870564177632332 : Allocated: 505.929216 MB, Reserved: 10703.863808 MB\n",
      "SDF loss:  tensor(0.0034, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(3.4045, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 63: loss = 3.87864089012146\n",
      "before loss.backward(): Allocated: 2407.892992 MB, Reserved: 11798.577152 MB\n",
      "After loss.backward(): Allocated: 459.346432 MB, Reserved: 12046.041088 MB\n",
      "-----------------\n",
      "points torch.Size([114982, 3])\n",
      "CVT loss:  tensor(0.0057, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.5679, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.8716495105763897e-05 weighted: 0.018716495484113693 : Allocated: 505.835008 MB, Reserved: 12046.041088 MB\n",
      "SDF loss:  tensor(0.0033, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(3.3306, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 64: loss = 3.89845871925354\n",
      "before loss.backward(): Allocated: 2410.109952 MB, Reserved: 12046.041088 MB\n",
      "After loss.backward(): Allocated: 459.355136 MB, Reserved: 12046.041088 MB\n",
      "-----------------\n",
      "points torch.Size([115425, 3])\n",
      "CVT loss:  tensor(0.0084, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.8362, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.8905688193626702e-05 weighted: 0.01890568807721138 : Allocated: 506.077696 MB, Reserved: 12046.041088 MB\n",
      "SDF loss:  tensor(0.0033, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(3.2566, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 65: loss = 4.092829704284668\n",
      "before loss.backward(): Allocated: 2415.918592 MB, Reserved: 12046.041088 MB\n",
      "After loss.backward(): Allocated: 459.374592 MB, Reserved: 12046.041088 MB\n",
      "-----------------\n",
      "points torch.Size([115921, 3])\n",
      "CVT loss:  tensor(0.0047, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4728, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.90344471775461e-05 weighted: 0.01903444714844227 : Allocated: 505.934336 MB, Reserved: 12046.041088 MB\n",
      "SDF loss:  tensor(0.0032, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(3.1832, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 66: loss = 3.655999183654785\n",
      "before loss.backward(): Allocated: 2421.884416 MB, Reserved: 12046.041088 MB\n",
      "After loss.backward(): Allocated: 459.39712 MB, Reserved: 12046.041088 MB\n",
      "-----------------\n",
      "points torch.Size([116428, 3])\n",
      "CVT loss:  tensor(0.0052, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.5214, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.9000839529326186e-05 weighted: 0.019000839442014694 : Allocated: 506.300928 MB, Reserved: 12046.041088 MB\n",
      "SDF loss:  tensor(0.0031, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(3.1097, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 67: loss = 3.63106369972229\n",
      "before loss.backward(): Allocated: 2429.124096 MB, Reserved: 12046.041088 MB\n",
      "After loss.backward(): Allocated: 459.419648 MB, Reserved: 12046.041088 MB\n",
      "-----------------\n",
      "points torch.Size([116960, 3])\n",
      "CVT loss:  tensor(0.0080, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.7993, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.8650251149665564e-05 weighted: 0.018650250509381294 : Allocated: 506.048 MB, Reserved: 12046.041088 MB\n",
      "SDF loss:  tensor(0.0030, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(3.0363, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 68: loss = 3.8356807231903076\n",
      "before loss.backward(): Allocated: 2455.306752 MB, Reserved: 12046.041088 MB\n",
      "After loss.backward(): Allocated: 459.443712 MB, Reserved: 12046.041088 MB\n",
      "-----------------\n",
      "points torch.Size([117166, 3])\n",
      "CVT loss:  tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2881, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.8801218175212853e-05 weighted: 0.018801217898726463 : Allocated: 506.479104 MB, Reserved: 12046.041088 MB\n",
      "SDF loss:  tensor(0.0030, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(2.9648, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 69: loss = 3.2528235912323\n",
      "before loss.backward(): Allocated: 2456.166912 MB, Reserved: 12046.041088 MB\n",
      "After loss.backward(): Allocated: 459.45344 MB, Reserved: 12046.041088 MB\n",
      "-----------------\n",
      "points torch.Size([117455, 3])\n",
      "CVT loss:  tensor(0.0038, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3809, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.8875824025599286e-05 weighted: 0.01887582428753376 : Allocated: 506.103808 MB, Reserved: 12046.041088 MB\n",
      "SDF loss:  tensor(0.0029, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(2.8926, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 70: loss = 3.2735862731933594\n",
      "before loss.backward(): Allocated: 2456.390656 MB, Reserved: 12046.041088 MB\n",
      "After loss.backward(): Allocated: 459.466752 MB, Reserved: 12046.041088 MB\n",
      "-----------------\n",
      "points torch.Size([117638, 3])\n",
      "CVT loss:  tensor(0.0068, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.6795, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.9074796000495553e-05 weighted: 0.01907479576766491 : Allocated: 507.320832 MB, Reserved: 12046.041088 MB\n",
      "SDF loss:  tensor(0.0028, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(2.8211, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 71: loss = 3.5006096363067627\n",
      "before loss.backward(): Allocated: 2457.989632 MB, Reserved: 12046.041088 MB\n",
      "After loss.backward(): Allocated: 459.474432 MB, Reserved: 12046.041088 MB\n",
      "-----------------\n",
      "points torch.Size([118157, 3])\n",
      "CVT loss:  tensor(0.0077, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.7683, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.8944338080473244e-05 weighted: 0.018944337964057922 : Allocated: 508.014592 MB, Reserved: 12046.041088 MB\n",
      "SDF loss:  tensor(0.0028, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(2.7529, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 72: loss = 3.52117657661438\n",
      "before loss.backward(): Allocated: 2459.76064 MB, Reserved: 12046.041088 MB\n",
      "After loss.backward(): Allocated: 459.497984 MB, Reserved: 12046.041088 MB\n",
      "-----------------\n",
      "points torch.Size([118504, 3])\n",
      "CVT loss:  tensor(0.0050, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4954, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.880161653389223e-05 weighted: 0.0188016165047884 : Allocated: 508.620288 MB, Reserved: 12046.041088 MB\n",
      "SDF loss:  tensor(0.0027, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(2.6867, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 73: loss = 3.182065486907959\n",
      "before loss.backward(): Allocated: 2461.08416 MB, Reserved: 12046.041088 MB\n",
      "After loss.backward(): Allocated: 459.513856 MB, Reserved: 12046.041088 MB\n",
      "-----------------\n",
      "points torch.Size([118286, 3])\n",
      "CVT loss:  tensor(0.0058, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.5817, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.8640421330928802e-05 weighted: 0.018640421330928802 : Allocated: 508.033024 MB, Reserved: 12046.041088 MB\n",
      "SDF loss:  tensor(0.0026, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(2.6182, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 74: loss = 3.1998748779296875\n",
      "before loss.backward(): Allocated: 2460.046848 MB, Reserved: 12046.041088 MB\n",
      "After loss.backward(): Allocated: 459.50464 MB, Reserved: 12046.041088 MB\n",
      "-----------------\n",
      "points torch.Size([118514, 3])\n",
      "CVT loss:  tensor(0.0043, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4324, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.9053226424148306e-05 weighted: 0.019053226336836815 : Allocated: 508.62848 MB, Reserved: 12046.041088 MB\n",
      "SDF loss:  tensor(0.0026, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(2.5529, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 75: loss = 2.985278606414795\n",
      "before loss.backward(): Allocated: 2461.112832 MB, Reserved: 12046.041088 MB\n",
      "After loss.backward(): Allocated: 459.51488 MB, Reserved: 12046.041088 MB\n",
      "-----------------\n",
      "points torch.Size([119111, 3])\n",
      "CVT loss:  tensor(0.0055, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.5524, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.8935510524897836e-05 weighted: 0.018935510888695717 : Allocated: 508.127232 MB, Reserved: 12046.041088 MB\n",
      "SDF loss:  tensor(0.0025, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(2.4872, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 76: loss = 3.039588451385498\n",
      "before loss.backward(): Allocated: 2465.368064 MB, Reserved: 13115.588608 MB\n",
      "After loss.backward(): Allocated: 459.542016 MB, Reserved: 13369.344 MB\n",
      "-----------------\n",
      "points torch.Size([119490, 3])\n",
      "CVT loss:  tensor(0.0037, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3706, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.93965679500252e-05 weighted: 0.019396567717194557 : Allocated: 508.851712 MB, Reserved: 13369.344 MB\n",
      "SDF loss:  tensor(0.0024, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(2.4227, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 77: loss = 2.793355941772461\n",
      "before loss.backward(): Allocated: 2470.855168 MB, Reserved: 13369.344 MB\n",
      "After loss.backward(): Allocated: 459.559424 MB, Reserved: 13369.344 MB\n",
      "-----------------\n",
      "points torch.Size([119812, 3])\n",
      "CVT loss:  tensor(0.0067, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.6663, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.9302857253933325e-05 weighted: 0.019302858039736748 : Allocated: 508.223488 MB, Reserved: 13369.344 MB\n",
      "SDF loss:  tensor(0.0024, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(2.3573, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 78: loss = 3.023615598678589\n",
      "before loss.backward(): Allocated: 2474.194432 MB, Reserved: 13369.344 MB\n",
      "After loss.backward(): Allocated: 459.57376 MB, Reserved: 13369.344 MB\n",
      "-----------------\n",
      "points torch.Size([119812, 3])\n",
      "CVT loss:  tensor(0.0037, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3661, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.922087903949432e-05 weighted: 0.019220879301428795 : Allocated: 508.933632 MB, Reserved: 13369.344 MB\n",
      "SDF loss:  tensor(0.0023, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(2.2908, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 79: loss = 2.6568729877471924\n",
      "before loss.backward(): Allocated: 2474.904576 MB, Reserved: 13369.344 MB\n",
      "After loss.backward(): Allocated: 459.57376 MB, Reserved: 13369.344 MB\n",
      "-----------------\n",
      "points torch.Size([119923, 3])\n",
      "CVT loss:  tensor(0.0035, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3454, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.9514081941451877e-05 weighted: 0.01951408199965954 : Allocated: 508.962304 MB, Reserved: 13369.344 MB\n",
      "SDF loss:  tensor(0.0022, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(2.2297, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 80: loss = 2.5751311779022217\n",
      "before loss.backward(): Allocated: 2476.297216 MB, Reserved: 13369.344 MB\n",
      "After loss.backward(): Allocated: 459.57888 MB, Reserved: 13369.344 MB\n",
      "-----------------\n",
      "points torch.Size([120410, 3])\n",
      "CVT loss:  tensor(0.0044, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4433, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.906750912894495e-05 weighted: 0.019067509099841118 : Allocated: 509.068288 MB, Reserved: 13369.344 MB\n",
      "SDF loss:  tensor(0.0022, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(2.1676, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 81: loss = 2.610914945602417\n",
      "before loss.backward(): Allocated: 2482.97216 MB, Reserved: 13369.344 MB\n",
      "After loss.backward(): Allocated: 459.600384 MB, Reserved: 13369.344 MB\n",
      "-----------------\n",
      "points torch.Size([120525, 3])\n",
      "CVT loss:  tensor(0.0057, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.5666, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.9196995708625764e-05 weighted: 0.019196996465325356 : Allocated: 509.098496 MB, Reserved: 13369.344 MB\n",
      "SDF loss:  tensor(0.0021, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(2.1043, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 82: loss = 2.6708686351776123\n",
      "before loss.backward(): Allocated: 2484.477952 MB, Reserved: 13369.344 MB\n",
      "After loss.backward(): Allocated: 459.606528 MB, Reserved: 13369.344 MB\n",
      "-----------------\n",
      "points torch.Size([120904, 3])\n",
      "CVT loss:  tensor(0.0063, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.6261, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.8955157429445535e-05 weighted: 0.018955158069729805 : Allocated: 509.182976 MB, Reserved: 13369.344 MB\n",
      "SDF loss:  tensor(0.0020, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(2.0448, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 83: loss = 2.6709001064300537\n",
      "before loss.backward(): Allocated: 2509.658624 MB, Reserved: 13369.344 MB\n",
      "After loss.backward(): Allocated: 459.623424 MB, Reserved: 13369.344 MB\n",
      "-----------------\n",
      "points torch.Size([121087, 3])\n",
      "CVT loss:  tensor(0.0043, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4264, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.902689109556377e-05 weighted: 0.01902689039707184 : Allocated: 510.235648 MB, Reserved: 13369.344 MB\n",
      "SDF loss:  tensor(0.0020, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(1.9840, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 84: loss = 2.410412311553955\n",
      "before loss.backward(): Allocated: 2511.18336 MB, Reserved: 13369.344 MB\n",
      "After loss.backward(): Allocated: 459.631104 MB, Reserved: 13369.344 MB\n",
      "-----------------\n",
      "points torch.Size([121481, 3])\n",
      "CVT loss:  tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2304, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.8787593944580294e-05 weighted: 0.018787594512104988 : Allocated: 509.306368 MB, Reserved: 13369.344 MB\n",
      "SDF loss:  tensor(0.0019, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(1.9256, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 85: loss = 2.15598464012146\n",
      "before loss.backward(): Allocated: 2511.277056 MB, Reserved: 13369.344 MB\n",
      "After loss.backward(): Allocated: 459.648512 MB, Reserved: 13369.344 MB\n",
      "-----------------\n",
      "points torch.Size([121512, 3])\n",
      "CVT loss:  tensor(0.0063, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.6303, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.9148617866449058e-05 weighted: 0.01914861798286438 : Allocated: 510.294528 MB, Reserved: 13369.344 MB\n",
      "SDF loss:  tensor(0.0019, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(1.8688, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 86: loss = 2.4991137981414795\n",
      "before loss.backward(): Allocated: 2512.344576 MB, Reserved: 13369.344 MB\n",
      "After loss.backward(): Allocated: 459.65056 MB, Reserved: 13369.344 MB\n",
      "-----------------\n",
      "points torch.Size([121901, 3])\n",
      "CVT loss:  tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2657, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.9099852579529397e-05 weighted: 0.019099852070212364 : Allocated: 509.412864 MB, Reserved: 13369.344 MB\n",
      "SDF loss:  tensor(0.0018, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(1.8112, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 87: loss = 2.0769271850585938\n",
      "before loss.backward(): Allocated: 2512.469504 MB, Reserved: 13369.344 MB\n",
      "After loss.backward(): Allocated: 459.667968 MB, Reserved: 13369.344 MB\n",
      "-----------------\n",
      "points torch.Size([122173, 3])\n",
      "CVT loss:  tensor(0.0033, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3337, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.9009072275366634e-05 weighted: 0.019009072333574295 : Allocated: 510.386688 MB, Reserved: 13369.344 MB\n",
      "SDF loss:  tensor(0.0018, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(1.7541, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 88: loss = 2.08774471282959\n",
      "before loss.backward(): Allocated: 2514.146816 MB, Reserved: 13369.344 MB\n",
      "After loss.backward(): Allocated: 459.680768 MB, Reserved: 13369.344 MB\n",
      "-----------------\n",
      "points torch.Size([122371, 3])\n",
      "CVT loss:  tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2372, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.9240431356593035e-05 weighted: 0.019240431487560272 : Allocated: 509.518848 MB, Reserved: 13369.344 MB\n",
      "SDF loss:  tensor(0.0017, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(1.7013, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 89: loss = 1.9384570121765137\n",
      "before loss.backward(): Allocated: 2513.793024 MB, Reserved: 13369.344 MB\n",
      "After loss.backward(): Allocated: 459.689472 MB, Reserved: 13369.344 MB\n",
      "-----------------\n",
      "points torch.Size([122330, 3])\n",
      "CVT loss:  tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2353, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.9514956875354983e-05 weighted: 0.019514957442879677 : Allocated: 510.408192 MB, Reserved: 13369.344 MB\n",
      "SDF loss:  tensor(0.0016, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(1.6477, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 90: loss = 1.8829747438430786\n",
      "before loss.backward(): Allocated: 2514.573824 MB, Reserved: 13369.344 MB\n",
      "After loss.backward(): Allocated: 459.687424 MB, Reserved: 13369.344 MB\n",
      "-----------------\n",
      "points torch.Size([122508, 3])\n",
      "CVT loss:  tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3411, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.9838884327327833e-05 weighted: 0.019838884472846985 : Allocated: 509.541888 MB, Reserved: 13369.344 MB\n",
      "SDF loss:  tensor(0.0016, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(1.5946, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 91: loss = 1.9357035160064697\n",
      "before loss.backward(): Allocated: 2514.170368 MB, Reserved: 13369.344 MB\n",
      "After loss.backward(): Allocated: 459.695616 MB, Reserved: 13369.344 MB\n",
      "-----------------\n",
      "points torch.Size([122917, 3])\n",
      "CVT loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1471, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.9720468117156997e-05 weighted: 0.019720468670129776 : Allocated: 510.48448 MB, Reserved: 13369.344 MB\n",
      "SDF loss:  tensor(0.0015, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(1.5428, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 92: loss = 1.6898605823516846\n",
      "before loss.backward(): Allocated: 2516.549632 MB, Reserved: 14409.531392 MB\n",
      "After loss.backward(): Allocated: 459.713536 MB, Reserved: 14604.566528 MB\n",
      "-----------------\n",
      "points torch.Size([122970, 3])\n",
      "CVT loss:  tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3138, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.9721619537449442e-05 weighted: 0.019721619784832 : Allocated: 509.654528 MB, Reserved: 14604.566528 MB\n",
      "SDF loss:  tensor(0.0015, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(1.4924, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 93: loss = 1.8062316179275513\n",
      "before loss.backward(): Allocated: 2516.39808 MB, Reserved: 14604.566528 MB\n",
      "After loss.backward(): Allocated: 459.716608 MB, Reserved: 14604.566528 MB\n",
      "-----------------\n",
      "points torch.Size([123154, 3])\n",
      "CVT loss:  tensor(0.0047, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4724, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.954260551428888e-05 weighted: 0.019542604684829712 : Allocated: 510.520832 MB, Reserved: 14604.566528 MB\n",
      "SDF loss:  tensor(0.0014, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(1.4417, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 94: loss = 1.9140558242797852\n",
      "before loss.backward(): Allocated: 2519.626752 MB, Reserved: 14604.566528 MB\n",
      "After loss.backward(): Allocated: 459.7248 MB, Reserved: 14604.566528 MB\n",
      "-----------------\n",
      "points torch.Size([123355, 3])\n",
      "CVT loss:  tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3434, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.9497152607073076e-05 weighted: 0.019497152417898178 : Allocated: 510.789632 MB, Reserved: 14604.566528 MB\n",
      "SDF loss:  tensor(0.0014, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(1.3928, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 95: loss = 1.7361929416656494\n",
      "before loss.backward(): Allocated: 2522.471936 MB, Reserved: 14604.566528 MB\n",
      "After loss.backward(): Allocated: 460.77696 MB, Reserved: 14604.566528 MB\n",
      "-----------------\n",
      "points torch.Size([123941, 3])\n",
      "CVT loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1620, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.922515730257146e-05 weighted: 0.01922515779733658 : Allocated: 510.62784 MB, Reserved: 14604.566528 MB\n",
      "SDF loss:  tensor(0.0013, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(1.3439, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 96: loss = 1.5059071779251099\n",
      "before loss.backward(): Allocated: 2529.547776 MB, Reserved: 14604.566528 MB\n",
      "After loss.backward(): Allocated: 459.759616 MB, Reserved: 14604.566528 MB\n",
      "-----------------\n",
      "points torch.Size([124003, 3])\n",
      "CVT loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.0834, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.0126291929045692e-05 weighted: 0.02012629248201847 : Allocated: 510.925824 MB, Reserved: 14604.566528 MB\n",
      "SDF loss:  tensor(0.0013, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(1.2985, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 97: loss = 1.3819068670272827\n",
      "before loss.backward(): Allocated: 2530.607616 MB, Reserved: 14604.566528 MB\n",
      "After loss.backward(): Allocated: 460.79488 MB, Reserved: 14604.566528 MB\n",
      "-----------------\n",
      "points torch.Size([124373, 3])\n",
      "CVT loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1268, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.945763324329164e-05 weighted: 0.019457632675766945 : Allocated: 510.690816 MB, Reserved: 14604.566528 MB\n",
      "SDF loss:  tensor(0.0013, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(1.2514, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 98: loss = 1.378171682357788\n",
      "before loss.backward(): Allocated: 2535.432192 MB, Reserved: 14604.566528 MB\n",
      "After loss.backward(): Allocated: 459.780096 MB, Reserved: 14604.566528 MB\n",
      "-----------------\n",
      "points torch.Size([124157, 3])\n",
      "CVT loss:  tensor(0.0041, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4067, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.8516662748879753e-05 weighted: 0.0185166634619236 : Allocated: 510.962176 MB, Reserved: 14604.566528 MB\n",
      "SDF loss:  tensor(0.0012, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(1.2031, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 99: loss = 1.609834909439087\n",
      "before loss.backward(): Allocated: 2532.931584 MB, Reserved: 14604.566528 MB\n",
      "After loss.backward(): Allocated: 460.797952 MB, Reserved: 14604.566528 MB\n",
      "-----------------\n",
      "points torch.Size([124187, 3])\n",
      "CVT loss:  tensor(0.0005, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.0493, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.8903716409113258e-05 weighted: 0.018903715535998344 : Allocated: 510.663168 MB, Reserved: 14604.566528 MB\n",
      "SDF loss:  tensor(0.0012, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(1.1580, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 100: loss = 1.2072901725769043\n",
      "before loss.backward(): Allocated: 2533.02016 MB, Reserved: 14604.566528 MB\n",
      "After loss.backward(): Allocated: 459.771904 MB, Reserved: 14604.566528 MB\n",
      "-----------------\n",
      "Saved to chairvoroloss_to_clip.npz\n",
      "Sites length:  33280\n",
      "min sites:  tensor(-0.7072, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "max sites:  tensor(0.7797, device='cuda:0', grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "site_file_path = f'{destination}{max_iter}_cvt_{lambda_cvt}_chamfer_{lambda_chamfer}_eikonal_{lambda_eikonal}.npy'\n",
    "#check if optimized sites file exists\n",
    "if not os.path.exists(site_file_path):\n",
    "    #import sites\n",
    "    print(\"Importing sites\")\n",
    "    sites = np.load(site_file_path)\n",
    "    sites = torch.from_numpy(sites).to(device).requires_grad_(True)\n",
    "else:\n",
    "    # import cProfile, pstats\n",
    "    # import time\n",
    "    # profiler = cProfile.Profile()\n",
    "    # profiler.enable()\n",
    "\n",
    "#     with torch.profiler.profile(activities=[\n",
    "#             torch.profiler.ProfilerActivity.CPU,\n",
    "#             torch.profiler.ProfilerActivity.CUDA,\n",
    "#         ],\n",
    "#         record_shapes=False,\n",
    "#         with_stack=True  # Captures function calls\n",
    "#     ) as prof:\n",
    "#         sites = autograd(sites, model, max_iter=max_iter, upsampling=0, lambda_weights=lambda_weights)\n",
    "#         torch.cuda.synchronize()\n",
    "# # \n",
    "#     print(prof.key_averages().table(sort_by=\"self_cuda_time_total\"))\n",
    "#     prof.export_chrome_trace(\"trace.json\")\n",
    "    \n",
    "    # \n",
    "    sites = autograd(sites, model, max_iter=max_iter, upsampling=0, lambda_weights=lambda_weights)\n",
    "\n",
    "    \n",
    "    # profiler.disable()\n",
    "    # stats = pstats.Stats(profiler).sort_stats('cumtime')\n",
    "    # stats.print_stats()\n",
    "    # stats.dump_stats(f'{destination}{mesh[0]}{max_iter}_3d_profile_{num_centroids}_chamfer{lambda_chamfer}.prof')\n",
    "    \n",
    "    \n",
    "    sites_np = sites.detach().cpu().numpy()\n",
    "    np.save(site_file_path, sites_np)\n",
    "    \n",
    "    \n",
    "\n",
    "print(\"Sites length: \", len(sites))\n",
    "print(\"min sites: \", torch.min(sites))\n",
    "print(\"max sites: \", torch.max(sites))\n",
    "#ps_cloud = ps.register_point_cloud(\"best_optimized_cvt_grid\",sites.detach().cpu().numpy())\n",
    "    \n",
    "lim=torch.abs(torch.max(sites)).detach().cpu().numpy()*1.1\n",
    "#plot_voronoi_3d(sites,lim,lim,lim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e4fcfff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model ./images/autograd/HotSpot/chair100_100_3d_model_512_chamfer1000.pth\n",
      "sites ./images/autograd/HotSpot/chair100_100_3d_sites_512_chamfer1000.pth\n"
     ]
    }
   ],
   "source": [
    "epoch = 100\n",
    "\n",
    "model_file_path = f'{destination}{mesh[0]}{max_iter}_{epoch}_3d_model_{num_centroids}_chamfer{lambda_chamfer}.pth'\n",
    "site_file_path = f'{destination}{mesh[0]}{max_iter}_{epoch}_3d_sites_{num_centroids}_chamfer{lambda_chamfer}.pth'\n",
    " \n",
    "sites = torch.load(site_file_path)\n",
    "\n",
    "sites_np = sites.detach().cpu().numpy()\n",
    "model.load_state_dict(torch.load(model_file_path))\n",
    "#\n",
    "#polyscope_sdf(model)\n",
    "#\n",
    "print(\"model\", model_file_path)\n",
    "print(\"sites\", site_file_path)\n",
    "ps_cloud = ps.register_point_cloud(f\"{epoch} epoch_cvt_grid\",sites_np)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72e588cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-Crossing faces final shape:  (73466, 3)\n",
      "comb torch.Size([6, 2])\n",
      "face_mask torch.Size([4096, 215616])\n",
      "counts torch.Size([4096])\n",
      "Kmax 12\n",
      "face_mask torch.Size([4096, 215616])\n",
      "counts torch.Size([4096])\n",
      "Kmax 12\n",
      "face_mask torch.Size([4096, 215616])\n",
      "counts torch.Size([4096])\n",
      "Kmax 13\n",
      "face_mask torch.Size([4096, 215616])\n",
      "counts torch.Size([4096])\n",
      "Kmax 13\n",
      "face_mask torch.Size([4096, 215616])\n",
      "counts torch.Size([4096])\n",
      "Kmax 12\n",
      "face_mask torch.Size([4096, 215616])\n",
      "counts torch.Size([4096])\n",
      "Kmax 13\n",
      "face_mask torch.Size([4096, 215616])\n",
      "counts torch.Size([4096])\n",
      "Kmax 13\n",
      "face_mask torch.Size([4096, 215616])\n",
      "counts torch.Size([4096])\n",
      "Kmax 13\n",
      "face_mask torch.Size([4096, 215616])\n",
      "counts torch.Size([4096])\n",
      "Kmax 12\n",
      "face_mask torch.Size([4096, 215616])\n",
      "counts torch.Size([4096])\n",
      "Kmax 14\n",
      "face_mask torch.Size([4096, 215616])\n",
      "counts torch.Size([4096])\n",
      "Kmax 12\n",
      "face_mask torch.Size([4096, 215616])\n",
      "counts torch.Size([4096])\n",
      "Kmax 13\n",
      "face_mask torch.Size([1928, 215616])\n",
      "counts torch.Size([1928])\n",
      "Kmax 13\n",
      "faces 51080\n",
      "-> vertices: torch.Size([73466, 3])\n",
      "-> projected vertices: torch.Size([73466, 3])\n",
      "-> #faces: 51080\n"
     ]
    }
   ],
   "source": [
    "final_mesh = su.get_zero_crossing_mesh_3d(sites, model)\n",
    "#ps.register_surface_mesh(\"Zero-Crossing faces direct\", final_mesh[0], final_mesh[1])\n",
    "\n",
    "#save to file\n",
    "final_mesh_file = f'{mesh[0]}voroloss_sdf_trained{model_trained_it}.npz'\n",
    "faces = np.array(final_mesh[1], dtype=object)\n",
    "np.savez(final_mesh_file, vertices=final_mesh[0], faces=faces)\n",
    "\n",
    "data = np.load(final_mesh_file, allow_pickle=True)\n",
    "verts = data[\"vertices\"]       # (N_vertices, 3)\n",
    "faces = data[\"faces\"].tolist() # back to a list of lists\n",
    "\n",
    "print(\"Zero-Crossing faces final shape: \", verts.shape)\n",
    "ps.register_surface_mesh(\"Zero-Crossing faces final\", verts, faces)\n",
    "\n",
    "v_vect, f_vect = su.get_clipped_mesh_torch(sites, model, None, batch_size=4096)\n",
    "ps.register_surface_mesh(\"vectorized diff mesh\", v_vect.detach().cpu().numpy(), f_vect)\n",
    "\n",
    "\n",
    "\n",
    "import scipy.spatial as spatial\n",
    "from scipy.spatial import Delaunay\n",
    "\n",
    "tri = Delaunay(sites_np)\n",
    "delaunay_vertices =torch.tensor(np.array(tri.simplices), device=device)\n",
    "sdf_values = model(sites)\n",
    "\n",
    "# Assuming sites is a PyTorch tensor of shape [M, 3]\n",
    "sites = sites.unsqueeze(0)  # Now shape [1, M, 3]\n",
    "\n",
    "# Assuming SDF_Values is a PyTorch tensor of shape [M]\n",
    "sdf_values = sdf_values.unsqueeze(0)  # Now shape [1, M]\n",
    "\n",
    "marching_tetrehedra_mesh = kaolin.ops.conversions.marching_tetrahedra(sites, delaunay_vertices, sdf_values, return_tet_idx=False)\n",
    "#print(marching_tetrehedra_mesh)\n",
    "vertices_list, faces_list = marching_tetrehedra_mesh\n",
    "vertices = vertices_list[0]\n",
    "faces = faces_list[0]\n",
    "vertices_np = vertices.detach().cpu().numpy()  # Shape [N, 3]\n",
    "faces_np = faces.detach().cpu().numpy()  # Shape [M, 3] (triangles)\n",
    "ps.register_surface_mesh(\"Marching Tetrahedra Mesh final\", vertices_np, faces_np)\n",
    "\n",
    "# clipped_cvt = \"clipped_CVT.obj\"\n",
    "# if os.path.exists(clipped_cvt):\n",
    "#     clipped_cvt_mesh = trimesh.load(clipped_cvt)\n",
    "#     ps.register_surface_mesh(\"Clipped CVT\", clipped_cvt_mesh.vertices, clipped_cvt_mesh.faces)\n",
    "ps.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5deeda7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "End of script",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnd of script\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: End of script"
     ]
    }
   ],
   "source": [
    "assert False, \"End of script\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d940a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the meshed of different sdf trained total epochs and the clipped version \n",
    "import polyscope as ps\n",
    "import numpy as np\n",
    "import trimesh\n",
    "import os \n",
    "\n",
    "ps.init()\n",
    "nb_it = [\"\",\"_1000\",\"_3000\",\"_5000\",\"_7000\"]\n",
    "for it in nb_it:\n",
    "    final_mesh_file = f'gargoyle_sdf_trained{it}.npz'\n",
    "    data = np.load(final_mesh_file, allow_pickle=True)\n",
    "    verts = data[\"vertices\"]       # (N_vertices, 3)\n",
    "    faces = data[\"faces\"].tolist() # back to a list of lists\n",
    "\n",
    "    ps.register_surface_mesh(f\"Zero-Crossing faces final {it}\", verts, faces) \n",
    "\n",
    "for it in nb_it:\n",
    "    clipped_mesh_file = f'gargoyle_to_clip{it}.npz_clipped.obj'\n",
    "    clipped_cvt_mesh = trimesh.load(clipped_mesh_file)\n",
    "    ps.register_surface_mesh(f\"Clipped CVT {it}\", clipped_cvt_mesh.vertices, clipped_cvt_mesh.faces)\n",
    "    \n",
    "for it in nb_it:\n",
    "    final_mesh_file = f'bunnyvoroloss_sdf_trained{it}.npz'\n",
    "    if os.path.exists(final_mesh_file):\n",
    "        data = np.load(final_mesh_file, allow_pickle=True)\n",
    "        verts = data[\"vertices\"]       # (N_vertices, 3)\n",
    "        faces = data[\"faces\"].tolist() # back to a list of lists\n",
    "\n",
    "        ps.register_surface_mesh(f\"Voroloss Zero-Crossing faces final {it}\", verts, faces) \n",
    "\n",
    "for it in nb_it:\n",
    "    clipped_mesh_file = f'bunnyvoroloss_to_clip{it}.npz_clipped.obj'\n",
    "    if os.path.exists(clipped_mesh_file):\n",
    "        clipped_cvt_mesh = trimesh.load(clipped_mesh_file)\n",
    "        ps.register_surface_mesh(f\"Voroloss Clipped CVT {it}\", clipped_cvt_mesh.vertices, clipped_cvt_mesh.faces)\n",
    "    \n",
    "ps.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a193f128",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, \"End of script\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72240a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Voromesh points and values to try and plot the voronoi diagram\n",
    "import numpy as np\n",
    "from scipy.spatial import Voronoi\n",
    "import polyscope as ps\n",
    "def get_zero_crossing_mesh_3d(sites, values):\n",
    "    sites_np = sites\n",
    "    vor = Voronoi(sites_np)  # Compute 3D Voronoi diagram\n",
    "\n",
    "    sdf_values = values\n",
    "\n",
    "    valid_faces = []  # List of polygonal faces\n",
    "    used_vertices = set()  # Set of indices for valid vertices\n",
    "\n",
    "    for (point1, point2), ridge_vertices in zip(vor.ridge_points, vor.ridge_vertices):\n",
    "        if -1 in ridge_vertices:\n",
    "            continue  # Skip infinite ridges\n",
    "\n",
    "        # Check if SDF changes sign across this ridge\n",
    "        if np.sign(sdf_values[point1]) != np.sign(sdf_values[point2]):\n",
    "            valid_faces.append(ridge_vertices)\n",
    "            used_vertices.update(ridge_vertices)\n",
    "\n",
    "    # **Filter Voronoi vertices**\n",
    "    used_vertices = sorted(used_vertices)  # Keep unique, sorted indices\n",
    "    vertex_map = {old_idx: new_idx for new_idx, old_idx in enumerate(used_vertices)}\n",
    "    filtered_vertices = vor.vertices[used_vertices]\n",
    "\n",
    "    # **Re-index faces to match the new filtered vertex list**\n",
    "    filtered_faces = [[vertex_map[v] for v in face] for face in valid_faces]\n",
    "\n",
    "    return filtered_vertices, filtered_faces\n",
    "\n",
    "n_sample = [1, 16, 32, 150, 2400]\n",
    "grid_size = [32,128]\n",
    "voromesh_points = []\n",
    "voromesh_values = []\n",
    "ps.init()\n",
    "# groud plane none\n",
    "ps.set_ground_plane_mode(\"none\") \n",
    "for g in grid_size:\n",
    "    for i in n_sample:\n",
    "        try:\n",
    "            voromesh_points = np.load(f\"/home/wylliam/dev/VoroMesh/points_{i}_{g}.npy\")\n",
    "            voromesh_values = np.load(f\"/home/wylliam/dev/VoroMesh/values_{i}_{g}.npy\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"File not found for points_{i}_{g}.npy or values_{i}_{g}.npy\")\n",
    "            continue\n",
    "        mesh = get_zero_crossing_mesh_3d(voromesh_points, voromesh_values)\n",
    "        ps.register_surface_mesh(f\"mesh_{g}_{i}\", mesh[0], mesh[1])\n",
    "\n",
    "ps.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3355a005",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, \"End of script\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3c340c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#working version of differentiable meshing not vectorized\n",
    "\n",
    "\n",
    "from collections import defaultdict\n",
    "import itertools\n",
    "\n",
    "def sort_face_loop(vertices, face):\n",
    "    pts = vertices[face]                       # shape (N,3)\n",
    "    ctr = pts.mean(axis=0)                     # centroid\n",
    "    # compute a normal for the polygon plane (via PCA/SVD)\n",
    "    _, _, vt = np.linalg.svd(pts - ctr)\n",
    "    normal = vt[2]                             # last singular vector\n",
    "\n",
    "    # pick a reference axis in the plane\n",
    "    ref = pts[0] - ctr\n",
    "    ref -= normal * (normal @ ref)             # project off normal\n",
    "\n",
    "    # compute angles of each point around the centroid\n",
    "    def angle(p):\n",
    "        v = p - ctr\n",
    "        v -= normal * (normal @ v)             # project into plane\n",
    "        a = np.arctan2(np.linalg.norm(np.cross(ref, v)),\n",
    "                    ref @ v)\n",
    "        # sign:\n",
    "        if np.dot(normal, np.cross(ref, v)) < 0:\n",
    "            a = 2*np.pi - a\n",
    "        return a\n",
    "\n",
    "    face_sorted = sorted(face, key=lambda idx: angle(vertices[idx]))\n",
    "    return face_sorted\n",
    "\n",
    "def get_clipped_mesh(sites, model):\n",
    "    sites_np = sites.detach().cpu().numpy()\n",
    "    d3dsimplices = diffvoronoi.get_delaunay_simplices(sites_np.reshape(input_dims*sites_np.shape[0]))\n",
    "    d3dsimplices_np = np.array(d3dsimplices)\n",
    "    \n",
    "    sdf_values = model(sites)\n",
    "    # sdf_gradients = torch.autograd.grad(outputs=sdf_values, inputs=sites, grad_outputs=torch.ones_like(sdf_values), create_graph=True, retain_graph=True,)[0] # (N, 3)\n",
    "    # N, D = sites.shape\n",
    "    # hess_sdf = torch.zeros(N, D, D, device=sites.device)\n",
    "    # for i in range(D):\n",
    "    #     grad2 = torch.autograd.grad(outputs=sdf_gradients[:, i], inputs=sites, grad_outputs=torch.ones_like(sdf_gradients[:, i]), create_graph=False, retain_graph=True,)[0] # (N, 3)\n",
    "    #     hess_sdf[:, i, :] = grad2 # fill row i of each 3Ã—3 Hessian\n",
    "\n",
    "    d3dsimplices_tensor = torch.tensor(d3dsimplices_np, device=device)\n",
    "    voronoi_vertices = su.compute_vertices_3d_vectorized(sites, d3dsimplices_tensor)    \n",
    "    tetra_edges = torch.cat([\n",
    "        d3dsimplices_tensor[:, [0, 1]],\n",
    "        d3dsimplices_tensor[:, [1, 2]],\n",
    "        d3dsimplices_tensor[:, [2, 3]],\n",
    "        d3dsimplices_tensor[:, [3, 0]],\n",
    "        d3dsimplices_tensor[:, [0, 2]],\n",
    "        d3dsimplices_tensor[:, [1, 3]]\n",
    "                                ], dim=0).to(device)\n",
    "    # Sort each edge to ensure uniqueness (because (a, b) and (b, a) are the same)\n",
    "    tetra_edges, _ = torch.sort(tetra_edges, dim=1)\n",
    "    # Get unique edges\n",
    "    voronoi_ridges = torch.unique(tetra_edges, dim=0)\n",
    "    # create a dictionnary to store the d3dsimplices composing the faces\n",
    "    # there is a face for every voronoi_ridges\n",
    "    # every vertices of the face is a simplex containing the two sites of the ridge\n",
    "    face_dict = defaultdict(list)\n",
    "    for simplex_idx, simplex in enumerate(d3dsimplices_np):\n",
    "        for a,b in itertools.combinations(simplex, 2):\n",
    "            key = (a, b) if a < b else (b, a)\n",
    "            face_dict[key].append(simplex_idx)\n",
    "\n",
    "    # Extract the SDF values for each site in the pair\n",
    "    sdf_i = sdf_values[voronoi_ridges[:, 0]]  # First site in each pair\n",
    "    sdf_j = sdf_values[voronoi_ridges[:, 1]]  # Second site in each pair\n",
    "    # Find the indices where SDF values have opposing signs or one is zero\n",
    "    mask_zero_crossing_sites = (sdf_i * sdf_j <= 0).squeeze()\n",
    "    # filter the faces based on the mask\n",
    "    filtered_faces = voronoi_ridges[mask_zero_crossing_sites].detach().cpu().numpy()\n",
    "    faces = []\n",
    "    for a, b in filtered_faces:\n",
    "        key = (a, b) if a < b else (b, a)\n",
    "        match = face_dict.get(key, [])\n",
    "        match = sort_face_loop(voronoi_vertices.detach().cpu().numpy(), match)\n",
    "        faces.append(match)\n",
    "\n",
    "\n",
    "    # Not sure if i should do this at all.\n",
    "    # 1) find every vertex index thatâ€™s actually used\n",
    "    used = set(idx for face in faces for idx in face)\n",
    "    # 2) create old->new mapping\n",
    "    old2new = {old: new for new, old in enumerate(sorted(used))}\n",
    "    # 3) build new, compact vertex array\n",
    "    vertices = voronoi_vertices[sorted(used), :]\n",
    "    # 4) remap faces\n",
    "    faces_new = [[old2new[idx] for idx in face] for face in faces]\n",
    "\n",
    "    print(\"vertices shape: \", vertices)\n",
    "    print(\"faces : \", faces_new)\n",
    "\n",
    "    return vertices, faces_new\n",
    "    return voronoi_vertices, faces"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
