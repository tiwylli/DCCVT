{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed71bbfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device:  NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "import kaolin\n",
    "import torch\n",
    "import math\n",
    "import matplotlib\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import polyscope as ps\n",
    "import trimesh\n",
    "import diffvoronoi\n",
    "\n",
    "from scipy.spatial import Voronoi, voronoi_plot_2d, Delaunay\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import sdfpred_utils.sdfpred_utils as su\n",
    "import sdfpred_utils.sdf_MLP as mlp\n",
    "import sdfpred_utils.sdf_functions as sdf\n",
    "import sdfpred_utils.loss_functions as lf\n",
    "import sdfpred_utils.Steik_data3d as sd3d\n",
    "import sdfpred_utils.Steik_Loss as sl\n",
    "import sdfpred_utils.Steik_utils as Stu \n",
    "import open3d as o3d\n",
    "\n",
    "#cuda devices\n",
    "device = torch.device(\"cuda:0\")\n",
    "print(\"Using device: \", torch.cuda.get_device_name(device))\n",
    "\n",
    "#default tensor types\n",
    "#torch.set_default_tensor_type(torch.cuda.DoubleTensor)\n",
    "\n",
    "multires = 2\n",
    "input_dims = 3\n",
    "lr_sites = 0.005\n",
    "#lr_model = 0.00005*2\n",
    "destination = \"./images/autograd/HotSpot/\"\n",
    "mesh = [\"gargoyle\",\"/home/wylliam/dev/Kyushu_experiments/data/gargoyle\"]\n",
    "mesh = [\"bunny\",\"/home/wylliam/dev/Kyushu_experiments/data/bunny\"]\n",
    "\n",
    "model_trained_it = \"\"\n",
    "trained_model_path = f\"/home/wylliam/dev/HotSpot/log/3D/pc/HotSpot-all-2025-04-24-18-16-03/gargoyle/gargoyle/trained_models/model{model_trained_it}.pth\"\n",
    "trained_model_path = f\"/home/wylliam/dev/HotSpot/log/3D/pc/HotSpot-all-2025-04-25-17-32-49/bunny/bunny/trained_models/model{model_trained_it}.pth\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96ddcc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch3d.ops import knn_points, knn_gather\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class Voroloss_opt(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Voroloss_opt, self).__init__()\n",
    "        self.knn = 16\n",
    "\n",
    "    def __call__(self, points, spoints):\n",
    "        \"\"\"points, self.points\"\"\"\n",
    "        # WARNING: fecthing for knn\n",
    "        with torch.no_grad():\n",
    "            indices = knn_points(points, spoints, K=self.knn).idx\n",
    "\n",
    "        points_knn = knn_gather(spoints, indices)\n",
    "        points_to_voronoi_center = points - points_knn[:, :, 0]\n",
    "\n",
    "        voronoi_edge = points_knn[:, :, 1:] - points_knn[:, :, 0].unsqueeze(2)\n",
    "        voronoi_edge_l = torch.sqrt(((voronoi_edge**2).sum(-1)))\n",
    "        vector_length = (points_to_voronoi_center.unsqueeze(2) * voronoi_edge).sum(\n",
    "            -1\n",
    "        ) / voronoi_edge_l\n",
    "        sq_dist = (vector_length - voronoi_edge_l / 2) ** 2\n",
    "        return sq_dist.min(-1)[0]\n",
    "    \n",
    "voroloss = Voroloss_opt().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95a49d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sites_spread_loss(sites):\n",
    "#     with torch.no_grad():\n",
    "#         indices = knn_points(sites, sites, K=).idx\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a4b4e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new sites\n",
      "Sites shape:  torch.Size([512, 3])\n"
     ]
    }
   ],
   "source": [
    "num_centroids = 8**3\n",
    "\n",
    "print(\"Creating new sites\")\n",
    "noise_scale = 0.1\n",
    "domain_limit = 1\n",
    "x = torch.linspace(-domain_limit, domain_limit, int(round(num_centroids**(1/3))))\n",
    "y = torch.linspace(-domain_limit, domain_limit, int(round(num_centroids**(1/3))))\n",
    "z = torch.linspace(-domain_limit, domain_limit, int(round(num_centroids**(1/3))))\n",
    "meshgrid = torch.meshgrid(x, y, z)\n",
    "meshgrid = torch.stack(meshgrid, dim=3).view(-1, 3)\n",
    "#add noise to meshgrid\n",
    "meshgrid += torch.randn_like(meshgrid) * noise_scale\n",
    "sites = meshgrid.to(device, dtype=torch.float32).requires_grad_(True)\n",
    "\n",
    "print(\"Sites shape: \", sites.shape)\n",
    "ps.init()\n",
    "#ps.register_point_cloud(\"initial_cvt_grid\",sites.detach().cpu().numpy())\n",
    "\n",
    "# # load pointcloud used for sdf training\n",
    "# pointcloud = o3d.io.read_point_cloud(mesh[1]+\".ply\")\n",
    "# print(\"Pointcloud shape: \", np.asarray(pointcloud.points).shape)\n",
    "# # sample pointcloud to 150*32*32\n",
    "# chamfer_distance_pc_gt = pointcloud.uniform_down_sample(int((128**3)/(150*32*32)))\n",
    "# chamfer_distance_pc_gt = np.asarray(chamfer_distance_pc_gt.points)\n",
    "# print(\"Chamfer distance pointcloud shape: \", chamfer_distance_pc_gt.shape)\n",
    "\n",
    "\n",
    "# ps.register_point_cloud(\"pointcloud_gt\", chamfer_distance_pc_gt)\n",
    "# chamfer_distance_pc_gt = torch.tensor(chamfer_distance_pc_gt, device=device, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe96048f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnfld_points shape:  torch.Size([1, 153600, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LOAD MODEL WITH HOTSPOT\n",
    "import sys\n",
    "sys.path.append(\"3rdparty/HotSpot\")\n",
    "from dataset import shape_3d\n",
    "import models.Net as Net\n",
    "\n",
    "loss_type = \"igr_w_heat\"\n",
    "loss_weights = [350, 0, 0, 1, 0, 0, 20]\n",
    "\n",
    "train_set = shape_3d.ReconDataset(\n",
    "    file_path = mesh[1]+\".ply\",\n",
    "    n_points=32*32*150,#15000, #args.n_points,\n",
    "    n_samples=10001, #args.n_iterations,\n",
    "    grid_res=256, #args.grid_res,\n",
    "    grid_range=1.1, #args.grid_range,\n",
    "    sample_type=\"uniform_central_gaussian\", #args.nonmnfld_sample_type,\n",
    "    sampling_std=0.5, #args.nonmnfld_sample_std,\n",
    "    n_random_samples=7500, #args.n_random_samples,\n",
    "    resample=True,\n",
    "    compute_sal_dist_gt=(\n",
    "        True if \"sal\" in loss_type and loss_weights[5] > 0 else False\n",
    "    ),\n",
    "    scale_method=\"mean\"#\"mean\" #args.pcd_scale_method,\n",
    ")\n",
    "\n",
    "model = Net.Network(\n",
    "    latent_size=0,#args.latent_size,\n",
    "    in_dim=3,\n",
    "    decoder_hidden_dim=128,#args.decoder_hidden_dim,\n",
    "    nl=\"sine\",#args.nl,\n",
    "    encoder_type=\"none\",#args.encoder_type,\n",
    "    decoder_n_hidden_layers=5,#args.decoder_n_hidden_layers,\n",
    "    neuron_type=\"quadratic\",#args.neuron_type,\n",
    "    init_type=\"mfgi\",#args.init_type,\n",
    "    sphere_init_params=[1.6, 0.1],#args.sphere_init_params,\n",
    "    n_repeat_period=30#args.n_repeat_period,\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "######       \n",
    "test_dataloader = torch.utils.data.DataLoader(train_set, batch_size=1, shuffle=False, num_workers=0, pin_memory=False)   \n",
    "test_data = next(iter(test_dataloader))\n",
    "mnfld_points = test_data[\"mnfld_points\"].to(device)\n",
    "mnfld_points.requires_grad_()\n",
    "print(\"mnfld_points shape: \", mnfld_points.shape)\n",
    "if torch.cuda.is_available():\n",
    "    map_location = torch.device(\"cuda\")\n",
    "else:\n",
    "    map_location = torch.device(\"cpu\")\n",
    "model.load_state_dict(torch.load(trained_model_path, weights_only=True, map_location=map_location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5753400f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #add mnfld points with random noise to sites \n",
    "N = mnfld_points.squeeze(0).shape[0]\n",
    "num_samples = 32**3\n",
    "idx = torch.randint(0, N, (num_samples,))\n",
    "sampled = mnfld_points.squeeze(0)[idx]\n",
    "perturbed = sampled + (torch.rand_like(sampled)-0.5)*0.1\n",
    "sites = torch.cat((sites, perturbed), dim=0)\n",
    "\n",
    "# make sites a leaf tensor\n",
    "sites = sites.detach().requires_grad_()\n",
    "\n",
    "sites_pred = model(sites)#[\"nonmanifold_pnts_pred\"]\n",
    "#mnfld_preds = model(mnfld_points)#[\"nonmanifold_pnts_pred\"]\n",
    "\n",
    "ps_cloud = ps.register_point_cloud(\"initial_cvt_grid+pc_gt\",sites.detach().cpu().numpy())\n",
    "mnf_cloud = ps.register_point_cloud(\"mnfld_points_pred\",mnfld_points.squeeze(0).detach().cpu().numpy())\n",
    "#mnf_cloud.add_scalar_quantity(\"mnfld_points_pred\", mnfld_preds.reshape(-1).detach().cpu().numpy(), enabled=True)\n",
    "ps_cloud.add_scalar_quantity(\"vis_grid_pred\", sites_pred.reshape(-1).detach().cpu().numpy(), enabled=True)\n",
    "\n",
    "initial_mesh = su.get_zero_crossing_mesh_3d(sites, model)\n",
    "ps.register_surface_mesh(\"initial Zero-Crossing faces\", initial_mesh[0], initial_mesh[1])\n",
    "\n",
    "ps.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "460a316b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SITES OPTIMISATION LOOP\n",
    "cvt_loss_values = []\n",
    "min_distance_loss_values = []\n",
    "chamfer_distance_loss_values = []\n",
    "eikonal_loss_values = []\n",
    "domain_restriction_loss_values = []\n",
    "sdf_loss_values = []\n",
    "div_loss_values = []\n",
    "loss_values = []\n",
    "\n",
    "\n",
    "\n",
    "def autograd(sites, model, max_iter=100, stop_train_threshold=1e-6, upsampling=0, lambda_weights = [0.1,1.0,0.1,0.1,1.0,1.0,0.1]):\n",
    "    optimizer = torch.optim.Adam([\n",
    "    {'params': [sites], 'lr': lr_sites}\n",
    "], betas=(0.9, 0.999))\n",
    "\n",
    "    prev_loss = float(\"inf\")\n",
    "    best_loss = float(\"inf\")\n",
    "    upsampled = 0.0\n",
    "    epoch = 0\n",
    "    lambda_cvt = lambda_weights[0]\n",
    "    # lambda_pc = lambda_weights[1]\n",
    "    lambda_min_distance = lambda_weights[2]\n",
    "    # lambda_laplace = lambda_weights[3]\n",
    "    lambda_chamfer = lambda_weights[4]\n",
    "    lambda_eikonal = lambda_weights[5]\n",
    "    lambda_domain_restriction = lambda_weights[6]\n",
    "    # lambda_target_points = lambda_weights[7]\n",
    "    lambda_sdf = 5e3\n",
    "    lambda_div = 1e2\n",
    "    lambda_eikonal = 5e1\n",
    "    best_sites = sites.clone()\n",
    "    best_sites.best_loss = best_loss\n",
    "    \n",
    "    while epoch <= max_iter:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # compute voronoi and delaunay once for each epoch and pass it around\n",
    "        # Compute Voronoi diagram\n",
    "        sites_np = sites.detach().cpu().numpy()\n",
    "        #vor = Voronoi(sites_np)\n",
    "        #tri = Delaunay(sites_np)\n",
    "      \n",
    "      \n",
    "        d3dsimplices = diffvoronoi.get_delaunay_simplices(sites_np.reshape(input_dims*sites_np.shape[0]))\n",
    "        d3dsimplices = np.array(d3dsimplices)\n",
    "        #print(\"Delaunay simplices shape: \", d3dsimplices.shape)\n",
    "        \n",
    "        vertices_to_compute, bisectors_to_compute = su.compute_zero_crossing_vertices_3d(sites, None, None, d3dsimplices, model)\n",
    "                \n",
    "        #vertices_to_compute, bisectors_to_compute = su.compute_zero_crossing_vertices_3d(sites, None, tri, None, model)\n",
    "        #vertices_to_compute, bisectors_to_compute = su.compute_zero_crossing_vertices_3d(sites, vor, tri, None, model)\n",
    "        \n",
    "        vertices = su.compute_vertices_3d_vectorized(sites, vertices_to_compute)    \n",
    "        bisectors = su.compute_all_bisectors_vectorized(sites, bisectors_to_compute)\n",
    "        points = torch.cat((vertices, bisectors), 0)\n",
    "        print(\"points\", points.shape) \n",
    "\n",
    "        # Compute losses       \n",
    "        #cvt_loss = lf.compute_cvt_loss_vectorized_voronoi(sites, vor)\n",
    "        #cvt_loss = lf.compute_cvt_loss_vectorized_delaunay(sites, tri)\n",
    "    \n",
    "        cvt_loss = lf.compute_cvt_loss_vectorized_delaunay(sites, None, d3dsimplices)\n",
    "        print(\"CVT loss: \", cvt_loss, \"weighted: \", lambda_cvt*cvt_loss)\n",
    "        #min_distance_loss = lf.sdf_weighted_min_distance_loss(model, sites)\n",
    "        \n",
    "        from pytorch3d.loss import chamfer_distance\n",
    "        chamfer_loss, _ = chamfer_distance(mnfld_points.detach(), points.unsqueeze(0))\n",
    "        print(f\"Chamfer loss PYTORCH3D {chamfer_loss} weighted: {lambda_chamfer*chamfer_loss} : Allocated: {torch.cuda.memory_allocated() / 1e6} MB, Reserved: {torch.cuda.memory_reserved() / 1e6} MB\")\n",
    "\n",
    "\n",
    "        # voroloss_loss = voroloss(points.unsqueeze(0), mnfld_points)\n",
    "        # #voroloss_loss = voroloss(sites.unsqueeze(0), mnfld_points)\n",
    "        # voroloss_loss = voroloss_loss.mean()\n",
    "        # print(f\"After Voronoi loss: {voroloss_loss} : Allocated: {torch.cuda.memory_allocated() / 1e6} MB, Reserved: {torch.cuda.memory_reserved() / 1e6} MB\")\n",
    "        \n",
    "        #SDF loss\n",
    "        sdf_loss = torch.mean(model(points)**2) + torch.maximum((model(sites).abs() - 0.05), torch.tensor(0.0)).mean()\n",
    "        #sdf_loss = torch.maximum((model(sites).abs() - 0.01), torch.tensor(0.0)).mean()\n",
    "        #sdf_loss = torch.maximum((model(sites).abs() - 0.05), torch.tensor(0.0)).mean()\n",
    "        print(\"SDF loss: \", sdf_loss, \"weighted: \", lambda_chamfer*sdf_loss)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        sites_loss = (\n",
    "            lambda_cvt * cvt_loss +\n",
    "            #lambda_chamfer * chamfer_loss \n",
    "            #lambda_chamfer * voroloss_loss\n",
    "            + lambda_chamfer * sdf_loss\n",
    "        )\n",
    "            \n",
    "        loss = sites_loss\n",
    "        loss_values.append(loss.item())\n",
    "        print(f\"Epoch {epoch}: loss = {loss.item()}\")\n",
    "        print(f\"before loss.backward(): Allocated: {torch.cuda.memory_allocated() / 1e6} MB, Reserved: {torch.cuda.memory_reserved() / 1e6} MB\")\n",
    "\n",
    "        loss.backward()\n",
    "        print(f\"After loss.backward(): Allocated: {torch.cuda.memory_allocated() / 1e6} MB, Reserved: {torch.cuda.memory_reserved() / 1e6} MB\")\n",
    "        print(\"-----------------\")\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        if loss.item() < best_loss:\n",
    "            best_loss = loss.item()\n",
    "            best_epoch = epoch\n",
    "            best_sites = sites.clone()\n",
    "            best_sites.best_loss = best_loss\n",
    "            #if upsampled > 0:\n",
    "                #print(f\"UPSAMPLED {upsampled} Best Epoch {best_epoch}: Best loss = {best_loss}\")\n",
    "                #return best_sites\n",
    "        \n",
    "        if abs(prev_loss - loss.item()) < stop_train_threshold:\n",
    "            print(f\"Converged at epoch {epoch} with loss {loss.item()}\")\n",
    "            #break\n",
    "        \n",
    "        prev_loss = loss.item() \n",
    "        \n",
    "        # if epoch>100 and (epoch // 100) == upsampled+1 and loss.item() < 0.5 and upsampled < upsampling:\n",
    "        if epoch/max_iter > (upsampled+1)/(upsampling+1) and upsampled < upsampling:\n",
    "            print(\"sites length BEFORE UPSAMPLING: \",len(sites))\n",
    "            sites = su.upsampling_vectorized(sites, tri=None, vor=None, simplices=d3dsimplices, model=model)\n",
    "            sites = sites.detach().requires_grad_(True)\n",
    "            optimizer = torch.optim.Adam([{'params': [sites], 'lr': lr_sites}])\n",
    "            upsampled += 1.0\n",
    "            print(\"sites length AFTER: \",len(sites))\n",
    "            \n",
    "          \n",
    "        if epoch % (max_iter/50) == 0:\n",
    "            #print(f\"Epoch {epoch}: loss = {loss.item()}\")\n",
    "            #print(f\"Best Epoch {best_epoch}: Best loss = {best_loss}\")\n",
    "            #save model and sites\n",
    "            site_file_path = f'{destination}{mesh[0]}{max_iter}_{epoch}_3d_sites_{num_centroids}_chamfer{lambda_chamfer}.pth'\n",
    "            model_file_path = f'{destination}{mesh[0]}{max_iter}_{epoch}_3d_model_{num_centroids}_chamfer{lambda_chamfer}.pth'\n",
    "            torch.save(model.state_dict(), model_file_path)\n",
    "            torch.save(sites, site_file_path)\n",
    "            \n",
    "        epoch += 1           \n",
    "    \n",
    "    #Export the sites, their sdf values, the gradients of the sdf values and the hessian\n",
    "    sdf_values = model(sites)\n",
    "\n",
    "    sdf_gradients = torch.autograd.grad(outputs=sdf_values, inputs=sites, grad_outputs=torch.ones_like(sdf_values), create_graph=True, retain_graph=True,)[0] # (N, 3)\n",
    "\n",
    "    N, D = sites.shape\n",
    "    hess_sdf = torch.zeros(N, D, D, device=sites.device)\n",
    "    for i in range(D):\n",
    "        grad2 = torch.autograd.grad(outputs=sdf_gradients[:, i], inputs=sites, grad_outputs=torch.ones_like(sdf_gradients[:, i]), create_graph=False, retain_graph=True,)[0] # (N, 3)\n",
    "        hess_sdf[:, i, :] = grad2 # fill row i of each 3Ã—3 Hessian\n",
    "    \n",
    "    np.savez(f'{mesh[0]}voroloss_to_clip{model_trained_it}.npz', sites=sites.detach().cpu().numpy(), sdf_values=sdf_values.detach().cpu().numpy(), sdf_gradients=sdf_gradients.detach().cpu().numpy(), sdf_hessians=hess_sdf.detach().cpu().numpy())\n",
    "    print(f\"Saved to {mesh[0]}voroloss_to_clip{model_trained_it}.npz\")\n",
    "    return best_sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7e96773",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lambda_weights = [252,0,0,0,10.211111,0,100,0]\n",
    "#lambda_weights = [500,0,0,0,1000,0,100,0]\n",
    "lambda_weights = [100,0,0,0,1000,0,100,0]\n",
    "\n",
    "\n",
    "lambda_cvt = lambda_weights[0]\n",
    "lambda_sdf = lambda_weights[1]\n",
    "lambda_min_distance = lambda_weights[2]\n",
    "lambda_laplace = lambda_weights[3]\n",
    "lambda_chamfer = lambda_weights[4]\n",
    "lambda_eikonal = lambda_weights[5]\n",
    "lambda_domain_restriction = lambda_weights[6]\n",
    "lambda_true_points = lambda_weights[7]\n",
    "\n",
    "max_iter = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6fb2cefd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "points torch.Size([86390, 3])\n",
      "CVT loss:  tensor(0.0059, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.5906, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 8.212863758672029e-05 weighted: 0.08212863653898239 : Allocated: 8932.633088 MB, Reserved: 15497.95328 MB\n",
      "SDF loss:  tensor(0.0101, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(10.0815, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0: loss = 10.67210865020752\n",
      "before loss.backward(): Allocated: 10469.330432 MB, Reserved: 15502.147584 MB\n",
      "After loss.backward(): Allocated: 8907.614208 MB, Reserved: 15502.147584 MB\n",
      "-----------------\n",
      "points torch.Size([84958, 3])\n",
      "CVT loss:  tensor(0.0067, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.6724, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 4.097502460354008e-05 weighted: 0.040975023061037064 : Allocated: 8942.232576 MB, Reserved: 15502.147584 MB\n",
      "SDF loss:  tensor(0.0097, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(9.7470, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1: loss = 10.419407844543457\n",
      "before loss.backward(): Allocated: 10460.542976 MB, Reserved: 15504.244736 MB\n",
      "After loss.backward(): Allocated: 8909.235712 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([84694, 3])\n",
      "CVT loss:  tensor(0.0053, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.5285, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 3.485088382149115e-05 weighted: 0.03485088422894478 : Allocated: 8942.03136 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0095, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(9.5152, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2: loss = 10.043659210205078\n",
      "before loss.backward(): Allocated: 10456.95232 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8908.35712 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([83445, 3])\n",
      "CVT loss:  tensor(0.0046, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4568, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 3.5585122532211244e-05 weighted: 0.03558512404561043 : Allocated: 8941.536256 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0094, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(9.3515, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3: loss = 9.808284759521484\n",
      "before loss.backward(): Allocated: 10440.418816 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8909.17888 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([81211, 3])\n",
      "CVT loss:  tensor(0.0032, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3172, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 3.478377766441554e-05 weighted: 0.034783776849508286 : Allocated: 8940.631552 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0092, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(9.2099, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 4: loss = 9.527146339416504\n",
      "before loss.backward(): Allocated: 10410.83136 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8908.130304 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([80185, 3])\n",
      "CVT loss:  tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2578, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 3.300997195765376e-05 weighted: 0.03300997242331505 : Allocated: 8939.51488 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0091, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(9.0857, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5: loss = 9.343523025512695\n",
      "before loss.backward(): Allocated: 10396.540928 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8908.04736 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([79791, 3])\n",
      "CVT loss:  tensor(0.0050, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.5010, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 4.793117841472849e-05 weighted: 0.04793117940425873 : Allocated: 8939.00544 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0090, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(8.9766, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6: loss = 9.477545738220215\n",
      "before loss.backward(): Allocated: 10390.972928 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8908.076032 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([79975, 3])\n",
      "CVT loss:  tensor(0.0043, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4319, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 5.0703747547231615e-05 weighted: 0.0507037490606308 : Allocated: 8939.400704 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0089, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(8.8655, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 7: loss = 9.297418594360352\n",
      "before loss.backward(): Allocated: 10393.729024 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8908.034048 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([81037, 3])\n",
      "CVT loss:  tensor(0.0053, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.5307, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 5.149847856955603e-05 weighted: 0.05149848014116287 : Allocated: 8940.520448 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0088, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(8.7550, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8: loss = 9.285697937011719\n",
      "before loss.backward(): Allocated: 10408.487424 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8908.125184 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([81834, 3])\n",
      "CVT loss:  tensor(0.0045, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4525, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 5.340026837075129e-05 weighted: 0.05340026691555977 : Allocated: 8941.07648 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0087, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(8.6509, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9: loss = 9.103370666503906\n",
      "before loss.backward(): Allocated: 10419.275776 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8908.140032 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([82935, 3])\n",
      "CVT loss:  tensor(0.0049, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4852, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 5.0373182602925226e-05 weighted: 0.05037318170070648 : Allocated: 8940.2752 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0085, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(8.5385, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 10: loss = 9.023706436157227\n",
      "before loss.backward(): Allocated: 10432.60928 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8908.20352 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([83866, 3])\n",
      "CVT loss:  tensor(0.0092, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.9186, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 4.2439984099473804e-05 weighted: 0.042439982295036316 : Allocated: 8941.766144 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0084, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(8.4325, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11: loss = 9.351033210754395\n",
      "before loss.backward(): Allocated: 10446.05696 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8908.25728 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([84523, 3])\n",
      "CVT loss:  tensor(0.0099, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.9937, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.4625944206491113e-05 weighted: 0.02462594397366047 : Allocated: 8941.914112 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0083, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(8.3239, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12: loss = 9.317598342895508\n",
      "before loss.backward(): Allocated: 10454.64064 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8908.295168 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([85393, 3])\n",
      "CVT loss:  tensor(0.0081, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.8067, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.4755925551289693e-05 weighted: 0.024755924940109253 : Allocated: 8942.322176 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0082, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(8.2162, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 13: loss = 9.022917747497559\n",
      "before loss.backward(): Allocated: 10466.220032 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8909.314048 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([85862, 3])\n",
      "CVT loss:  tensor(0.0056, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.5594, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.4739054424571805e-05 weighted: 0.024739054962992668 : Allocated: 8942.306304 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0081, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(8.1106, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14: loss = 8.669975280761719\n",
      "before loss.backward(): Allocated: 10472.223744 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8908.37248 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([86663, 3])\n",
      "CVT loss:  tensor(0.0052, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.5229, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.4821969418553635e-05 weighted: 0.024821968749165535 : Allocated: 8942.598144 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0080, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(8.0075, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15: loss = 8.53038215637207\n",
      "before loss.backward(): Allocated: 10482.8032 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8908.41856 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([87397, 3])\n",
      "CVT loss:  tensor(0.0064, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.6417, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.4681434297235683e-05 weighted: 0.02468143403530121 : Allocated: 8943.449088 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0079, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(7.9049, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16: loss = 8.546648979187012\n",
      "before loss.backward(): Allocated: 10493.344768 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8909.677568 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([88184, 3])\n",
      "CVT loss:  tensor(0.0076, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.7552, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.4581140678492375e-05 weighted: 0.024581139907240868 : Allocated: 8943.888896 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0078, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(7.8077, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17: loss = 8.562967300415039\n",
      "before loss.backward(): Allocated: 10503.87968 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8908.98432 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([89348, 3])\n",
      "CVT loss:  tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3383, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.4345925339730456e-05 weighted: 0.024345925077795982 : Allocated: 8944.725504 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0077, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(7.7010, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18: loss = 8.039300918579102\n",
      "before loss.backward(): Allocated: 10519.651328 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8909.072896 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([89743, 3])\n",
      "CVT loss:  tensor(0.0038, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3830, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.4055094399955124e-05 weighted: 0.02405509352684021 : Allocated: 8944.178688 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0076, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(7.6002, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19: loss = 7.983109474182129\n",
      "before loss.backward(): Allocated: 10524.171264 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8909.538816 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([90325, 3])\n",
      "CVT loss:  tensor(0.0055, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.5481, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.3835593310650438e-05 weighted: 0.023835593834519386 : Allocated: 8944.600576 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0075, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(7.4977, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20: loss = 8.045833587646484\n",
      "before loss.backward(): Allocated: 10531.963904 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8908.922368 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([91367, 3])\n",
      "CVT loss:  tensor(0.0050, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4977, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.3727867301204242e-05 weighted: 0.023727867752313614 : Allocated: 8945.454592 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0074, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(7.3950, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21: loss = 7.8927483558654785\n",
      "before loss.backward(): Allocated: 10546.277376 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8909.164544 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([92213, 3])\n",
      "CVT loss:  tensor(0.0035, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3502, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.3568914912175387e-05 weighted: 0.02356891520321369 : Allocated: 8945.138688 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0073, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(7.2977, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 22: loss = 7.647918701171875\n",
      "before loss.backward(): Allocated: 10556.81536 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8909.577728 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([93007, 3])\n",
      "CVT loss:  tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2912, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.3514568965765648e-05 weighted: 0.02351456880569458 : Allocated: 8945.021952 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0072, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(7.1961, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 23: loss = 7.487337112426758\n",
      "before loss.backward(): Allocated: 10566.883328 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8909.162496 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([93655, 3])\n",
      "CVT loss:  tensor(0.0037, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3740, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.3366133973468095e-05 weighted: 0.023366134613752365 : Allocated: 8945.846784 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0071, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(7.0949, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 24: loss = 7.468935012817383\n",
      "before loss.backward(): Allocated: 10576.02048 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8908.824576 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([94381, 3])\n",
      "CVT loss:  tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2810, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.3160220735007897e-05 weighted: 0.023160221055150032 : Allocated: 8946.988032 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0070, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(6.9956, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 25: loss = 7.276529312133789\n",
      "before loss.backward(): Allocated: 10586.476032 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8909.751808 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([95113, 3])\n",
      "CVT loss:  tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2146, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.2904539946466684e-05 weighted: 0.022904539480805397 : Allocated: 8946.762752 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0069, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(6.8971, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 26: loss = 7.111704349517822\n",
      "before loss.backward(): Allocated: 10595.641856 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8909.101568 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([95876, 3])\n",
      "CVT loss:  tensor(0.0040, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4020, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.270771801704541e-05 weighted: 0.02270771749317646 : Allocated: 8947.759104 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0068, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(6.7983, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 27: loss = 7.2002787590026855\n",
      "before loss.backward(): Allocated: 10606.426112 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8909.044736 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([96747, 3])\n",
      "CVT loss:  tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2365, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.2416952560888603e-05 weighted: 0.02241695299744606 : Allocated: 8948.514304 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0067, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(6.7000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 28: loss = 6.936520099639893\n",
      "before loss.backward(): Allocated: 10618.351616 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8909.597696 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([97364, 3])\n",
      "CVT loss:  tensor(0.0050, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4996, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.2272895876085386e-05 weighted: 0.022272896021604538 : Allocated: 8947.365888 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0066, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(6.6052, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 29: loss = 7.104762077331543\n",
      "before loss.backward(): Allocated: 10624.974848 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8909.037056 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([98372, 3])\n",
      "CVT loss:  tensor(0.0062, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.6188, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 3.3537748095113784e-05 weighted: 0.03353774920105934 : Allocated: 8948.7744 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0065, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(6.5122, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 30: loss = 7.130928039550781\n",
      "before loss.backward(): Allocated: 10639.458304 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8909.481984 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([99407, 3])\n",
      "CVT loss:  tensor(0.0045, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4481, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 3.389310950296931e-05 weighted: 0.03389310836791992 : Allocated: 8951.844352 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0064, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(6.4177, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 31: loss = 6.865806579589844\n",
      "before loss.backward(): Allocated: 10655.804928 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8910.271488 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([100076, 3])\n",
      "CVT loss:  tensor(0.0036, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3630, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 3.179761552019045e-05 weighted: 0.0317976139485836 : Allocated: 8950.95808 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0063, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(6.3229, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 32: loss = 6.685837268829346\n",
      "before loss.backward(): Allocated: 10663.499776 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8909.558784 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([100874, 3])\n",
      "CVT loss:  tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2418, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 3.104671122855507e-05 weighted: 0.031046710908412933 : Allocated: 8950.948352 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0062, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(6.2289, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 33: loss = 6.470678329467773\n",
      "before loss.backward(): Allocated: 10673.729536 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8909.25056 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([101414, 3])\n",
      "CVT loss:  tensor(0.0040, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4032, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.9729459129157476e-05 weighted: 0.029729459434747696 : Allocated: 8951.217152 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0061, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(6.1350, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 34: loss = 6.5381975173950195\n",
      "before loss.backward(): Allocated: 10680.924672 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8909.619712 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([102086, 3])\n",
      "CVT loss:  tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2097, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.1176389054744504e-05 weighted: 0.02117638848721981 : Allocated: 8952.141824 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0060, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(6.0397, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 35: loss = 6.2493743896484375\n",
      "before loss.backward(): Allocated: 10690.468864 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8910.343168 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([103008, 3])\n",
      "CVT loss:  tensor(0.0044, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4350, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.092939757858403e-05 weighted: 0.020929398015141487 : Allocated: 8951.517696 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0059, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(5.9485, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 36: loss = 6.383516311645508\n",
      "before loss.backward(): Allocated: 10701.671424 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8909.69088 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([103873, 3])\n",
      "CVT loss:  tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2552, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.081725324387662e-05 weighted: 0.02081725373864174 : Allocated: 8952.333824 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0059, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(5.8581, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 37: loss = 6.113290309906006\n",
      "before loss.backward(): Allocated: 10713.58464 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8910.391808 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([104804, 3])\n",
      "CVT loss:  tensor(0.0041, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4078, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 6.10765564488247e-05 weighted: 0.06107655540108681 : Allocated: 8951.868416 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0058, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(5.7831, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 38: loss = 6.190898895263672\n",
      "before loss.backward(): Allocated: 10725.06112 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8909.7728 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([105648, 3])\n",
      "CVT loss:  tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2419, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 6.025216862326488e-05 weighted: 0.06025216728448868 : Allocated: 8952.531968 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0057, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(5.6922, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 39: loss = 5.934140205383301\n",
      "before loss.backward(): Allocated: 10736.55296 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8910.4384 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([106571, 3])\n",
      "CVT loss:  tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3398, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 5.7554207160137594e-05 weighted: 0.0575542077422142 : Allocated: 8952.208896 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0056, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(5.6027, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 40: loss = 5.942461967468262\n",
      "before loss.backward(): Allocated: 10748.069376 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8909.852672 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([107233, 3])\n",
      "CVT loss:  tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2979, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 5.395567859522998e-05 weighted: 0.05395567789673805 : Allocated: 8952.706048 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0055, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(5.5121, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 41: loss = 5.809975624084473\n",
      "before loss.backward(): Allocated: 10757.058048 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8910.480384 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([107758, 3])\n",
      "CVT loss:  tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2793, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 4.733366222353652e-05 weighted: 0.04733366146683693 : Allocated: 8952.442368 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0054, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(5.4221, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 42: loss = 5.701326370239258\n",
      "before loss.backward(): Allocated: 10763.528704 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8909.906432 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([108193, 3])\n",
      "CVT loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1709, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 4.621328480425291e-05 weighted: 0.04621328413486481 : Allocated: 8952.81664 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0053, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(5.3344, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 43: loss = 5.505251407623291\n",
      "before loss.backward(): Allocated: 10769.485312 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8910.505984 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([109066, 3])\n",
      "CVT loss:  tensor(0.0048, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4787, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 4.743530007544905e-05 weighted: 0.047435298562049866 : Allocated: 8952.699392 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0052, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(5.2483, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 44: loss = 5.7270426750183105\n",
      "before loss.backward(): Allocated: 10780.567552 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8909.965824 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([109902, 3])\n",
      "CVT loss:  tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2180, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 4.463269578991458e-05 weighted: 0.044632695615291595 : Allocated: 8953.401856 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0052, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(5.1610, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 45: loss = 5.379024505615234\n",
      "before loss.backward(): Allocated: 10792.247808 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8910.551552 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([110887, 3])\n",
      "CVT loss:  tensor(0.0045, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4497, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 4.25414509663824e-05 weighted: 0.04254145175218582 : Allocated: 8954.97984 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0051, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(5.0755, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 46: loss = 5.525114059448242\n",
      "before loss.backward(): Allocated: 10806.840832 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8910.048256 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([111518, 3])\n",
      "CVT loss:  tensor(0.0056, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.5600, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.574106474639848e-05 weighted: 0.02574106492102146 : Allocated: 8954.546688 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0050, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(4.9838, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 47: loss = 5.543816566467285\n",
      "before loss.backward(): Allocated: 10814.124032 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8910.59456 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([112063, 3])\n",
      "CVT loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1409, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.3630787836737e-05 weighted: 0.023630788549780846 : Allocated: 8954.098688 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0049, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(4.8994, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 48: loss = 5.040271282196045\n",
      "before loss.backward(): Allocated: 10820.990464 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8910.101504 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([112663, 3])\n",
      "CVT loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1741, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.370120637351647e-05 weighted: 0.023701205849647522 : Allocated: 8954.6752 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0048, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(4.8142, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 49: loss = 4.988349914550781\n",
      "before loss.backward(): Allocated: 10828.9408 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8910.62528 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([113692, 3])\n",
      "CVT loss:  tensor(0.0039, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3856, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 3.4640466765267774e-05 weighted: 0.034640464931726456 : Allocated: 8954.416128 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0047, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(4.7355, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 50: loss = 5.12115478515625\n",
      "before loss.backward(): Allocated: 10842.12992 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8910.175232 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([114212, 3])\n",
      "CVT loss:  tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2713, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.901522591651883e-05 weighted: 0.019015226513147354 : Allocated: 8955.063808 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0046, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(4.6467, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 51: loss = 4.918036937713623\n",
      "before loss.backward(): Allocated: 10849.199616 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8910.667264 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([114963, 3])\n",
      "CVT loss:  tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2572, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.8891740182880312e-05 weighted: 0.01889174059033394 : Allocated: 8954.860544 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0046, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(4.5634, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 52: loss = 4.820611476898193\n",
      "before loss.backward(): Allocated: 10858.820096 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8910.232576 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([115642, 3])\n",
      "CVT loss:  tensor(0.0049, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4914, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.872828943305649e-05 weighted: 0.018728289753198624 : Allocated: 8955.535872 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0045, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(4.4827, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 53: loss = 4.9741106033325195\n",
      "before loss.backward(): Allocated: 10868.015104 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8910.705152 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([115973, 3])\n",
      "CVT loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1304, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.8693317542783916e-05 weighted: 0.018693316727876663 : Allocated: 8955.219456 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0044, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(4.4002, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 54: loss = 4.5305705070495605\n",
      "before loss.backward(): Allocated: 10872.088576 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8910.278656 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([116584, 3])\n",
      "CVT loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1282, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.8573922716313973e-05 weighted: 0.018573923036456108 : Allocated: 8955.853824 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0043, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(4.3195, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 55: loss = 4.447780609130859\n",
      "before loss.backward(): Allocated: 10880.415744 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8910.73024 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([117198, 3])\n",
      "CVT loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1289, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.855467417044565e-05 weighted: 0.018554674461483955 : Allocated: 8955.644928 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0042, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(4.2392, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 56: loss = 4.368080139160156\n",
      "before loss.backward(): Allocated: 10888.169984 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8910.33344 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([117772, 3])\n",
      "CVT loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1293, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.842684650910087e-05 weighted: 0.018426846712827682 : Allocated: 8956.260352 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0042, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(4.1583, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 57: loss = 4.287590026855469\n",
      "before loss.backward(): Allocated: 10896.064512 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8910.762496 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([118402, 3])\n",
      "CVT loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1340, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.834977592807263e-05 weighted: 0.018349776044487953 : Allocated: 8956.07296 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0041, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(4.0789, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 58: loss = 4.212857723236084\n",
      "before loss.backward(): Allocated: 10903.988736 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8910.388736 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([118687, 3])\n",
      "CVT loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1427, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.8318070942768827e-05 weighted: 0.018318070098757744 : Allocated: 8956.563456 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0040, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(3.9997, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 59: loss = 4.1423773765563965\n",
      "before loss.backward(): Allocated: 10908.104704 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8910.78656 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([119323, 3])\n",
      "CVT loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1579, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.8232884031021968e-05 weighted: 0.018232883885502815 : Allocated: 8956.391424 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0039, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(3.9214, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 60: loss = 4.079304218292236\n",
      "before loss.backward(): Allocated: 10916.091392 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8910.415872 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([119870, 3])\n",
      "CVT loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1767, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.8099044609698467e-05 weighted: 0.018099045380949974 : Allocated: 8956.955136 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0038, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(3.8442, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 61: loss = 4.020880699157715\n",
      "before loss.backward(): Allocated: 10923.67104 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8910.332928 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([120151, 3])\n",
      "CVT loss:  tensor(0.0036, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3623, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.8032944353763014e-05 weighted: 0.018032943829894066 : Allocated: 8957.578752 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0038, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(3.7676, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 62: loss = 4.12983512878418\n",
      "before loss.backward(): Allocated: 10928.078336 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8910.468096 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([120563, 3])\n",
      "CVT loss:  tensor(0.0038, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3758, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.804235034796875e-05 weighted: 0.018042350187897682 : Allocated: 8957.192704 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0037, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(3.6922, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 63: loss = 4.067999362945557\n",
      "before loss.backward(): Allocated: 10932.796928 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8910.836224 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([121108, 3])\n",
      "CVT loss:  tensor(0.0055, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.5539, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.7996644601225853e-05 weighted: 0.017996644601225853 : Allocated: 8956.947456 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0036, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(3.6173, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 64: loss = 4.171243667602539\n",
      "before loss.backward(): Allocated: 10939.5456 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8910.4128 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([121634, 3])\n",
      "CVT loss:  tensor(0.0082, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.8172, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 3.784758155234158e-05 weighted: 0.03784758225083351 : Allocated: 8957.782528 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0035, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(3.5489, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 65: loss = 4.366073131561279\n",
      "before loss.backward(): Allocated: 10947.014144 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8910.53568 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([122319, 3])\n",
      "CVT loss:  tensor(0.0068, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.6804, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 3.2999720133375376e-05 weighted: 0.03299972042441368 : Allocated: 8958.519808 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0035, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(3.4740, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 66: loss = 4.154468536376953\n",
      "before loss.backward(): Allocated: 10956.651008 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8910.62528 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([122812, 3])\n",
      "CVT loss:  tensor(0.0044, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4390, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 3.1559258786728606e-05 weighted: 0.031559258699417114 : Allocated: 8958.464 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0034, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(3.4024, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 67: loss = 3.8413891792297363\n",
      "before loss.backward(): Allocated: 10962.820608 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8910.587904 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([123314, 3])\n",
      "CVT loss:  tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2996, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.941166894743219e-05 weighted: 0.029411669820547104 : Allocated: 8958.727168 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0033, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(3.3291, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 68: loss = 3.6286792755126953\n",
      "before loss.backward(): Allocated: 10969.62304 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8910.61504 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([123660, 3])\n",
      "CVT loss:  tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2221, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.894993667723611e-05 weighted: 0.028949936851859093 : Allocated: 8958.745088 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0033, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(3.2575, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 69: loss = 3.4796864986419678\n",
      "before loss.backward(): Allocated: 10973.991424 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8910.627328 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([123966, 3])\n",
      "CVT loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1777, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.935288102889899e-05 weighted: 0.029352881014347076 : Allocated: 8958.866944 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0032, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(3.1867, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 70: loss = 3.364326000213623\n",
      "before loss.backward(): Allocated: 10978.126336 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8910.60736 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([124566, 3])\n",
      "CVT loss:  tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2804, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.7948117601918057e-05 weighted: 0.01794811710715294 : Allocated: 8959.04 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0031, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(3.1142, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 71: loss = 3.3946194648742676\n",
      "before loss.backward(): Allocated: 10985.918976 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8910.667776 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([124850, 3])\n",
      "CVT loss:  tensor(0.0032, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3177, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.7917958757607266e-05 weighted: 0.01791795901954174 : Allocated: 8959.056896 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0030, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(3.0429, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 72: loss = 3.3606648445129395\n",
      "before loss.backward(): Allocated: 10989.656576 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8910.605824 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([125177, 3])\n",
      "CVT loss:  tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2306, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.7881968233268708e-05 weighted: 0.0178819689899683 : Allocated: 8959.253504 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0030, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(2.9727, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 73: loss = 3.2032957077026367\n",
      "before loss.backward(): Allocated: 10993.974784 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8910.694912 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([125537, 3])\n",
      "CVT loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1707, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.787198198144324e-05 weighted: 0.017871981486678123 : Allocated: 8959.305728 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0029, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(2.9045, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 74: loss = 3.0752146244049072\n",
      "before loss.backward(): Allocated: 10998.716928 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8910.645248 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([126017, 3])\n",
      "CVT loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1465, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.7779841073206626e-05 weighted: 0.017779840156435966 : Allocated: 8959.527424 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0028, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(2.8356, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 75: loss = 2.9820919036865234\n",
      "before loss.backward(): Allocated: 11005.036032 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8910.733824 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([126599, 3])\n",
      "CVT loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1301, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.77463298314251e-05 weighted: 0.017746329307556152 : Allocated: 8959.661056 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0028, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(2.7693, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 76: loss = 2.8994245529174805\n",
      "before loss.backward(): Allocated: 11012.698112 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8910.705664 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([127041, 3])\n",
      "CVT loss:  tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2138, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 3.238275530748069e-05 weighted: 0.03238275647163391 : Allocated: 8959.874048 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0027, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(2.7079, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 77: loss = 2.921720504760742\n",
      "before loss.backward(): Allocated: 11018.530816 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8910.780416 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([127468, 3])\n",
      "CVT loss:  tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2974, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 3.2222247682511806e-05 weighted: 0.03222224861383438 : Allocated: 8960.133632 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0026, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(2.6423, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 78: loss = 2.9397060871124268\n",
      "before loss.backward(): Allocated: 11024.315392 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8910.755328 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([127438, 3])\n",
      "CVT loss:  tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2279, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 3.053466934943572e-05 weighted: 0.030534669756889343 : Allocated: 8961.37472 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0026, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(2.5757, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 79: loss = 2.8035616874694824\n",
      "before loss.backward(): Allocated: 11025.50528 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8910.75328 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([128088, 3])\n",
      "CVT loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1600, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.9821210773661733e-05 weighted: 0.029821211472153664 : Allocated: 8960.968192 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0025, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(2.5118, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 80: loss = 2.671738862991333\n",
      "before loss.backward(): Allocated: 11034.052608 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8910.827008 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([128360, 3])\n",
      "CVT loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1591, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.9203376470832154e-05 weighted: 0.029203375801444054 : Allocated: 8960.998912 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0024, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(2.4475, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 81: loss = 2.606545925140381\n",
      "before loss.backward(): Allocated: 11036.62336 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.04512 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([128752, 3])\n",
      "CVT loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1744, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.8687662052107044e-05 weighted: 0.02868766151368618 : Allocated: 8960.933376 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0024, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(2.3840, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 82: loss = 2.558403730392456\n",
      "before loss.backward(): Allocated: 11042.50368 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8910.857216 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([129124, 3])\n",
      "CVT loss:  tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2511, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.759664883138612e-05 weighted: 0.017596649006009102 : Allocated: 8961.2416 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0023, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(2.3183, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 83: loss = 2.569380521774292\n",
      "before loss.backward(): Allocated: 11046.666752 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.0656 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([129530, 3])\n",
      "CVT loss:  tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2683, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.7530153854750097e-05 weighted: 0.017530154436826706 : Allocated: 8961.199104 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0023, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(2.2577, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 84: loss = 2.5260183811187744\n",
      "before loss.backward(): Allocated: 11052.715008 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8910.892032 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([129514, 3])\n",
      "CVT loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.0945, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.7488468074589036e-05 weighted: 0.017488468438386917 : Allocated: 8961.386496 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0022, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(2.1977, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 85: loss = 2.2921969890594482\n",
      "before loss.backward(): Allocated: 11051.8144 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.075328 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([129796, 3])\n",
      "CVT loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.0845, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.7393522284692153e-05 weighted: 0.01739352196455002 : Allocated: 8961.304064 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0021, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(2.1380, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 86: loss = 2.222517490386963\n",
      "before loss.backward(): Allocated: 11056.222208 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8910.90432 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([129865, 3])\n",
      "CVT loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2017, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.7329139154753648e-05 weighted: 0.01732913963496685 : Allocated: 8961.505792 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0021, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(2.0793, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 87: loss = 2.28098726272583\n",
      "before loss.backward(): Allocated: 11056.437248 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.085568 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([130046, 3])\n",
      "CVT loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.0871, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.7271815522690304e-05 weighted: 0.01727181486785412 : Allocated: 8961.39776 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0020, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(2.0222, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 88: loss = 2.109246015548706\n",
      "before loss.backward(): Allocated: 11059.5072 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8910.915584 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([130159, 3])\n",
      "CVT loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.0771, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.3544300347566605e-05 weighted: 0.023544300347566605 : Allocated: 8961.631744 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0020, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(1.9673, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 89: loss = 2.0443849563598633\n",
      "before loss.backward(): Allocated: 11060.333568 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.092736 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([130574, 3])\n",
      "CVT loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.0757, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.443360244797077e-05 weighted: 0.024433601647615433 : Allocated: 8962.635264 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0019, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(1.9110, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 90: loss = 1.9866820573806763\n",
      "before loss.backward(): Allocated: 11067.494912 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8910.94016 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([130811, 3])\n",
      "CVT loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.0774, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.3509135644417256e-05 weighted: 0.023509135469794273 : Allocated: 8962.871296 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0019, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(1.8547, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 91: loss = 1.9321117401123047\n",
      "before loss.backward(): Allocated: 11069.93664 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.110144 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([130773, 3])\n",
      "CVT loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.0874, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.7198377463500947e-05 weighted: 0.01719837822020054 : Allocated: 8962.700288 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0018, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(1.8012, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 92: loss = 1.8885927200317383\n",
      "before loss.backward(): Allocated: 11069.438464 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8910.949376 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([131305, 3])\n",
      "CVT loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1138, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.7221254893229343e-05 weighted: 0.017221255227923393 : Allocated: 8963.003392 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0017, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(1.7474, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 93: loss = 1.8611656427383423\n",
      "before loss.backward(): Allocated: 11077.394432 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.123456 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([131531, 3])\n",
      "CVT loss:  tensor(0.0037, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3727, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.717353552521672e-05 weighted: 0.017173536121845245 : Allocated: 8963.114496 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0017, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(1.6947, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 94: loss = 2.0673727989196777\n",
      "before loss.backward(): Allocated: 11079.568384 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.165952 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([131703, 3])\n",
      "CVT loss:  tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2188, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.715476901154034e-05 weighted: 0.017154768109321594 : Allocated: 8963.887104 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0016, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(1.6428, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 95: loss = 1.861568808555603\n",
      "before loss.backward(): Allocated: 11082.520064 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.101952 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([131610, 3])\n",
      "CVT loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1233, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.7101250705309212e-05 weighted: 0.01710125058889389 : Allocated: 8962.945536 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0016, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(1.5914, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 96: loss = 1.7147597074508667\n",
      "before loss.backward(): Allocated: 11080.270336 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8910.984192 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([131641, 3])\n",
      "CVT loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1152, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.7073212802642956e-05 weighted: 0.017073212191462517 : Allocated: 8964.642304 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0015, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(1.5417, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 97: loss = 1.6568762063980103\n",
      "before loss.backward(): Allocated: 11083.268608 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.879168 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([131870, 3])\n",
      "CVT loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.0668, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.70175244420534e-05 weighted: 0.01701752468943596 : Allocated: 8963.472384 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0015, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(1.4933, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 98: loss = 1.560125708580017\n",
      "before loss.backward(): Allocated: 11084.1344 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.423488 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([132109, 3])\n",
      "CVT loss:  tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2256, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.6985290130833164e-05 weighted: 0.016985289752483368 : Allocated: 8964.005888 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0014, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(1.4448, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 99: loss = 1.6703944206237793\n",
      "before loss.backward(): Allocated: 11088.1792 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.894016 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([132135, 3])\n",
      "CVT loss:  tensor(0.0035, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3542, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.0432747987797484e-05 weighted: 0.020432747900485992 : Allocated: 8964.781056 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0014, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(1.3992, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 100: loss = 1.7533817291259766\n",
      "before loss.backward(): Allocated: 11089.742336 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.873024 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([132182, 3])\n",
      "CVT loss:  tensor(0.0044, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4400, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.0231665985193104e-05 weighted: 0.020231666043400764 : Allocated: 8964.041216 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0014, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(1.3527, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 101: loss = 1.792679786682129\n",
      "before loss.backward(): Allocated: 11089.455104 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.906816 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([132197, 3])\n",
      "CVT loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1722, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.3387327019008808e-05 weighted: 0.023387327790260315 : Allocated: 8963.54048 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0013, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(1.3078, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 102: loss = 1.480008602142334\n",
      "before loss.backward(): Allocated: 11088.39936 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.395328 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([132554, 3])\n",
      "CVT loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1001, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.5215695131919347e-05 weighted: 0.025215694680809975 : Allocated: 8964.148736 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0013, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(1.2636, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 103: loss = 1.3637605905532837\n",
      "before loss.backward(): Allocated: 11094.01344 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.905792 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([132821, 3])\n",
      "CVT loss:  tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2164, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.2823431208962575e-05 weighted: 0.022823430597782135 : Allocated: 8965.05344 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0012, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(1.2190, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 104: loss = 1.4354393482208252\n",
      "before loss.backward(): Allocated: 11098.635776 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.987712 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([132907, 3])\n",
      "CVT loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1772, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.1664867745130323e-05 weighted: 0.02166486717760563 : Allocated: 8962.633728 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0012, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(1.1758, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 105: loss = 1.3530436754226685\n",
      "before loss.backward(): Allocated: 11097.512448 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.54944 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([132903, 3])\n",
      "CVT loss:  tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.0634, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.9923019863199443e-05 weighted: 0.019923020154237747 : Allocated: 8963.406336 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0011, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(1.1337, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 106: loss = 1.1971478462219238\n",
      "before loss.backward(): Allocated: 11097.69728 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.014912 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([133100, 3])\n",
      "CVT loss:  tensor(0.0039, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3910, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.704697908484377e-05 weighted: 0.02704697847366333 : Allocated: 8964.260352 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0011, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(1.0959, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 107: loss = 1.4869734048843384\n",
      "before loss.backward(): Allocated: 11100.746752 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.166976 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([132891, 3])\n",
      "CVT loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1163, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.660139580257237e-05 weighted: 0.0266013965010643 : Allocated: 8963.8016 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0011, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(1.0557, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 108: loss = 1.172005534172058\n",
      "before loss.backward(): Allocated: 11097.575936 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.014912 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([133196, 3])\n",
      "CVT loss:  tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.0563, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.7261154173174873e-05 weighted: 0.02726115472614765 : Allocated: 8964.289024 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0010, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(1.0154, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 109: loss = 1.0716917514801025\n",
      "before loss.backward(): Allocated: 11102.0032 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.168512 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([133135, 3])\n",
      "CVT loss:  tensor(0.0004, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.0442, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.487025449227076e-05 weighted: 0.02487025409936905 : Allocated: 8963.864064 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0010, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.9759, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 110: loss = 1.0200859308242798\n",
      "before loss.backward(): Allocated: 11100.769792 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.0272 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([133286, 3])\n",
      "CVT loss:  tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.0560, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.6386256649857387e-05 weighted: 0.026386257261037827 : Allocated: 8964.30592 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0009, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.9379, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 111: loss = 0.9938762187957764\n",
      "before loss.backward(): Allocated: 11103.171072 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.171072 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([133545, 3])\n",
      "CVT loss:  tensor(0.0004, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.0403, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.4672206563991494e-05 weighted: 0.02467220649123192 : Allocated: 8964.583424 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0009, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.9017, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 112: loss = 0.9419305920600891\n",
      "before loss.backward(): Allocated: 11107.643392 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.716864 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([133281, 3])\n",
      "CVT loss:  tensor(0.0004, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.0376, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.5277582608396187e-05 weighted: 0.025277582928538322 : Allocated: 8963.621888 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0009, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.8654, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 113: loss = 0.9029380679130554\n",
      "before loss.backward(): Allocated: 11102.423552 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.171072 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([133613, 3])\n",
      "CVT loss:  tensor(0.0004, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.0396, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.5147990527329966e-05 weighted: 0.025147991254925728 : Allocated: 8964.598272 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0008, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.8293, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 114: loss = 0.8688483238220215\n",
      "before loss.backward(): Allocated: 11108.527616 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.716352 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([133898, 3])\n",
      "CVT loss:  tensor(0.0004, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.0398, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.4369137463509105e-05 weighted: 0.0243691373616457 : Allocated: 8964.135424 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0008, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.7944, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 115: loss = 0.8341678977012634\n",
      "before loss.backward(): Allocated: 11111.501312 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.542272 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([134130, 3])\n",
      "CVT loss:  tensor(0.0119, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(1.1858, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.3785407393006608e-05 weighted: 0.023785406723618507 : Allocated: 8966.639616 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0008, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.7594, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 116: loss = 1.945218563079834\n",
      "before loss.backward(): Allocated: 11116.647936 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.986112 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([133937, 3])\n",
      "CVT loss:  tensor(0.0046, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4607, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.6075302230310626e-05 weighted: 0.026075301691889763 : Allocated: 8964.258304 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0007, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.7258, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 117: loss = 1.1865370273590088\n",
      "before loss.backward(): Allocated: 11112.102912 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.865344 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([133717, 3])\n",
      "CVT loss:  tensor(0.0037, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3675, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.6228077583946288e-05 weighted: 0.016228077933192253 : Allocated: 8965.218816 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0007, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.6915, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 118: loss = 1.0590249300003052\n",
      "before loss.backward(): Allocated: 11109.914112 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.289792 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([133967, 3])\n",
      "CVT loss:  tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2661, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.624199649086222e-05 weighted: 0.016241995617747307 : Allocated: 8964.59264 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0007, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.6605, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 119: loss = 0.9266010522842407\n",
      "before loss.backward(): Allocated: 11112.178688 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.377408 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([134057, 3])\n",
      "CVT loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1991, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.6189864254556596e-05 weighted: 0.01618986390531063 : Allocated: 8964.548096 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0006, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.6315, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 120: loss = 0.8306427597999573\n",
      "before loss.backward(): Allocated: 11113.359872 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.861184 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([133815, 3])\n",
      "CVT loss:  tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2592, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.6181700630113482e-05 weighted: 0.01618169993162155 : Allocated: 8964.322816 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0006, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.6033, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 121: loss = 0.8624842166900635\n",
      "before loss.backward(): Allocated: 11110.499328 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.600128 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([134144, 3])\n",
      "CVT loss:  tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.0564, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.621492629055865e-05 weighted: 0.016214925795793533 : Allocated: 8964.5952 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0006, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.5754, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 122: loss = 0.631814181804657\n",
      "before loss.backward(): Allocated: 11114.78784 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.366592 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([134132, 3])\n",
      "CVT loss:  tensor(0.0048, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4761, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.617122325114906e-05 weighted: 0.016171222552657127 : Allocated: 8964.333568 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0005, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.5480, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 123: loss = 1.0241539478302002\n",
      "before loss.backward(): Allocated: 11114.333184 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.325696 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([134156, 3])\n",
      "CVT loss:  tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.0582, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.608281490916852e-05 weighted: 0.01608281582593918 : Allocated: 8966.269952 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0005, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.5228, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 124: loss = 0.5810147523880005\n",
      "before loss.backward(): Allocated: 11116.578304 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.30464 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([134141, 3])\n",
      "CVT loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.0711, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.600672294443939e-05 weighted: 0.016006723046302795 : Allocated: 8964.615168 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0005, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.4987, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 125: loss = 0.5698588490486145\n",
      "before loss.backward(): Allocated: 11114.43456 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.649792 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([134247, 3])\n",
      "CVT loss:  tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2301, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.601791700522881e-05 weighted: 0.016017917543649673 : Allocated: 8966.285312 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0005, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.4748, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 126: loss = 0.7049025297164917\n",
      "before loss.backward(): Allocated: 11117.787648 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.950272 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([134157, 3])\n",
      "CVT loss:  tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2958, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5983036064426415e-05 weighted: 0.015983035787940025 : Allocated: 8964.293632 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0005, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.4516, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 127: loss = 0.747405469417572\n",
      "before loss.backward(): Allocated: 11114.95936 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.86432 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([134290, 3])\n",
      "CVT loss:  tensor(0.0043, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4290, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.593934757693205e-05 weighted: 0.015939347445964813 : Allocated: 8965.756928 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0004, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.4295, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 128: loss = 0.8584355115890503\n",
      "before loss.backward(): Allocated: 11117.779456 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.307712 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([134478, 3])\n",
      "CVT loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.0849, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5944298866088502e-05 weighted: 0.01594429835677147 : Allocated: 8964.689408 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0004, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.4090, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 129: loss = 0.49395430088043213\n",
      "before loss.backward(): Allocated: 11118.836736 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.394816 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([134679, 3])\n",
      "CVT loss:  tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2291, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5945233826641925e-05 weighted: 0.015945233404636383 : Allocated: 8964.686848 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0004, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.3880, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 130: loss = 0.6170781850814819\n",
      "before loss.backward(): Allocated: 11121.470976 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.840192 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([134799, 3])\n",
      "CVT loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1011, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5968866136972792e-05 weighted: 0.015968866646289825 : Allocated: 8965.156864 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0004, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.3693, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 131: loss = 0.47038376331329346\n",
      "before loss.backward(): Allocated: 11123.938816 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.91552 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([134759, 3])\n",
      "CVT loss:  tensor(0.0005, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.0493, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.591089676367119e-05 weighted: 0.01591089740395546 : Allocated: 8964.49792 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0004, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.3518, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 132: loss = 0.4011073708534241\n",
      "before loss.backward(): Allocated: 11122.860544 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.098816 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([134910, 3])\n",
      "CVT loss:  tensor(0.0003, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.0296, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.589017301739659e-05 weighted: 0.015890173614025116 : Allocated: 8964.790272 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0003, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.3323, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 133: loss = 0.3619406521320343\n",
      "before loss.backward(): Allocated: 11124.735488 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.313408 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([134881, 3])\n",
      "CVT loss:  tensor(0.0003, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.0271, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5827718016225845e-05 weighted: 0.015827717259526253 : Allocated: 8963.638784 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0003, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.3159, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 134: loss = 0.34305399656295776\n",
      "before loss.backward(): Allocated: 11122.960384 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.572992 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([135083, 3])\n",
      "CVT loss:  tensor(0.0003, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.0342, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.587005317560397e-05 weighted: 0.015870053321123123 : Allocated: 8965.868544 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0003, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.2982, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 135: loss = 0.332400918006897\n",
      "before loss.backward(): Allocated: 11128.035328 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.646656 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([135051, 3])\n",
      "CVT loss:  tensor(0.0003, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.0264, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.579614036018029e-05 weighted: 0.01579613983631134 : Allocated: 8964.47232 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0003, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.2820, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 136: loss = 0.308346688747406\n",
      "before loss.backward(): Allocated: 11126.57152 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.297984 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([134860, 3])\n",
      "CVT loss:  tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2165, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5776027794345282e-05 weighted: 0.015776026993989944 : Allocated: 8964.148224 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0003, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.2659, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 137: loss = 0.4823911488056183\n",
      "before loss.backward(): Allocated: 11123.243008 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.018944 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([134948, 3])\n",
      "CVT loss:  tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.0569, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5763716874062084e-05 weighted: 0.015763716772198677 : Allocated: 8964.442112 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0003, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.2523, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 138: loss = 0.3092094361782074\n",
      "before loss.backward(): Allocated: 11125.228544 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.665152 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([135147, 3])\n",
      "CVT loss:  tensor(0.0004, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.0359, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5751707906019874e-05 weighted: 0.015751708298921585 : Allocated: 8963.90144 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.2394, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 139: loss = 0.2753261625766754\n",
      "before loss.backward(): Allocated: 11126.678528 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.598592 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([135037, 3])\n",
      "CVT loss:  tensor(0.0005, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.0490, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5766989235999063e-05 weighted: 0.015766989439725876 : Allocated: 8964.883968 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.2270, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 140: loss = 0.2759782671928406\n",
      "before loss.backward(): Allocated: 11126.479872 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.821248 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([135673, 3])\n",
      "CVT loss:  tensor(0.0002, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.0242, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 3.474035474937409e-05 weighted: 0.03474035486578941 : Allocated: 8964.81024 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.2228, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 141: loss = 0.24695797264575958\n",
      "before loss.backward(): Allocated: 11134.508544 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.768064 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([135190, 3])\n",
      "CVT loss:  tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2265, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 3.499451486277394e-05 weighted: 0.034994516521692276 : Allocated: 8965.151744 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.2109, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 142: loss = 0.43736493587493896\n",
      "before loss.backward(): Allocated: 11128.448512 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.664128 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([135285, 3])\n",
      "CVT loss:  tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2369, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 3.120905967080034e-05 weighted: 0.031209059059619904 : Allocated: 8965.4656 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.1989, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 143: loss = 0.4358091354370117\n",
      "before loss.backward(): Allocated: 11130.240512 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.74752 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([135163, 3])\n",
      "CVT loss:  tensor(0.0003, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.0283, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.8300273697823286e-05 weighted: 0.028300274163484573 : Allocated: 8964.59008 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.1876, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 144: loss = 0.21589623391628265\n",
      "before loss.backward(): Allocated: 11128.1152 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.65184 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([135160, 3])\n",
      "CVT loss:  tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2587, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.9749895727727562e-05 weighted: 0.019749896600842476 : Allocated: 8964.854784 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.1741, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 145: loss = 0.43281418085098267\n",
      "before loss.backward(): Allocated: 11128.026112 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.274432 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([135306, 3])\n",
      "CVT loss:  tensor(0.0044, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4358, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.8305752746528015e-05 weighted: 0.01830575242638588 : Allocated: 8965.148672 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.1649, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 146: loss = 0.6006671786308289\n",
      "before loss.backward(): Allocated: 11130.518016 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.761344 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([135150, 3])\n",
      "CVT loss:  tensor(0.0059, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.5900, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.8525235645938665e-05 weighted: 0.01852523535490036 : Allocated: 8964.680192 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0002, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.1557, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 147: loss = 0.7456319332122803\n",
      "before loss.backward(): Allocated: 11128.04096 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.65696 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([135358, 3])\n",
      "CVT loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1817, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.5302007998107e-05 weighted: 0.025302007794380188 : Allocated: 8964.94336 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0001, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.1488, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 148: loss = 0.33047232031822205\n",
      "before loss.backward(): Allocated: 11130.619392 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.386112 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([135259, 3])\n",
      "CVT loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1877, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.8713148165261373e-05 weighted: 0.018713148310780525 : Allocated: 8966.042112 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0001, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.1395, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 149: loss = 0.32721927762031555\n",
      "before loss.backward(): Allocated: 11130.218496 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.311296 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([135125, 3])\n",
      "CVT loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1316, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.7473283151048236e-05 weighted: 0.017473282292485237 : Allocated: 8964.799488 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0001, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.1308, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 150: loss = 0.26236915588378906\n",
      "before loss.backward(): Allocated: 11127.256064 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.660032 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([135413, 3])\n",
      "CVT loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1591, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 3.121475310763344e-05 weighted: 0.031214753165841103 : Allocated: 8966.461952 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0001, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.1308, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 151: loss = 0.28986436128616333\n",
      "before loss.backward(): Allocated: 11132.886528 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.898048 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([135489, 3])\n",
      "CVT loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.0723, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.9708655347349122e-05 weighted: 0.029708655551075935 : Allocated: 8965.201408 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0001, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.1228, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 152: loss = 0.19509533047676086\n",
      "before loss.backward(): Allocated: 11132.908544 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.924224 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([135494, 3])\n",
      "CVT loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.0843, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.970739660668187e-05 weighted: 0.029707396402955055 : Allocated: 8965.556736 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0001, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.1164, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 153: loss = 0.20074231922626495\n",
      "before loss.backward(): Allocated: 11132.972032 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.055296 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([135518, 3])\n",
      "CVT loss:  tensor(0.0039, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3899, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.9845559765817598e-05 weighted: 0.02984555996954441 : Allocated: 8965.145088 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0001, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.1099, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 154: loss = 0.4997914731502533\n",
      "before loss.backward(): Allocated: 11132.645888 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.684096 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([135561, 3])\n",
      "CVT loss:  tensor(0.0053, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.5308, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 3.166620444972068e-05 weighted: 0.03166620433330536 : Allocated: 8964.872704 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(0.0001, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.1039, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 155: loss = 0.634661853313446\n",
      "before loss.backward(): Allocated: 11132.955648 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.805888 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([135680, 3])\n",
      "CVT loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.0999, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.8564836611622013e-05 weighted: 0.02856483682990074 : Allocated: 8965.323776 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(9.7728e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0977, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 156: loss = 0.19762587547302246\n",
      "before loss.backward(): Allocated: 11135.37792 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.929344 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([135752, 3])\n",
      "CVT loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1743, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.8583899620571174e-05 weighted: 0.02858389914035797 : Allocated: 8964.66944 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(9.2442e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0924, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 157: loss = 0.26672545075416565\n",
      "before loss.backward(): Allocated: 11135.739904 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.032768 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([135615, 3])\n",
      "CVT loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1416, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.5151392037514597e-05 weighted: 0.025151392444968224 : Allocated: 8965.014528 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(8.8561e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0886, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 158: loss = 0.23012518882751465\n",
      "before loss.backward(): Allocated: 11133.9776 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.4112 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([135554, 3])\n",
      "CVT loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.0683, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5380492186523043e-05 weighted: 0.015380492433905602 : Allocated: 8966.07744 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(8.2059e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0821, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 159: loss = 0.15035675466060638\n",
      "before loss.backward(): Allocated: 11134.043648 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.622592 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([135466, 3])\n",
      "CVT loss:  tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2561, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.537266689410899e-05 weighted: 0.015372666530311108 : Allocated: 8964.863488 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(7.8528e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0785, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 160: loss = 0.3346176743507385\n",
      "before loss.backward(): Allocated: 11131.6992 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.660544 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([135712, 3])\n",
      "CVT loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.0933, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5377732779597864e-05 weighted: 0.015377732925117016 : Allocated: 8966.503936 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(7.5392e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0754, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 161: loss = 0.16869039833545685\n",
      "before loss.backward(): Allocated: 11136.754176 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.892928 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([135821, 3])\n",
      "CVT loss:  tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2351, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5320405509555712e-05 weighted: 0.01532040536403656 : Allocated: 8965.253632 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(7.2410e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0724, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 162: loss = 0.30746516585350037\n",
      "before loss.backward(): Allocated: 11137.211904 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.929344 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([136102, 3])\n",
      "CVT loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1065, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5319612430175766e-05 weighted: 0.015319612808525562 : Allocated: 8966.563328 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(6.8705e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0687, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 163: loss = 0.17521247267723083\n",
      "before loss.backward(): Allocated: 11142.121984 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.562688 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([135918, 3])\n",
      "CVT loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1245, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5379322576336563e-05 weighted: 0.015379322692751884 : Allocated: 8965.033472 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(6.7998e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0680, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 164: loss = 0.1924714744091034\n",
      "before loss.backward(): Allocated: 11138.217984 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.988224 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([135562, 3])\n",
      "CVT loss:  tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2930, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.54505451064324e-05 weighted: 0.015450544655323029 : Allocated: 8964.911104 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(6.5050e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0650, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 165: loss = 0.35808712244033813\n",
      "before loss.backward(): Allocated: 11133.200896 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.359488 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([135579, 3])\n",
      "CVT loss:  tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2167, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5461113434867002e-05 weighted: 0.015461113303899765 : Allocated: 8964.57728 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(6.3570e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0636, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 166: loss = 0.280275821685791\n",
      "before loss.backward(): Allocated: 11132.862976 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.845888 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([135919, 3])\n",
      "CVT loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.0947, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5390891348943114e-05 weighted: 0.015390891581773758 : Allocated: 8965.360128 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(6.2162e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0622, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 167: loss = 0.1568879336118698\n",
      "before loss.backward(): Allocated: 11138.009088 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.926208 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([135811, 3])\n",
      "CVT loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1590, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.534782313683536e-05 weighted: 0.01534782350063324 : Allocated: 8964.62592 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(5.9849e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0598, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 168: loss = 0.21887384355068207\n",
      "before loss.backward(): Allocated: 11136.449024 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.29184 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([135995, 3])\n",
      "CVT loss:  tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2768, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.530028566776309e-05 weighted: 0.015300286002457142 : Allocated: 8964.359168 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(5.8418e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0584, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 169: loss = 0.3352022171020508\n",
      "before loss.backward(): Allocated: 11138.005504 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.975424 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([136266, 3])\n",
      "CVT loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1436, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.7335241611581296e-05 weighted: 0.027335241436958313 : Allocated: 8964.228096 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(6.0515e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0605, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 170: loss = 0.20415940880775452\n",
      "before loss.backward(): Allocated: 11141.88288 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.386112 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([136095, 3])\n",
      "CVT loss:  tensor(0.0042, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4199, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5335765056079254e-05 weighted: 0.015335764735937119 : Allocated: 8963.617792 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(5.5847e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0558, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 171: loss = 0.47570836544036865\n",
      "before loss.backward(): Allocated: 11138.984448 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.414272 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([136313, 3])\n",
      "CVT loss:  tensor(0.0035, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3530, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 3.0378216251847334e-05 weighted: 0.03037821687757969 : Allocated: 8965.327872 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(6.0018e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0600, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 172: loss = 0.41300293803215027\n",
      "before loss.backward(): Allocated: 11143.046656 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.54784 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([136185, 3])\n",
      "CVT loss:  tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3059, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 3.008368003065698e-05 weighted: 0.030083680525422096 : Allocated: 8965.099008 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(5.7976e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0580, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 173: loss = 0.36384814977645874\n",
      "before loss.backward(): Allocated: 11141.379584 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.97952 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([136260, 3])\n",
      "CVT loss:  tensor(0.0053, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.5274, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.7381516702007502e-05 weighted: 0.027381516993045807 : Allocated: 8964.849152 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(5.6058e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0561, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 174: loss = 0.5835068225860596\n",
      "before loss.backward(): Allocated: 11142.058496 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.80288 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([136286, 3])\n",
      "CVT loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.0916, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.7720780053641647e-05 weighted: 0.027720779180526733 : Allocated: 8965.720576 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(5.5725e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0557, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 175: loss = 0.14731459319591522\n",
      "before loss.backward(): Allocated: 11143.082496 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.443456 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([136287, 3])\n",
      "CVT loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1963, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.7367512302589603e-05 weighted: 0.02736751176416874 : Allocated: 8966.216192 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(5.5370e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0554, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 176: loss = 0.25164076685905457\n",
      "before loss.backward(): Allocated: 11143.590912 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.552448 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([136384, 3])\n",
      "CVT loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1034, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.9595885280286893e-05 weighted: 0.029595885425806046 : Allocated: 8965.203968 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(5.4698e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0547, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 177: loss = 0.15813755989074707\n",
      "before loss.backward(): Allocated: 11143.998464 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.445504 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([136441, 3])\n",
      "CVT loss:  tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3029, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5360157703980803e-05 weighted: 0.015360157936811447 : Allocated: 8966.606848 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.9158e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0492, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 178: loss = 0.35202857851982117\n",
      "before loss.backward(): Allocated: 11146.12992 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.63488 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([136491, 3])\n",
      "CVT loss:  tensor(0.0038, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3821, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.530631743662525e-05 weighted: 0.015306317247450352 : Allocated: 8965.078528 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.8095e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0481, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 179: loss = 0.43017059564590454\n",
      "before loss.backward(): Allocated: 11145.074176 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.455232 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([136744, 3])\n",
      "CVT loss:  tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2124, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5293670003302395e-05 weighted: 0.015293669886887074 : Allocated: 8965.142016 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.8943e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0489, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 180: loss = 0.261342853307724\n",
      "before loss.backward(): Allocated: 11148.385792 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.772096 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([136996, 3])\n",
      "CVT loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.0915, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5283470929716714e-05 weighted: 0.01528347097337246 : Allocated: 8965.592576 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.7508e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0475, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 181: loss = 0.13896235823631287\n",
      "before loss.backward(): Allocated: 11152.495616 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.939584 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([136831, 3])\n",
      "CVT loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.0918, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5311279639718123e-05 weighted: 0.015311279334127903 : Allocated: 8964.974592 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.7249e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0472, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 182: loss = 0.1390514224767685\n",
      "before loss.backward(): Allocated: 11149.83424 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.050176 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([136802, 3])\n",
      "CVT loss:  tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2865, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5320940292440355e-05 weighted: 0.01532093994319439 : Allocated: 8965.200384 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.7576e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0476, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 183: loss = 0.3340788185596466\n",
      "before loss.backward(): Allocated: 11149.377536 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.23808 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([136747, 3])\n",
      "CVT loss:  tensor(0.0085, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.8491, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5362697013188154e-05 weighted: 0.015362696722149849 : Allocated: 8964.648448 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.6115e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0461, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 184: loss = 0.895188570022583\n",
      "before loss.backward(): Allocated: 11148.442624 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.052224 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([136807, 3])\n",
      "CVT loss:  tensor(0.0052, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.5237, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5420522686326876e-05 weighted: 0.015420522540807724 : Allocated: 8965.26848 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.8661e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0487, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 185: loss = 0.5723682641983032\n",
      "before loss.backward(): Allocated: 11149.471232 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.434752 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([136731, 3])\n",
      "CVT loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1856, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.532868918729946e-05 weighted: 0.015328689478337765 : Allocated: 8964.104192 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.6529e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0465, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 186: loss = 0.2321198582649231\n",
      "before loss.backward(): Allocated: 11147.182592 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.588864 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([136762, 3])\n",
      "CVT loss:  tensor(0.0035, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3486, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5232955774990842e-05 weighted: 0.015232956036925316 : Allocated: 8965.820416 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.6256e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0463, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 187: loss = 0.3949027359485626\n",
      "before loss.backward(): Allocated: 11149.447168 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.566784 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([136924, 3])\n",
      "CVT loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1373, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5255822290782817e-05 weighted: 0.015255821868777275 : Allocated: 8964.923392 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.7570e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0476, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 188: loss = 0.18490897119045258\n",
      "before loss.backward(): Allocated: 11150.621184 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.727616 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([136890, 3])\n",
      "CVT loss:  tensor(0.0064, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.6358, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5289107977878302e-05 weighted: 0.015289108268916607 : Allocated: 8966.609408 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5985e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0460, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 189: loss = 0.6817386150360107\n",
      "before loss.backward(): Allocated: 11152.102912 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.214528 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([137209, 3])\n",
      "CVT loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1062, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5313213225454092e-05 weighted: 0.01531321369111538 : Allocated: 8966.642688 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.6104e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0461, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 190: loss = 0.15227115154266357\n",
      "before loss.backward(): Allocated: 11156.777472 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.835584 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([137152, 3])\n",
      "CVT loss:  tensor(0.0050, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.5038, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5238341802614741e-05 weighted: 0.015238341875374317 : Allocated: 8965.33504 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5649e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0456, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 191: loss = 0.5494295358657837\n",
      "before loss.backward(): Allocated: 11154.306048 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.987712 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([137314, 3])\n",
      "CVT loss:  tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2101, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5257545783242676e-05 weighted: 0.015257545746862888 : Allocated: 8965.11488 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5033e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0450, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 192: loss = 0.25514930486679077\n",
      "before loss.backward(): Allocated: 11155.798528 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.49056 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([137357, 3])\n",
      "CVT loss:  tensor(0.0054, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.5446, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5288058420992456e-05 weighted: 0.015288058668375015 : Allocated: 8965.952512 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5620e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0456, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 193: loss = 0.5902499556541443\n",
      "before loss.backward(): Allocated: 11157.068288 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.501312 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([137637, 3])\n",
      "CVT loss:  tensor(0.0054, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.5450, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5208077456918545e-05 weighted: 0.015208077616989613 : Allocated: 8966.81472 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.6338e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0463, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 194: loss = 0.5912935733795166\n",
      "before loss.backward(): Allocated: 11161.628672 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.516096 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([137463, 3])\n",
      "CVT loss:  tensor(0.0076, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.7645, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5247776900650933e-05 weighted: 0.015247777104377747 : Allocated: 8965.403648 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5238e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0452, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 195: loss = 0.8097651600837708\n",
      "before loss.backward(): Allocated: 11157.879296 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.909888 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([137416, 3])\n",
      "CVT loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1167, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.532449823571369e-05 weighted: 0.015324498526751995 : Allocated: 8966.021632 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.6382e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0464, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 196: loss = 0.16311633586883545\n",
      "before loss.backward(): Allocated: 11158.008832 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.62208 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([137314, 3])\n",
      "CVT loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1157, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5319525118684396e-05 weighted: 0.015319525264203548 : Allocated: 8965.249024 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5504e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0455, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 197: loss = 0.1612500548362732\n",
      "before loss.backward(): Allocated: 11155.811328 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.668736 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([137492, 3])\n",
      "CVT loss:  tensor(0.0035, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3503, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5248341696860734e-05 weighted: 0.015248341485857964 : Allocated: 8966.794752 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5295e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0453, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 198: loss = 0.39558276534080505\n",
      "before loss.backward(): Allocated: 11159.804928 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.81408 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([137631, 3])\n",
      "CVT loss:  tensor(0.0035, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3495, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5233781596180052e-05 weighted: 0.015233781188726425 : Allocated: 8965.653504 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5659e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0457, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 199: loss = 0.39511701464653015\n",
      "before loss.backward(): Allocated: 11160.758784 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.94368 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([137578, 3])\n",
      "CVT loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1487, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5232589248626027e-05 weighted: 0.015232589095830917 : Allocated: 8966.024704 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5325e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0453, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 200: loss = 0.19402042031288147\n",
      "before loss.backward(): Allocated: 11160.08192 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.05888 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([137830, 3])\n",
      "CVT loss:  tensor(0.0039, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3947, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5303899999707937e-05 weighted: 0.015303900465369225 : Allocated: 8965.656576 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5968e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0460, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 201: loss = 0.44062548875808716\n",
      "before loss.backward(): Allocated: 11162.935296 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.77728 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([137551, 3])\n",
      "CVT loss:  tensor(0.0042, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4204, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5304744010791183e-05 weighted: 0.015304744243621826 : Allocated: 8966.191616 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5302e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0453, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 202: loss = 0.46573489904403687\n",
      "before loss.backward(): Allocated: 11159.799808 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.371712 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([137665, 3])\n",
      "CVT loss:  tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2384, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5251115655701142e-05 weighted: 0.015251115895807743 : Allocated: 8965.615616 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.6447e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0464, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 203: loss = 0.2848365008831024\n",
      "before loss.backward(): Allocated: 11160.786432 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.772672 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([137636, 3])\n",
      "CVT loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1953, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5259833162417635e-05 weighted: 0.015259833075106144 : Allocated: 8966.211584 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5121e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0451, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 204: loss = 0.24041888117790222\n",
      "before loss.backward(): Allocated: 11160.909312 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.37632 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([137577, 3])\n",
      "CVT loss:  tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2838, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5267403796315193e-05 weighted: 0.015267403796315193 : Allocated: 8965.561856 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5689e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0457, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 205: loss = 0.3294660449028015\n",
      "before loss.backward(): Allocated: 11159.500288 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.923712 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([137795, 3])\n",
      "CVT loss:  tensor(0.0040, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3953, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.527432323200628e-05 weighted: 0.015274323523044586 : Allocated: 8966.851072 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5169e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0452, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 206: loss = 0.44050830602645874\n",
      "before loss.backward(): Allocated: 11163.736064 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.798208 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([137853, 3])\n",
      "CVT loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1030, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.525138122815406e-05 weighted: 0.015251381322741508 : Allocated: 8965.713408 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.6190e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0462, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 207: loss = 0.14922328293323517\n",
      "before loss.backward(): Allocated: 11163.650048 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.954432 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([137849, 3])\n",
      "CVT loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1617, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5327157598221675e-05 weighted: 0.015327157452702522 : Allocated: 8966.079488 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5830e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0458, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 208: loss = 0.2075507938861847\n",
      "before loss.backward(): Allocated: 11163.600384 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.055808 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([137823, 3])\n",
      "CVT loss:  tensor(0.0068, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.6775, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5277028069249354e-05 weighted: 0.01527702808380127 : Allocated: 8965.620736 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5423e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0454, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 209: loss = 0.722928524017334\n",
      "before loss.backward(): Allocated: 11162.717696 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.921152 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([137957, 3])\n",
      "CVT loss:  tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3392, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5520225133514032e-05 weighted: 0.015520225279033184 : Allocated: 8966.88384 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.6289e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0463, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 210: loss = 0.38545775413513184\n",
      "before loss.backward(): Allocated: 11165.83424 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.7936 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([138185, 3])\n",
      "CVT loss:  tensor(0.0052, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.5163, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5210977835522499e-05 weighted: 0.015210977755486965 : Allocated: 8965.780992 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5715e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0457, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 211: loss = 0.5620530843734741\n",
      "before loss.backward(): Allocated: 11167.970816 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.945216 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([138139, 3])\n",
      "CVT loss:  tensor(0.0037, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3723, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5479881767532788e-05 weighted: 0.015479881316423416 : Allocated: 8966.164992 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5522e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0455, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 212: loss = 0.4178246259689331\n",
      "before loss.backward(): Allocated: 11167.394816 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.059392 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([138127, 3])\n",
      "CVT loss:  tensor(0.0064, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.6366, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5248845556925517e-05 weighted: 0.01524884533137083 : Allocated: 8965.689344 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.4842e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0448, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 213: loss = 0.6814375519752502\n",
      "before loss.backward(): Allocated: 11166.69184 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.922176 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([138020, 3])\n",
      "CVT loss:  tensor(0.0049, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4906, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5270861695171334e-05 weighted: 0.01527086179703474 : Allocated: 8966.157312 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.6495e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0465, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 214: loss = 0.5370907187461853\n",
      "before loss.backward(): Allocated: 11165.866496 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.367616 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([137980, 3])\n",
      "CVT loss:  tensor(0.0043, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4285, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.528748543933034e-05 weighted: 0.015287484973669052 : Allocated: 8965.648896 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.6210e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0462, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 215: loss = 0.4746633470058441\n",
      "before loss.backward(): Allocated: 11164.761088 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.923712 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([137894, 3])\n",
      "CVT loss:  tensor(0.0052, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.5237, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5262161468854174e-05 weighted: 0.015262161381542683 : Allocated: 8966.122496 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5452e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0455, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 216: loss = 0.5691507458686829\n",
      "before loss.backward(): Allocated: 11164.22144 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.368128 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([137828, 3])\n",
      "CVT loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1847, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5344126950367354e-05 weighted: 0.015344127081334591 : Allocated: 8965.620224 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.6018e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0460, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 217: loss = 0.23071011900901794\n",
      "before loss.backward(): Allocated: 11162.781696 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.921664 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([138165, 3])\n",
      "CVT loss:  tensor(0.0077, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.7678, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.523532500868896e-05 weighted: 0.015235325321555138 : Allocated: 8966.91712 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5390e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0454, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 218: loss = 0.8131636381149292\n",
      "before loss.backward(): Allocated: 11168.537088 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.780288 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([138095, 3])\n",
      "CVT loss:  tensor(0.0060, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.6034, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5209747289191e-05 weighted: 0.015209747478365898 : Allocated: 8965.277184 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5344e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0453, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 219: loss = 0.6487315893173218\n",
      "before loss.backward(): Allocated: 11166.30272 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.91296 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([138183, 3])\n",
      "CVT loss:  tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3001, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.515419535280671e-05 weighted: 0.01515419501811266 : Allocated: 8966.519808 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.4855e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0449, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 220: loss = 0.3449937403202057\n",
      "before loss.backward(): Allocated: 11168.311808 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.308736 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([138155, 3])\n",
      "CVT loss:  tensor(0.0041, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4073, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5166735465754755e-05 weighted: 0.015166735276579857 : Allocated: 8965.433344 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5378e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0454, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 221: loss = 0.45267945528030396\n",
      "before loss.backward(): Allocated: 11166.794752 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.6672 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([138410, 3])\n",
      "CVT loss:  tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2180, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5213796359603293e-05 weighted: 0.015213795937597752 : Allocated: 8966.95808 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5235e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0452, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 222: loss = 0.2631893754005432\n",
      "before loss.backward(): Allocated: 11171.708416 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.771072 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([138422, 3])\n",
      "CVT loss:  tensor(0.0044, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4375, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5184070434770547e-05 weighted: 0.015184069983661175 : Allocated: 8965.846528 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5278e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0453, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 223: loss = 0.48274558782577515\n",
      "before loss.backward(): Allocated: 11171.058688 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.96416 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([138244, 3])\n",
      "CVT loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1474, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.527186032035388e-05 weighted: 0.015271860174834728 : Allocated: 8966.170624 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5740e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0457, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 224: loss = 0.1931149661540985\n",
      "before loss.backward(): Allocated: 11168.743936 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.048128 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([138340, 3])\n",
      "CVT loss:  tensor(0.0046, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4616, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5230119970510714e-05 weighted: 0.015230120159685612 : Allocated: 8965.782016 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5204e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0452, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 225: loss = 0.5068427920341492\n",
      "before loss.backward(): Allocated: 11169.57952 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.811584 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([138548, 3])\n",
      "CVT loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1496, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5195035302895121e-05 weighted: 0.015195035375654697 : Allocated: 8966.706688 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5777e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0458, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 226: loss = 0.19536621868610382\n",
      "before loss.backward(): Allocated: 11173.164032 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.381952 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([138670, 3])\n",
      "CVT loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1699, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5208257536869496e-05 weighted: 0.015208257362246513 : Allocated: 8965.866496 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5038e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0450, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 227: loss = 0.2149735391139984\n",
      "before loss.backward(): Allocated: 11173.883392 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.830016 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([138479, 3])\n",
      "CVT loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1904, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5186995369731449e-05 weighted: 0.015186995267868042 : Allocated: 8966.364672 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5205e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0452, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 228: loss = 0.23555508255958557\n",
      "before loss.backward(): Allocated: 11171.886592 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.369152 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([138401, 3])\n",
      "CVT loss:  tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2408, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5203891052806284e-05 weighted: 0.015203891322016716 : Allocated: 8965.747712 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5434e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0454, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 229: loss = 0.2862660884857178\n",
      "before loss.backward(): Allocated: 11170.268672 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.924736 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([138498, 3])\n",
      "CVT loss:  tensor(0.0062, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.6170, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5196941603790037e-05 weighted: 0.015196941792964935 : Allocated: 8966.977024 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5474e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0455, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 230: loss = 0.6624276638031006\n",
      "before loss.backward(): Allocated: 11172.84608 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.764416 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([138486, 3])\n",
      "CVT loss:  tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2421, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.520683326816652e-05 weighted: 0.015206833370029926 : Allocated: 8965.374464 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.4816e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0448, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 231: loss = 0.2869248688220978\n",
      "before loss.backward(): Allocated: 11171.400704 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.914496 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([138751, 3])\n",
      "CVT loss:  tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2846, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5196415915852413e-05 weighted: 0.015196415595710278 : Allocated: 8966.649856 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5481e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0455, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 232: loss = 0.33005884289741516\n",
      "before loss.backward(): Allocated: 11175.699968 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.31488 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([138599, 3])\n",
      "CVT loss:  tensor(0.0055, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.5542, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.521189187769778e-05 weighted: 0.015211892314255238 : Allocated: 8965.53472 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.4670e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0447, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 233: loss = 0.5988689661026001\n",
      "before loss.backward(): Allocated: 11172.596736 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.67232 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([138559, 3])\n",
      "CVT loss:  tensor(0.0038, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3797, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5210605852189474e-05 weighted: 0.015210606157779694 : Allocated: 8966.539776 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.6004e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0460, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 234: loss = 0.4256719648838043\n",
      "before loss.backward(): Allocated: 11173.136896 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.61952 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([138696, 3])\n",
      "CVT loss:  tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2590, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5223152331600431e-05 weighted: 0.015223152004182339 : Allocated: 8965.621248 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5664e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0457, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 235: loss = 0.3046822249889374\n",
      "before loss.backward(): Allocated: 11173.969408 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.575552 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([138974, 3])\n",
      "CVT loss:  tensor(0.0066, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.6585, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5218966836982872e-05 weighted: 0.015218966640532017 : Allocated: 8967.036928 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5565e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0456, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 236: loss = 0.7040748000144958\n",
      "before loss.backward(): Allocated: 11178.938368 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.638976 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139064, 3])\n",
      "CVT loss:  tensor(0.0050, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.5003, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5179293768596835e-05 weighted: 0.015179294161498547 : Allocated: 8965.703168 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5928e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0459, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 237: loss = 0.5462054014205933\n",
      "before loss.backward(): Allocated: 11178.756608 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.597568 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139016, 3])\n",
      "CVT loss:  tensor(0.0052, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.5232, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5193641957012005e-05 weighted: 0.015193642117083073 : Allocated: 8966.722048 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5818e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0458, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 238: loss = 0.5690535306930542\n",
      "before loss.backward(): Allocated: 11179.140096 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.627712 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([138913, 3])\n",
      "CVT loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1715, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5155856999626849e-05 weighted: 0.015155857428908348 : Allocated: 8965.600256 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5344e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0453, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 239: loss = 0.21688342094421387\n",
      "before loss.backward(): Allocated: 11176.695808 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.670784 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([138927, 3])\n",
      "CVT loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1323, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.518766293884255e-05 weighted: 0.015187663026154041 : Allocated: 8967.05024 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5729e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0457, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 240: loss = 0.17805172502994537\n",
      "before loss.backward(): Allocated: 11178.399744 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.743936 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([138912, 3])\n",
      "CVT loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.0951, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5180328773567453e-05 weighted: 0.015180328860878944 : Allocated: 8965.484032 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5179e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0452, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 241: loss = 0.140316441655159\n",
      "before loss.backward(): Allocated: 11176.959488 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.919616 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139128, 3])\n",
      "CVT loss:  tensor(0.0055, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.5535, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5193122635537293e-05 weighted: 0.015193122439086437 : Allocated: 8966.725632 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5264e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0453, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 242: loss = 0.5987282991409302\n",
      "before loss.backward(): Allocated: 11180.5952 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.312832 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139296, 3])\n",
      "CVT loss:  tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2781, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5133990928006824e-05 weighted: 0.015133990906178951 : Allocated: 8965.764096 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.4933e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0449, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 243: loss = 0.32306554913520813\n",
      "before loss.backward(): Allocated: 11181.783552 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.607808 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139278, 3])\n",
      "CVT loss:  tensor(0.0035, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3523, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5134663044591434e-05 weighted: 0.015134663321077824 : Allocated: 8966.77632 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.4742e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0447, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 244: loss = 0.3970620036125183\n",
      "before loss.backward(): Allocated: 11182.557696 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.630272 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139166, 3])\n",
      "CVT loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1367, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5139543393161148e-05 weighted: 0.015139543451368809 : Allocated: 8965.657088 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5396e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0454, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 245: loss = 0.182074174284935\n",
      "before loss.backward(): Allocated: 11180.00128 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.67232 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139156, 3])\n",
      "CVT loss:  tensor(0.0058, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.5767, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5118013834580779e-05 weighted: 0.015118014067411423 : Allocated: 8966.685696 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5469e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0455, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 246: loss = 0.6221598982810974\n",
      "before loss.backward(): Allocated: 11180.9152 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.621568 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139131, 3])\n",
      "CVT loss:  tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2892, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5081850506248884e-05 weighted: 0.015081850811839104 : Allocated: 8965.651456 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5521e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0455, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 247: loss = 0.334697425365448\n",
      "before loss.backward(): Allocated: 11179.542528 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.66976 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139166, 3])\n",
      "CVT loss:  tensor(0.0032, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3225, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5072175301611423e-05 weighted: 0.015072175301611423 : Allocated: 8967.091712 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5001e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0450, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 248: loss = 0.3675321936607361\n",
      "before loss.backward(): Allocated: 11181.498368 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.735232 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139111, 3])\n",
      "CVT loss:  tensor(0.0032, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3191, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.505792806710815e-05 weighted: 0.015057927928864956 : Allocated: 8965.535232 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5468e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0455, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 249: loss = 0.36458688974380493\n",
      "before loss.backward(): Allocated: 11179.551744 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.924224 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139142, 3])\n",
      "CVT loss:  tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3118, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5027833796921186e-05 weighted: 0.015027834102511406 : Allocated: 8966.724608 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5198e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0452, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 250: loss = 0.35700851678848267\n",
      "before loss.backward(): Allocated: 11180.775424 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.305664 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139315, 3])\n",
      "CVT loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1268, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5023890227894299e-05 weighted: 0.01502388995140791 : Allocated: 8965.770752 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5198e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0452, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 251: loss = 0.17201374471187592\n",
      "before loss.backward(): Allocated: 11182.031872 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.609344 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139260, 3])\n",
      "CVT loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1159, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5033790077723097e-05 weighted: 0.015033789910376072 : Allocated: 8966.771712 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5056e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0451, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 252: loss = 0.1609317809343338\n",
      "before loss.backward(): Allocated: 11182.319616 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.628224 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139278, 3])\n",
      "CVT loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1124, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5022062143543735e-05 weighted: 0.01502206176519394 : Allocated: 8965.759488 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5557e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0456, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 253: loss = 0.15796354413032532\n",
      "before loss.backward(): Allocated: 11181.549056 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.612928 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139141, 3])\n",
      "CVT loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1477, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5021319995867088e-05 weighted: 0.015021320432424545 : Allocated: 8966.744064 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.4426e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0444, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 254: loss = 0.19209057092666626\n",
      "before loss.backward(): Allocated: 11180.768256 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.621568 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139209, 3])\n",
      "CVT loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.0979, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5154517313931137e-05 weighted: 0.015154517255723476 : Allocated: 8965.74464 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5618e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0456, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 255: loss = 0.14349687099456787\n",
      "before loss.backward(): Allocated: 11180.650496 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.606784 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139327, 3])\n",
      "CVT loss:  tensor(0.0045, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4461, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5084858205227647e-05 weighted: 0.015084858052432537 : Allocated: 8967.084032 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.4717e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0447, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 256: loss = 0.49081578850746155\n",
      "before loss.backward(): Allocated: 11183.49824 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.631296 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139543, 3])\n",
      "CVT loss:  tensor(0.0049, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4920, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.507861634308938e-05 weighted: 0.015078616328537464 : Allocated: 8965.830656 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5760e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0458, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 257: loss = 0.5377267599105835\n",
      "before loss.backward(): Allocated: 11185.014272 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.620096 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139502, 3])\n",
      "CVT loss:  tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3068, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5069425899127964e-05 weighted: 0.015069426037371159 : Allocated: 8966.822912 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5876e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0459, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 258: loss = 0.3527008593082428\n",
      "before loss.backward(): Allocated: 11185.478144 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.630272 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139372, 3])\n",
      "CVT loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1075, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.502706072642468e-05 weighted: 0.015027061104774475 : Allocated: 8965.70624 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5656e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0457, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 259: loss = 0.15318337082862854\n",
      "before loss.backward(): Allocated: 11182.693376 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.672832 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139195, 3])\n",
      "CVT loss:  tensor(0.0037, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3665, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.4982095308369026e-05 weighted: 0.01498209498822689 : Allocated: 8966.703616 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5048e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0450, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 260: loss = 0.411562442779541\n",
      "before loss.backward(): Allocated: 11181.42976 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.613888 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139364, 3])\n",
      "CVT loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2027, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5005021850811318e-05 weighted: 0.015005022287368774 : Allocated: 8965.787136 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5270e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0453, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 261: loss = 0.2480015605688095\n",
      "before loss.backward(): Allocated: 11182.672896 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.612928 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139591, 3])\n",
      "CVT loss:  tensor(0.0071, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.7066, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5000275197962765e-05 weighted: 0.01500027533620596 : Allocated: 8967.138816 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5046e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0450, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 262: loss = 0.751655101776123\n",
      "before loss.backward(): Allocated: 11186.937344 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.636416 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139631, 3])\n",
      "CVT loss:  tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2171, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.4985220332164317e-05 weighted: 0.0149852205067873 : Allocated: 8965.8496 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.4670e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0447, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 263: loss = 0.2617644965648651\n",
      "before loss.backward(): Allocated: 11186.16064 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.631872 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139585, 3])\n",
      "CVT loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1096, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5015077224234119e-05 weighted: 0.015015076845884323 : Allocated: 8966.832128 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5734e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0457, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 264: loss = 0.15529362857341766\n",
      "before loss.backward(): Allocated: 11186.554368 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.623616 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139567, 3])\n",
      "CVT loss:  tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2180, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.502384475315921e-05 weighted: 0.015023844316601753 : Allocated: 8965.743104 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5202e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0452, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 265: loss = 0.26320531964302063\n",
      "before loss.backward(): Allocated: 11185.234432 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.671296 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139666, 3])\n",
      "CVT loss:  tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.0577, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5100848031579517e-05 weighted: 0.01510084792971611 : Allocated: 8967.175168 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5231e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0452, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 266: loss = 0.10291571915149689\n",
      "before loss.backward(): Allocated: 11187.97824 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.712192 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139570, 3])\n",
      "CVT loss:  tensor(0.0039, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3944, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5043169696582481e-05 weighted: 0.015043169260025024 : Allocated: 8965.66272 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.4968e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0450, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 267: loss = 0.4393869638442993\n",
      "before loss.backward(): Allocated: 11185.548288 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.929856 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139813, 3])\n",
      "CVT loss:  tensor(0.0041, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4097, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.4897334040142596e-05 weighted: 0.014897334389388561 : Allocated: 8966.864896 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.4772e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0448, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 268: loss = 0.45451033115386963\n",
      "before loss.backward(): Allocated: 11189.514752 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.30976 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139936, 3])\n",
      "CVT loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1401, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.4918387023499236e-05 weighted: 0.014918386936187744 : Allocated: 8965.925376 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.4941e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0449, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 269: loss = 0.1850328892469406\n",
      "before loss.backward(): Allocated: 11190.154752 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.645696 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139904, 3])\n",
      "CVT loss:  tensor(0.0035, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3498, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.4902370821801014e-05 weighted: 0.014902370981872082 : Allocated: 8966.895104 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5139e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0451, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 270: loss = 0.3949298560619354\n",
      "before loss.backward(): Allocated: 11190.711296 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.626688 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139717, 3])\n",
      "CVT loss:  tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2081, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.4938663298380561e-05 weighted: 0.014938663691282272 : Allocated: 8965.77792 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5257e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0453, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 271: loss = 0.2533800005912781\n",
      "before loss.backward(): Allocated: 11187.196416 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.676416 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139753, 3])\n",
      "CVT loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1096, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5034665921120904e-05 weighted: 0.015034666284918785 : Allocated: 8967.187456 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.4916e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0449, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 272: loss = 0.1545364111661911\n",
      "before loss.backward(): Allocated: 11189.09696 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.701952 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139716, 3])\n",
      "CVT loss:  tensor(0.0035, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3455, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.4992729120422155e-05 weighted: 0.01499272882938385 : Allocated: 8965.696512 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5359e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0454, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 273: loss = 0.39089933037757874\n",
      "before loss.backward(): Allocated: 11187.449856 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.929344 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139713, 3])\n",
      "CVT loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1008, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.498856636317214e-05 weighted: 0.014988566748797894 : Allocated: 8966.561792 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5904e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0459, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 274: loss = 0.14666825532913208\n",
      "before loss.backward(): Allocated: 11188.217344 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.303104 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139643, 3])\n",
      "CVT loss:  tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3366, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5011710274848156e-05 weighted: 0.015011710114777088 : Allocated: 8965.760512 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5019e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0450, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 275: loss = 0.3816027343273163\n",
      "before loss.backward(): Allocated: 11186.226176 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.672832 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139538, 3])\n",
      "CVT loss:  tensor(0.0036, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3608, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5033792806207202e-05 weighted: 0.015033792704343796 : Allocated: 8966.779904 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5324e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0453, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 276: loss = 0.4060879051685333\n",
      "before loss.backward(): Allocated: 11185.937408 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.617984 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139574, 3])\n",
      "CVT loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1621, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.509876165073365e-05 weighted: 0.015098761767148972 : Allocated: 8965.835776 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5003e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0450, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 277: loss = 0.2071424126625061\n",
      "before loss.backward(): Allocated: 11185.416704 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.629312 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139876, 3])\n",
      "CVT loss:  tensor(0.0035, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3494, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5089000953594223e-05 weighted: 0.015089000575244427 : Allocated: 8967.184896 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5046e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0450, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 278: loss = 0.3944151699542999\n",
      "before loss.backward(): Allocated: 11190.642176 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.634368 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139931, 3])\n",
      "CVT loss:  tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2515, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5029567293822765e-05 weighted: 0.015029567293822765 : Allocated: 8965.920768 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.4744e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0447, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 279: loss = 0.29628923535346985\n",
      "before loss.backward(): Allocated: 11190.086144 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.648256 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([140047, 3])\n",
      "CVT loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1604, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.536562376713846e-05 weighted: 0.015365623869001865 : Allocated: 8967.197184 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5902e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0459, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 280: loss = 0.2062716782093048\n",
      "before loss.backward(): Allocated: 11192.85248 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.628736 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([140226, 3])\n",
      "CVT loss:  tensor(0.0039, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3934, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.4995979654486291e-05 weighted: 0.014995980076491833 : Allocated: 8965.997056 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5749e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0457, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 281: loss = 0.43919143080711365\n",
      "before loss.backward(): Allocated: 11193.949184 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.661056 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([140050, 3])\n",
      "CVT loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1880, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.4946137525839731e-05 weighted: 0.014946137554943562 : Allocated: 8966.918144 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5034e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0450, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 282: loss = 0.23305675387382507\n",
      "before loss.backward(): Allocated: 11192.613888 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.623104 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([140059, 3])\n",
      "CVT loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1508, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.4882848518027458e-05 weighted: 0.014882848598062992 : Allocated: 8965.955072 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.6020e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0460, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 283: loss = 0.19683995842933655\n",
      "before loss.backward(): Allocated: 11191.763968 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.65696 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139893, 3])\n",
      "CVT loss:  tensor(0.0066, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.6635, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.4916071449988522e-05 weighted: 0.01491607166826725 : Allocated: 8966.888448 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5421e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0454, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 284: loss = 0.7089487314224243\n",
      "before loss.backward(): Allocated: 11190.565376 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.618496 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139788, 3])\n",
      "CVT loss:  tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2669, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.4941004337742925e-05 weighted: 0.014941004104912281 : Allocated: 8965.791744 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5840e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0458, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 285: loss = 0.3127695918083191\n",
      "before loss.backward(): Allocated: 11188.122624 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.674368 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139737, 3])\n",
      "CVT loss:  tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2631, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.4961608030716889e-05 weighted: 0.0149616077542305 : Allocated: 8966.828032 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.6479e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0465, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 286: loss = 0.3095478117465973\n",
      "before loss.backward(): Allocated: 11188.530176 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.617984 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139803, 3])\n",
      "CVT loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1952, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.4979023035266437e-05 weighted: 0.014979023486375809 : Allocated: 8965.889536 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5280e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0453, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 287: loss = 0.24049079418182373\n",
      "before loss.backward(): Allocated: 11188.411392 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.641088 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139815, 3])\n",
      "CVT loss:  tensor(0.0066, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.6573, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.4940275832486805e-05 weighted: 0.014940275810658932 : Allocated: 8967.153664 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5320e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0453, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 288: loss = 0.702665388584137\n",
      "before loss.backward(): Allocated: 11189.82912 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.625664 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139945, 3])\n",
      "CVT loss:  tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.0597, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.4902609109412879e-05 weighted: 0.014902609400451183 : Allocated: 8965.928448 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.6392e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0464, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 289: loss = 0.1061324030160904\n",
      "before loss.backward(): Allocated: 11190.273024 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.645696 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139989, 3])\n",
      "CVT loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1077, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.4940259461582173e-05 weighted: 0.014940259046852589 : Allocated: 8967.186944 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.4914e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0449, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 290: loss = 0.15256395936012268\n",
      "before loss.backward(): Allocated: 11192.095232 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.628736 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139827, 3])\n",
      "CVT loss:  tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2109, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5018064914329443e-05 weighted: 0.01501806452870369 : Allocated: 8965.803008 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.4603e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0446, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 291: loss = 0.25552254915237427\n",
      "before loss.backward(): Allocated: 11188.634112 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.675904 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139788, 3])\n",
      "CVT loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1389, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.4879748050589114e-05 weighted: 0.014879748225212097 : Allocated: 8966.834688 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5366e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0454, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 292: loss = 0.18422949314117432\n",
      "before loss.backward(): Allocated: 11189.191168 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.616448 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139699, 3])\n",
      "CVT loss:  tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3398, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.4915924111846834e-05 weighted: 0.01491592451930046 : Allocated: 8965.7728 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5710e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0457, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 293: loss = 0.38554149866104126\n",
      "before loss.backward(): Allocated: 11186.959872 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.673344 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139756, 3])\n",
      "CVT loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.0837, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.4875357919663657e-05 weighted: 0.01487535797059536 : Allocated: 8967.190528 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5447e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0454, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 294: loss = 0.12913689017295837\n",
      "before loss.backward(): Allocated: 11189.139456 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.705024 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139834, 3])\n",
      "CVT loss:  tensor(0.0039, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3900, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.4944893337087706e-05 weighted: 0.014944893307983875 : Allocated: 8966.162944 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5895e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0459, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 295: loss = 0.4359067976474762\n",
      "before loss.backward(): Allocated: 11189.430272 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.97696 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139747, 3])\n",
      "CVT loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1258, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.4934617865947075e-05 weighted: 0.014934618026018143 : Allocated: 8966.525952 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.4912e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0449, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 296: loss = 0.17075759172439575\n",
      "before loss.backward(): Allocated: 11188.673536 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.049664 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139636, 3])\n",
      "CVT loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1184, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.4960922271711752e-05 weighted: 0.014960922300815582 : Allocated: 8966.014976 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5042e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0450, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 297: loss = 0.1634906828403473\n",
      "before loss.backward(): Allocated: 11186.391552 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.928832 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139724, 3])\n",
      "CVT loss:  tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3090, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.506023090769304e-05 weighted: 0.01506023108959198 : Allocated: 8967.1808 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5211e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0452, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 298: loss = 0.3541761338710785\n",
      "before loss.backward(): Allocated: 11188.722688 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.708096 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139837, 3])\n",
      "CVT loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2048, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5019179045339115e-05 weighted: 0.015019179321825504 : Allocated: 8966.160896 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5570e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0456, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 299: loss = 0.25038808584213257\n",
      "before loss.backward(): Allocated: 11189.469184 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.972352 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139760, 3])\n",
      "CVT loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1626, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.497477205703035e-05 weighted: 0.014974771998822689 : Allocated: 8966.53056 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5084e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0451, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 300: loss = 0.20766206085681915\n",
      "before loss.backward(): Allocated: 11188.844544 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.051712 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139825, 3])\n",
      "CVT loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.0875, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.4976760212448426e-05 weighted: 0.014976760372519493 : Allocated: 8966.152192 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5299e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0453, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 301: loss = 0.13275334239006042\n",
      "before loss.backward(): Allocated: 11188.95616 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.8976 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139818, 3])\n",
      "CVT loss:  tensor(0.0045, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4534, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.4994215234764852e-05 weighted: 0.014994215220212936 : Allocated: 8966.617088 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.4742e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0447, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 302: loss = 0.4981456995010376\n",
      "before loss.backward(): Allocated: 11189.331456 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.370688 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139794, 3])\n",
      "CVT loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1317, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.8297788958298042e-05 weighted: 0.0282977893948555 : Allocated: 8966.150144 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(5.1128e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0511, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 303: loss = 0.1828363537788391\n",
      "before loss.backward(): Allocated: 11188.5568 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.898112 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139675, 3])\n",
      "CVT loss:  tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2414, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5019450074760243e-05 weighted: 0.015019450336694717 : Allocated: 8966.585856 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5252e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0453, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 304: loss = 0.2866136133670807\n",
      "before loss.backward(): Allocated: 11187.465728 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.364544 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139564, 3])\n",
      "CVT loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.0654, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5004365195636638e-05 weighted: 0.015004364773631096 : Allocated: 8965.997568 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5784e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0458, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 305: loss = 0.11114157736301422\n",
      "before loss.backward(): Allocated: 11185.45152 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.928832 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139521, 3])\n",
      "CVT loss:  tensor(0.0006, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.0600, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.4994782759458758e-05 weighted: 0.014994782395660877 : Allocated: 8966.518272 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.6871e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0469, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 306: loss = 0.10689158737659454\n",
      "before loss.backward(): Allocated: 11185.46176 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.364544 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139382, 3])\n",
      "CVT loss:  tensor(0.0033, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3291, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.499408062954899e-05 weighted: 0.014994080178439617 : Allocated: 8965.956096 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5245e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0452, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 307: loss = 0.374311625957489\n",
      "before loss.backward(): Allocated: 11183.071744 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.931904 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139327, 3])\n",
      "CVT loss:  tensor(0.0055, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.5510, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5615376469213516e-05 weighted: 0.015615376643836498 : Allocated: 8966.465024 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.6159e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0462, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 308: loss = 0.5971539616584778\n",
      "before loss.backward(): Allocated: 11182.879744 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.362496 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139371, 3])\n",
      "CVT loss:  tensor(0.0038, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3833, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5312831237679347e-05 weighted: 0.015312830917537212 : Allocated: 8966.041088 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5849e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0458, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 309: loss = 0.4291910231113434\n",
      "before loss.backward(): Allocated: 11183.016448 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.871488 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139402, 3])\n",
      "CVT loss:  tensor(0.0081, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.8126, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5075345800141804e-05 weighted: 0.015075345523655415 : Allocated: 8966.539264 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5817e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0458, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 310: loss = 0.8583930730819702\n",
      "before loss.backward(): Allocated: 11183.914496 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.372224 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139422, 3])\n",
      "CVT loss:  tensor(0.0041, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4097, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5071636880747974e-05 weighted: 0.015071636997163296 : Allocated: 8966.052352 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5695e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0457, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 311: loss = 0.455416738986969\n",
      "before loss.backward(): Allocated: 11183.682048 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.875584 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139611, 3])\n",
      "CVT loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.0777, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5053657989483327e-05 weighted: 0.015053657814860344 : Allocated: 8966.877184 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5395e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0454, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 312: loss = 0.12309373915195465\n",
      "before loss.backward(): Allocated: 11186.932224 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.376832 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139546, 3])\n",
      "CVT loss:  tensor(0.0035, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3522, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5050276488182135e-05 weighted: 0.015050276182591915 : Allocated: 8965.991936 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5356e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0454, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 313: loss = 0.3975444734096527\n",
      "before loss.backward(): Allocated: 11185.214976 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.92832 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139654, 3])\n",
      "CVT loss:  tensor(0.0063, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.6297, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5036977856652811e-05 weighted: 0.01503697782754898 : Allocated: 8967.171072 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5598e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0456, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 314: loss = 0.6752615571022034\n",
      "before loss.backward(): Allocated: 11187.821568 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.711168 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139356, 3])\n",
      "CVT loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1616, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.4994300727266818e-05 weighted: 0.014994300901889801 : Allocated: 8965.607424 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.6094e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0461, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 315: loss = 0.20773369073867798\n",
      "before loss.backward(): Allocated: 11182.747136 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.935488 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139364, 3])\n",
      "CVT loss:  tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2313, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.4974468285799958e-05 weighted: 0.014974468387663364 : Allocated: 8966.46656 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5175e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0452, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 316: loss = 0.2764267921447754\n",
      "before loss.backward(): Allocated: 11183.353856 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.29696 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139341, 3])\n",
      "CVT loss:  tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3086, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.497277662565466e-05 weighted: 0.014972776174545288 : Allocated: 8965.687296 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5255e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0453, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 317: loss = 0.3539036810398102\n",
      "before loss.backward(): Allocated: 11182.276096 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.671808 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139264, 3])\n",
      "CVT loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1887, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5023395462776534e-05 weighted: 0.015023395419120789 : Allocated: 8966.705664 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5595e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0456, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 318: loss = 0.23426000773906708\n",
      "before loss.backward(): Allocated: 11182.314496 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.622592 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139198, 3])\n",
      "CVT loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1259, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5084047845448367e-05 weighted: 0.015084047801792622 : Allocated: 8965.658112 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5622e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0456, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 319: loss = 0.17151060700416565\n",
      "before loss.backward(): Allocated: 11180.411392 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.671808 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139311, 3])\n",
      "CVT loss:  tensor(0.0065, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.6516, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5125702702789567e-05 weighted: 0.015125703066587448 : Allocated: 8967.112192 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5688e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0457, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 320: loss = 0.697272777557373\n",
      "before loss.backward(): Allocated: 11183.376896 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.72704 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139410, 3])\n",
      "CVT loss:  tensor(0.0059, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.5870, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5174749933066778e-05 weighted: 0.015174750238656998 : Allocated: 8966.063616 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5966e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0460, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 321: loss = 0.6329602003097534\n",
      "before loss.backward(): Allocated: 11183.912448 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.970816 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139482, 3])\n",
      "CVT loss:  tensor(0.0038, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3771, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.51802505570231e-05 weighted: 0.015180250629782677 : Allocated: 8967.094784 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5067e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0451, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 322: loss = 0.42214375734329224\n",
      "before loss.backward(): Allocated: 11185.862144 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.409088 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139676, 3])\n",
      "CVT loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.0979, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5179474758042488e-05 weighted: 0.015179474838078022 : Allocated: 8966.112256 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.4895e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0449, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 323: loss = 0.1427798569202423\n",
      "before loss.backward(): Allocated: 11187.367936 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.645696 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139374, 3])\n",
      "CVT loss:  tensor(0.0057, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.5660, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5208112017717212e-05 weighted: 0.015208112075924873 : Allocated: 8966.769152 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5811e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0458, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 324: loss = 0.6118371486663818\n",
      "before loss.backward(): Allocated: 11183.783936 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.367616 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139373, 3])\n",
      "CVT loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1431, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5159890608629212e-05 weighted: 0.015159890986979008 : Allocated: 8965.946368 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5708e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0457, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 325: loss = 0.18882349133491516\n",
      "before loss.backward(): Allocated: 11182.944768 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.927296 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139611, 3])\n",
      "CVT loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1775, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5199610970739741e-05 weighted: 0.015199610963463783 : Allocated: 8967.15776 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5079e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0451, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 326: loss = 0.22259841859340668\n",
      "before loss.backward(): Allocated: 11187.263488 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.716288 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139753, 3])\n",
      "CVT loss:  tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2523, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5633355360478163e-05 weighted: 0.01563335582613945 : Allocated: 8966.139904 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5636e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0456, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 327: loss = 0.2979544401168823\n",
      "before loss.backward(): Allocated: 11188.375552 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.970304 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139832, 3])\n",
      "CVT loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.0916, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5255027392413467e-05 weighted: 0.015255027450621128 : Allocated: 8967.159296 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5595e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0456, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 328: loss = 0.1371859610080719\n",
      "before loss.backward(): Allocated: 11190.403584 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.393216 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139776, 3])\n",
      "CVT loss:  tensor(0.0058, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.5797, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.521958620287478e-05 weighted: 0.015219585970044136 : Allocated: 8966.02368 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5686e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0457, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 329: loss = 0.62538743019104\n",
      "before loss.backward(): Allocated: 11188.544 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.993856 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139535, 3])\n",
      "CVT loss:  tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2173, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5213633560051676e-05 weighted: 0.015213633887469769 : Allocated: 8965.997568 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.6020e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0460, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 330: loss = 0.26333633065223694\n",
      "before loss.backward(): Allocated: 11185.433088 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.620608 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139493, 3])\n",
      "CVT loss:  tensor(0.0039, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3918, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5201456335489638e-05 weighted: 0.015201455913484097 : Allocated: 8965.226496 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5698e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0457, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 331: loss = 0.43748605251312256\n",
      "before loss.backward(): Allocated: 11183.766016 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.920128 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139566, 3])\n",
      "CVT loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1573, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5210309356916696e-05 weighted: 0.015210309065878391 : Allocated: 8966.160896 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5240e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0452, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 332: loss = 0.20258888602256775\n",
      "before loss.backward(): Allocated: 11185.639424 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.722944 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139579, 3])\n",
      "CVT loss:  tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3390, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5241678738675546e-05 weighted: 0.015241678804159164 : Allocated: 8965.721088 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.4989e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0450, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 333: loss = 0.383975625038147\n",
      "before loss.backward(): Allocated: 11185.726976 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.8848 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139494, 3])\n",
      "CVT loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1420, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.520732621429488e-05 weighted: 0.015207326039671898 : Allocated: 8967.164416 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5543e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0455, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 334: loss = 0.18750426173210144\n",
      "before loss.backward(): Allocated: 11185.71776 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.375296 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139514, 3])\n",
      "CVT loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1274, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.515003987151431e-05 weighted: 0.015150039456784725 : Allocated: 8967.0144 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5469e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0455, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 335: loss = 0.17285624146461487\n",
      "before loss.backward(): Allocated: 11186.762752 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.720384 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139703, 3])\n",
      "CVT loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1757, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5166422599577345e-05 weighted: 0.015166422352194786 : Allocated: 8966.1184 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.4808e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0448, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 336: loss = 0.2205415666103363\n",
      "before loss.backward(): Allocated: 11187.717632 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.652352 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139714, 3])\n",
      "CVT loss:  tensor(0.0065, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.6541, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5137734408199321e-05 weighted: 0.015137734822928905 : Allocated: 8968.044032 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5025e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0450, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 337: loss = 0.6990829706192017\n",
      "before loss.backward(): Allocated: 11189.457408 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.57344 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139579, 3])\n",
      "CVT loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1689, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5111761968000792e-05 weighted: 0.015111762098968029 : Allocated: 8966.735872 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5663e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0457, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 338: loss = 0.2145974338054657\n",
      "before loss.backward(): Allocated: 11187.319296 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.357888 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139516, 3])\n",
      "CVT loss:  tensor(0.0071, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.7126, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.511252503405558e-05 weighted: 0.015112524852156639 : Allocated: 8965.999616 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5378e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0454, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 339: loss = 0.7579858899116516\n",
      "before loss.backward(): Allocated: 11184.83456 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.672832 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139553, 3])\n",
      "CVT loss:  tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2060, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5146386431297287e-05 weighted: 0.015146386809647083 : Allocated: 8966.870016 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.6028e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0460, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 340: loss = 0.25202563405036926\n",
      "before loss.backward(): Allocated: 11186.225664 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.71424 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139572, 3])\n",
      "CVT loss:  tensor(0.0033, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3258, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.51680924318498e-05 weighted: 0.015168092213571072 : Allocated: 8965.746688 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5715e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0457, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 341: loss = 0.3715435266494751\n",
      "before loss.backward(): Allocated: 11185.662976 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.6288 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139465, 3])\n",
      "CVT loss:  tensor(0.0056, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.5590, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5150935723795556e-05 weighted: 0.015150935389101505 : Allocated: 8966.796288 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5296e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0453, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 342: loss = 0.6043179631233215\n",
      "before loss.backward(): Allocated: 11184.978432 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.303616 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139316, 3])\n",
      "CVT loss:  tensor(0.0045, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4492, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5146133591770194e-05 weighted: 0.015146133489906788 : Allocated: 8965.679616 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.6112e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0461, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 343: loss = 0.4953581690788269\n",
      "before loss.backward(): Allocated: 11181.94944 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.67488 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139115, 3])\n",
      "CVT loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.0840, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5151166735449806e-05 weighted: 0.01515116635710001 : Allocated: 8966.669312 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.6376e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0464, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 344: loss = 0.13041749596595764\n",
      "before loss.backward(): Allocated: 11180.374016 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.615424 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139148, 3])\n",
      "CVT loss:  tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3416, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5180576156126335e-05 weighted: 0.015180576592683792 : Allocated: 8965.720576 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5150e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0451, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 345: loss = 0.3867694139480591\n",
      "before loss.backward(): Allocated: 11179.849728 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.604736 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139250, 3])\n",
      "CVT loss:  tensor(0.0048, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4793, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.516267002443783e-05 weighted: 0.01516267005354166 : Allocated: 8967.05536 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5249e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0452, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 346: loss = 0.5245763063430786\n",
      "before loss.backward(): Allocated: 11182.486528 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.631296 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139075, 3])\n",
      "CVT loss:  tensor(0.0005, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.0475, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5133033230085857e-05 weighted: 0.015133033506572247 : Allocated: 8965.62688 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.6127e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0461, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 347: loss = 0.09365136921405792\n",
      "before loss.backward(): Allocated: 11178.802176 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.675392 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139307, 3])\n",
      "CVT loss:  tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2770, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.1574158381554298e-05 weighted: 0.02157415822148323 : Allocated: 8967.106048 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.7934e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0479, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 348: loss = 0.3249113857746124\n",
      "before loss.backward(): Allocated: 11183.325184 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.723968 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139111, 3])\n",
      "CVT loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.0783, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5158395399339497e-05 weighted: 0.015158395282924175 : Allocated: 8965.545984 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.4866e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0449, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 349: loss = 0.12313204258680344\n",
      "before loss.backward(): Allocated: 11179.557376 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.929344 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139247, 3])\n",
      "CVT loss:  tensor(0.0036, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3629, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5187441022135317e-05 weighted: 0.015187441371381283 : Allocated: 8966.733312 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5454e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0455, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 350: loss = 0.40838879346847534\n",
      "before loss.backward(): Allocated: 11182.125568 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.305152 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139234, 3])\n",
      "CVT loss:  tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3120, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5638528566341847e-05 weighted: 0.015638528391718864 : Allocated: 8965.66528 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.6269e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0463, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 351: loss = 0.35830917954444885\n",
      "before loss.backward(): Allocated: 11180.87936 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.670272 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139216, 3])\n",
      "CVT loss:  tensor(0.0036, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3639, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5252207958837971e-05 weighted: 0.015252208337187767 : Allocated: 8966.691328 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5394e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0454, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 352: loss = 0.40931159257888794\n",
      "before loss.backward(): Allocated: 11181.68832 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.625664 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139098, 3])\n",
      "CVT loss:  tensor(0.0051, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.5137, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5254227946570609e-05 weighted: 0.015254228375852108 : Allocated: 8965.630464 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5641e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0456, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 353: loss = 0.5593639016151428\n",
      "before loss.backward(): Allocated: 11179.099648 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.673856 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139046, 3])\n",
      "CVT loss:  tensor(0.0080, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.8026, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5230642020469531e-05 weighted: 0.015230641700327396 : Allocated: 8966.647296 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.6725e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0467, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 354: loss = 0.8493272662162781\n",
      "before loss.backward(): Allocated: 11179.472384 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.621568 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([138994, 3])\n",
      "CVT loss:  tensor(0.0044, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4391, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5239520507748239e-05 weighted: 0.01523952092975378 : Allocated: 8965.612032 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5895e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0459, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 355: loss = 0.4850254952907562\n",
      "before loss.backward(): Allocated: 11177.744384 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.671296 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([138975, 3])\n",
      "CVT loss:  tensor(0.0037, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3709, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5261019143508747e-05 weighted: 0.015261019580066204 : Allocated: 8966.631936 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5176e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0452, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 356: loss = 0.4160308837890625\n",
      "before loss.backward(): Allocated: 11178.547712 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.625664 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([138939, 3])\n",
      "CVT loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1504, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5236216313496698e-05 weighted: 0.015236216597259045 : Allocated: 8965.59872 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5832e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0458, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 357: loss = 0.1962091624736786\n",
      "before loss.backward(): Allocated: 11177.02656 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.670272 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([138750, 3])\n",
      "CVT loss:  tensor(0.0042, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4188, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5177580280578695e-05 weighted: 0.015177580527961254 : Allocated: 8966.584832 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.6243e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0462, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 358: loss = 0.46500471234321594\n",
      "before loss.backward(): Allocated: 11175.62368 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.620544 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([138943, 3])\n",
      "CVT loss:  tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2850, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5140578398131765e-05 weighted: 0.015140578150749207 : Allocated: 8965.669376 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.6151e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0462, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 359: loss = 0.33112749457359314\n",
      "before loss.backward(): Allocated: 11177.177088 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.586816 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139066, 3])\n",
      "CVT loss:  tensor(0.0055, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.5522, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5138384696911089e-05 weighted: 0.015138384886085987 : Allocated: 8967.035904 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5343e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0453, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 360: loss = 0.5975613594055176\n",
      "before loss.backward(): Allocated: 11180.115968 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.637952 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139055, 3])\n",
      "CVT loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.0767, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5160511793510523e-05 weighted: 0.015160512179136276 : Allocated: 8965.62176 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.6099e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0461, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 361: loss = 0.12277325987815857\n",
      "before loss.backward(): Allocated: 11178.539008 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.670784 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139027, 3])\n",
      "CVT loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1064, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.517113469162723e-05 weighted: 0.01517113484442234 : Allocated: 8966.64576 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5111e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0451, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 362: loss = 0.15150919556617737\n",
      "before loss.backward(): Allocated: 11179.22816 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.626176 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139033, 3])\n",
      "CVT loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1915, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.53912166954251e-05 weighted: 0.025391217321157455 : Allocated: 8965.694976 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.9266e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0493, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 363: loss = 0.24075040221214294\n",
      "before loss.backward(): Allocated: 11178.330112 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.597568 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139022, 3])\n",
      "CVT loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1068, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.439302988932468e-05 weighted: 0.024393029510974884 : Allocated: 8966.715904 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.8613e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0486, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 364: loss = 0.15538102388381958\n",
      "before loss.backward(): Allocated: 11179.21024 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.6272 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([138804, 3])\n",
      "CVT loss:  tensor(0.0054, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.5432, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5135956346057355e-05 weighted: 0.01513595599681139 : Allocated: 8965.563392 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5578e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0456, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 365: loss = 0.5888003706932068\n",
      "before loss.backward(): Allocated: 11175.26016 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.676928 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139018, 3])\n",
      "CVT loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1920, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5175821317825466e-05 weighted: 0.015175821259617805 : Allocated: 8967.048704 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.6270e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0463, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 366: loss = 0.23828306794166565\n",
      "before loss.backward(): Allocated: 11179.57376 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.739328 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([138933, 3])\n",
      "CVT loss:  tensor(0.0045, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4487, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5214027371257544e-05 weighted: 0.015214027836918831 : Allocated: 8965.484032 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.6683e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0467, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 367: loss = 0.4953696131706238\n",
      "before loss.backward(): Allocated: 11177.227776 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.923712 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139049, 3])\n",
      "CVT loss:  tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2349, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5277120837708935e-05 weighted: 0.015277121216058731 : Allocated: 8966.695936 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.4666e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0447, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 368: loss = 0.27953147888183594\n",
      "before loss.backward(): Allocated: 11179.559424 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.30976 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([138697, 3])\n",
      "CVT loss:  tensor(0.0014, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1376, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.540494486107491e-05 weighted: 0.015404945239424706 : Allocated: 8965.53984 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5488e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0455, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 369: loss = 0.18310868740081787\n",
      "before loss.backward(): Allocated: 11173.863424 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.682048 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([138837, 3])\n",
      "CVT loss:  tensor(0.0046, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4584, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.889531995402649e-05 weighted: 0.01889532059431076 : Allocated: 8967.012864 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.6880e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0469, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 370: loss = 0.5053269863128662\n",
      "before loss.backward(): Allocated: 11177.21856 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.743936 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([138768, 3])\n",
      "CVT loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1726, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5196670574368909e-05 weighted: 0.015196670778095722 : Allocated: 8965.432832 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5429e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0454, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 371: loss = 0.2180100381374359\n",
      "before loss.backward(): Allocated: 11175.068672 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.922176 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([138818, 3])\n",
      "CVT loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1324, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.1022513465140946e-05 weighted: 0.021022513508796692 : Allocated: 8966.637568 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(5.0774e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0508, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 372: loss = 0.18319423496723175\n",
      "before loss.backward(): Allocated: 11176.548864 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.308736 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([138595, 3])\n",
      "CVT loss:  tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2641, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5260633517755195e-05 weighted: 0.015260633081197739 : Allocated: 8965.510656 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.7404e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0474, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 373: loss = 0.3115423321723938\n",
      "before loss.backward(): Allocated: 11172.522496 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.676928 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([138657, 3])\n",
      "CVT loss:  tensor(0.0065, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.6483, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.539317236165516e-05 weighted: 0.015393172390758991 : Allocated: 8966.982656 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.6072e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0461, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 374: loss = 0.6944013833999634\n",
      "before loss.backward(): Allocated: 11174.8864 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.76032 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139046, 3])\n",
      "CVT loss:  tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2158, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 4.1760031308513135e-05 weighted: 0.04176003113389015 : Allocated: 8965.960704 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(5.9250e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0592, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 375: loss = 0.2750912010669708\n",
      "before loss.backward(): Allocated: 11179.170816 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.939584 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139176, 3])\n",
      "CVT loss:  tensor(0.0032, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3175, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 3.9340851799352095e-05 weighted: 0.039340849965810776 : Allocated: 8967.07584 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(5.6669e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0567, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 376: loss = 0.374129056930542\n",
      "before loss.backward(): Allocated: 11181.935104 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.4352 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([139057, 3])\n",
      "CVT loss:  tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2104, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 3.573916183086112e-05 weighted: 0.03573916107416153 : Allocated: 8965.832192 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(5.5469e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0555, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 377: loss = 0.2658250331878662\n",
      "before loss.backward(): Allocated: 11179.159552 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.993344 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([138840, 3])\n",
      "CVT loss:  tensor(0.0081, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.8101, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 3.1911513360682875e-05 weighted: 0.031911514699459076 : Allocated: 8965.799424 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(5.5134e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0551, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 378: loss = 0.8652713298797607\n",
      "before loss.backward(): Allocated: 11175.98976 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.572992 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([138874, 3])\n",
      "CVT loss:  tensor(0.0035, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3527, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.782289811875671e-05 weighted: 0.02782289870083332 : Allocated: 8965.409792 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(5.4275e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0543, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 379: loss = 0.40693822503089905\n",
      "before loss.backward(): Allocated: 11176.000512 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.90784 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([138626, 3])\n",
      "CVT loss:  tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3093, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.816152871469967e-05 weighted: 0.018161527812480927 : Allocated: 8965.931008 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(5.0295e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0503, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 380: loss = 0.35955920815467834\n",
      "before loss.backward(): Allocated: 11173.67552 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.761344 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([138591, 3])\n",
      "CVT loss:  tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3353, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.557226278237067e-05 weighted: 0.015572262927889824 : Allocated: 8965.359104 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(5.1144e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0511, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 381: loss = 0.3864240348339081\n",
      "before loss.backward(): Allocated: 11172.723712 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.235008 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([138564, 3])\n",
      "CVT loss:  tensor(0.0042, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4190, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.812935781548731e-05 weighted: 0.02812935784459114 : Allocated: 8965.105152 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(5.6005e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0560, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 382: loss = 0.47496530413627625\n",
      "before loss.backward(): Allocated: 11171.71712 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.9872 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([138566, 3])\n",
      "CVT loss:  tensor(0.0050, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4978, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.447643782943487e-05 weighted: 0.024476438760757446 : Allocated: 8966.19008 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(5.3824e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0538, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 383: loss = 0.5516126155853271\n",
      "before loss.backward(): Allocated: 11173.244416 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.483328 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([138566, 3])\n",
      "CVT loss:  tensor(0.0046, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4608, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.3736578441457823e-05 weighted: 0.023736579343676567 : Allocated: 8966.537216 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(5.3585e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0536, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 384: loss = 0.5144184827804565\n",
      "before loss.backward(): Allocated: 11173.227008 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.881728 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([138697, 3])\n",
      "CVT loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.0957, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5497415006393567e-05 weighted: 0.015497415326535702 : Allocated: 8966.959104 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(5.1916e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0519, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 385: loss = 0.1476234644651413\n",
      "before loss.backward(): Allocated: 11175.32416 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.632832 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([138761, 3])\n",
      "CVT loss:  tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2765, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5442843505297787e-05 weighted: 0.015442843548953533 : Allocated: 8965.609472 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(5.1979e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0520, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 386: loss = 0.3284527659416199\n",
      "before loss.backward(): Allocated: 11174.79424 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.579648 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([138568, 3])\n",
      "CVT loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.0914, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5500612789765e-05 weighted: 0.015500612556934357 : Allocated: 8966.618112 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(5.1982e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0520, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 387: loss = 0.14340677857398987\n",
      "before loss.backward(): Allocated: 11173.28384 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.626688 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([138212, 3])\n",
      "CVT loss:  tensor(0.0052, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.5209, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5559404346277006e-05 weighted: 0.015559404157102108 : Allocated: 8965.422592 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(5.1488e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0515, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 388: loss = 0.5723661780357361\n",
      "before loss.backward(): Allocated: 11167.518208 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.681024 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([138133, 3])\n",
      "CVT loss:  tensor(0.0049, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4929, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5558127415715717e-05 weighted: 0.01555812731385231 : Allocated: 8966.404608 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(5.1957e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0520, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 389: loss = 0.5449029803276062\n",
      "before loss.backward(): Allocated: 11167.56224 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.617472 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([138143, 3])\n",
      "CVT loss:  tensor(0.0046, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4615, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5464702300960198e-05 weighted: 0.015464702621102333 : Allocated: 8965.453824 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(5.2197e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0522, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 390: loss = 0.5137147903442383\n",
      "before loss.backward(): Allocated: 11166.66112 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.545856 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([137952, 3])\n",
      "CVT loss:  tensor(0.0033, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3264, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.545703344163485e-05 weighted: 0.015457033179700375 : Allocated: 8966.496256 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(5.1172e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0512, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 391: loss = 0.37758520245552063\n",
      "before loss.backward(): Allocated: 11165.251584 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.626688 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([138061, 3])\n",
      "CVT loss:  tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2733, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5408677427330986e-05 weighted: 0.01540867704898119 : Allocated: 8965.430272 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(5.3457e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0535, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 392: loss = 0.326728880405426\n",
      "before loss.backward(): Allocated: 11165.666816 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.537664 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([138324, 3])\n",
      "CVT loss:  tensor(0.0033, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3270, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5427611288032494e-05 weighted: 0.015427610836923122 : Allocated: 8966.911488 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(5.2972e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0530, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 393: loss = 0.37993329763412476\n",
      "before loss.backward(): Allocated: 11170.509824 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.64512 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([138186, 3])\n",
      "CVT loss:  tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2392, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5396146409329958e-05 weighted: 0.015396146103739738 : Allocated: 8965.40672 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(5.2504e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0525, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 394: loss = 0.2917341887950897\n",
      "before loss.backward(): Allocated: 11167.166464 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.675392 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([138131, 3])\n",
      "CVT loss:  tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2765, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5488847566302866e-05 weighted: 0.01548884715884924 : Allocated: 8966.401536 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(5.1722e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0517, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 395: loss = 0.32823488116264343\n",
      "before loss.backward(): Allocated: 11167.535104 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.627712 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([137570, 3])\n",
      "CVT loss:  tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2065, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5496068954234943e-05 weighted: 0.015496068634092808 : Allocated: 8965.273088 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(5.2110e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0521, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 396: loss = 0.25863122940063477\n",
      "before loss.backward(): Allocated: 11159.128064 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.687168 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([137662, 3])\n",
      "CVT loss:  tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2860, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5443387383129448e-05 weighted: 0.015443387441337109 : Allocated: 8966.792704 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(5.1446e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0514, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 397: loss = 0.33746352791786194\n",
      "before loss.backward(): Allocated: 11161.977344 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.802816 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([137798, 3])\n",
      "CVT loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1173, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.537169373477809e-05 weighted: 0.015371693298220634 : Allocated: 8965.661696 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(5.1735e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0517, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 398: loss = 0.169038787484169\n",
      "before loss.backward(): Allocated: 11162.906624 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.950848 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([137947, 3])\n",
      "CVT loss:  tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2505, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5328485460486263e-05 weighted: 0.015328485518693924 : Allocated: 8966.833664 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(5.1304e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0513, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 399: loss = 0.3018175959587097\n",
      "before loss.backward(): Allocated: 11165.983232 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.49408 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([137800, 3])\n",
      "CVT loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1687, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5281639207387343e-05 weighted: 0.01528163906186819 : Allocated: 8965.467136 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(5.2805e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0528, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 400: loss = 0.22150176763534546\n",
      "before loss.backward(): Allocated: 11162.7264 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.99232 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([137778, 3])\n",
      "CVT loss:  tensor(0.0035, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3482, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.536649142508395e-05 weighted: 0.015366491861641407 : Allocated: 8965.467648 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(5.1804e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0518, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 401: loss = 0.40005040168762207\n",
      "before loss.backward(): Allocated: 11162.08896 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.494144 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([137769, 3])\n",
      "CVT loss:  tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3064, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5370202163467184e-05 weighted: 0.015370202250778675 : Allocated: 8964.3648 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(5.2403e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0524, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 402: loss = 0.3587626814842224\n",
      "before loss.backward(): Allocated: 11160.770048 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.602688 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([137539, 3])\n",
      "CVT loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1675, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5318775695050135e-05 weighted: 0.015318775549530983 : Allocated: 8965.95712 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(5.1971e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0520, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 403: loss = 0.21944718062877655\n",
      "before loss.backward(): Allocated: 11159.512064 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.52736 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([137524, 3])\n",
      "CVT loss:  tensor(0.0035, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3531, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.527005406387616e-05 weighted: 0.015270054340362549 : Allocated: 8965.349888 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(5.1452e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0515, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 404: loss = 0.4045127332210541\n",
      "before loss.backward(): Allocated: 11158.768128 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.584704 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([137352, 3])\n",
      "CVT loss:  tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2194, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.530752888356801e-05 weighted: 0.015307528898119926 : Allocated: 8964.422144 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(5.1867e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0519, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 405: loss = 0.27123090624809265\n",
      "before loss.backward(): Allocated: 11155.955712 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.702016 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([137343, 3])\n",
      "CVT loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1691, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5616304153809324e-05 weighted: 0.015616304241120815 : Allocated: 8965.298176 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(5.2964e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0530, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 406: loss = 0.22209621965885162\n",
      "before loss.backward(): Allocated: 11156.401664 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.5888 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([137742, 3])\n",
      "CVT loss:  tensor(0.0072, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.7175, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.533723116153851e-05 weighted: 0.015337231568992138 : Allocated: 8964.494848 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(5.0807e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0508, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 407: loss = 0.7683161497116089\n",
      "before loss.backward(): Allocated: 11160.553984 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.90272 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([137721, 3])\n",
      "CVT loss:  tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2142, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5349027307820506e-05 weighted: 0.015349027700722218 : Allocated: 8964.220928 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(5.1636e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0516, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 408: loss = 0.2658567428588867\n",
      "before loss.backward(): Allocated: 11160.11264 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.52128 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([137539, 3])\n",
      "CVT loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.0933, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5363324564532377e-05 weighted: 0.01536332443356514 : Allocated: 8965.538816 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(5.2517e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0525, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 409: loss = 0.14582571387290955\n",
      "before loss.backward(): Allocated: 11158.991872 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.014848 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([137660, 3])\n",
      "CVT loss:  tensor(0.0058, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.5779, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.528526991023682e-05 weighted: 0.015285270288586617 : Allocated: 8966.794752 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(5.1155e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0512, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 410: loss = 0.629036545753479\n",
      "before loss.backward(): Allocated: 11161.9584 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.817664 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([137559, 3])\n",
      "CVT loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1682, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.528194479760714e-05 weighted: 0.015281944535672665 : Allocated: 8965.075968 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(5.0945e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0509, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 411: loss = 0.2191849946975708\n",
      "before loss.backward(): Allocated: 11159.257088 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.911936 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([137597, 3])\n",
      "CVT loss:  tensor(0.0038, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3833, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5317578800022602e-05 weighted: 0.015317578800022602 : Allocated: 8966.356992 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(5.0628e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0506, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 412: loss = 0.4338906705379486\n",
      "before loss.backward(): Allocated: 11160.664576 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.316928 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([137872, 3])\n",
      "CVT loss:  tensor(0.0052, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.5235, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5352503396570683e-05 weighted: 0.015352503396570683 : Allocated: 8965.365248 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(5.1507e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0515, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 413: loss = 0.5749627947807312\n",
      "before loss.backward(): Allocated: 11163.190784 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.520256 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([137849, 3])\n",
      "CVT loss:  tensor(0.0079, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.7920, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5400008123833686e-05 weighted: 0.015400008298456669 : Allocated: 8966.47168 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(5.1222e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0512, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 414: loss = 0.8432679176330566\n",
      "before loss.backward(): Allocated: 11163.901952 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.646656 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([137823, 3])\n",
      "CVT loss:  tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3372, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.538038850412704e-05 weighted: 0.015380388125777245 : Allocated: 8965.319168 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(5.0831e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0508, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 415: loss = 0.388016939163208\n",
      "before loss.backward(): Allocated: 11162.416128 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.671296 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([137884, 3])\n",
      "CVT loss:  tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3113, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.537016942165792e-05 weighted: 0.015370169654488564 : Allocated: 8966.841856 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(5.1175e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0512, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 416: loss = 0.36250290274620056\n",
      "before loss.backward(): Allocated: 11164.867584 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.814592 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([138182, 3])\n",
      "CVT loss:  tensor(0.0038, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3753, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.3824650270398706e-05 weighted: 0.023824650794267654 : Allocated: 8965.735424 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(5.3442e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0534, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 417: loss = 0.42873555421829224\n",
      "before loss.backward(): Allocated: 11167.899136 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.942144 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([137910, 3])\n",
      "CVT loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.0884, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.5170520530082285e-05 weighted: 0.025170519948005676 : Allocated: 8966.085632 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(5.3146e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0531, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 418: loss = 0.1414996236562729\n",
      "before loss.backward(): Allocated: 11164.393984 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.064 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([137961, 3])\n",
      "CVT loss:  tensor(0.0036, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3550, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.619462065922562e-05 weighted: 0.02619462087750435 : Allocated: 8965.645312 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(5.3902e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0539, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 419: loss = 0.40893644094467163\n",
      "before loss.backward(): Allocated: 11164.604928 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.789056 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([137834, 3])\n",
      "CVT loss:  tensor(0.0040, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3964, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5369449101854116e-05 weighted: 0.015369448810815811 : Allocated: 8966.202368 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(5.0494e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0505, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 420: loss = 0.4469321668148041\n",
      "before loss.backward(): Allocated: 11163.441664 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.377856 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([137523, 3])\n",
      "CVT loss:  tensor(0.0097, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.9668, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5332252587541007e-05 weighted: 0.015332252718508244 : Allocated: 8965.499392 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.9716e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0497, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 421: loss = 1.0164903402328491\n",
      "before loss.backward(): Allocated: 11158.749184 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.937024 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([137659, 3])\n",
      "CVT loss:  tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2776, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.2606574930250645e-05 weighted: 0.02260657399892807 : Allocated: 8966.78912 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(5.2663e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0527, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 422: loss = 0.3302423655986786\n",
      "before loss.backward(): Allocated: 11161.941504 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.815104 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([137511, 3])\n",
      "CVT loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1983, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.527524000266567e-05 weighted: 0.015275239944458008 : Allocated: 8965.060608 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.9869e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0499, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 423: loss = 0.24814307689666748\n",
      "before loss.backward(): Allocated: 11158.62784 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.913984 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([137391, 3])\n",
      "CVT loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.0778, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5289391740225255e-05 weighted: 0.01528939139097929 : Allocated: 8965.971456 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.9485e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0495, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 424: loss = 0.12732245028018951\n",
      "before loss.backward(): Allocated: 11157.647872 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.311808 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([137379, 3])\n",
      "CVT loss:  tensor(0.0005, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.0530, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5381567209260538e-05 weighted: 0.015381567180156708 : Allocated: 8965.216256 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.9017e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0490, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 425: loss = 0.10203707218170166\n",
      "before loss.backward(): Allocated: 11156.614144 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.670784 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([137285, 3])\n",
      "CVT loss:  tensor(0.0117, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(1.1720, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.538797005196102e-05 weighted: 0.01538797002285719 : Allocated: 8966.183424 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(5.0038e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 426: loss = 1.222074031829834\n",
      "before loss.backward(): Allocated: 11156.505088 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.636416 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([137198, 3])\n",
      "CVT loss:  tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2270, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5340259778895415e-05 weighted: 0.015340260230004787 : Allocated: 8965.174784 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(5.0018e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 427: loss = 0.2770135700702667\n",
      "before loss.backward(): Allocated: 11154.247168 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.673856 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([137173, 3])\n",
      "CVT loss:  tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2849, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.528583379695192e-05 weighted: 0.015285833738744259 : Allocated: 8966.145024 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.8771e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0488, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 428: loss = 0.3336459994316101\n",
      "before loss.backward(): Allocated: 11155.035648 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.636416 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([137093, 3])\n",
      "CVT loss:  tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2298, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.538209653517697e-05 weighted: 0.01538209617137909 : Allocated: 8965.144576 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.8796e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0488, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 429: loss = 0.2786237895488739\n",
      "before loss.backward(): Allocated: 11152.871424 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.673344 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([137233, 3])\n",
      "CVT loss:  tensor(0.0048, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4766, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.541582605568692e-05 weighted: 0.015415825881063938 : Allocated: 8966.71488 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.8937e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0489, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 430: loss = 0.5255266427993774\n",
      "before loss.backward(): Allocated: 11156.42368 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.84736 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([137302, 3])\n",
      "CVT loss:  tensor(0.0051, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.5054, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5533076293650083e-05 weighted: 0.015533076599240303 : Allocated: 8965.522432 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.9475e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0495, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 431: loss = 0.5548474788665771\n",
      "before loss.backward(): Allocated: 11156.427776 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.952896 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([137240, 3])\n",
      "CVT loss:  tensor(0.0041, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4088, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5458210327778943e-05 weighted: 0.015458210371434689 : Allocated: 8965.883392 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.9110e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0491, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 432: loss = 0.4578947424888611\n",
      "before loss.backward(): Allocated: 11155.632128 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.067072 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([137288, 3])\n",
      "CVT loss:  tensor(0.0070, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.6978, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5482988601434045e-05 weighted: 0.015482988208532333 : Allocated: 8965.456896 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.8058e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0481, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 433: loss = 0.7458959817886353\n",
      "before loss.backward(): Allocated: 11155.818496 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.748608 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([137449, 3])\n",
      "CVT loss:  tensor(0.0062, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.6177, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5579651517327875e-05 weighted: 0.015579651109874249 : Allocated: 8966.477824 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.8211e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0482, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 434: loss = 0.6659592986106873\n",
      "before loss.backward(): Allocated: 11158.89664 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.392704 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([137048, 3])\n",
      "CVT loss:  tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2786, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.546947896713391e-05 weighted: 0.015469479374587536 : Allocated: 8965.386752 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.8675e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0487, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 435: loss = 0.3272653818130493\n",
      "before loss.backward(): Allocated: 11152.5376 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.939072 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([137096, 3])\n",
      "CVT loss:  tensor(0.0039, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3864, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 3.1820760341361165e-05 weighted: 0.03182075917720795 : Allocated: 8966.68928 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(5.3973e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0540, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 436: loss = 0.44038456678390503\n",
      "before loss.backward(): Allocated: 11154.642944 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.83968 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([137149, 3])\n",
      "CVT loss:  tensor(0.0052, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.5201, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 3.3043430448742583e-05 weighted: 0.033043429255485535 : Allocated: 8965.495296 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(5.5342e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0553, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 437: loss = 0.5754058957099915\n",
      "before loss.backward(): Allocated: 11154.441728 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.952896 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([137381, 3])\n",
      "CVT loss:  tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2079, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 4.2976458644261584e-05 weighted: 0.04297645762562752 : Allocated: 8966.733312 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(6.0836e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0608, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 438: loss = 0.26874732971191406\n",
      "before loss.backward(): Allocated: 11158.655488 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.51968 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([137109, 3])\n",
      "CVT loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1790, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.53770576819079e-05 weighted: 0.025377057492733 : Allocated: 8965.274624 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(5.1274e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0513, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 439: loss = 0.23024316132068634\n",
      "before loss.backward(): Allocated: 11153.696768 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.998464 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([136986, 3])\n",
      "CVT loss:  tensor(0.0005, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.0481, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.7683658117894083e-05 weighted: 0.02768365852534771 : Allocated: 8965.229568 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(5.0794e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0508, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 440: loss = 0.09891870617866516\n",
      "before loss.backward(): Allocated: 11151.730688 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.437312 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([136909, 3])\n",
      "CVT loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.0858, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.6939911549561657e-05 weighted: 0.026939911767840385 : Allocated: 8964.10368 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(5.0452e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0505, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 441: loss = 0.13623863458633423\n",
      "before loss.backward(): Allocated: 11149.466112 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.6032 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([136810, 3])\n",
      "CVT loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.0716, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.0721970940940082e-05 weighted: 0.02072197012603283 : Allocated: 8965.764608 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.8688e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0487, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 442: loss = 0.1202557310461998\n",
      "before loss.backward(): Allocated: 11150.00576 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.566784 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([136577, 3])\n",
      "CVT loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1151, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5326641005231068e-05 weighted: 0.01532664056867361 : Allocated: 8964.004352 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.8334e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0483, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 443: loss = 0.163414865732193\n",
      "before loss.backward(): Allocated: 11145.309184 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.529472 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([136613, 3])\n",
      "CVT loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1784, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5369088941952214e-05 weighted: 0.01536908932030201 : Allocated: 8964.137984 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.8127e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0481, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 444: loss = 0.2264842838048935\n",
      "before loss.backward(): Allocated: 11145.70496 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.898112 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([136564, 3])\n",
      "CVT loss:  tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2623, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5460267604794353e-05 weighted: 0.015460267663002014 : Allocated: 8963.761152 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.7258e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0473, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 445: loss = 0.3095186948776245\n",
      "before loss.backward(): Allocated: 11144.86784 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.453696 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([136547, 3])\n",
      "CVT loss:  tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2200, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.552495450596325e-05 weighted: 0.015524954535067081 : Allocated: 8965.31456 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.8126e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0481, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 446: loss = 0.2681417167186737\n",
      "before loss.backward(): Allocated: 11146.02752 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.036864 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([136373, 3])\n",
      "CVT loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1551, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5524406990152784e-05 weighted: 0.015524406917393208 : Allocated: 8965.94944 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.8800e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0488, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 447: loss = 0.20385858416557312\n",
      "before loss.backward(): Allocated: 11144.616448 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.638464 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([136553, 3])\n",
      "CVT loss:  tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2640, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 3.0386363505385816e-05 weighted: 0.030386364087462425 : Allocated: 8965.028864 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(5.1577e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0516, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 448: loss = 0.3155554234981537\n",
      "before loss.backward(): Allocated: 11145.818624 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.451648 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([136343, 3])\n",
      "CVT loss:  tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3404, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.546500607219059e-05 weighted: 0.015465006232261658 : Allocated: 8965.267968 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.7307e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0473, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 449: loss = 0.38772881031036377\n",
      "before loss.backward(): Allocated: 11143.372288 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.873984 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([136415, 3])\n",
      "CVT loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.0732, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5444828022737056e-05 weighted: 0.015444828197360039 : Allocated: 8964.7616 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.7886e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0479, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 450: loss = 0.12112528085708618\n",
      "before loss.backward(): Allocated: 11144.008192 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.45216 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([136666, 3])\n",
      "CVT loss:  tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3014, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.549573426018469e-05 weighted: 0.01549573428928852 : Allocated: 8964.10624 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.7861e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0479, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 451: loss = 0.3492633104324341\n",
      "before loss.backward(): Allocated: 11146.354688 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.849472 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([136865, 3])\n",
      "CVT loss:  tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2600, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.6711280952440575e-05 weighted: 0.02671128138899803 : Allocated: 8965.288448 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(5.2662e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0527, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 452: loss = 0.31263288855552673\n",
      "before loss.backward(): Allocated: 11150.244864 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.002048 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([136571, 3])\n",
      "CVT loss:  tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2150, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.5423240003874525e-05 weighted: 0.025423239916563034 : Allocated: 8965.351936 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(5.1344e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0513, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 453: loss = 0.26637890934944153\n",
      "before loss.backward(): Allocated: 11146.372096 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.03584 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([136636, 3])\n",
      "CVT loss:  tensor(0.0040, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4042, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.935070006060414e-05 weighted: 0.029350699856877327 : Allocated: 8965.185024 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(5.2221e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0522, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 454: loss = 0.4563913941383362\n",
      "before loss.backward(): Allocated: 11147.213312 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.45472 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([136617, 3])\n",
      "CVT loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1616, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.7656682505039498e-05 weighted: 0.027656681835651398 : Allocated: 8966.219264 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(5.0547e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0505, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 455: loss = 0.2121814787387848\n",
      "before loss.backward(): Allocated: 11147.832832 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.326656 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([136567, 3])\n",
      "CVT loss:  tensor(0.0066, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.6613, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.774067615973763e-05 weighted: 0.02774067595601082 : Allocated: 8965.023232 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(5.0279e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0503, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 456: loss = 0.7116196155548096\n",
      "before loss.backward(): Allocated: 11145.992704 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.671296 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([136403, 3])\n",
      "CVT loss:  tensor(0.0061, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.6135, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.547875399410259e-05 weighted: 0.015478754416108131 : Allocated: 8965.955584 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.7271e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0473, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 457: loss = 0.6607388257980347\n",
      "before loss.backward(): Allocated: 11145.005568 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.637952 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([136698, 3])\n",
      "CVT loss:  tensor(0.0054, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.5377, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5544814232271165e-05 weighted: 0.015544814057648182 : Allocated: 8965.05344 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.8000e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0480, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 458: loss = 0.5856578350067139\n",
      "before loss.backward(): Allocated: 11147.70432 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.453184 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([136502, 3])\n",
      "CVT loss:  tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2280, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5445964891114272e-05 weighted: 0.015445965342223644 : Allocated: 8965.302272 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.7549e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0475, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 459: loss = 0.2755904197692871\n",
      "before loss.backward(): Allocated: 11145.443328 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.8704 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([136404, 3])\n",
      "CVT loss:  tensor(0.0067, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.6696, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5456020264537074e-05 weighted: 0.015456019900739193 : Allocated: 8963.670016 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.6659e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0467, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 460: loss = 0.716295063495636\n",
      "before loss.backward(): Allocated: 11142.770176 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.269376 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([136363, 3])\n",
      "CVT loss:  tensor(0.0044, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4425, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.54702429426834e-05 weighted: 0.01547024305909872 : Allocated: 8963.871744 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.6831e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0468, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 461: loss = 0.4893198609352112\n",
      "before loss.backward(): Allocated: 11142.235136 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.484928 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([136156, 3])\n",
      "CVT loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1922, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.548995351186022e-05 weighted: 0.015489953570067883 : Allocated: 8963.921408 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.6863e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0469, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 462: loss = 0.23911283910274506\n",
      "before loss.backward(): Allocated: 11139.8144 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.223296 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([135989, 3])\n",
      "CVT loss:  tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2249, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5568150047329254e-05 weighted: 0.015568150207400322 : Allocated: 8964.207616 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.6872e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0469, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 463: loss = 0.2717824876308441\n",
      "before loss.backward(): Allocated: 11138.22976 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.471104 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([136215, 3])\n",
      "CVT loss:  tensor(0.0064, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.6369, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.557901305204723e-05 weighted: 0.015579013153910637 : Allocated: 8963.935744 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.7488e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0475, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 464: loss = 0.6843795776367188\n",
      "before loss.backward(): Allocated: 11140.58496 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.22176 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([136167, 3])\n",
      "CVT loss:  tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2232, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5525234630331397e-05 weighted: 0.01552523486316204 : Allocated: 8964.255744 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.7123e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0471, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 465: loss = 0.27030614018440247\n",
      "before loss.backward(): Allocated: 11140.55424 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.47776 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([136032, 3])\n",
      "CVT loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.0680, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.548424370412249e-05 weighted: 0.015484243631362915 : Allocated: 8963.8912 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.7466e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0475, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 466: loss = 0.11547288298606873\n",
      "before loss.backward(): Allocated: 11138.19904 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.22688 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([136189, 3])\n",
      "CVT loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1311, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5516727216891013e-05 weighted: 0.015516727231442928 : Allocated: 8966.265344 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.6519e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0465, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 467: loss = 0.17757979035377502\n",
      "before loss.backward(): Allocated: 11142.380544 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.109056 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([136201, 3])\n",
      "CVT loss:  tensor(0.0074, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.7376, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5671657820348628e-05 weighted: 0.015671657398343086 : Allocated: 8965.384704 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.8039e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0480, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 468: loss = 0.7856143712997437\n",
      "before loss.backward(): Allocated: 11142.567936 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.383488 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([136327, 3])\n",
      "CVT loss:  tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2234, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5653531590942293e-05 weighted: 0.01565353199839592 : Allocated: 8965.148672 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.6492e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0465, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 469: loss = 0.26986071467399597\n",
      "before loss.backward(): Allocated: 11143.230976 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.201792 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([136116, 3])\n",
      "CVT loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1030, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5611221897415817e-05 weighted: 0.015611222013831139 : Allocated: 8965.76 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.7093e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0471, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 470: loss = 0.15007853507995605\n",
      "before loss.backward(): Allocated: 11140.940288 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.18176 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([136164, 3])\n",
      "CVT loss:  tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2303, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5594301657984033e-05 weighted: 0.015594301745295525 : Allocated: 8963.662848 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.6720e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0467, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 471: loss = 0.27698081731796265\n",
      "before loss.backward(): Allocated: 11139.564544 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.1936 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([135968, 3])\n",
      "CVT loss:  tensor(0.0012, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1235, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.550560409668833e-05 weighted: 0.015505604445934296 : Allocated: 8964.099072 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.6265e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0463, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 472: loss = 0.16973884403705597\n",
      "before loss.backward(): Allocated: 11137.381888 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.463936 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([136190, 3])\n",
      "CVT loss:  tensor(0.0097, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.9664, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.554756090627052e-05 weighted: 0.015547560527920723 : Allocated: 8965.11488 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.7006e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0470, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 473: loss = 1.0133782625198364\n",
      "before loss.backward(): Allocated: 11141.44256 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.019968 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([136009, 3])\n",
      "CVT loss:  tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3132, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.548988075228408e-05 weighted: 0.015489880926907063 : Allocated: 8964.562432 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.7147e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0471, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 474: loss = 0.3603231608867645\n",
      "before loss.backward(): Allocated: 11138.370048 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.256064 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([135834, 3])\n",
      "CVT loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1994, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5478650311706588e-05 weighted: 0.015478650107979774 : Allocated: 8964.319744 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.7275e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0473, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 475: loss = 0.24669484794139862\n",
      "before loss.backward(): Allocated: 11135.881728 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.670784 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([135959, 3])\n",
      "CVT loss:  tensor(0.0035, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3531, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5505669580306858e-05 weighted: 0.015505669638514519 : Allocated: 8964.905472 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.6596e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0466, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 476: loss = 0.3997437059879303\n",
      "before loss.backward(): Allocated: 11138.282496 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.183808 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([135756, 3])\n",
      "CVT loss:  tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2289, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5485617041122168e-05 weighted: 0.015485617332160473 : Allocated: 8964.299264 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.6677e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0467, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 477: loss = 0.2755853533744812\n",
      "before loss.backward(): Allocated: 11134.858752 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.671296 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([135688, 3])\n",
      "CVT loss:  tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1348, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5502686437685043e-05 weighted: 0.015502686612308025 : Allocated: 8964.449792 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.6041e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0460, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 478: loss = 0.18079715967178345\n",
      "before loss.backward(): Allocated: 11134.36416 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.18944 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([135933, 3])\n",
      "CVT loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.0759, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.558870280859992e-05 weighted: 0.015588702633976936 : Allocated: 8964.6464 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.6160e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0462, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 479: loss = 0.12209110707044601\n",
      "before loss.backward(): Allocated: 11137.47456 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.433728 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([135857, 3])\n",
      "CVT loss:  tensor(0.0040, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3999, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.563977093610447e-05 weighted: 0.0156397707760334 : Allocated: 8964.136448 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.6236e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0462, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 480: loss = 0.4461342990398407\n",
      "before loss.backward(): Allocated: 11136.209408 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.219712 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([135703, 3])\n",
      "CVT loss:  tensor(0.0042, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4240, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.564898047945462e-05 weighted: 0.0156489796936512 : Allocated: 8964.309504 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.6492e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0465, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 481: loss = 0.4705401062965393\n",
      "before loss.backward(): Allocated: 11134.18752 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.655424 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([135728, 3])\n",
      "CVT loss:  tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2959, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5651054127374664e-05 weighted: 0.015651054680347443 : Allocated: 8963.554816 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.6826e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0468, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 482: loss = 0.34270066022872925\n",
      "before loss.backward(): Allocated: 11134.240256 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.474176 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([135480, 3])\n",
      "CVT loss:  tensor(0.0058, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.5805, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5603942301822826e-05 weighted: 0.01560394186526537 : Allocated: 8963.68128 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.6602e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0466, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 483: loss = 0.6271024942398071\n",
      "before loss.backward(): Allocated: 11130.962944 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.702016 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([135280, 3])\n",
      "CVT loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1115, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5708657883806154e-05 weighted: 0.01570865698158741 : Allocated: 8963.139584 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.7092e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0471, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 484: loss = 0.15863510966300964\n",
      "before loss.backward(): Allocated: 11128.076288 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.54432 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([135331, 3])\n",
      "CVT loss:  tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.0696, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5653311493224464e-05 weighted: 0.01565331220626831 : Allocated: 8964.215808 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.6935e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0469, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 485: loss = 0.11656730622053146\n",
      "before loss.backward(): Allocated: 11129.316864 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.75936 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([135283, 3])\n",
      "CVT loss:  tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2256, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.55801772052655e-05 weighted: 0.015580177307128906 : Allocated: 8963.957248 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.6066e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0461, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 486: loss = 0.27165478467941284\n",
      "before loss.backward(): Allocated: 11129.047552 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.204352 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([135211, 3])\n",
      "CVT loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1934, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5599574908264913e-05 weighted: 0.015599574893712997 : Allocated: 8963.86304 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5981e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0460, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 487: loss = 0.2393711507320404\n",
      "before loss.backward(): Allocated: 11127.423488 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.657984 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([135060, 3])\n",
      "CVT loss:  tensor(0.0097, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.9745, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5597443052683957e-05 weighted: 0.015597443096339703 : Allocated: 8963.11296 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5888e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0459, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 488: loss = 1.0203617811203003\n",
      "before loss.backward(): Allocated: 11125.248512 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.242752 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([135200, 3])\n",
      "CVT loss:  tensor(0.0056, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.5600, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5636987882317044e-05 weighted: 0.01563698798418045 : Allocated: 8963.875328 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.6402e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0464, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 489: loss = 0.6064135432243347\n",
      "before loss.backward(): Allocated: 11127.552512 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.140864 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([135264, 3])\n",
      "CVT loss:  tensor(0.0041, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4122, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5609406545991078e-05 weighted: 0.015609406866133213 : Allocated: 8965.270016 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.6132e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0461, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 490: loss = 0.45830413699150085\n",
      "before loss.backward(): Allocated: 11129.763328 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.909376 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([135414, 3])\n",
      "CVT loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2029, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.5612235074513592e-05 weighted: 0.01561223529279232 : Allocated: 8964.528128 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.6898e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0469, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 491: loss = 0.24981427192687988\n",
      "before loss.backward(): Allocated: 11130.692608 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.437312 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([135372, 3])\n",
      "CVT loss:  tensor(0.0101, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(1.0134, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.569356936670374e-05 weighted: 0.01569356955587864 : Allocated: 8963.981824 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.5573e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0456, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 492: loss = 1.0589667558670044\n",
      "before loss.backward(): Allocated: 11129.857024 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.209472 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([135461, 3])\n",
      "CVT loss:  tensor(0.0045, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4463, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.875961763493251e-05 weighted: 0.02875961735844612 : Allocated: 8964.566528 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(5.1183e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0512, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 493: loss = 0.497525155544281\n",
      "before loss.backward(): Allocated: 11131.336704 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.155712 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([135487, 3])\n",
      "CVT loss:  tensor(0.0057, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.5651, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 3.34224350808654e-05 weighted: 0.03342243656516075 : Allocated: 8964.305408 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(5.1772e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0518, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 494: loss = 0.6168657541275024\n",
      "before loss.backward(): Allocated: 11131.649024 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.21152 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([135445, 3])\n",
      "CVT loss:  tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2590, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 3.059476148337126e-05 weighted: 0.030594762414693832 : Allocated: 8964.245504 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(5.1110e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0511, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 495: loss = 0.31006890535354614\n",
      "before loss.backward(): Allocated: 11130.81088 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.654912 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([135386, 3])\n",
      "CVT loss:  tensor(0.0054, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.5443, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 3.0195718863978982e-05 weighted: 0.03019571863114834 : Allocated: 8963.230208 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(5.0387e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0504, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 496: loss = 0.5946512818336487\n",
      "before loss.backward(): Allocated: 11129.036288 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.26016 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([135667, 3])\n",
      "CVT loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2004, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.841976129275281e-05 weighted: 0.02841976098716259 : Allocated: 8964.601344 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(5.0054e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0501, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 497: loss = 0.2504500150680542\n",
      "before loss.backward(): Allocated: 11134.014464 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.750656 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([135206, 3])\n",
      "CVT loss:  tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2727, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 2.4906345061026514e-05 weighted: 0.024906344711780548 : Allocated: 8963.963392 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.8632e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0486, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 498: loss = 0.3213302791118622\n",
      "before loss.backward(): Allocated: 11128.054272 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.209472 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([135254, 3])\n",
      "CVT loss:  tensor(0.0051, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.5074, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.566325590829365e-05 weighted: 0.015663255006074905 : Allocated: 8964.177408 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.6214e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0462, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 499: loss = 0.5536395907402039\n",
      "before loss.backward(): Allocated: 11128.543744 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8911.141376 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "points torch.Size([135200, 3])\n",
      "CVT loss:  tensor(0.0010, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1009, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 1.566001446917653e-05 weighted: 0.015660014003515244 : Allocated: 8965.549568 MB, Reserved: 15506.341888 MB\n",
      "SDF loss:  tensor(4.6540e-05, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(0.0465, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 500: loss = 0.14740458130836487\n",
      "before loss.backward(): Allocated: 11128.969728 MB, Reserved: 15506.341888 MB\n",
      "After loss.backward(): Allocated: 8912.161792 MB, Reserved: 15506.341888 MB\n",
      "-----------------\n",
      "Saved to bunnyvoroloss_to_clip.npz\n",
      "Sites length:  33280\n",
      "min sites:  tensor(-1.3632, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "max sites:  tensor(1.0915, device='cuda:0', grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "site_file_path = f'{destination}{max_iter}_cvt_{lambda_cvt}_chamfer_{lambda_chamfer}_eikonal_{lambda_eikonal}.npy'\n",
    "#check if optimized sites file exists\n",
    "if not os.path.exists(site_file_path):\n",
    "    #import sites\n",
    "    print(\"Importing sites\")\n",
    "    sites = np.load(site_file_path)\n",
    "    sites = torch.from_numpy(sites).to(device).requires_grad_(True)\n",
    "else:\n",
    "    # import cProfile, pstats\n",
    "    # import time\n",
    "    # profiler = cProfile.Profile()\n",
    "    # profiler.enable()\n",
    "\n",
    "#     with torch.profiler.profile(activities=[\n",
    "#             torch.profiler.ProfilerActivity.CPU,\n",
    "#             torch.profiler.ProfilerActivity.CUDA,\n",
    "#         ],\n",
    "#         record_shapes=False,\n",
    "#         with_stack=True  # Captures function calls\n",
    "#     ) as prof:\n",
    "#         sites = autograd(sites, model, max_iter=max_iter, upsampling=0, lambda_weights=lambda_weights)\n",
    "#         torch.cuda.synchronize()\n",
    "# # \n",
    "#     print(prof.key_averages().table(sort_by=\"self_cuda_time_total\"))\n",
    "#     prof.export_chrome_trace(\"trace.json\")\n",
    "    \n",
    "    # \n",
    "    sites = autograd(sites, model, max_iter=max_iter, upsampling=0, lambda_weights=lambda_weights)\n",
    "\n",
    "    \n",
    "    # profiler.disable()\n",
    "    # stats = pstats.Stats(profiler).sort_stats('cumtime')\n",
    "    # stats.print_stats()\n",
    "    # stats.dump_stats(f'{destination}{mesh[0]}{max_iter}_3d_profile_{num_centroids}_chamfer{lambda_chamfer}.prof')\n",
    "    \n",
    "    \n",
    "    sites_np = sites.detach().cpu().numpy()\n",
    "    np.save(site_file_path, sites_np)\n",
    "    \n",
    "    \n",
    "\n",
    "print(\"Sites length: \", len(sites))\n",
    "print(\"min sites: \", torch.min(sites))\n",
    "print(\"max sites: \", torch.max(sites))\n",
    "#ps_cloud = ps.register_point_cloud(\"best_optimized_cvt_grid\",sites.detach().cpu().numpy())\n",
    "    \n",
    "lim=torch.abs(torch.max(sites)).detach().cpu().numpy()*1.1\n",
    "#plot_voronoi_3d(sites,lim,lim,lim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4e4fcfff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model ./images/autograd/HotSpot/bunny500_500_3d_model_512_chamfer1000.pth\n",
      "sites ./images/autograd/HotSpot/bunny500_500_3d_sites_512_chamfer1000.pth\n"
     ]
    }
   ],
   "source": [
    "epoch = 500\n",
    "\n",
    "model_file_path = f'{destination}{mesh[0]}{max_iter}_{epoch}_3d_model_{num_centroids}_chamfer{lambda_chamfer}.pth'\n",
    "site_file_path = f'{destination}{mesh[0]}{max_iter}_{epoch}_3d_sites_{num_centroids}_chamfer{lambda_chamfer}.pth'\n",
    " \n",
    "sites = torch.load(site_file_path)\n",
    "\n",
    "sites_np = sites.detach().cpu().numpy()\n",
    "model.load_state_dict(torch.load(model_file_path))\n",
    "#\n",
    "#polyscope_sdf(model)\n",
    "#\n",
    "print(\"model\", model_file_path)\n",
    "print(\"sites\", site_file_path)\n",
    "ps_cloud = ps.register_point_cloud(f\"{epoch} epoch_cvt_grid\",sites_np)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "72e588cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-Crossing faces final shape:  (79050, 3)\n",
      "comb torch.Size([6, 2])\n",
      "face_mask torch.Size([4096, 213111])\n",
      "counts torch.Size([4096])\n",
      "Kmax 14\n",
      "face_mask torch.Size([4096, 213111])\n",
      "counts torch.Size([4096])\n",
      "Kmax 14\n",
      "face_mask torch.Size([4096, 213111])\n",
      "counts torch.Size([4096])\n",
      "Kmax 14\n",
      "face_mask torch.Size([4096, 213111])\n",
      "counts torch.Size([4096])\n",
      "Kmax 14\n",
      "face_mask torch.Size([4096, 213111])\n",
      "counts torch.Size([4096])\n",
      "Kmax 13\n",
      "face_mask torch.Size([4096, 213111])\n",
      "counts torch.Size([4096])\n",
      "Kmax 13\n",
      "face_mask torch.Size([4096, 213111])\n",
      "counts torch.Size([4096])\n",
      "Kmax 13\n",
      "face_mask torch.Size([4096, 213111])\n",
      "counts torch.Size([4096])\n",
      "Kmax 14\n",
      "face_mask torch.Size([4096, 213111])\n",
      "counts torch.Size([4096])\n",
      "Kmax 13\n",
      "face_mask torch.Size([4096, 213111])\n",
      "counts torch.Size([4096])\n",
      "Kmax 13\n",
      "face_mask torch.Size([4096, 213111])\n",
      "counts torch.Size([4096])\n",
      "Kmax 14\n",
      "face_mask torch.Size([4096, 213111])\n",
      "counts torch.Size([4096])\n",
      "Kmax 12\n",
      "face_mask torch.Size([4096, 213111])\n",
      "counts torch.Size([4096])\n",
      "Kmax 13\n",
      "face_mask torch.Size([2758, 213111])\n",
      "counts torch.Size([2758])\n",
      "Kmax 14\n",
      "faces 56006\n",
      "-> vertices: torch.Size([79050, 3])\n",
      "-> projected vertices: torch.Size([79050, 3])\n",
      "-> #faces: 56006\n"
     ]
    }
   ],
   "source": [
    "final_mesh = su.get_zero_crossing_mesh_3d(sites, model)\n",
    "#ps.register_surface_mesh(\"Zero-Crossing faces direct\", final_mesh[0], final_mesh[1])\n",
    "\n",
    "#save to file\n",
    "final_mesh_file = f'{mesh[0]}voroloss_sdf_trained{model_trained_it}.npz'\n",
    "faces = np.array(final_mesh[1], dtype=object)\n",
    "np.savez(final_mesh_file, vertices=final_mesh[0], faces=faces)\n",
    "\n",
    "data = np.load(final_mesh_file, allow_pickle=True)\n",
    "verts = data[\"vertices\"]       # (N_vertices, 3)\n",
    "faces = data[\"faces\"].tolist() # back to a list of lists\n",
    "\n",
    "print(\"Zero-Crossing faces final shape: \", verts.shape)\n",
    "ps.register_surface_mesh(\"Zero-Crossing faces final\", verts, faces)\n",
    "\n",
    "v_vect, f_vect = su.get_clipped_mesh_torch(sites, model, None, batch_size=4096)\n",
    "ps.register_surface_mesh(\"vectorized diff mesh\", v_vect.detach().cpu().numpy(), f_vect)\n",
    "\n",
    "\n",
    "\n",
    "import scipy.spatial as spatial\n",
    "from scipy.spatial import Delaunay\n",
    "\n",
    "tri = Delaunay(sites_np)\n",
    "delaunay_vertices =torch.tensor(np.array(tri.simplices), device=device)\n",
    "sdf_values = model(sites)\n",
    "\n",
    "# Assuming sites is a PyTorch tensor of shape [M, 3]\n",
    "sites = sites.unsqueeze(0)  # Now shape [1, M, 3]\n",
    "\n",
    "# Assuming SDF_Values is a PyTorch tensor of shape [M]\n",
    "sdf_values = sdf_values.unsqueeze(0)  # Now shape [1, M]\n",
    "\n",
    "marching_tetrehedra_mesh = kaolin.ops.conversions.marching_tetrahedra(sites, delaunay_vertices, sdf_values, return_tet_idx=False)\n",
    "#print(marching_tetrehedra_mesh)\n",
    "vertices_list, faces_list = marching_tetrehedra_mesh\n",
    "vertices = vertices_list[0]\n",
    "faces = faces_list[0]\n",
    "vertices_np = vertices.detach().cpu().numpy()  # Shape [N, 3]\n",
    "faces_np = faces.detach().cpu().numpy()  # Shape [M, 3] (triangles)\n",
    "ps.register_surface_mesh(\"Marching Tetrahedra Mesh final\", vertices_np, faces_np)\n",
    "\n",
    "# clipped_cvt = \"clipped_CVT.obj\"\n",
    "# if os.path.exists(clipped_cvt):\n",
    "#     clipped_cvt_mesh = trimesh.load(clipped_cvt)\n",
    "#     ps.register_surface_mesh(\"Clipped CVT\", clipped_cvt_mesh.vertices, clipped_cvt_mesh.faces)\n",
    "ps.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e5deeda7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "End of script",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnd of script\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: End of script"
     ]
    }
   ],
   "source": [
    "assert False, \"End of script\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d940a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the meshed of different sdf trained total epochs and the clipped version \n",
    "import polyscope as ps\n",
    "import numpy as np\n",
    "import trimesh\n",
    "import os \n",
    "\n",
    "ps.init()\n",
    "nb_it = [\"\",\"_1000\",\"_3000\",\"_5000\",\"_7000\"]\n",
    "for it in nb_it:\n",
    "    final_mesh_file = f'gargoyle_sdf_trained{it}.npz'\n",
    "    data = np.load(final_mesh_file, allow_pickle=True)\n",
    "    verts = data[\"vertices\"]       # (N_vertices, 3)\n",
    "    faces = data[\"faces\"].tolist() # back to a list of lists\n",
    "\n",
    "    ps.register_surface_mesh(f\"Zero-Crossing faces final {it}\", verts, faces) \n",
    "\n",
    "for it in nb_it:\n",
    "    clipped_mesh_file = f'gargoyle_to_clip{it}.npz_clipped.obj'\n",
    "    clipped_cvt_mesh = trimesh.load(clipped_mesh_file)\n",
    "    ps.register_surface_mesh(f\"Clipped CVT {it}\", clipped_cvt_mesh.vertices, clipped_cvt_mesh.faces)\n",
    "    \n",
    "for it in nb_it:\n",
    "    final_mesh_file = f'bunnyvoroloss_sdf_trained{it}.npz'\n",
    "    if os.path.exists(final_mesh_file):\n",
    "        data = np.load(final_mesh_file, allow_pickle=True)\n",
    "        verts = data[\"vertices\"]       # (N_vertices, 3)\n",
    "        faces = data[\"faces\"].tolist() # back to a list of lists\n",
    "\n",
    "        ps.register_surface_mesh(f\"Voroloss Zero-Crossing faces final {it}\", verts, faces) \n",
    "\n",
    "for it in nb_it:\n",
    "    clipped_mesh_file = f'bunnyvoroloss_to_clip{it}.npz_clipped.obj'\n",
    "    if os.path.exists(clipped_mesh_file):\n",
    "        clipped_cvt_mesh = trimesh.load(clipped_mesh_file)\n",
    "        ps.register_surface_mesh(f\"Voroloss Clipped CVT {it}\", clipped_cvt_mesh.vertices, clipped_cvt_mesh.faces)\n",
    "    \n",
    "ps.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a193f128",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, \"End of script\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72240a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Voromesh points and values to try and plot the voronoi diagram\n",
    "import numpy as np\n",
    "from scipy.spatial import Voronoi\n",
    "import polyscope as ps\n",
    "def get_zero_crossing_mesh_3d(sites, values):\n",
    "    sites_np = sites\n",
    "    vor = Voronoi(sites_np)  # Compute 3D Voronoi diagram\n",
    "\n",
    "    sdf_values = values\n",
    "\n",
    "    valid_faces = []  # List of polygonal faces\n",
    "    used_vertices = set()  # Set of indices for valid vertices\n",
    "\n",
    "    for (point1, point2), ridge_vertices in zip(vor.ridge_points, vor.ridge_vertices):\n",
    "        if -1 in ridge_vertices:\n",
    "            continue  # Skip infinite ridges\n",
    "\n",
    "        # Check if SDF changes sign across this ridge\n",
    "        if np.sign(sdf_values[point1]) != np.sign(sdf_values[point2]):\n",
    "            valid_faces.append(ridge_vertices)\n",
    "            used_vertices.update(ridge_vertices)\n",
    "\n",
    "    # **Filter Voronoi vertices**\n",
    "    used_vertices = sorted(used_vertices)  # Keep unique, sorted indices\n",
    "    vertex_map = {old_idx: new_idx for new_idx, old_idx in enumerate(used_vertices)}\n",
    "    filtered_vertices = vor.vertices[used_vertices]\n",
    "\n",
    "    # **Re-index faces to match the new filtered vertex list**\n",
    "    filtered_faces = [[vertex_map[v] for v in face] for face in valid_faces]\n",
    "\n",
    "    return filtered_vertices, filtered_faces\n",
    "\n",
    "n_sample = [1, 16, 32, 150, 2400]\n",
    "grid_size = [32,128]\n",
    "voromesh_points = []\n",
    "voromesh_values = []\n",
    "ps.init()\n",
    "# groud plane none\n",
    "ps.set_ground_plane_mode(\"none\") \n",
    "for g in grid_size:\n",
    "    for i in n_sample:\n",
    "        try:\n",
    "            voromesh_points = np.load(f\"/home/wylliam/dev/VoroMesh/points_{i}_{g}.npy\")\n",
    "            voromesh_values = np.load(f\"/home/wylliam/dev/VoroMesh/values_{i}_{g}.npy\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"File not found for points_{i}_{g}.npy or values_{i}_{g}.npy\")\n",
    "            continue\n",
    "        mesh = get_zero_crossing_mesh_3d(voromesh_points, voromesh_values)\n",
    "        ps.register_surface_mesh(f\"mesh_{g}_{i}\", mesh[0], mesh[1])\n",
    "\n",
    "ps.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3355a005",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, \"End of script\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3c340c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#working version of differentiable meshing not vectorized\n",
    "\n",
    "\n",
    "from collections import defaultdict\n",
    "import itertools\n",
    "\n",
    "def sort_face_loop(vertices, face):\n",
    "    pts = vertices[face]                       # shape (N,3)\n",
    "    ctr = pts.mean(axis=0)                     # centroid\n",
    "    # compute a normal for the polygon plane (via PCA/SVD)\n",
    "    _, _, vt = np.linalg.svd(pts - ctr)\n",
    "    normal = vt[2]                             # last singular vector\n",
    "\n",
    "    # pick a reference axis in the plane\n",
    "    ref = pts[0] - ctr\n",
    "    ref -= normal * (normal @ ref)             # project off normal\n",
    "\n",
    "    # compute angles of each point around the centroid\n",
    "    def angle(p):\n",
    "        v = p - ctr\n",
    "        v -= normal * (normal @ v)             # project into plane\n",
    "        a = np.arctan2(np.linalg.norm(np.cross(ref, v)),\n",
    "                    ref @ v)\n",
    "        # sign:\n",
    "        if np.dot(normal, np.cross(ref, v)) < 0:\n",
    "            a = 2*np.pi - a\n",
    "        return a\n",
    "\n",
    "    face_sorted = sorted(face, key=lambda idx: angle(vertices[idx]))\n",
    "    return face_sorted\n",
    "\n",
    "def get_clipped_mesh(sites, model):\n",
    "    sites_np = sites.detach().cpu().numpy()\n",
    "    d3dsimplices = diffvoronoi.get_delaunay_simplices(sites_np.reshape(input_dims*sites_np.shape[0]))\n",
    "    d3dsimplices_np = np.array(d3dsimplices)\n",
    "    \n",
    "    sdf_values = model(sites)\n",
    "    # sdf_gradients = torch.autograd.grad(outputs=sdf_values, inputs=sites, grad_outputs=torch.ones_like(sdf_values), create_graph=True, retain_graph=True,)[0] # (N, 3)\n",
    "    # N, D = sites.shape\n",
    "    # hess_sdf = torch.zeros(N, D, D, device=sites.device)\n",
    "    # for i in range(D):\n",
    "    #     grad2 = torch.autograd.grad(outputs=sdf_gradients[:, i], inputs=sites, grad_outputs=torch.ones_like(sdf_gradients[:, i]), create_graph=False, retain_graph=True,)[0] # (N, 3)\n",
    "    #     hess_sdf[:, i, :] = grad2 # fill row i of each 3Ã—3 Hessian\n",
    "\n",
    "    d3dsimplices_tensor = torch.tensor(d3dsimplices_np, device=device)\n",
    "    voronoi_vertices = su.compute_vertices_3d_vectorized(sites, d3dsimplices_tensor)    \n",
    "    tetra_edges = torch.cat([\n",
    "        d3dsimplices_tensor[:, [0, 1]],\n",
    "        d3dsimplices_tensor[:, [1, 2]],\n",
    "        d3dsimplices_tensor[:, [2, 3]],\n",
    "        d3dsimplices_tensor[:, [3, 0]],\n",
    "        d3dsimplices_tensor[:, [0, 2]],\n",
    "        d3dsimplices_tensor[:, [1, 3]]\n",
    "                                ], dim=0).to(device)\n",
    "    # Sort each edge to ensure uniqueness (because (a, b) and (b, a) are the same)\n",
    "    tetra_edges, _ = torch.sort(tetra_edges, dim=1)\n",
    "    # Get unique edges\n",
    "    voronoi_ridges = torch.unique(tetra_edges, dim=0)\n",
    "    # create a dictionnary to store the d3dsimplices composing the faces\n",
    "    # there is a face for every voronoi_ridges\n",
    "    # every vertices of the face is a simplex containing the two sites of the ridge\n",
    "    face_dict = defaultdict(list)\n",
    "    for simplex_idx, simplex in enumerate(d3dsimplices_np):\n",
    "        for a,b in itertools.combinations(simplex, 2):\n",
    "            key = (a, b) if a < b else (b, a)\n",
    "            face_dict[key].append(simplex_idx)\n",
    "\n",
    "    # Extract the SDF values for each site in the pair\n",
    "    sdf_i = sdf_values[voronoi_ridges[:, 0]]  # First site in each pair\n",
    "    sdf_j = sdf_values[voronoi_ridges[:, 1]]  # Second site in each pair\n",
    "    # Find the indices where SDF values have opposing signs or one is zero\n",
    "    mask_zero_crossing_sites = (sdf_i * sdf_j <= 0).squeeze()\n",
    "    # filter the faces based on the mask\n",
    "    filtered_faces = voronoi_ridges[mask_zero_crossing_sites].detach().cpu().numpy()\n",
    "    faces = []\n",
    "    for a, b in filtered_faces:\n",
    "        key = (a, b) if a < b else (b, a)\n",
    "        match = face_dict.get(key, [])\n",
    "        match = sort_face_loop(voronoi_vertices.detach().cpu().numpy(), match)\n",
    "        faces.append(match)\n",
    "\n",
    "\n",
    "    # Not sure if i should do this at all.\n",
    "    # 1) find every vertex index thatâ€™s actually used\n",
    "    used = set(idx for face in faces for idx in face)\n",
    "    # 2) create old->new mapping\n",
    "    old2new = {old: new for new, old in enumerate(sorted(used))}\n",
    "    # 3) build new, compact vertex array\n",
    "    vertices = voronoi_vertices[sorted(used), :]\n",
    "    # 4) remap faces\n",
    "    faces_new = [[old2new[idx] for idx in face] for face in faces]\n",
    "\n",
    "    print(\"vertices shape: \", vertices)\n",
    "    print(\"faces : \", faces_new)\n",
    "\n",
    "    return vertices, faces_new\n",
    "    return voronoi_vertices, faces"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
