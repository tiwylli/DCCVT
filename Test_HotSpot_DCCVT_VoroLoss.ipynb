{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed71bbfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "Using device:  NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "import kaolin\n",
    "import torch\n",
    "import math\n",
    "import matplotlib\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import polyscope as ps\n",
    "import trimesh\n",
    "import diffvoronoi\n",
    "\n",
    "from scipy.spatial import Voronoi, voronoi_plot_2d, Delaunay\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import sdfpred_utils.sdfpred_utils as su\n",
    "import sdfpred_utils.sdf_MLP as mlp\n",
    "import sdfpred_utils.sdf_functions as sdf\n",
    "import sdfpred_utils.loss_functions as lf\n",
    "import sdfpred_utils.Steik_data3d as sd3d\n",
    "import sdfpred_utils.Steik_Loss as sl\n",
    "import sdfpred_utils.Steik_utils as Stu \n",
    "import open3d as o3d\n",
    "\n",
    "#cuda devices\n",
    "device = torch.device(\"cuda:0\")\n",
    "print(\"Using device: \", torch.cuda.get_device_name(device))\n",
    "\n",
    "#default tensor types\n",
    "#torch.set_default_tensor_type(torch.cuda.DoubleTensor)\n",
    "\n",
    "multires = 2\n",
    "input_dims = 3\n",
    "lr_sites = 0.005\n",
    "#lr_model = 0.00005*2\n",
    "destination = \"./images/autograd/HotSpot/\"\n",
    "mesh = [\"gargoyle\",\"/home/wylliam/dev/Kyushu_experiments/data/gargoyle\"]\n",
    "mesh = [\"bunny\",\"/home/wylliam/dev/Kyushu_experiments/data/bunny\"]\n",
    "\n",
    "model_trained_it = \"\"\n",
    "trained_model_path = f\"/home/wylliam/dev/HotSpot/log/3D/pc/HotSpot-all-2025-04-24-18-16-03/gargoyle/gargoyle/trained_models/model{model_trained_it}.pth\"\n",
    "trained_model_path = f\"/home/wylliam/dev/HotSpot/log/3D/pc/HotSpot-all-2025-04-25-17-32-49/bunny/bunny/trained_models/model{model_trained_it}.pth\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96ddcc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch3d.ops import knn_points, knn_gather\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class Voroloss_opt(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Voroloss_opt, self).__init__()\n",
    "        self.knn = 16\n",
    "\n",
    "    def __call__(self, points, spoints):\n",
    "        \"\"\"points, self.points\"\"\"\n",
    "        # WARNING: fecthing for knn\n",
    "        with torch.no_grad():\n",
    "            indices = knn_points(points, spoints, K=self.knn).idx\n",
    "\n",
    "        points_knn = knn_gather(spoints, indices)\n",
    "        points_to_voronoi_center = points - points_knn[:, :, 0]\n",
    "\n",
    "        voronoi_edge = points_knn[:, :, 1:] - points_knn[:, :, 0].unsqueeze(2)\n",
    "        voronoi_edge_l = torch.sqrt(((voronoi_edge**2).sum(-1)))\n",
    "        vector_length = (points_to_voronoi_center.unsqueeze(2) * voronoi_edge).sum(\n",
    "            -1\n",
    "        ) / voronoi_edge_l\n",
    "        sq_dist = (vector_length - voronoi_edge_l / 2) ** 2\n",
    "        return sq_dist.min(-1)[0]\n",
    "    \n",
    "voroloss = Voroloss_opt().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95a49d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sites_spread_loss(sites):\n",
    "#     with torch.no_grad():\n",
    "#         indices = knn_points(sites, sites, K=).idx\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a4b4e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new sites\n",
      "Sites shape:  torch.Size([512, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wylliam/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1678402412426/work/aten/src/ATen/native/TensorShape.cpp:3483.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[polyscope] Backend: openGL3_glfw -- Loaded openGL version: 3.3.0 NVIDIA 570.144\n"
     ]
    }
   ],
   "source": [
    "num_centroids = 8**3\n",
    "\n",
    "print(\"Creating new sites\")\n",
    "noise_scale = 0.1\n",
    "domain_limit = 1\n",
    "x = torch.linspace(-domain_limit, domain_limit, int(round(num_centroids**(1/3))))\n",
    "y = torch.linspace(-domain_limit, domain_limit, int(round(num_centroids**(1/3))))\n",
    "z = torch.linspace(-domain_limit, domain_limit, int(round(num_centroids**(1/3))))\n",
    "meshgrid = torch.meshgrid(x, y, z)\n",
    "meshgrid = torch.stack(meshgrid, dim=3).view(-1, 3)\n",
    "#add noise to meshgrid\n",
    "meshgrid += torch.randn_like(meshgrid) * noise_scale\n",
    "sites = meshgrid.to(device, dtype=torch.float32).requires_grad_(True)\n",
    "\n",
    "print(\"Sites shape: \", sites.shape)\n",
    "ps.init()\n",
    "#ps.register_point_cloud(\"initial_cvt_grid\",sites.detach().cpu().numpy())\n",
    "\n",
    "# # load pointcloud used for sdf training\n",
    "# pointcloud = o3d.io.read_point_cloud(mesh[1]+\".ply\")\n",
    "# print(\"Pointcloud shape: \", np.asarray(pointcloud.points).shape)\n",
    "# # sample pointcloud to 150*32*32\n",
    "# chamfer_distance_pc_gt = pointcloud.uniform_down_sample(int((128**3)/(150*32*32)))\n",
    "# chamfer_distance_pc_gt = np.asarray(chamfer_distance_pc_gt.points)\n",
    "# print(\"Chamfer distance pointcloud shape: \", chamfer_distance_pc_gt.shape)\n",
    "\n",
    "\n",
    "# ps.register_point_cloud(\"pointcloud_gt\", chamfer_distance_pc_gt)\n",
    "# chamfer_distance_pc_gt = torch.tensor(chamfer_distance_pc_gt, device=device, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe96048f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnfld_points shape:  torch.Size([1, 153600, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wylliam/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LOAD MODEL WITH HOTSPOT\n",
    "import sys\n",
    "sys.path.append(\"3rdparty/HotSpot\")\n",
    "from dataset import shape_3d\n",
    "import models.Net as Net\n",
    "\n",
    "loss_type = \"igr_w_heat\"\n",
    "loss_weights = [350, 0, 0, 1, 0, 0, 20]\n",
    "\n",
    "train_set = shape_3d.ReconDataset(\n",
    "    file_path = mesh[1]+\".ply\",\n",
    "    n_points=32*32*150,#15000, #args.n_points,\n",
    "    n_samples=10001, #args.n_iterations,\n",
    "    grid_res=256, #args.grid_res,\n",
    "    grid_range=1.1, #args.grid_range,\n",
    "    sample_type=\"uniform_central_gaussian\", #args.nonmnfld_sample_type,\n",
    "    sampling_std=0.5, #args.nonmnfld_sample_std,\n",
    "    n_random_samples=7500, #args.n_random_samples,\n",
    "    resample=True,\n",
    "    compute_sal_dist_gt=(\n",
    "        True if \"sal\" in loss_type and loss_weights[5] > 0 else False\n",
    "    ),\n",
    "    scale_method=\"mean\"#\"mean\" #args.pcd_scale_method,\n",
    ")\n",
    "\n",
    "model = Net.Network(\n",
    "    latent_size=0,#args.latent_size,\n",
    "    in_dim=3,\n",
    "    decoder_hidden_dim=128,#args.decoder_hidden_dim,\n",
    "    nl=\"sine\",#args.nl,\n",
    "    encoder_type=\"none\",#args.encoder_type,\n",
    "    decoder_n_hidden_layers=5,#args.decoder_n_hidden_layers,\n",
    "    neuron_type=\"quadratic\",#args.neuron_type,\n",
    "    init_type=\"mfgi\",#args.init_type,\n",
    "    sphere_init_params=[1.6, 0.1],#args.sphere_init_params,\n",
    "    n_repeat_period=30#args.n_repeat_period,\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "######       \n",
    "test_dataloader = torch.utils.data.DataLoader(train_set, batch_size=1, shuffle=False, num_workers=0, pin_memory=False)   \n",
    "test_data = next(iter(test_dataloader))\n",
    "mnfld_points = test_data[\"mnfld_points\"].to(device)\n",
    "mnfld_points.requires_grad_()\n",
    "print(\"mnfld_points shape: \", mnfld_points.shape)\n",
    "if torch.cuda.is_available():\n",
    "    map_location = torch.device(\"cuda\")\n",
    "else:\n",
    "    map_location = torch.device(\"cpu\")\n",
    "model.load_state_dict(torch.load(trained_model_path, weights_only=True, map_location=map_location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5753400f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #add mnfld points with random noise to sites \n",
    "N = mnfld_points.squeeze(0).shape[0]\n",
    "num_samples = 16**3\n",
    "idx = torch.randint(0, N, (num_samples,))\n",
    "sampled = mnfld_points.squeeze(0)[idx]\n",
    "perturbed = sampled + (torch.rand_like(sampled)-0.5)*0.1\n",
    "sites = torch.cat((sites, perturbed), dim=0)\n",
    "\n",
    "# make sites a leaf tensor\n",
    "sites = sites.detach().requires_grad_()\n",
    "\n",
    "sites_pred = model(sites)#[\"nonmanifold_pnts_pred\"]\n",
    "#mnfld_preds = model(mnfld_points)#[\"nonmanifold_pnts_pred\"]\n",
    "\n",
    "ps_cloud = ps.register_point_cloud(\"initial_cvt_grid+pc_gt\",sites.detach().cpu().numpy())\n",
    "mnf_cloud = ps.register_point_cloud(\"mnfld_points_pred\",mnfld_points.squeeze(0).detach().cpu().numpy())\n",
    "#mnf_cloud.add_scalar_quantity(\"mnfld_points_pred\", mnfld_preds.reshape(-1).detach().cpu().numpy(), enabled=True)\n",
    "ps_cloud.add_scalar_quantity(\"vis_grid_pred\", sites_pred.reshape(-1).detach().cpu().numpy(), enabled=True)\n",
    "\n",
    "initial_mesh = su.get_zero_crossing_mesh_3d(sites, model)\n",
    "ps.register_surface_mesh(\"initial Zero-Crossing faces\", initial_mesh[0], initial_mesh[1])\n",
    "\n",
    "ps.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "460a316b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SITES OPTIMISATION LOOP\n",
    "cvt_loss_values = []\n",
    "min_distance_loss_values = []\n",
    "chamfer_distance_loss_values = []\n",
    "eikonal_loss_values = []\n",
    "domain_restriction_loss_values = []\n",
    "sdf_loss_values = []\n",
    "div_loss_values = []\n",
    "loss_values = []\n",
    "\n",
    "\n",
    "\n",
    "def autograd(sites, model, max_iter=100, stop_train_threshold=1e-6, upsampling=0, lambda_weights = [0.1,1.0,0.1,0.1,1.0,1.0,0.1]):\n",
    "    optimizer = torch.optim.Adam([\n",
    "    {'params': [sites], 'lr': lr_sites}\n",
    "], betas=(0.9, 0.999))\n",
    "\n",
    "    prev_loss = float(\"inf\")\n",
    "    best_loss = float(\"inf\")\n",
    "    upsampled = 0.0\n",
    "    epoch = 0\n",
    "    lambda_cvt = lambda_weights[0]\n",
    "    # lambda_pc = lambda_weights[1]\n",
    "    lambda_min_distance = lambda_weights[2]\n",
    "    # lambda_laplace = lambda_weights[3]\n",
    "    lambda_chamfer = lambda_weights[4]\n",
    "    lambda_eikonal = lambda_weights[5]\n",
    "    lambda_domain_restriction = lambda_weights[6]\n",
    "    # lambda_target_points = lambda_weights[7]\n",
    "    lambda_sdf = 5e3\n",
    "    lambda_div = 1e2\n",
    "    lambda_eikonal = 5e1\n",
    "    best_sites = sites.clone()\n",
    "    best_sites.best_loss = best_loss\n",
    "    \n",
    "    while epoch <= max_iter:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # compute voronoi and delaunay once for each epoch and pass it around\n",
    "        # Compute Voronoi diagram\n",
    "        sites_np = sites.detach().cpu().numpy()\n",
    "        #vor = Voronoi(sites_np)\n",
    "        #tri = Delaunay(sites_np)\n",
    "      \n",
    "      \n",
    "        d3dsimplices = diffvoronoi.get_delaunay_simplices(sites_np.reshape(input_dims*sites_np.shape[0]))\n",
    "        d3dsimplices = np.array(d3dsimplices)\n",
    "        #print(\"Delaunay simplices shape: \", d3dsimplices.shape)\n",
    "        \n",
    "        vertices_to_compute, bisectors_to_compute = su.compute_zero_crossing_vertices_3d(sites, None, None, d3dsimplices, model)\n",
    "                \n",
    "        #vertices_to_compute, bisectors_to_compute = su.compute_zero_crossing_vertices_3d(sites, None, tri, None, model)\n",
    "        #vertices_to_compute, bisectors_to_compute = su.compute_zero_crossing_vertices_3d(sites, vor, tri, None, model)\n",
    "        \n",
    "        vertices = su.compute_vertices_3d_vectorized(sites, vertices_to_compute)    \n",
    "        bisectors = su.compute_all_bisectors_vectorized(sites, bisectors_to_compute)\n",
    "        points = torch.cat((vertices, bisectors), 0)\n",
    "        print(\"points\", points.shape) \n",
    "\n",
    "        # Compute losses       \n",
    "        #cvt_loss = lf.compute_cvt_loss_vectorized_voronoi(sites, vor)\n",
    "        #cvt_loss = lf.compute_cvt_loss_vectorized_delaunay(sites, tri)\n",
    "    \n",
    "        cvt_loss = lf.compute_cvt_loss_vectorized_delaunay(sites, None, d3dsimplices)\n",
    "        print(\"CVT loss: \", cvt_loss, \"weighted: \", lambda_cvt*cvt_loss)\n",
    "        #min_distance_loss = lf.sdf_weighted_min_distance_loss(model, sites)\n",
    "        \n",
    "        from pytorch3d.loss import chamfer_distance\n",
    "        chamfer_loss, _ = chamfer_distance(mnfld_points.detach(), points.unsqueeze(0))\n",
    "        print(f\"Chamfer loss PYTORCH3D {chamfer_loss} weighted: {lambda_chamfer*chamfer_loss} : Allocated: {torch.cuda.memory_allocated() / 1e6} MB, Reserved: {torch.cuda.memory_reserved() / 1e6} MB\")\n",
    "\n",
    "\n",
    "        # voroloss_loss = voroloss(points.unsqueeze(0), mnfld_points)\n",
    "        # #voroloss_loss = voroloss(sites.unsqueeze(0), mnfld_points)\n",
    "        # voroloss_loss = voroloss_loss.mean()\n",
    "        # print(f\"After Voronoi loss: {voroloss_loss} : Allocated: {torch.cuda.memory_allocated() / 1e6} MB, Reserved: {torch.cuda.memory_reserved() / 1e6} MB\")\n",
    "        \n",
    "        #SDF loss\n",
    "        sdf_loss = torch.mean(model(points)**2) + torch.maximum((model(sites).abs() - 0.05), torch.tensor(0.0)).mean()\n",
    "        #sdf_loss = torch.maximum((model(sites).abs() - 0.01), torch.tensor(0.0)).mean()\n",
    "        #sdf_loss = torch.maximum((model(sites).abs() - 0.05), torch.tensor(0.0)).mean()\n",
    "        print(\"SDF loss: \", sdf_loss, \"weighted: \", lambda_chamfer*sdf_loss)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        sites_loss = (\n",
    "            lambda_cvt * cvt_loss +\n",
    "            #lambda_chamfer * chamfer_loss \n",
    "            #lambda_chamfer * voroloss_loss\n",
    "            + lambda_chamfer * sdf_loss\n",
    "        )\n",
    "            \n",
    "        loss = sites_loss\n",
    "        loss_values.append(loss.item())\n",
    "        print(f\"Epoch {epoch}: loss = {loss.item()}\")\n",
    "        print(f\"before loss.backward(): Allocated: {torch.cuda.memory_allocated() / 1e6} MB, Reserved: {torch.cuda.memory_reserved() / 1e6} MB\")\n",
    "\n",
    "        loss.backward()\n",
    "        print(f\"After loss.backward(): Allocated: {torch.cuda.memory_allocated() / 1e6} MB, Reserved: {torch.cuda.memory_reserved() / 1e6} MB\")\n",
    "        print(\"-----------------\")\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        if loss.item() < best_loss:\n",
    "            best_loss = loss.item()\n",
    "            best_epoch = epoch\n",
    "            best_sites = sites.clone()\n",
    "            best_sites.best_loss = best_loss\n",
    "            #if upsampled > 0:\n",
    "                #print(f\"UPSAMPLED {upsampled} Best Epoch {best_epoch}: Best loss = {best_loss}\")\n",
    "                #return best_sites\n",
    "        \n",
    "        if abs(prev_loss - loss.item()) < stop_train_threshold:\n",
    "            print(f\"Converged at epoch {epoch} with loss {loss.item()}\")\n",
    "            #break\n",
    "        \n",
    "        prev_loss = loss.item() \n",
    "        \n",
    "        # if epoch>100 and (epoch // 100) == upsampled+1 and loss.item() < 0.5 and upsampled < upsampling:\n",
    "        if epoch/max_iter > (upsampled+1)/(upsampling+1) and upsampled < upsampling:\n",
    "            print(\"sites length BEFORE UPSAMPLING: \",len(sites))\n",
    "            sites = su.upsampling_vectorized(sites, tri=None, vor=None, simplices=d3dsimplices, model=model)\n",
    "            sites = sites.detach().requires_grad_(True)\n",
    "            optimizer = torch.optim.Adam([{'params': [sites], 'lr': lr_sites}])\n",
    "            upsampled += 1.0\n",
    "            print(\"sites length AFTER: \",len(sites))\n",
    "            \n",
    "          \n",
    "        if epoch % (max_iter/50) == 0:\n",
    "            #print(f\"Epoch {epoch}: loss = {loss.item()}\")\n",
    "            #print(f\"Best Epoch {best_epoch}: Best loss = {best_loss}\")\n",
    "            #save model and sites\n",
    "            site_file_path = f'{destination}{mesh[0]}{max_iter}_{epoch}_3d_sites_{num_centroids}_chamfer{lambda_chamfer}.pth'\n",
    "            model_file_path = f'{destination}{mesh[0]}{max_iter}_{epoch}_3d_model_{num_centroids}_chamfer{lambda_chamfer}.pth'\n",
    "            torch.save(model.state_dict(), model_file_path)\n",
    "            torch.save(sites, site_file_path)\n",
    "            \n",
    "        epoch += 1           \n",
    "    \n",
    "    #Export the sites, their sdf values, the gradients of the sdf values and the hessian\n",
    "    sdf_values = model(sites)\n",
    "\n",
    "    sdf_gradients = torch.autograd.grad(outputs=sdf_values, inputs=sites, grad_outputs=torch.ones_like(sdf_values), create_graph=True, retain_graph=True,)[0] # (N, 3)\n",
    "\n",
    "    N, D = sites.shape\n",
    "    hess_sdf = torch.zeros(N, D, D, device=sites.device)\n",
    "    for i in range(D):\n",
    "        grad2 = torch.autograd.grad(outputs=sdf_gradients[:, i], inputs=sites, grad_outputs=torch.ones_like(sdf_gradients[:, i]), create_graph=False, retain_graph=True,)[0] # (N, 3)\n",
    "        hess_sdf[:, i, :] = grad2 # fill row i of each 3Ã—3 Hessian\n",
    "    \n",
    "    np.savez(f'{mesh[0]}voroloss_to_clip{model_trained_it}.npz', sites=sites.detach().cpu().numpy(), sdf_values=sdf_values.detach().cpu().numpy(), sdf_gradients=sdf_gradients.detach().cpu().numpy(), sdf_hessians=hess_sdf.detach().cpu().numpy())\n",
    "    print(f\"Saved to {mesh[0]}voroloss_to_clip{model_trained_it}.npz\")\n",
    "    return best_sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7e96773",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lambda_weights = [252,0,0,0,10.211111,0,100,0]\n",
    "#lambda_weights = [500,0,0,0,1000,0,100,0]\n",
    "lambda_weights = [100,0,0,0,1000,0,100,0]\n",
    "\n",
    "\n",
    "lambda_cvt = lambda_weights[0]\n",
    "lambda_sdf = lambda_weights[1]\n",
    "lambda_min_distance = lambda_weights[2]\n",
    "lambda_laplace = lambda_weights[3]\n",
    "lambda_chamfer = lambda_weights[4]\n",
    "lambda_eikonal = lambda_weights[5]\n",
    "lambda_domain_restriction = lambda_weights[6]\n",
    "lambda_true_points = lambda_weights[7]\n",
    "\n",
    "max_iter = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb2cefd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "points torch.Size([19162, 3])\n",
      "CVT loss:  tensor(0.0433, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(4.3321, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.0003433668171055615 weighted: 0.3433668315410614 : Allocated: 81.212928 MB, Reserved: 159.383552 MB\n",
      "SDF loss:  tensor(0.0701, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(70.1120, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0: loss = 74.44414520263672\n",
      "before loss.backward(): Allocated: 386.440704 MB, Reserved: 432.013312 MB\n",
      "After loss.backward(): Allocated: 83.106816 MB, Reserved: 434.110464 MB\n",
      "-----------------\n",
      "points torch.Size([18451, 3])\n",
      "CVT loss:  tensor(0.0594, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(5.9404, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.00018264114623889327 weighted: 0.1826411485671997 : Allocated: 90.29888 MB, Reserved: 434.110464 MB\n",
      "SDF loss:  tensor(0.0690, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(68.9956, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1: loss = 74.93597412109375\n",
      "before loss.backward(): Allocated: 387.053568 MB, Reserved: 434.110464 MB\n",
      "After loss.backward(): Allocated: 83.175936 MB, Reserved: 434.110464 MB\n",
      "-----------------\n",
      "points torch.Size([18582, 3])\n",
      "CVT loss:  tensor(0.0415, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(4.1508, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.00011950699263252318 weighted: 0.11950699239969254 : Allocated: 90.330112 MB, Reserved: 434.110464 MB\n",
      "SDF loss:  tensor(0.0680, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(68.0228, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2: loss = 72.1736068725586\n",
      "before loss.backward(): Allocated: 388.76672 MB, Reserved: 434.110464 MB\n",
      "After loss.backward(): Allocated: 83.182592 MB, Reserved: 436.207616 MB\n",
      "-----------------\n",
      "points torch.Size([18685, 3])\n",
      "CVT loss:  tensor(0.0458, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(4.5838, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.00010153431503567845 weighted: 0.10153431445360184 : Allocated: 90.363392 MB, Reserved: 436.207616 MB\n",
      "SDF loss:  tensor(0.0672, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(67.1915, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3: loss = 71.77526092529297\n",
      "before loss.backward(): Allocated: 390.119424 MB, Reserved: 436.207616 MB\n",
      "After loss.backward(): Allocated: 83.1872 MB, Reserved: 436.207616 MB\n",
      "-----------------\n",
      "points torch.Size([18881, 3])\n",
      "CVT loss:  tensor(0.0361, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(3.6137, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 9.971886174753308e-05 weighted: 0.0997188612818718 : Allocated: 90.458112 MB, Reserved: 436.207616 MB\n",
      "SDF loss:  tensor(0.0664, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(66.3745, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 4: loss = 69.98816680908203\n",
      "before loss.backward(): Allocated: 392.732672 MB, Reserved: 436.207616 MB\n",
      "After loss.backward(): Allocated: 83.2 MB, Reserved: 436.207616 MB\n",
      "-----------------\n",
      "points torch.Size([19007, 3])\n",
      "CVT loss:  tensor(0.0362, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(3.6233, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 9.929084626492113e-05 weighted: 0.09929084777832031 : Allocated: 90.50624 MB, Reserved: 436.207616 MB\n",
      "SDF loss:  tensor(0.0656, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(65.5842, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5: loss = 69.20758056640625\n",
      "before loss.backward(): Allocated: 394.39872 MB, Reserved: 436.207616 MB\n",
      "After loss.backward(): Allocated: 83.206144 MB, Reserved: 436.207616 MB\n",
      "-----------------\n",
      "points torch.Size([18908, 3])\n",
      "CVT loss:  tensor(0.0361, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(3.6050, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 9.769186726771295e-05 weighted: 0.0976918637752533 : Allocated: 90.475008 MB, Reserved: 436.207616 MB\n",
      "SDF loss:  tensor(0.0648, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(64.7837, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6: loss = 68.38876342773438\n",
      "before loss.backward(): Allocated: 393.09568 MB, Reserved: 436.207616 MB\n",
      "After loss.backward(): Allocated: 83.201536 MB, Reserved: 436.207616 MB\n",
      "-----------------\n",
      "points torch.Size([18849, 3])\n",
      "CVT loss:  tensor(0.0491, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(4.9099, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 9.516943100607023e-05 weighted: 0.09516943246126175 : Allocated: 90.446336 MB, Reserved: 436.207616 MB\n",
      "SDF loss:  tensor(0.0640, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(64.0048, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 7: loss = 68.91472625732422\n",
      "before loss.backward(): Allocated: 392.310784 MB, Reserved: 436.207616 MB\n",
      "After loss.backward(): Allocated: 83.196928 MB, Reserved: 436.207616 MB\n",
      "-----------------\n",
      "points torch.Size([18916, 3])\n",
      "CVT loss:  tensor(0.0562, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(5.6195, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.00016105140093714 weighted: 0.161051407456398 : Allocated: 90.479616 MB, Reserved: 436.207616 MB\n",
      "SDF loss:  tensor(0.0632, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(63.2481, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8: loss = 68.86759185791016\n",
      "before loss.backward(): Allocated: 393.202688 MB, Reserved: 436.207616 MB\n",
      "After loss.backward(): Allocated: 83.201536 MB, Reserved: 436.207616 MB\n",
      "-----------------\n",
      "points torch.Size([18787, 3])\n",
      "CVT loss:  tensor(0.0432, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(4.3180, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.00016163788677658886 weighted: 0.16163788735866547 : Allocated: 90.423808 MB, Reserved: 436.207616 MB\n",
      "SDF loss:  tensor(0.0625, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(62.4702, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9: loss = 66.78817749023438\n",
      "before loss.backward(): Allocated: 391.49056 MB, Reserved: 436.207616 MB\n",
      "After loss.backward(): Allocated: 83.194368 MB, Reserved: 436.207616 MB\n",
      "-----------------\n",
      "points torch.Size([18755, 3])\n",
      "CVT loss:  tensor(0.0357, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(3.5738, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 9.190183482132852e-05 weighted: 0.09190183132886887 : Allocated: 90.401792 MB, Reserved: 436.207616 MB\n",
      "SDF loss:  tensor(0.0617, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(61.6747, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 10: loss = 65.24849700927734\n",
      "before loss.backward(): Allocated: 391.058432 MB, Reserved: 436.207616 MB\n",
      "After loss.backward(): Allocated: 83.19232 MB, Reserved: 436.207616 MB\n",
      "-----------------\n",
      "points torch.Size([18750, 3])\n",
      "CVT loss:  tensor(0.0325, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(3.2518, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 9.115273860516027e-05 weighted: 0.09115273505449295 : Allocated: 90.386944 MB, Reserved: 436.207616 MB\n",
      "SDF loss:  tensor(0.0609, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(60.9075, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11: loss = 64.15926361083984\n",
      "before loss.backward(): Allocated: 390.979584 MB, Reserved: 436.207616 MB\n",
      "After loss.backward(): Allocated: 83.190784 MB, Reserved: 436.207616 MB\n",
      "-----------------\n",
      "points torch.Size([18623, 3])\n",
      "CVT loss:  tensor(0.0433, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(4.3260, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 9.14331030799076e-05 weighted: 0.0914331004023552 : Allocated: 90.340864 MB, Reserved: 436.207616 MB\n",
      "SDF loss:  tensor(0.0601, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(60.1458, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12: loss = 64.47183227539062\n",
      "before loss.backward(): Allocated: 389.302784 MB, Reserved: 436.207616 MB\n",
      "After loss.backward(): Allocated: 83.18464 MB, Reserved: 436.207616 MB\n",
      "-----------------\n",
      "points torch.Size([18431, 3])\n",
      "CVT loss:  tensor(0.0325, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(3.2490, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 9.158851753454655e-05 weighted: 0.09158851951360703 : Allocated: 90.253824 MB, Reserved: 436.207616 MB\n",
      "SDF loss:  tensor(0.0594, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(59.3910, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 13: loss = 62.639930725097656\n",
      "before loss.backward(): Allocated: 386.748416 MB, Reserved: 436.207616 MB\n",
      "After loss.backward(): Allocated: 83.172864 MB, Reserved: 436.207616 MB\n",
      "-----------------\n",
      "points torch.Size([18493, 3])\n",
      "CVT loss:  tensor(0.0228, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(2.2817, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 9.342429984826595e-05 weighted: 0.09342429786920547 : Allocated: 90.277888 MB, Reserved: 436.207616 MB\n",
      "SDF loss:  tensor(0.0586, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(58.6488, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14: loss = 60.93045425415039\n",
      "before loss.backward(): Allocated: 387.570688 MB, Reserved: 436.207616 MB\n",
      "After loss.backward(): Allocated: 83.17696 MB, Reserved: 436.207616 MB\n",
      "-----------------\n",
      "points torch.Size([18547, 3])\n",
      "CVT loss:  tensor(0.0425, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(4.2501, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 9.196001337841153e-05 weighted: 0.09196001291275024 : Allocated: 90.302976 MB, Reserved: 436.207616 MB\n",
      "SDF loss:  tensor(0.0579, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(57.9032, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15: loss = 62.15327453613281\n",
      "before loss.backward(): Allocated: 388.287488 MB, Reserved: 436.207616 MB\n",
      "After loss.backward(): Allocated: 83.180032 MB, Reserved: 436.207616 MB\n",
      "-----------------\n",
      "points torch.Size([18601, 3])\n",
      "CVT loss:  tensor(0.0315, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(3.1479, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 9.324146230937913e-05 weighted: 0.09324146062135696 : Allocated: 90.326016 MB, Reserved: 436.207616 MB\n",
      "SDF loss:  tensor(0.0572, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(57.1540, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16: loss = 60.30190658569336\n",
      "before loss.backward(): Allocated: 389.005824 MB, Reserved: 436.207616 MB\n",
      "After loss.backward(): Allocated: 83.183104 MB, Reserved: 436.207616 MB\n",
      "-----------------\n",
      "points torch.Size([18747, 3])\n",
      "CVT loss:  tensor(0.0297, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(2.9654, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 9.201587818097323e-05 weighted: 0.09201587736606598 : Allocated: 90.37824 MB, Reserved: 436.207616 MB\n",
      "SDF loss:  tensor(0.0564, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(56.4154, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17: loss = 59.38078308105469\n",
      "before loss.backward(): Allocated: 390.93248 MB, Reserved: 436.207616 MB\n",
      "After loss.backward(): Allocated: 83.190784 MB, Reserved: 436.207616 MB\n",
      "-----------------\n",
      "points torch.Size([18841, 3])\n",
      "CVT loss:  tensor(0.0285, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(2.8493, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.00010023631330113858 weighted: 0.10023631155490875 : Allocated: 90.425344 MB, Reserved: 436.207616 MB\n",
      "SDF loss:  tensor(0.0557, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(55.6937, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18: loss = 58.543006896972656\n",
      "before loss.backward(): Allocated: 392.187392 MB, Reserved: 436.207616 MB\n",
      "After loss.backward(): Allocated: 83.196416 MB, Reserved: 436.207616 MB\n",
      "-----------------\n",
      "points torch.Size([18865, 3])\n",
      "CVT loss:  tensor(0.0267, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(2.6724, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 9.745282295625657e-05 weighted: 0.09745281934738159 : Allocated: 90.436096 MB, Reserved: 436.207616 MB\n",
      "SDF loss:  tensor(0.0550, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(54.9574, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19: loss = 57.629798889160156\n",
      "before loss.backward(): Allocated: 392.505856 MB, Reserved: 436.207616 MB\n",
      "After loss.backward(): Allocated: 83.197952 MB, Reserved: 436.207616 MB\n",
      "-----------------\n",
      "points torch.Size([18985, 3])\n",
      "CVT loss:  tensor(0.0276, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(2.7629, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 9.519702143734321e-05 weighted: 0.09519702196121216 : Allocated: 90.491904 MB, Reserved: 436.207616 MB\n",
      "SDF loss:  tensor(0.0542, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(54.2297, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20: loss = 56.99256896972656\n",
      "before loss.backward(): Allocated: 394.102272 MB, Reserved: 436.207616 MB\n",
      "After loss.backward(): Allocated: 83.20512 MB, Reserved: 436.207616 MB\n",
      "-----------------\n",
      "points torch.Size([19057, 3])\n",
      "CVT loss:  tensor(0.0302, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(3.0176, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 9.374554792884737e-05 weighted: 0.09374554455280304 : Allocated: 90.519552 MB, Reserved: 436.207616 MB\n",
      "SDF loss:  tensor(0.0535, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(53.5006, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21: loss = 56.51816177368164\n",
      "before loss.backward(): Allocated: 395.052544 MB, Reserved: 436.207616 MB\n",
      "After loss.backward(): Allocated: 83.208704 MB, Reserved: 436.207616 MB\n",
      "-----------------\n",
      "points torch.Size([19124, 3])\n",
      "CVT loss:  tensor(0.0254, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(2.5386, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 9.385656449012458e-05 weighted: 0.0938565656542778 : Allocated: 90.544128 MB, Reserved: 436.207616 MB\n",
      "SDF loss:  tensor(0.0528, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(52.7766, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 22: loss = 55.31519317626953\n",
      "before loss.backward(): Allocated: 395.939328 MB, Reserved: 436.207616 MB\n",
      "After loss.backward(): Allocated: 83.2128 MB, Reserved: 436.207616 MB\n",
      "-----------------\n",
      "points torch.Size([19224, 3])\n",
      "CVT loss:  tensor(0.0228, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(2.2751, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 9.239165228791535e-05 weighted: 0.09239165484905243 : Allocated: 90.57792 MB, Reserved: 436.207616 MB\n",
      "SDF loss:  tensor(0.0521, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(52.0567, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 23: loss = 54.33183670043945\n",
      "before loss.backward(): Allocated: 397.257728 MB, Reserved: 436.207616 MB\n",
      "After loss.backward(): Allocated: 83.21792 MB, Reserved: 436.207616 MB\n",
      "-----------------\n",
      "points torch.Size([19265, 3])\n",
      "CVT loss:  tensor(0.0352, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(3.5185, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 9.056988346856087e-05 weighted: 0.0905698835849762 : Allocated: 90.603008 MB, Reserved: 436.207616 MB\n",
      "SDF loss:  tensor(0.0513, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(51.3465, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 24: loss = 54.86500930786133\n",
      "before loss.backward(): Allocated: 397.808128 MB, Reserved: 436.207616 MB\n",
      "After loss.backward(): Allocated: 83.220992 MB, Reserved: 436.207616 MB\n",
      "-----------------\n",
      "points torch.Size([19333, 3])\n",
      "CVT loss:  tensor(0.0285, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(2.8539, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 8.74431716511026e-05 weighted: 0.08744317293167114 : Allocated: 90.633728 MB, Reserved: 436.207616 MB\n",
      "SDF loss:  tensor(0.0506, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(50.6273, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 25: loss = 53.481178283691406\n",
      "before loss.backward(): Allocated: 398.713856 MB, Reserved: 436.207616 MB\n",
      "After loss.backward(): Allocated: 83.225088 MB, Reserved: 436.207616 MB\n",
      "-----------------\n",
      "points torch.Size([19497, 3])\n",
      "CVT loss:  tensor(0.0278, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(2.7753, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 8.633092511445284e-05 weighted: 0.08633092790842056 : Allocated: 90.704896 MB, Reserved: 436.207616 MB\n",
      "SDF loss:  tensor(0.0499, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(49.9251, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 26: loss = 52.70037078857422\n",
      "before loss.backward(): Allocated: 412.968448 MB, Reserved: 436.207616 MB\n",
      "After loss.backward(): Allocated: 83.234304 MB, Reserved: 436.207616 MB\n",
      "-----------------\n",
      "points torch.Size([19553, 3])\n",
      "CVT loss:  tensor(0.0291, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(2.9061, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 8.546386379748583e-05 weighted: 0.08546386659145355 : Allocated: 90.72128 MB, Reserved: 436.207616 MB\n",
      "SDF loss:  tensor(0.0492, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(49.2220, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 27: loss = 52.12803649902344\n",
      "before loss.backward(): Allocated: 413.014528 MB, Reserved: 436.207616 MB\n",
      "After loss.backward(): Allocated: 83.237376 MB, Reserved: 436.207616 MB\n",
      "-----------------\n",
      "points torch.Size([19711, 3])\n",
      "CVT loss:  tensor(0.0273, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(2.7302, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 8.369760325876996e-05 weighted: 0.0836976021528244 : Allocated: 90.791936 MB, Reserved: 436.207616 MB\n",
      "SDF loss:  tensor(0.0485, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(48.5312, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 28: loss = 51.261409759521484\n",
      "before loss.backward(): Allocated: 413.1712 MB, Reserved: 436.207616 MB\n",
      "After loss.backward(): Allocated: 83.24608 MB, Reserved: 436.207616 MB\n",
      "-----------------\n",
      "points torch.Size([19724, 3])\n",
      "CVT loss:  tensor(0.0248, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(2.4801, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 8.256491855718195e-05 weighted: 0.08256492018699646 : Allocated: 90.800128 MB, Reserved: 436.207616 MB\n",
      "SDF loss:  tensor(0.0478, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(47.8434, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 29: loss = 50.323585510253906\n",
      "before loss.backward(): Allocated: 413.190144 MB, Reserved: 436.207616 MB\n",
      "After loss.backward(): Allocated: 83.247616 MB, Reserved: 436.207616 MB\n",
      "-----------------\n",
      "points torch.Size([19951, 3])\n",
      "CVT loss:  tensor(0.0331, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(3.3114, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 8.130184141919017e-05 weighted: 0.08130183815956116 : Allocated: 90.894336 MB, Reserved: 436.207616 MB\n",
      "SDF loss:  tensor(0.0472, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(47.1614, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 30: loss = 50.47285461425781\n",
      "before loss.backward(): Allocated: 413.40672 MB, Reserved: 436.207616 MB\n",
      "After loss.backward(): Allocated: 83.259904 MB, Reserved: 436.207616 MB\n",
      "-----------------\n",
      "points torch.Size([19953, 3])\n",
      "CVT loss:  tensor(0.0248, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(2.4831, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 8.064418216235936e-05 weighted: 0.08064418286085129 : Allocated: 90.898432 MB, Reserved: 436.207616 MB\n",
      "SDF loss:  tensor(0.0465, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(46.4806, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 31: loss = 48.96366882324219\n",
      "before loss.backward(): Allocated: 413.41184 MB, Reserved: 436.207616 MB\n",
      "After loss.backward(): Allocated: 83.259904 MB, Reserved: 436.207616 MB\n",
      "-----------------\n",
      "points torch.Size([20151, 3])\n",
      "CVT loss:  tensor(0.0258, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(2.5815, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 8.020192035473883e-05 weighted: 0.08020192384719849 : Allocated: 90.976768 MB, Reserved: 436.207616 MB\n",
      "SDF loss:  tensor(0.0458, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(45.8050, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 32: loss = 48.38652420043945\n",
      "before loss.backward(): Allocated: 413.60128 MB, Reserved: 436.207616 MB\n",
      "After loss.backward(): Allocated: 83.27168 MB, Reserved: 436.207616 MB\n",
      "-----------------\n",
      "points torch.Size([20266, 3])\n",
      "CVT loss:  tensor(0.0253, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(2.5282, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 7.933502638479695e-05 weighted: 0.07933502644300461 : Allocated: 91.02336 MB, Reserved: 436.207616 MB\n",
      "SDF loss:  tensor(0.0451, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(45.1274, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 33: loss = 47.65553665161133\n",
      "before loss.backward(): Allocated: 413.71136 MB, Reserved: 436.207616 MB\n",
      "After loss.backward(): Allocated: 83.277824 MB, Reserved: 436.207616 MB\n",
      "-----------------\n",
      "points torch.Size([20308, 3])\n",
      "CVT loss:  tensor(0.0200, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(2.0021, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 7.903268124209717e-05 weighted: 0.07903268188238144 : Allocated: 91.04128 MB, Reserved: 436.207616 MB\n",
      "SDF loss:  tensor(0.0445, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(44.4529, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 34: loss = 46.4550666809082\n",
      "before loss.backward(): Allocated: 413.751296 MB, Reserved: 436.207616 MB\n",
      "After loss.backward(): Allocated: 83.280384 MB, Reserved: 436.207616 MB\n",
      "-----------------\n",
      "points torch.Size([20346, 3])\n",
      "CVT loss:  tensor(0.0225, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(2.2480, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 7.812754483893514e-05 weighted: 0.07812754809856415 : Allocated: 91.065344 MB, Reserved: 436.207616 MB\n",
      "SDF loss:  tensor(0.0438, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(43.7837, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 35: loss = 46.03171157836914\n",
      "before loss.backward(): Allocated: 413.795328 MB, Reserved: 436.207616 MB\n",
      "After loss.backward(): Allocated: 83.282432 MB, Reserved: 436.207616 MB\n",
      "-----------------\n",
      "points torch.Size([20521, 3])\n",
      "CVT loss:  tensor(0.0337, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(3.3672, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 7.687101606279612e-05 weighted: 0.07687101513147354 : Allocated: 91.134976 MB, Reserved: 436.207616 MB\n",
      "SDF loss:  tensor(0.0431, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(43.1207, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 36: loss = 46.487884521484375\n",
      "before loss.backward(): Allocated: 418.57792 MB, Reserved: 562.036736 MB\n",
      "After loss.backward(): Allocated: 83.29216 MB, Reserved: 622.854144 MB\n",
      "-----------------\n",
      "points torch.Size([20634, 3])\n",
      "CVT loss:  tensor(0.0342, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(3.4216, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 7.62068884796463e-05 weighted: 0.07620688527822495 : Allocated: 91.184128 MB, Reserved: 622.854144 MB\n",
      "SDF loss:  tensor(0.0425, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(42.4617, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 37: loss = 45.883296966552734\n",
      "before loss.backward(): Allocated: 419.847168 MB, Reserved: 622.854144 MB\n",
      "After loss.backward(): Allocated: 83.299328 MB, Reserved: 622.854144 MB\n",
      "-----------------\n",
      "points torch.Size([20834, 3])\n",
      "CVT loss:  tensor(0.0398, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(3.9799, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 7.555366028100252e-05 weighted: 0.07555366307497025 : Allocated: 91.266048 MB, Reserved: 622.854144 MB\n",
      "SDF loss:  tensor(0.0418, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(41.8047, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 38: loss = 45.78459548950195\n",
      "before loss.backward(): Allocated: 422.085632 MB, Reserved: 622.854144 MB\n",
      "After loss.backward(): Allocated: 83.310592 MB, Reserved: 622.854144 MB\n",
      "-----------------\n",
      "points torch.Size([20883, 3])\n",
      "CVT loss:  tensor(0.0373, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(3.7312, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 7.495723548345268e-05 weighted: 0.0749572366476059 : Allocated: 91.284992 MB, Reserved: 622.854144 MB\n",
      "SDF loss:  tensor(0.0412, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(41.1518, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 39: loss = 44.88302230834961\n",
      "before loss.backward(): Allocated: 422.63552 MB, Reserved: 622.854144 MB\n",
      "After loss.backward(): Allocated: 83.313664 MB, Reserved: 622.854144 MB\n",
      "-----------------\n",
      "points torch.Size([20914, 3])\n",
      "CVT loss:  tensor(0.0368, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(3.6826, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 7.44081407901831e-05 weighted: 0.0744081437587738 : Allocated: 91.29728 MB, Reserved: 622.854144 MB\n",
      "SDF loss:  tensor(0.0405, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(40.5081, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 40: loss = 44.19070816040039\n",
      "before loss.backward(): Allocated: 422.981632 MB, Reserved: 622.854144 MB\n",
      "After loss.backward(): Allocated: 83.3152 MB, Reserved: 622.854144 MB\n",
      "-----------------\n",
      "points torch.Size([21033, 3])\n",
      "CVT loss:  tensor(0.0347, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(3.4707, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 7.405132055282593e-05 weighted: 0.07405132055282593 : Allocated: 91.34592 MB, Reserved: 622.854144 MB\n",
      "SDF loss:  tensor(0.0399, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(39.8636, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 41: loss = 43.33430099487305\n",
      "before loss.backward(): Allocated: 424.314368 MB, Reserved: 622.854144 MB\n",
      "After loss.backward(): Allocated: 83.321856 MB, Reserved: 624.951296 MB\n",
      "-----------------\n",
      "points torch.Size([21048, 3])\n",
      "CVT loss:  tensor(0.0230, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(2.3000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 7.351450767600909e-05 weighted: 0.07351450622081757 : Allocated: 91.355648 MB, Reserved: 624.951296 MB\n",
      "SDF loss:  tensor(0.0392, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(39.2245, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 42: loss = 41.5245246887207\n",
      "before loss.backward(): Allocated: 424.485888 MB, Reserved: 624.951296 MB\n",
      "After loss.backward(): Allocated: 83.32288 MB, Reserved: 624.951296 MB\n",
      "-----------------\n",
      "points torch.Size([21053, 3])\n",
      "CVT loss:  tensor(0.0449, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(4.4870, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 7.328050560317934e-05 weighted: 0.07328050583600998 : Allocated: 91.35616 MB, Reserved: 624.951296 MB\n",
      "SDF loss:  tensor(0.0386, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(38.5888, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 43: loss = 43.0758056640625\n",
      "before loss.backward(): Allocated: 424.54016 MB, Reserved: 624.951296 MB\n",
      "After loss.backward(): Allocated: 83.32288 MB, Reserved: 624.951296 MB\n",
      "-----------------\n",
      "points torch.Size([21048, 3])\n",
      "CVT loss:  tensor(0.0300, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(2.9976, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 7.309306238312274e-05 weighted: 0.07309306412935257 : Allocated: 91.35616 MB, Reserved: 624.951296 MB\n",
      "SDF loss:  tensor(0.0380, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(37.9612, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 44: loss = 40.958778381347656\n",
      "before loss.backward(): Allocated: 424.4864 MB, Reserved: 624.951296 MB\n",
      "After loss.backward(): Allocated: 83.32288 MB, Reserved: 624.951296 MB\n",
      "-----------------\n",
      "points torch.Size([20920, 3])\n",
      "CVT loss:  tensor(0.0459, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(4.5933, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 7.345360791077837e-05 weighted: 0.07345360517501831 : Allocated: 91.306496 MB, Reserved: 624.951296 MB\n",
      "SDF loss:  tensor(0.0373, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(37.3308, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 45: loss = 41.9240608215332\n",
      "before loss.backward(): Allocated: 423.05536 MB, Reserved: 624.951296 MB\n",
      "After loss.backward(): Allocated: 83.315712 MB, Reserved: 624.951296 MB\n",
      "-----------------\n",
      "points torch.Size([21083, 3])\n",
      "CVT loss:  tensor(0.0362, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(3.6166, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 7.314630784094334e-05 weighted: 0.07314630597829819 : Allocated: 91.36896 MB, Reserved: 624.951296 MB\n",
      "SDF loss:  tensor(0.0367, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(36.7064, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 46: loss = 40.322940826416016\n",
      "before loss.backward(): Allocated: 424.876032 MB, Reserved: 624.951296 MB\n",
      "After loss.backward(): Allocated: 83.324928 MB, Reserved: 624.951296 MB\n",
      "-----------------\n",
      "points torch.Size([21123, 3])\n",
      "CVT loss:  tensor(0.0312, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(3.1224, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 7.280557474587113e-05 weighted: 0.07280557602643967 : Allocated: 91.384832 MB, Reserved: 624.951296 MB\n",
      "SDF loss:  tensor(0.0361, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(36.0868, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 47: loss = 39.20918655395508\n",
      "before loss.backward(): Allocated: 425.32608 MB, Reserved: 624.951296 MB\n",
      "After loss.backward(): Allocated: 83.327488 MB, Reserved: 624.951296 MB\n",
      "-----------------\n",
      "points torch.Size([21184, 3])\n",
      "CVT loss:  tensor(0.0436, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(4.3567, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 7.244733569677919e-05 weighted: 0.07244733721017838 : Allocated: 91.414528 MB, Reserved: 624.951296 MB\n",
      "SDF loss:  tensor(0.0355, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(35.4713, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 48: loss = 39.828033447265625\n",
      "before loss.backward(): Allocated: 426.01216 MB, Reserved: 624.951296 MB\n",
      "After loss.backward(): Allocated: 83.33056 MB, Reserved: 624.951296 MB\n",
      "-----------------\n",
      "points torch.Size([21227, 3])\n",
      "CVT loss:  tensor(0.0352, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(3.5219, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 7.233872020151466e-05 weighted: 0.07233872264623642 : Allocated: 91.429888 MB, Reserved: 624.951296 MB\n",
      "SDF loss:  tensor(0.0349, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(34.8592, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 49: loss = 38.38100814819336\n",
      "before loss.backward(): Allocated: 426.490368 MB, Reserved: 624.951296 MB\n",
      "After loss.backward(): Allocated: 83.332608 MB, Reserved: 624.951296 MB\n",
      "-----------------\n",
      "points torch.Size([21378, 3])\n",
      "CVT loss:  tensor(0.0388, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(3.8849, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 7.17184811946936e-05 weighted: 0.0717184841632843 : Allocated: 91.492352 MB, Reserved: 624.951296 MB\n",
      "SDF loss:  tensor(0.0343, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(34.2502, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 50: loss = 38.1351203918457\n",
      "before loss.backward(): Allocated: 428.1856 MB, Reserved: 624.951296 MB\n",
      "After loss.backward(): Allocated: 83.341824 MB, Reserved: 624.951296 MB\n",
      "-----------------\n",
      "points torch.Size([21328, 3])\n",
      "CVT loss:  tensor(0.0315, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(3.1499, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 7.142635149648413e-05 weighted: 0.07142635434865952 : Allocated: 91.473408 MB, Reserved: 624.951296 MB\n",
      "SDF loss:  tensor(0.0336, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(33.6471, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 51: loss = 36.797035217285156\n",
      "before loss.backward(): Allocated: 427.624448 MB, Reserved: 624.951296 MB\n",
      "After loss.backward(): Allocated: 83.338752 MB, Reserved: 624.951296 MB\n",
      "-----------------\n",
      "points torch.Size([21290, 3])\n",
      "CVT loss:  tensor(0.0297, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(2.9736, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 7.122631359379739e-05 weighted: 0.07122631371021271 : Allocated: 91.462656 MB, Reserved: 624.951296 MB\n",
      "SDF loss:  tensor(0.0330, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(33.0422, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 52: loss = 36.01573944091797\n",
      "before loss.backward(): Allocated: 427.204608 MB, Reserved: 624.951296 MB\n",
      "After loss.backward(): Allocated: 83.336704 MB, Reserved: 624.951296 MB\n",
      "-----------------\n",
      "points torch.Size([21402, 3])\n",
      "CVT loss:  tensor(0.0336, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(3.3644, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 7.096716581145301e-05 weighted: 0.0709671676158905 : Allocated: 91.50208 MB, Reserved: 624.951296 MB\n",
      "SDF loss:  tensor(0.0324, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(32.4437, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 53: loss = 35.80814743041992\n",
      "before loss.backward(): Allocated: 428.453376 MB, Reserved: 624.951296 MB\n",
      "After loss.backward(): Allocated: 83.342848 MB, Reserved: 624.951296 MB\n",
      "-----------------\n",
      "points torch.Size([21466, 3])\n",
      "CVT loss:  tensor(0.0396, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(3.9565, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 7.108142017386854e-05 weighted: 0.07108142226934433 : Allocated: 91.525632 MB, Reserved: 624.951296 MB\n",
      "SDF loss:  tensor(0.0318, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(31.8467, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 54: loss = 35.80322265625\n",
      "before loss.backward(): Allocated: 429.16608 MB, Reserved: 624.951296 MB\n",
      "After loss.backward(): Allocated: 83.346432 MB, Reserved: 624.951296 MB\n",
      "-----------------\n",
      "points torch.Size([21570, 3])\n",
      "CVT loss:  tensor(0.0424, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(4.2449, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 7.402129267575219e-05 weighted: 0.07402129471302032 : Allocated: 91.570176 MB, Reserved: 624.951296 MB\n",
      "SDF loss:  tensor(0.0313, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(31.2523, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 55: loss = 35.49728012084961\n",
      "before loss.backward(): Allocated: 430.33344 MB, Reserved: 624.951296 MB\n",
      "After loss.backward(): Allocated: 83.353088 MB, Reserved: 624.951296 MB\n",
      "-----------------\n",
      "points torch.Size([21698, 3])\n",
      "CVT loss:  tensor(0.0643, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(6.4332, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.00016019289614632726 weighted: 0.16019289195537567 : Allocated: 91.639296 MB, Reserved: 624.951296 MB\n",
      "SDF loss:  tensor(0.0307, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(30.6964, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 56: loss = 37.12960433959961\n",
      "before loss.backward(): Allocated: 431.783936 MB, Reserved: 624.951296 MB\n",
      "After loss.backward(): Allocated: 83.360768 MB, Reserved: 624.951296 MB\n",
      "-----------------\n",
      "points torch.Size([21618, 3])\n",
      "CVT loss:  tensor(0.0572, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(5.7195, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 7.352470129262656e-05 weighted: 0.07352469861507416 : Allocated: 91.592192 MB, Reserved: 624.951296 MB\n",
      "SDF loss:  tensor(0.0301, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(30.0740, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 57: loss = 35.793479919433594\n",
      "before loss.backward(): Allocated: 430.872064 MB, Reserved: 624.951296 MB\n",
      "After loss.backward(): Allocated: 83.355136 MB, Reserved: 624.951296 MB\n",
      "-----------------\n",
      "points torch.Size([21645, 3])\n",
      "CVT loss:  tensor(0.0508, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(5.0846, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 7.169668970163912e-05 weighted: 0.0716966912150383 : Allocated: 91.609088 MB, Reserved: 624.951296 MB\n",
      "SDF loss:  tensor(0.0295, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(29.4934, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 58: loss = 34.5780029296875\n",
      "before loss.backward(): Allocated: 431.18336 MB, Reserved: 624.951296 MB\n",
      "After loss.backward(): Allocated: 83.357184 MB, Reserved: 624.951296 MB\n",
      "-----------------\n",
      "points torch.Size([21795, 3])\n",
      "CVT loss:  tensor(0.0454, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(4.5394, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 7.116886990843341e-05 weighted: 0.07116886973381042 : Allocated: 91.664384 MB, Reserved: 624.951296 MB\n",
      "SDF loss:  tensor(0.0289, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(28.9185, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 59: loss = 33.4578971862793\n",
      "before loss.backward(): Allocated: 432.856576 MB, Reserved: 624.951296 MB\n",
      "After loss.backward(): Allocated: 83.365376 MB, Reserved: 624.951296 MB\n",
      "-----------------\n",
      "points torch.Size([21850, 3])\n",
      "CVT loss:  tensor(0.0449, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(4.4884, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 8.479703683406115e-05 weighted: 0.08479703962802887 : Allocated: 91.688448 MB, Reserved: 624.951296 MB\n",
      "SDF loss:  tensor(0.0284, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(28.3682, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 60: loss = 32.85658264160156\n",
      "before loss.backward(): Allocated: 433.473024 MB, Reserved: 624.951296 MB\n",
      "After loss.backward(): Allocated: 83.369472 MB, Reserved: 624.951296 MB\n",
      "-----------------\n",
      "points torch.Size([21790, 3])\n",
      "CVT loss:  tensor(0.0496, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(4.9598, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 7.117868517525494e-05 weighted: 0.07117868214845657 : Allocated: 91.664384 MB, Reserved: 624.951296 MB\n",
      "SDF loss:  tensor(0.0278, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(27.7805, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 61: loss = 32.74029541015625\n",
      "before loss.backward(): Allocated: 432.802816 MB, Reserved: 624.951296 MB\n",
      "After loss.backward(): Allocated: 83.365376 MB, Reserved: 624.951296 MB\n",
      "-----------------\n",
      "points torch.Size([21891, 3])\n",
      "CVT loss:  tensor(0.0448, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(4.4806, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 7.099370122887194e-05 weighted: 0.07099369913339615 : Allocated: 91.705344 MB, Reserved: 624.951296 MB\n",
      "SDF loss:  tensor(0.0272, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(27.2164, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 62: loss = 31.697038650512695\n",
      "before loss.backward(): Allocated: 433.934848 MB, Reserved: 624.951296 MB\n",
      "After loss.backward(): Allocated: 83.371008 MB, Reserved: 624.951296 MB\n",
      "-----------------\n",
      "points torch.Size([21950, 3])\n",
      "CVT loss:  tensor(0.0285, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(2.8522, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 7.519771315855905e-05 weighted: 0.07519771158695221 : Allocated: 91.734528 MB, Reserved: 624.951296 MB\n",
      "SDF loss:  tensor(0.0267, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(26.6726, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 63: loss = 29.524761199951172\n",
      "before loss.backward(): Allocated: 434.598912 MB, Reserved: 624.951296 MB\n",
      "After loss.backward(): Allocated: 83.37408 MB, Reserved: 624.951296 MB\n",
      "-----------------\n",
      "points torch.Size([22035, 3])\n",
      "CVT loss:  tensor(0.0221, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(2.2122, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 7.61798582971096e-05 weighted: 0.0761798620223999 : Allocated: 91.77088 MB, Reserved: 624.951296 MB\n",
      "SDF loss:  tensor(0.0261, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(26.1209, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 64: loss = 28.333066940307617\n",
      "before loss.backward(): Allocated: 435.553792 MB, Reserved: 624.951296 MB\n",
      "After loss.backward(): Allocated: 83.3792 MB, Reserved: 624.951296 MB\n",
      "-----------------\n",
      "points torch.Size([22035, 3])\n",
      "CVT loss:  tensor(0.0189, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(1.8881, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 7.45708093745634e-05 weighted: 0.07457081228494644 : Allocated: 91.775488 MB, Reserved: 624.951296 MB\n",
      "SDF loss:  tensor(0.0256, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(25.5734, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 65: loss = 27.461502075195312\n",
      "before loss.backward(): Allocated: 435.5584 MB, Reserved: 624.951296 MB\n",
      "After loss.backward(): Allocated: 83.3792 MB, Reserved: 624.951296 MB\n",
      "-----------------\n",
      "points torch.Size([21965, 3])\n",
      "CVT loss:  tensor(0.0304, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(3.0439, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 7.296814146684483e-05 weighted: 0.07296814024448395 : Allocated: 91.746816 MB, Reserved: 624.951296 MB\n",
      "SDF loss:  tensor(0.0250, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(25.0307, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 66: loss = 28.074634552001953\n",
      "before loss.backward(): Allocated: 434.77248 MB, Reserved: 624.951296 MB\n",
      "After loss.backward(): Allocated: 83.375104 MB, Reserved: 624.951296 MB\n",
      "-----------------\n",
      "points torch.Size([22039, 3])\n",
      "CVT loss:  tensor(0.0242, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(2.4231, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 7.422879571095109e-05 weighted: 0.07422879338264465 : Allocated: 91.775488 MB, Reserved: 624.951296 MB\n",
      "SDF loss:  tensor(0.0245, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(24.4983, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 67: loss = 26.921438217163086\n",
      "before loss.backward(): Allocated: 435.601408 MB, Reserved: 624.951296 MB\n",
      "After loss.backward(): Allocated: 83.3792 MB, Reserved: 624.951296 MB\n",
      "-----------------\n",
      "points torch.Size([22093, 3])\n",
      "CVT loss:  tensor(0.0125, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(1.2497, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 7.388072117464617e-05 weighted: 0.07388072460889816 : Allocated: 91.794432 MB, Reserved: 624.951296 MB\n",
      "SDF loss:  tensor(0.0240, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(23.9658, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 68: loss = 25.21554946899414\n",
      "before loss.backward(): Allocated: 436.201472 MB, Reserved: 624.951296 MB\n",
      "After loss.backward(): Allocated: 83.382784 MB, Reserved: 624.951296 MB\n",
      "-----------------\n",
      "points torch.Size([22058, 3])\n",
      "CVT loss:  tensor(0.0111, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(1.1052, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 7.235138764372095e-05 weighted: 0.07235138863325119 : Allocated: 91.78112 MB, Reserved: 624.951296 MB\n",
      "SDF loss:  tensor(0.0234, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(23.4383, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 69: loss = 24.543516159057617\n",
      "before loss.backward(): Allocated: 435.811328 MB, Reserved: 624.951296 MB\n",
      "After loss.backward(): Allocated: 83.380224 MB, Reserved: 624.951296 MB\n",
      "-----------------\n",
      "points torch.Size([22082, 3])\n",
      "CVT loss:  tensor(0.0105, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(1.0513, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 7.119801739463583e-05 weighted: 0.07119801640510559 : Allocated: 91.798016 MB, Reserved: 624.951296 MB\n",
      "SDF loss:  tensor(0.0229, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(22.9171, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 70: loss = 23.968332290649414\n",
      "before loss.backward(): Allocated: 436.086784 MB, Reserved: 624.951296 MB\n",
      "After loss.backward(): Allocated: 83.382272 MB, Reserved: 624.951296 MB\n",
      "-----------------\n",
      "points torch.Size([22139, 3])\n",
      "CVT loss:  tensor(0.0094, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.9396, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 7.09198066033423e-05 weighted: 0.07091980427503586 : Allocated: 91.822592 MB, Reserved: 624.951296 MB\n",
      "SDF loss:  tensor(0.0224, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(22.4000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 71: loss = 23.339580535888672\n",
      "before loss.backward(): Allocated: 436.724736 MB, Reserved: 624.951296 MB\n",
      "After loss.backward(): Allocated: 83.384832 MB, Reserved: 624.951296 MB\n",
      "-----------------\n",
      "points torch.Size([22170, 3])\n",
      "CVT loss:  tensor(0.0102, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(1.0229, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 7.094665488693863e-05 weighted: 0.07094665616750717 : Allocated: 91.82976 MB, Reserved: 624.951296 MB\n",
      "SDF loss:  tensor(0.0219, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(21.8852, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 72: loss = 22.908130645751953\n",
      "before loss.backward(): Allocated: 437.069312 MB, Reserved: 624.951296 MB\n",
      "After loss.backward(): Allocated: 83.387392 MB, Reserved: 624.951296 MB\n",
      "-----------------\n",
      "points torch.Size([22210, 3])\n",
      "CVT loss:  tensor(0.0105, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(1.0454, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 7.097245543263853e-05 weighted: 0.07097245752811432 : Allocated: 91.84256 MB, Reserved: 624.951296 MB\n",
      "SDF loss:  tensor(0.0214, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(21.3795, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 73: loss = 22.42485809326172\n",
      "before loss.backward(): Allocated: 437.512704 MB, Reserved: 624.951296 MB\n",
      "After loss.backward(): Allocated: 83.388928 MB, Reserved: 624.951296 MB\n",
      "-----------------\n",
      "points torch.Size([22220, 3])\n",
      "CVT loss:  tensor(0.0090, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.8994, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 7.105486292857677e-05 weighted: 0.0710548609495163 : Allocated: 91.847168 MB, Reserved: 624.951296 MB\n",
      "SDF loss:  tensor(0.0209, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(20.8787, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 74: loss = 21.778064727783203\n",
      "before loss.backward(): Allocated: 437.624832 MB, Reserved: 624.951296 MB\n",
      "After loss.backward(): Allocated: 83.38944 MB, Reserved: 624.951296 MB\n",
      "-----------------\n",
      "points torch.Size([22241, 3])\n",
      "CVT loss:  tensor(0.0079, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.7922, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 7.112313323887065e-05 weighted: 0.07112313061952591 : Allocated: 91.85792 MB, Reserved: 624.951296 MB\n",
      "SDF loss:  tensor(0.0204, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(20.3804, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 75: loss = 21.172592163085938\n",
      "before loss.backward(): Allocated: 437.861888 MB, Reserved: 624.951296 MB\n",
      "After loss.backward(): Allocated: 83.390976 MB, Reserved: 624.951296 MB\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "site_file_path = f'{destination}{max_iter}_cvt_{lambda_cvt}_chamfer_{lambda_chamfer}_eikonal_{lambda_eikonal}.npy'\n",
    "#check if optimized sites file exists\n",
    "if not os.path.exists(site_file_path):\n",
    "    #import sites\n",
    "    print(\"Importing sites\")\n",
    "    sites = np.load(site_file_path)\n",
    "    sites = torch.from_numpy(sites).to(device).requires_grad_(True)\n",
    "else:\n",
    "    # import cProfile, pstats\n",
    "    # import time\n",
    "    # profiler = cProfile.Profile()\n",
    "    # profiler.enable()\n",
    "\n",
    "#     with torch.profiler.profile(activities=[\n",
    "#             torch.profiler.ProfilerActivity.CPU,\n",
    "#             torch.profiler.ProfilerActivity.CUDA,\n",
    "#         ],\n",
    "#         record_shapes=False,\n",
    "#         with_stack=True  # Captures function calls\n",
    "#     ) as prof:\n",
    "#         sites = autograd(sites, model, max_iter=max_iter, upsampling=0, lambda_weights=lambda_weights)\n",
    "#         torch.cuda.synchronize()\n",
    "# # \n",
    "#     print(prof.key_averages().table(sort_by=\"self_cuda_time_total\"))\n",
    "#     prof.export_chrome_trace(\"trace.json\")\n",
    "    \n",
    "    # \n",
    "    sites = autograd(sites, model, max_iter=max_iter, upsampling=0, lambda_weights=lambda_weights)\n",
    "\n",
    "    \n",
    "    # profiler.disable()\n",
    "    # stats = pstats.Stats(profiler).sort_stats('cumtime')\n",
    "    # stats.print_stats()\n",
    "    # stats.dump_stats(f'{destination}{mesh[0]}{max_iter}_3d_profile_{num_centroids}_chamfer{lambda_chamfer}.prof')\n",
    "    \n",
    "    \n",
    "    sites_np = sites.detach().cpu().numpy()\n",
    "    np.save(site_file_path, sites_np)\n",
    "    \n",
    "    \n",
    "\n",
    "print(\"Sites length: \", len(sites))\n",
    "print(\"min sites: \", torch.min(sites))\n",
    "print(\"max sites: \", torch.max(sites))\n",
    "#ps_cloud = ps.register_point_cloud(\"best_optimized_cvt_grid\",sites.detach().cpu().numpy())\n",
    "    \n",
    "lim=torch.abs(torch.max(sites)).detach().cpu().numpy()*1.1\n",
    "#plot_voronoi_3d(sites,lim,lim,lim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4e4fcfff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model ./images/autograd/HotSpot/bunny100_100_3d_model_512_chamfer1000.pth\n",
      "sites ./images/autograd/HotSpot/bunny100_100_3d_sites_512_chamfer1000.pth\n"
     ]
    }
   ],
   "source": [
    "epoch = 100\n",
    "\n",
    "model_file_path = f'{destination}{mesh[0]}{max_iter}_{epoch}_3d_model_{num_centroids}_chamfer{lambda_chamfer}.pth'\n",
    "site_file_path = f'{destination}{mesh[0]}{max_iter}_{epoch}_3d_sites_{num_centroids}_chamfer{lambda_chamfer}.pth'\n",
    " \n",
    "sites = torch.load(site_file_path)\n",
    "\n",
    "sites_np = sites.detach().cpu().numpy()\n",
    "model.load_state_dict(torch.load(model_file_path))\n",
    "#\n",
    "#polyscope_sdf(model)\n",
    "#\n",
    "print(\"model\", model_file_path)\n",
    "print(\"sites\", site_file_path)\n",
    "ps_cloud = ps.register_point_cloud(f\"{epoch} epoch_cvt_grid\",sites_np)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72bc0096",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import itertools\n",
    "\n",
    "def get_clipped_mesh(sites, model):\n",
    "    sites_np = sites.detach().cpu().numpy()\n",
    "    d3dsimplices = diffvoronoi.get_delaunay_simplices(sites_np.reshape(input_dims*sites_np.shape[0]))\n",
    "    d3dsimplices_np = np.array(d3dsimplices)\n",
    "    \n",
    "    sdf_values = model(sites)\n",
    "    # sdf_gradients = torch.autograd.grad(outputs=sdf_values, inputs=sites, grad_outputs=torch.ones_like(sdf_values), create_graph=True, retain_graph=True,)[0] # (N, 3)\n",
    "    # N, D = sites.shape\n",
    "    # hess_sdf = torch.zeros(N, D, D, device=sites.device)\n",
    "    # for i in range(D):\n",
    "    #     grad2 = torch.autograd.grad(outputs=sdf_gradients[:, i], inputs=sites, grad_outputs=torch.ones_like(sdf_gradients[:, i]), create_graph=False, retain_graph=True,)[0] # (N, 3)\n",
    "    #     hess_sdf[:, i, :] = grad2 # fill row i of each 3Ã—3 Hessian\n",
    "\n",
    "    d3dsimplices_tensor = torch.tensor(d3dsimplices_np, device=device)\n",
    "    print(\"d3dsimplices shape: \", d3dsimplices_tensor.shape)\n",
    "    print(\"d3dsimplices: \", d3dsimplices_tensor)\n",
    "    voronoi_vertices = su.compute_vertices_3d_vectorized(sites, d3dsimplices_tensor)    \n",
    "    tetra_edges = torch.cat([\n",
    "        d3dsimplices_tensor[:, [0, 1]],\n",
    "        d3dsimplices_tensor[:, [1, 2]],\n",
    "        d3dsimplices_tensor[:, [2, 3]],\n",
    "        d3dsimplices_tensor[:, [3, 0]],\n",
    "        d3dsimplices_tensor[:, [0, 2]],\n",
    "        d3dsimplices_tensor[:, [1, 3]]\n",
    "                                ], dim=0).to(device)\n",
    "    # Sort each edge to ensure uniqueness (because (a, b) and (b, a) are the same)\n",
    "    tetra_edges, _ = torch.sort(tetra_edges, dim=1)\n",
    "    # Get unique edges\n",
    "    voronoi_ridges = torch.unique(tetra_edges, dim=0)\n",
    "    \n",
    "    print(\"voronoi_ridges shape: \", voronoi_ridges.shape)\n",
    "    print(\"voronoi_ridges: \", voronoi_ridges)\n",
    "    # create a dictionnary to store the d3dsimplices composing the faces\n",
    "    # there is a face for every voronoi_ridges\n",
    "    # every vertices of the face is a simplex containing the two sites of the ridge\n",
    "    face_dict = defaultdict(list)\n",
    "    for simplex_idx, simplex in enumerate(d3dsimplices_np):\n",
    "        for a,b in itertools.combinations(simplex, 2):\n",
    "            key = (a, b) if a < b else (b, a)\n",
    "            face_dict[key].append(simplex_idx)\n",
    "\n",
    "    # Extract the SDF values for each site in the pair\n",
    "    sdf_i = sdf_values[voronoi_ridges[:, 0]]  # First site in each pair\n",
    "    sdf_j = sdf_values[voronoi_ridges[:, 1]]  # Second site in each pair\n",
    "    # Find the indices where SDF values have opposing signs or one is zero\n",
    "    mask_zero_crossing_sites = (sdf_i * sdf_j <= 0).squeeze()\n",
    "    # filter the faces based on the mask\n",
    "    filtered_faces = voronoi_ridges[mask_zero_crossing_sites].detach().cpu().numpy()\n",
    "    #filtered_faces = voronoi_ridges.detach().cpu().numpy()\n",
    "    faces = []\n",
    "    for a, b in filtered_faces:\n",
    "        key = (a, b) if a < b else (b, a)\n",
    "        match = face_dict.get(key, [])\n",
    "        faces.append(match)\n",
    "    \n",
    "    # 1) find every vertex index thatâ€™s actually used\n",
    "    used = set(idx for face in faces for idx in face)\n",
    "    # 2) create old->new mapping\n",
    "    old2new = {old: new for new, old in enumerate(sorted(used))}\n",
    "    # 3) build new, compact vertex array\n",
    "    vertices = voronoi_vertices.detach().cpu().numpy()[sorted(used), :]\n",
    "    # 4) remap faces\n",
    "    faces_new = [[old2new[idx] for idx in face] for face in faces]\n",
    "\n",
    "    return vertices, faces_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "72e588cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d3dsimplices shape:  torch.Size([29817, 4])\n",
      "d3dsimplices:  tensor([[1207, 3143, 2170, 1846],\n",
      "        [2049,  343, 3263, 2333],\n",
      "        [  73, 3439,  617, 3670],\n",
      "        ...,\n",
      "        [ 191,  174, 2121,  124],\n",
      "        [ 191,  255,  311,  319],\n",
      "        [ 191,  255,  319,  254]], device='cuda:0')\n",
      "voronoi_ridges shape:  torch.Size([34450, 2])\n",
      "voronoi_ridges:  tensor([[   0,    1],\n",
      "        [   0,    8],\n",
      "        [   0,    9],\n",
      "        ...,\n",
      "        [4562, 4601],\n",
      "        [4575, 4602],\n",
      "        [4584, 4590]], device='cuda:0')\n",
      "[(tensor([[-0.4154, -0.1769,  0.1455],\n",
      "        [-0.4174, -0.1630,  0.1213],\n",
      "        [-0.4169, -0.1737,  0.1400],\n",
      "        ...,\n",
      "        [-0.1132,  0.3120,  0.3421],\n",
      "        [-0.3016, -0.2463,  0.2083],\n",
      "        [ 0.1274, -0.2861, -0.3018]], device='cuda:0', grad_fn=<SumBackward1>),), (tensor([[5140, 5141, 2132],\n",
      "        [5475, 6575, 3238],\n",
      "        [4581, 7633, 5141],\n",
      "        ...,\n",
      "        [8750, 8536, 8164],\n",
      "        [1233,  664, 8165],\n",
      "        [1233,  659,  664]], device='cuda:0'),)]\n"
     ]
    }
   ],
   "source": [
    "final_mesh = su.get_zero_crossing_mesh_3d(sites, model)\n",
    "#ps.register_surface_mesh(\"Zero-Crossing faces direct\", final_mesh[0], final_mesh[1])\n",
    "\n",
    "#save to file\n",
    "final_mesh_file = f'{mesh[0]}voroloss_sdf_trained{model_trained_it}.npz'\n",
    "faces = np.array(final_mesh[1], dtype=object)\n",
    "np.savez(final_mesh_file, vertices=final_mesh[0], faces=faces)\n",
    "\n",
    "data = np.load(final_mesh_file, allow_pickle=True)\n",
    "verts = data[\"vertices\"]       # (N_vertices, 3)\n",
    "faces = data[\"faces\"].tolist() # back to a list of lists\n",
    "\n",
    "ps.register_surface_mesh(\"Zero-Crossing faces final\", verts, faces)\n",
    "\n",
    "v_clip, f_clip = get_clipped_mesh(sites, model)\n",
    "ps.register_surface_mesh(\"Clipped Voronoi faces\", v_clip, f_clip)\n",
    "\n",
    "\n",
    "import scipy.spatial as spatial\n",
    "from scipy.spatial import Delaunay\n",
    "\n",
    "tri = Delaunay(sites_np)\n",
    "delaunay_vertices =torch.tensor(np.array(tri.simplices), device=device)\n",
    "sdf_values = model(sites)\n",
    "\n",
    "\n",
    "# Assuming sites is a PyTorch tensor of shape [M, 3]\n",
    "sites = sites.unsqueeze(0)  # Now shape [1, M, 3]\n",
    "\n",
    "# Assuming SDF_Values is a PyTorch tensor of shape [M]\n",
    "sdf_values = sdf_values.unsqueeze(0)  # Now shape [1, M]\n",
    "\n",
    "marching_tetrehedra_mesh = kaolin.ops.conversions.marching_tetrahedra(sites, delaunay_vertices, sdf_values, return_tet_idx=False)\n",
    "print(marching_tetrehedra_mesh)\n",
    "vertices_list, faces_list = marching_tetrehedra_mesh\n",
    "vertices = vertices_list[0]\n",
    "faces = faces_list[0]\n",
    "vertices_np = vertices.detach().cpu().numpy()  # Shape [N, 3]\n",
    "faces_np = faces.detach().cpu().numpy()  # Shape [M, 3] (triangles)\n",
    "ps.register_surface_mesh(\"Marching Tetrahedra Mesh final\", vertices_np, faces_np)\n",
    "\n",
    "# clipped_cvt = \"clipped_CVT.obj\"\n",
    "# if os.path.exists(clipped_cvt):\n",
    "#     clipped_cvt_mesh = trimesh.load(clipped_cvt)\n",
    "#     ps.register_surface_mesh(\"Clipped CVT\", clipped_cvt_mesh.vertices, clipped_cvt_mesh.faces)\n",
    "ps.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5deeda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, \"End of script\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d940a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the meshed of different sdf trained total epochs and the clipped version \n",
    "import polyscope as ps\n",
    "import numpy as np\n",
    "import trimesh\n",
    "import os \n",
    "\n",
    "ps.init()\n",
    "nb_it = [\"\",\"_1000\",\"_3000\",\"_5000\",\"_7000\"]\n",
    "for it in nb_it:\n",
    "    final_mesh_file = f'gargoyle_sdf_trained{it}.npz'\n",
    "    data = np.load(final_mesh_file, allow_pickle=True)\n",
    "    verts = data[\"vertices\"]       # (N_vertices, 3)\n",
    "    faces = data[\"faces\"].tolist() # back to a list of lists\n",
    "\n",
    "    ps.register_surface_mesh(f\"Zero-Crossing faces final {it}\", verts, faces) \n",
    "\n",
    "for it in nb_it:\n",
    "    clipped_mesh_file = f'gargoyle_to_clip{it}.npz_clipped.obj'\n",
    "    clipped_cvt_mesh = trimesh.load(clipped_mesh_file)\n",
    "    ps.register_surface_mesh(f\"Clipped CVT {it}\", clipped_cvt_mesh.vertices, clipped_cvt_mesh.faces)\n",
    "    \n",
    "for it in nb_it:\n",
    "    final_mesh_file = f'bunnyvoroloss_sdf_trained{it}.npz'\n",
    "    if os.path.exists(final_mesh_file):\n",
    "        data = np.load(final_mesh_file, allow_pickle=True)\n",
    "        verts = data[\"vertices\"]       # (N_vertices, 3)\n",
    "        faces = data[\"faces\"].tolist() # back to a list of lists\n",
    "\n",
    "        ps.register_surface_mesh(f\"Voroloss Zero-Crossing faces final {it}\", verts, faces) \n",
    "\n",
    "for it in nb_it:\n",
    "    clipped_mesh_file = f'bunnyvoroloss_to_clip{it}.npz_clipped.obj'\n",
    "    if os.path.exists(clipped_mesh_file):\n",
    "        clipped_cvt_mesh = trimesh.load(clipped_mesh_file)\n",
    "        ps.register_surface_mesh(f\"Voroloss Clipped CVT {it}\", clipped_cvt_mesh.vertices, clipped_cvt_mesh.faces)\n",
    "    \n",
    "ps.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a193f128",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, \"End of script\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72240a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Voromesh points and values to try and plot the voronoi diagram\n",
    "import numpy as np\n",
    "from scipy.spatial import Voronoi\n",
    "import polyscope as ps\n",
    "def get_zero_crossing_mesh_3d(sites, values):\n",
    "    sites_np = sites\n",
    "    vor = Voronoi(sites_np)  # Compute 3D Voronoi diagram\n",
    "\n",
    "    sdf_values = values\n",
    "\n",
    "    valid_faces = []  # List of polygonal faces\n",
    "    used_vertices = set()  # Set of indices for valid vertices\n",
    "\n",
    "    for (point1, point2), ridge_vertices in zip(vor.ridge_points, vor.ridge_vertices):\n",
    "        if -1 in ridge_vertices:\n",
    "            continue  # Skip infinite ridges\n",
    "\n",
    "        # Check if SDF changes sign across this ridge\n",
    "        if np.sign(sdf_values[point1]) != np.sign(sdf_values[point2]):\n",
    "            valid_faces.append(ridge_vertices)\n",
    "            used_vertices.update(ridge_vertices)\n",
    "\n",
    "    # **Filter Voronoi vertices**\n",
    "    used_vertices = sorted(used_vertices)  # Keep unique, sorted indices\n",
    "    vertex_map = {old_idx: new_idx for new_idx, old_idx in enumerate(used_vertices)}\n",
    "    filtered_vertices = vor.vertices[used_vertices]\n",
    "\n",
    "    # **Re-index faces to match the new filtered vertex list**\n",
    "    filtered_faces = [[vertex_map[v] for v in face] for face in valid_faces]\n",
    "\n",
    "    return filtered_vertices, filtered_faces\n",
    "\n",
    "n_sample = [1, 16, 32, 150, 2400]\n",
    "grid_size = [32,128]\n",
    "voromesh_points = []\n",
    "voromesh_values = []\n",
    "ps.init()\n",
    "# groud plane none\n",
    "ps.set_ground_plane_mode(\"none\") \n",
    "for g in grid_size:\n",
    "    for i in n_sample:\n",
    "        try:\n",
    "            voromesh_points = np.load(f\"/home/wylliam/dev/VoroMesh/points_{i}_{g}.npy\")\n",
    "            voromesh_values = np.load(f\"/home/wylliam/dev/VoroMesh/values_{i}_{g}.npy\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"File not found for points_{i}_{g}.npy or values_{i}_{g}.npy\")\n",
    "            continue\n",
    "        mesh = get_zero_crossing_mesh_3d(voromesh_points, voromesh_values)\n",
    "        ps.register_surface_mesh(f\"mesh_{g}_{i}\", mesh[0], mesh[1])\n",
    "\n",
    "ps.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3355a005",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, \"End of script\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
