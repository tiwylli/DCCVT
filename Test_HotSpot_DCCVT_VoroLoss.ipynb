{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed71bbfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "Using device:  NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "import kaolin\n",
    "import torch\n",
    "import math\n",
    "import matplotlib\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import polyscope as ps\n",
    "import trimesh\n",
    "import diffvoronoi\n",
    "\n",
    "from scipy.spatial import Voronoi, voronoi_plot_2d, Delaunay\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import sdfpred_utils.sdfpred_utils as su\n",
    "import sdfpred_utils.sdf_MLP as mlp\n",
    "import sdfpred_utils.sdf_functions as sdf\n",
    "import sdfpred_utils.loss_functions as lf\n",
    "import sdfpred_utils.Steik_data3d as sd3d\n",
    "import sdfpred_utils.Steik_Loss as sl\n",
    "import sdfpred_utils.Steik_utils as Stu \n",
    "import open3d as o3d\n",
    "\n",
    "#cuda devices\n",
    "device = torch.device(\"cuda:0\")\n",
    "print(\"Using device: \", torch.cuda.get_device_name(device))\n",
    "\n",
    "#default tensor types\n",
    "#torch.set_default_tensor_type(torch.cuda.DoubleTensor)\n",
    "\n",
    "multires = 2\n",
    "input_dims = 3\n",
    "lr_sites = 0.005\n",
    "#lr_model = 0.00005*2\n",
    "destination = \"./images/autograd/HotSpot/\"\n",
    "model_trained_it = \"\"\n",
    "\n",
    "# mesh = [\"gargoyle\",\"/home/wylliam/dev/Kyushu_experiments/data/gargoyle\"]\n",
    "# trained_model_path = f\"/home/wylliam/dev/HotSpot/log/3D/pc/HotSpot-all-2025-04-24-18-16-03/gargoyle/gargoyle/trained_models/model{model_trained_it}.pth\"\n",
    "\n",
    "# mesh = [\"chair\",\"/home/wylliam/dev/Kyushu_experiments/data/chair\"]\n",
    "# trained_model_path = f\"/home/wylliam/dev/HotSpot/log/3D/pc/HotSpot-all-2025-05-02-17-56-25/chair/chair/trained_models/model{model_trained_it}.pth\"\n",
    "\n",
    "mesh = [\"bunny\",\"/home/wylliam/dev/Kyushu_experiments/data/bunny\"]\n",
    "trained_model_path = f\"/home/wylliam/dev/HotSpot/log/3D/pc/HotSpot-all-2025-04-25-17-32-49/bunny/bunny/trained_models/model{model_trained_it}.pth\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96ddcc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch3d.ops import knn_points, knn_gather\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class Voroloss_opt(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Voroloss_opt, self).__init__()\n",
    "        self.knn = 16\n",
    "\n",
    "    def __call__(self, points, spoints):\n",
    "        \"\"\"points, self.points\"\"\"\n",
    "        # WARNING: fecthing for knn\n",
    "        with torch.no_grad():\n",
    "            indices = knn_points(points, spoints, K=self.knn).idx\n",
    "\n",
    "        points_knn = knn_gather(spoints, indices)\n",
    "        points_to_voronoi_center = points - points_knn[:, :, 0]\n",
    "\n",
    "        voronoi_edge = points_knn[:, :, 1:] - points_knn[:, :, 0].unsqueeze(2)\n",
    "        voronoi_edge_l = torch.sqrt(((voronoi_edge**2).sum(-1)))\n",
    "        vector_length = (points_to_voronoi_center.unsqueeze(2) * voronoi_edge).sum(\n",
    "            -1\n",
    "        ) / voronoi_edge_l\n",
    "        sq_dist = (vector_length - voronoi_edge_l / 2) ** 2\n",
    "        return sq_dist.min(-1)[0]\n",
    "    \n",
    "voroloss = Voroloss_opt().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95a49d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sites_spread_loss(sites):\n",
    "#     with torch.no_grad():\n",
    "#         indices = knn_points(sites, sites, K=).idx\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4b4e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new sites\n",
      "Sites shape:  torch.Size([32768, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wylliam/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1678402412426/work/aten/src/ATen/native/TensorShape.cpp:3483.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[polyscope] Backend: openGL3_glfw -- Loaded openGL version: 3.3.0 NVIDIA 570.144\n"
     ]
    }
   ],
   "source": [
    "num_centroids = 8**3\n",
    "\n",
    "print(\"Creating new sites\")\n",
    "noise_scale = 0.1\n",
    "domain_limit = 1\n",
    "x = torch.linspace(-domain_limit, domain_limit, int(round(num_centroids**(1/3))))\n",
    "y = torch.linspace(-domain_limit, domain_limit, int(round(num_centroids**(1/3))))\n",
    "z = torch.linspace(-domain_limit, domain_limit, int(round(num_centroids**(1/3))))\n",
    "meshgrid = torch.meshgrid(x, y, z)\n",
    "meshgrid = torch.stack(meshgrid, dim=3).view(-1, 3)\n",
    "#add noise to meshgrid\n",
    "meshgrid += torch.randn_like(meshgrid) * noise_scale\n",
    "sites = meshgrid.to(device, dtype=torch.float32).requires_grad_(True)\n",
    "\n",
    "print(\"Sites shape: \", sites.shape)\n",
    "ps.init()\n",
    "#ps.register_point_cloud(\"initial_cvt_grid\",sites.detach().cpu().numpy())\n",
    "\n",
    "# # load pointcloud used for sdf training\n",
    "# pointcloud = o3d.io.read_point_cloud(mesh[1]+\".ply\")\n",
    "# print(\"Pointcloud shape: \", np.asarray(pointcloud.points).shape)\n",
    "# # sample pointcloud to 150*32*32\n",
    "# chamfer_distance_pc_gt = pointcloud.uniform_down_sample(int((128**3)/(150*32*32)))\n",
    "# chamfer_distance_pc_gt = np.asarray(chamfer_distance_pc_gt.points)\n",
    "# print(\"Chamfer distance pointcloud shape: \", chamfer_distance_pc_gt.shape)\n",
    "\n",
    "\n",
    "# ps.register_point_cloud(\"pointcloud_gt\", chamfer_distance_pc_gt)\n",
    "# chamfer_distance_pc_gt = torch.tensor(chamfer_distance_pc_gt, device=device, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe96048f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnfld_points shape:  torch.Size([1, 153600, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wylliam/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LOAD MODEL WITH HOTSPOT\n",
    "import sys\n",
    "sys.path.append(\"3rdparty/HotSpot\")\n",
    "from dataset import shape_3d\n",
    "import models.Net as Net\n",
    "\n",
    "loss_type = \"igr_w_heat\"\n",
    "loss_weights = [350, 0, 0, 1, 0, 0, 20]\n",
    "\n",
    "train_set = shape_3d.ReconDataset(\n",
    "    file_path = mesh[1]+\".ply\",\n",
    "    n_points=32*32*150,#15000, #args.n_points,\n",
    "    n_samples=10001, #args.n_iterations,\n",
    "    grid_res=256, #args.grid_res,\n",
    "    grid_range=1.1, #args.grid_range,\n",
    "    sample_type=\"uniform_central_gaussian\", #args.nonmnfld_sample_type,\n",
    "    sampling_std=0.5, #args.nonmnfld_sample_std,\n",
    "    n_random_samples=7500, #args.n_random_samples,\n",
    "    resample=True,\n",
    "    compute_sal_dist_gt=(\n",
    "        True if \"sal\" in loss_type and loss_weights[5] > 0 else False\n",
    "    ),\n",
    "    scale_method=\"mean\"#\"mean\" #args.pcd_scale_method,\n",
    ")\n",
    "\n",
    "model = Net.Network(\n",
    "    latent_size=0,#args.latent_size,\n",
    "    in_dim=3,\n",
    "    decoder_hidden_dim=128,#args.decoder_hidden_dim,\n",
    "    nl=\"sine\",#args.nl,\n",
    "    encoder_type=\"none\",#args.encoder_type,\n",
    "    decoder_n_hidden_layers=5,#args.decoder_n_hidden_layers,\n",
    "    neuron_type=\"quadratic\",#args.neuron_type,\n",
    "    init_type=\"mfgi\",#args.init_type,\n",
    "    sphere_init_params=[1.6, 0.1],#args.sphere_init_params,\n",
    "    n_repeat_period=30#args.n_repeat_period,\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "######       \n",
    "test_dataloader = torch.utils.data.DataLoader(train_set, batch_size=1, shuffle=False, num_workers=0, pin_memory=False)   \n",
    "test_data = next(iter(test_dataloader))\n",
    "mnfld_points = test_data[\"mnfld_points\"].to(device)\n",
    "mnfld_points.requires_grad_()\n",
    "print(\"mnfld_points shape: \", mnfld_points.shape)\n",
    "if torch.cuda.is_available():\n",
    "    map_location = torch.device(\"cuda\")\n",
    "else:\n",
    "    map_location = torch.device(\"cpu\")\n",
    "model.load_state_dict(torch.load(trained_model_path, weights_only=True, map_location=map_location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5753400f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #add mnfld points with random noise to sites \n",
    "N = mnfld_points.squeeze(0).shape[0]\n",
    "num_samples = 32**3\n",
    "idx = torch.randint(0, N, (num_samples,))\n",
    "sampled = mnfld_points.squeeze(0)[idx]\n",
    "perturbed = sampled + (torch.rand_like(sampled)-0.5)*0.1\n",
    "sites = torch.cat((sites, perturbed), dim=0)\n",
    "\n",
    "# make sites a leaf tensor\n",
    "sites = sites.detach().requires_grad_()\n",
    "\n",
    "sites_pred = model(sites)#[\"nonmanifold_pnts_pred\"]\n",
    "#mnfld_preds = model(mnfld_points)#[\"nonmanifold_pnts_pred\"]\n",
    "\n",
    "ps_cloud = ps.register_point_cloud(\"initial_cvt_grid+pc_gt\",sites.detach().cpu().numpy())\n",
    "mnf_cloud = ps.register_point_cloud(\"mnfld_points_pred\",mnfld_points.squeeze(0).detach().cpu().numpy())\n",
    "#mnf_cloud.add_scalar_quantity(\"mnfld_points_pred\", mnfld_preds.reshape(-1).detach().cpu().numpy(), enabled=True)\n",
    "ps_cloud.add_scalar_quantity(\"vis_grid_pred\", sites_pred.reshape(-1).detach().cpu().numpy(), enabled=True)\n",
    "\n",
    "initial_mesh = su.get_zero_crossing_mesh_3d(sites, model)\n",
    "ps.register_surface_mesh(\"initial Zero-Crossing faces\", initial_mesh[0], initial_mesh[1])\n",
    "\n",
    "ps.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "460a316b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SITES OPTIMISATION LOOP\n",
    "cvt_loss_values = []\n",
    "min_distance_loss_values = []\n",
    "chamfer_distance_loss_values = []\n",
    "eikonal_loss_values = []\n",
    "domain_restriction_loss_values = []\n",
    "sdf_loss_values = []\n",
    "div_loss_values = []\n",
    "loss_values = []\n",
    "\n",
    "\n",
    "\n",
    "def autograd(sites, model, max_iter=100, stop_train_threshold=1e-6, upsampling=0, lambda_weights = [0.1,1.0,0.1,0.1,1.0,1.0,0.1]):\n",
    "    optimizer = torch.optim.Adam([\n",
    "    {'params': [sites], 'lr': lr_sites}\n",
    "], betas=(0.9, 0.999))\n",
    "\n",
    "    prev_loss = float(\"inf\")\n",
    "    best_loss = float(\"inf\")\n",
    "    upsampled = 0.0\n",
    "    epoch = 0\n",
    "    lambda_cvt = lambda_weights[0]\n",
    "    # lambda_pc = lambda_weights[1]\n",
    "    lambda_min_distance = lambda_weights[2]\n",
    "    # lambda_laplace = lambda_weights[3]\n",
    "    lambda_chamfer = lambda_weights[4]\n",
    "    lambda_eikonal = lambda_weights[5]\n",
    "    lambda_domain_restriction = lambda_weights[6]\n",
    "    # lambda_target_points = lambda_weights[7]\n",
    "    lambda_sdf = 5e3\n",
    "    lambda_div = 1e2\n",
    "    lambda_eikonal = 5e1\n",
    "    best_sites = sites.clone()\n",
    "    best_sites.best_loss = best_loss\n",
    "    \n",
    "    while epoch <= max_iter:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # compute voronoi and delaunay once for each epoch and pass it around\n",
    "        # Compute Voronoi diagram\n",
    "        sites_np = sites.detach().cpu().numpy()\n",
    "        #vor = Voronoi(sites_np)\n",
    "        #tri = Delaunay(sites_np)\n",
    "      \n",
    "      \n",
    "        d3dsimplices = diffvoronoi.get_delaunay_simplices(sites_np.reshape(input_dims*sites_np.shape[0]))\n",
    "        d3dsimplices = np.array(d3dsimplices)\n",
    "        #print(\"Delaunay simplices shape: \", d3dsimplices.shape)\n",
    "        \n",
    "        vertices_to_compute, bisectors_to_compute = su.compute_zero_crossing_vertices_3d(sites, None, None, d3dsimplices, model)\n",
    "                \n",
    "        #vertices_to_compute, bisectors_to_compute = su.compute_zero_crossing_vertices_3d(sites, None, tri, None, model)\n",
    "        #vertices_to_compute, bisectors_to_compute = su.compute_zero_crossing_vertices_3d(sites, vor, tri, None, model)\n",
    "        \n",
    "        vertices = su.compute_vertices_3d_vectorized(sites, vertices_to_compute)    \n",
    "        bisectors = su.compute_all_bisectors_vectorized(sites, bisectors_to_compute)\n",
    "        points = torch.cat((vertices, bisectors), 0)\n",
    "        print(\"points\", points.shape) \n",
    "\n",
    "        # Compute losses       \n",
    "        #cvt_loss = lf.compute_cvt_loss_vectorized_voronoi(sites, vor)\n",
    "        #cvt_loss = lf.compute_cvt_loss_vectorized_delaunay(sites, tri)\n",
    "    \n",
    "        cvt_loss = lf.compute_cvt_loss_vectorized_delaunay(sites, None, d3dsimplices)\n",
    "        print(\"CVT loss: \", cvt_loss, \"weighted: \", lambda_cvt*cvt_loss)\n",
    "        #min_distance_loss = lf.sdf_weighted_min_distance_loss(model, sites)\n",
    "        \n",
    "        from pytorch3d.loss import chamfer_distance\n",
    "        chamfer_loss, _ = chamfer_distance(mnfld_points.detach(), points.unsqueeze(0))\n",
    "        print(f\"Chamfer loss PYTORCH3D {chamfer_loss} weighted: {lambda_chamfer*chamfer_loss} : Allocated: {torch.cuda.memory_allocated() / 1e6} MB, Reserved: {torch.cuda.memory_reserved() / 1e6} MB\")\n",
    "\n",
    "\n",
    "        # voroloss_loss = voroloss(points.unsqueeze(0), mnfld_points)\n",
    "        # #voroloss_loss = voroloss(sites.unsqueeze(0), mnfld_points)\n",
    "        # voroloss_loss = voroloss_loss.mean()\n",
    "        # print(f\"After Voronoi loss: {voroloss_loss} : Allocated: {torch.cuda.memory_allocated() / 1e6} MB, Reserved: {torch.cuda.memory_reserved() / 1e6} MB\")\n",
    "        \n",
    "        #SDF loss\n",
    "        sdf_loss = torch.mean(model(points)**2) + torch.maximum((model(sites).abs() - 0.05), torch.tensor(0.0)).mean()\n",
    "        #sdf_loss = torch.maximum((model(sites).abs() - 0.01), torch.tensor(0.0)).mean()\n",
    "        #sdf_loss = torch.maximum((model(sites).abs() - 0.05), torch.tensor(0.0)).mean()\n",
    "        print(\"SDF loss: \", sdf_loss, \"weighted: \", lambda_chamfer*sdf_loss)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        sites_loss = (\n",
    "            lambda_cvt * cvt_loss +\n",
    "            #lambda_chamfer * chamfer_loss \n",
    "            #lambda_chamfer * voroloss_loss\n",
    "            + lambda_chamfer * sdf_loss\n",
    "        )\n",
    "            \n",
    "        loss = sites_loss\n",
    "        loss_values.append(loss.item())\n",
    "        print(f\"Epoch {epoch}: loss = {loss.item()}\")\n",
    "        print(f\"before loss.backward(): Allocated: {torch.cuda.memory_allocated() / 1e6} MB, Reserved: {torch.cuda.memory_reserved() / 1e6} MB\")\n",
    "\n",
    "        loss.backward()\n",
    "        print(f\"After loss.backward(): Allocated: {torch.cuda.memory_allocated() / 1e6} MB, Reserved: {torch.cuda.memory_reserved() / 1e6} MB\")\n",
    "        print(\"-----------------\")\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        if loss.item() < best_loss:\n",
    "            best_loss = loss.item()\n",
    "            best_epoch = epoch\n",
    "            best_sites = sites.clone()\n",
    "            best_sites.best_loss = best_loss\n",
    "            #if upsampled > 0:\n",
    "                #print(f\"UPSAMPLED {upsampled} Best Epoch {best_epoch}: Best loss = {best_loss}\")\n",
    "                #return best_sites\n",
    "        \n",
    "        if abs(prev_loss - loss.item()) < stop_train_threshold:\n",
    "            print(f\"Converged at epoch {epoch} with loss {loss.item()}\")\n",
    "            #break\n",
    "        \n",
    "        prev_loss = loss.item() \n",
    "        \n",
    "        # if epoch>100 and (epoch // 100) == upsampled+1 and loss.item() < 0.5 and upsampled < upsampling:\n",
    "        if epoch/max_iter > (upsampled+1)/(upsampling+1) and upsampled < upsampling:\n",
    "            print(\"sites length BEFORE UPSAMPLING: \",len(sites))\n",
    "            sites = su.upsampling_vectorized(sites, tri=None, vor=None, simplices=d3dsimplices, model=model)\n",
    "            sites = sites.detach().requires_grad_(True)\n",
    "            optimizer = torch.optim.Adam([{'params': [sites], 'lr': lr_sites}])\n",
    "            upsampled += 1.0\n",
    "            print(\"sites length AFTER: \",len(sites))\n",
    "            \n",
    "          \n",
    "        if epoch % (max_iter/50) == 0:\n",
    "            #print(f\"Epoch {epoch}: loss = {loss.item()}\")\n",
    "            #print(f\"Best Epoch {best_epoch}: Best loss = {best_loss}\")\n",
    "            #save model and sites\n",
    "            site_file_path = f'{destination}{mesh[0]}{max_iter}_{epoch}_3d_sites_{num_centroids}_chamfer{lambda_chamfer}.pth'\n",
    "            model_file_path = f'{destination}{mesh[0]}{max_iter}_{epoch}_3d_model_{num_centroids}_chamfer{lambda_chamfer}.pth'\n",
    "            torch.save(model.state_dict(), model_file_path)\n",
    "            torch.save(sites, site_file_path)\n",
    "            \n",
    "        epoch += 1           \n",
    "    \n",
    "    #Export the sites, their sdf values, the gradients of the sdf values and the hessian\n",
    "    sdf_values = model(sites)\n",
    "\n",
    "    sdf_gradients = torch.autograd.grad(outputs=sdf_values, inputs=sites, grad_outputs=torch.ones_like(sdf_values), create_graph=True, retain_graph=True,)[0] # (N, 3)\n",
    "\n",
    "    N, D = sites.shape\n",
    "    hess_sdf = torch.zeros(N, D, D, device=sites.device)\n",
    "    for i in range(D):\n",
    "        grad2 = torch.autograd.grad(outputs=sdf_gradients[:, i], inputs=sites, grad_outputs=torch.ones_like(sdf_gradients[:, i]), create_graph=False, retain_graph=True,)[0] # (N, 3)\n",
    "        hess_sdf[:, i, :] = grad2 # fill row i of each 3Ã—3 Hessian\n",
    "    \n",
    "    np.savez(f'{mesh[0]}voroloss_to_clip{model_trained_it}.npz', sites=sites.detach().cpu().numpy(), sdf_values=sdf_values.detach().cpu().numpy(), sdf_gradients=sdf_gradients.detach().cpu().numpy(), sdf_hessians=hess_sdf.detach().cpu().numpy())\n",
    "    print(f\"Saved to {mesh[0]}voroloss_to_clip{model_trained_it}.npz\")\n",
    "    return best_sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7e96773",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lambda_weights = [252,0,0,0,10.211111,0,100,0]\n",
    "#lambda_weights = [500,0,0,0,1000,0,100,0]\n",
    "lambda_weights = [100,0,0,0,1000,0,100,0]\n",
    "\n",
    "\n",
    "lambda_cvt = lambda_weights[0]\n",
    "lambda_sdf = lambda_weights[1]\n",
    "lambda_min_distance = lambda_weights[2]\n",
    "lambda_laplace = lambda_weights[3]\n",
    "lambda_chamfer = lambda_weights[4]\n",
    "lambda_eikonal = lambda_weights[5]\n",
    "lambda_domain_restriction = lambda_weights[6]\n",
    "lambda_true_points = lambda_weights[7]\n",
    "\n",
    "max_iter = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fb2cefd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "points torch.Size([6413, 3])\n",
      "CVT loss:  tensor(0.0115, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(1.1471, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.001040132949128747 weighted: 1.040132999420166 : Allocated: 437.530112 MB, Reserved: 943.7184 MB\n",
      "SDF loss:  tensor(0.5315, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(531.5006, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 0: loss = 532.647705078125\n",
      "before loss.backward(): Allocated: 942.189568 MB, Reserved: 977.272832 MB\n",
      "After loss.backward(): Allocated: 443.881472 MB, Reserved: 1061.158912 MB\n",
      "-----------------\n",
      "points torch.Size([6354, 3])\n",
      "CVT loss:  tensor(0.0118, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(1.1779, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.0007394835120067 weighted: 0.7394835352897644 : Allocated: 448.06656 MB, Reserved: 1063.256064 MB\n",
      "SDF loss:  tensor(0.5241, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(524.1182, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 1: loss = 525.2960815429688\n",
      "before loss.backward(): Allocated: 952.62976 MB, Reserved: 1063.256064 MB\n",
      "After loss.backward(): Allocated: 445.126144 MB, Reserved: 1063.256064 MB\n",
      "-----------------\n",
      "points torch.Size([6555, 3])\n",
      "CVT loss:  tensor(0.0140, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(1.3960, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.0005403570830821991 weighted: 0.5403571128845215 : Allocated: 447.682048 MB, Reserved: 1063.256064 MB\n",
      "SDF loss:  tensor(0.5169, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(516.9006, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 2: loss = 518.296630859375\n",
      "before loss.backward(): Allocated: 952.723456 MB, Reserved: 1063.256064 MB\n",
      "After loss.backward(): Allocated: 444.675584 MB, Reserved: 1063.256064 MB\n",
      "-----------------\n",
      "points torch.Size([6806, 3])\n",
      "CVT loss:  tensor(0.0143, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(1.4296, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.00038263239548541605 weighted: 0.38263240456581116 : Allocated: 448.244736 MB, Reserved: 1063.256064 MB\n",
      "SDF loss:  tensor(0.5098, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(509.7836, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 3: loss = 511.2132873535156\n",
      "before loss.backward(): Allocated: 956.509184 MB, Reserved: 1063.256064 MB\n",
      "After loss.backward(): Allocated: 445.151744 MB, Reserved: 1063.256064 MB\n",
      "-----------------\n",
      "points torch.Size([7044, 3])\n",
      "CVT loss:  tensor(0.0155, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(1.5494, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.00033749992144294083 weighted: 0.3374999165534973 : Allocated: 447.889408 MB, Reserved: 1063.256064 MB\n",
      "SDF loss:  tensor(0.5028, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(502.7625, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 4: loss = 504.3118591308594\n",
      "before loss.backward(): Allocated: 959.210496 MB, Reserved: 1063.256064 MB\n",
      "After loss.backward(): Allocated: 444.703744 MB, Reserved: 1063.256064 MB\n",
      "-----------------\n",
      "points torch.Size([7275, 3])\n",
      "CVT loss:  tensor(0.0120, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(1.1985, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.0003255648189224303 weighted: 0.32556483149528503 : Allocated: 448.455168 MB, Reserved: 1063.256064 MB\n",
      "SDF loss:  tensor(0.4958, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(495.8036, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 5: loss = 497.002197265625\n",
      "before loss.backward(): Allocated: 962.7392 MB, Reserved: 1063.256064 MB\n",
      "After loss.backward(): Allocated: 445.178368 MB, Reserved: 1063.256064 MB\n",
      "-----------------\n",
      "points torch.Size([7586, 3])\n",
      "CVT loss:  tensor(0.0091, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.9139, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.00031207455322146416 weighted: 0.31207454204559326 : Allocated: 448.131584 MB, Reserved: 1063.256064 MB\n",
      "SDF loss:  tensor(0.4889, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(488.9019, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 6: loss = 489.81585693359375\n",
      "before loss.backward(): Allocated: 967.210496 MB, Reserved: 1063.256064 MB\n",
      "After loss.backward(): Allocated: 444.734976 MB, Reserved: 1063.256064 MB\n",
      "-----------------\n",
      "points torch.Size([7900, 3])\n",
      "CVT loss:  tensor(0.0073, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.7334, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.0003064883640035987 weighted: 0.30648836493492126 : Allocated: 448.733184 MB, Reserved: 1063.256064 MB\n",
      "SDF loss:  tensor(0.4821, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(482.0551, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 7: loss = 482.7884216308594\n",
      "before loss.backward(): Allocated: 974.350336 MB, Reserved: 1063.256064 MB\n",
      "After loss.backward(): Allocated: 445.215232 MB, Reserved: 1063.256064 MB\n",
      "-----------------\n",
      "points torch.Size([8193, 3])\n",
      "CVT loss:  tensor(0.0068, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.6779, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.00030479003908112645 weighted: 0.30479004979133606 : Allocated: 448.403456 MB, Reserved: 1063.256064 MB\n",
      "SDF loss:  tensor(0.4753, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(475.2542, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 8: loss = 475.9321594238281\n",
      "before loss.backward(): Allocated: 974.477824 MB, Reserved: 1063.256064 MB\n",
      "After loss.backward(): Allocated: 444.770304 MB, Reserved: 1096.810496 MB\n",
      "-----------------\n",
      "points torch.Size([8449, 3])\n",
      "CVT loss:  tensor(0.0083, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.8261, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.0002997620031237602 weighted: 0.2997620105743408 : Allocated: 448.982016 MB, Reserved: 1098.907648 MB\n",
      "SDF loss:  tensor(0.4685, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(468.4990, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 9: loss = 469.32513427734375\n",
      "before loss.backward(): Allocated: 978.343424 MB, Reserved: 1098.907648 MB\n",
      "After loss.backward(): Allocated: 445.246976 MB, Reserved: 1098.907648 MB\n",
      "-----------------\n",
      "points torch.Size([8632, 3])\n",
      "CVT loss:  tensor(0.0090, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.8985, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.0003282995312474668 weighted: 0.32829952239990234 : Allocated: 448.601088 MB, Reserved: 1098.907648 MB\n",
      "SDF loss:  tensor(0.4618, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(461.8066, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 10: loss = 462.7052001953125\n",
      "before loss.backward(): Allocated: 980.310528 MB, Reserved: 1098.907648 MB\n",
      "After loss.backward(): Allocated: 444.79488 MB, Reserved: 1098.907648 MB\n",
      "-----------------\n",
      "points torch.Size([8972, 3])\n",
      "CVT loss:  tensor(0.0060, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.6015, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.0003242712118662894 weighted: 0.32427120208740234 : Allocated: 449.208832 MB, Reserved: 1098.907648 MB\n",
      "SDF loss:  tensor(0.4551, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(455.1398, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 11: loss = 455.7413024902344\n",
      "before loss.backward(): Allocated: 985.28512 MB, Reserved: 1098.907648 MB\n",
      "After loss.backward(): Allocated: 445.276672 MB, Reserved: 1098.907648 MB\n",
      "-----------------\n",
      "points torch.Size([9106, 3])\n",
      "CVT loss:  tensor(0.0061, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.6067, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.00032345083309337497 weighted: 0.32345083355903625 : Allocated: 448.807936 MB, Reserved: 1098.907648 MB\n",
      "SDF loss:  tensor(0.4485, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(448.5153, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 12: loss = 449.1219787597656\n",
      "before loss.backward(): Allocated: 986.604544 MB, Reserved: 1098.907648 MB\n",
      "After loss.backward(): Allocated: 444.822528 MB, Reserved: 1098.907648 MB\n",
      "-----------------\n",
      "points torch.Size([9395, 3])\n",
      "CVT loss:  tensor(0.0091, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.9105, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.0003286263672634959 weighted: 0.3286263644695282 : Allocated: 449.396736 MB, Reserved: 1098.907648 MB\n",
      "SDF loss:  tensor(0.4419, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(441.9344, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 13: loss = 442.8448486328125\n",
      "before loss.backward(): Allocated: 990.903296 MB, Reserved: 1098.907648 MB\n",
      "After loss.backward(): Allocated: 445.300736 MB, Reserved: 1098.907648 MB\n",
      "-----------------\n",
      "points torch.Size([9619, 3])\n",
      "CVT loss:  tensor(0.0079, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.7946, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.00032799114705994725 weighted: 0.32799115777015686 : Allocated: 449.043968 MB, Reserved: 1098.907648 MB\n",
      "SDF loss:  tensor(0.4354, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(435.3936, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 14: loss = 436.1881408691406\n",
      "before loss.backward(): Allocated: 993.427456 MB, Reserved: 1098.907648 MB\n",
      "After loss.backward(): Allocated: 444.852736 MB, Reserved: 1098.907648 MB\n",
      "-----------------\n",
      "points torch.Size([9949, 3])\n",
      "CVT loss:  tensor(0.0135, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(1.3530, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.0003458838618826121 weighted: 0.34588387608528137 : Allocated: 449.651712 MB, Reserved: 1098.907648 MB\n",
      "SDF loss:  tensor(0.4289, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(428.8934, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 15: loss = 430.2464294433594\n",
      "before loss.backward(): Allocated: 998.270464 MB, Reserved: 1098.907648 MB\n",
      "After loss.backward(): Allocated: 445.334016 MB, Reserved: 1098.907648 MB\n",
      "-----------------\n",
      "points torch.Size([10194, 3])\n",
      "CVT loss:  tensor(0.0150, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(1.5017, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.00033326781704090536 weighted: 0.33326780796051025 : Allocated: 449.305088 MB, Reserved: 1098.907648 MB\n",
      "SDF loss:  tensor(0.4224, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(422.4267, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 16: loss = 423.92840576171875\n",
      "before loss.backward(): Allocated: 1001.069568 MB, Reserved: 1098.907648 MB\n",
      "After loss.backward(): Allocated: 444.886016 MB, Reserved: 1098.907648 MB\n",
      "-----------------\n",
      "points torch.Size([10478, 3])\n",
      "CVT loss:  tensor(0.0129, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(1.2903, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.0003269587177783251 weighted: 0.32695871591567993 : Allocated: 449.887232 MB, Reserved: 1098.907648 MB\n",
      "SDF loss:  tensor(0.4160, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(416.0034, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 17: loss = 417.29364013671875\n",
      "before loss.backward(): Allocated: 1010.07872 MB, Reserved: 1098.907648 MB\n",
      "After loss.backward(): Allocated: 445.363712 MB, Reserved: 1098.907648 MB\n",
      "-----------------\n",
      "points torch.Size([10910, 3])\n",
      "CVT loss:  tensor(0.0138, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(1.3813, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.000323419866617769 weighted: 0.32341986894607544 : Allocated: 449.618432 MB, Reserved: 1098.907648 MB\n",
      "SDF loss:  tensor(0.4096, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(409.6385, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 18: loss = 411.0198059082031\n",
      "before loss.backward(): Allocated: 1011.695104 MB, Reserved: 1098.907648 MB\n",
      "After loss.backward(): Allocated: 444.926976 MB, Reserved: 1098.907648 MB\n",
      "-----------------\n",
      "points torch.Size([11317, 3])\n",
      "CVT loss:  tensor(0.0126, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(1.2633, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.00031270895851776004 weighted: 0.31270894408226013 : Allocated: 450.262528 MB, Reserved: 1098.907648 MB\n",
      "SDF loss:  tensor(0.4033, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(403.2888, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 19: loss = 404.55206298828125\n",
      "before loss.backward(): Allocated: 1018.083328 MB, Reserved: 1098.907648 MB\n",
      "After loss.backward(): Allocated: 445.41184 MB, Reserved: 1149.239296 MB\n",
      "-----------------\n",
      "points torch.Size([11798, 3])\n",
      "CVT loss:  tensor(0.0091, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.9106, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.0003056809364352375 weighted: 0.30568093061447144 : Allocated: 450.013184 MB, Reserved: 1149.239296 MB\n",
      "SDF loss:  tensor(0.3970, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(396.9823, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 20: loss = 397.89288330078125\n",
      "before loss.backward(): Allocated: 1023.271936 MB, Reserved: 1149.239296 MB\n",
      "After loss.backward(): Allocated: 444.978176 MB, Reserved: 1149.239296 MB\n",
      "-----------------\n",
      "points torch.Size([12161, 3])\n",
      "CVT loss:  tensor(0.0071, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.7115, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.0002949437184724957 weighted: 0.2949437201023102 : Allocated: 450.635264 MB, Reserved: 1149.239296 MB\n",
      "SDF loss:  tensor(0.3907, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(390.7068, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 21: loss = 391.4183044433594\n",
      "before loss.backward(): Allocated: 1027.999232 MB, Reserved: 1149.239296 MB\n",
      "After loss.backward(): Allocated: 445.460992 MB, Reserved: 1166.016512 MB\n",
      "-----------------\n",
      "points torch.Size([12698, 3])\n",
      "CVT loss:  tensor(0.0085, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.8532, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.0002862409455701709 weighted: 0.28624093532562256 : Allocated: 450.406912 MB, Reserved: 1166.016512 MB\n",
      "SDF loss:  tensor(0.3845, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(384.4793, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 22: loss = 385.3325500488281\n",
      "before loss.backward(): Allocated: 1034.390016 MB, Reserved: 1166.016512 MB\n",
      "After loss.backward(): Allocated: 445.029376 MB, Reserved: 1166.016512 MB\n",
      "-----------------\n",
      "points torch.Size([12970, 3])\n",
      "CVT loss:  tensor(0.0080, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.7955, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.00031854078406468034 weighted: 0.3185407817363739 : Allocated: 450.986496 MB, Reserved: 1166.016512 MB\n",
      "SDF loss:  tensor(0.3783, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(378.2935, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 23: loss = 379.089111328125\n",
      "before loss.backward(): Allocated: 1038.395904 MB, Reserved: 1166.016512 MB\n",
      "After loss.backward(): Allocated: 445.50656 MB, Reserved: 1166.016512 MB\n",
      "-----------------\n",
      "points torch.Size([13409, 3])\n",
      "CVT loss:  tensor(0.0089, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.8873, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.00030817330116406083 weighted: 0.3081732988357544 : Allocated: 450.714112 MB, Reserved: 1166.016512 MB\n",
      "SDF loss:  tensor(0.3721, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(372.1333, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 24: loss = 373.0206298828125\n",
      "before loss.backward(): Allocated: 1043.759104 MB, Reserved: 1166.016512 MB\n",
      "After loss.backward(): Allocated: 445.070336 MB, Reserved: 1166.016512 MB\n",
      "-----------------\n",
      "points torch.Size([13834, 3])\n",
      "CVT loss:  tensor(0.0132, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(1.3154, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.0002698160242289305 weighted: 0.26981601119041443 : Allocated: 451.36896 MB, Reserved: 1166.016512 MB\n",
      "SDF loss:  tensor(0.3660, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(366.0109, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 25: loss = 367.3262634277344\n",
      "before loss.backward(): Allocated: 1049.873408 MB, Reserved: 1166.016512 MB\n",
      "After loss.backward(): Allocated: 445.557248 MB, Reserved: 1166.016512 MB\n",
      "-----------------\n",
      "points torch.Size([14458, 3])\n",
      "CVT loss:  tensor(0.0099, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.9913, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.00026832002913579345 weighted: 0.2683200240135193 : Allocated: 451.17952 MB, Reserved: 1166.016512 MB\n",
      "SDF loss:  tensor(0.3599, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(359.9398, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 26: loss = 360.93115234375\n",
      "before loss.backward(): Allocated: 1057.692672 MB, Reserved: 1166.016512 MB\n",
      "After loss.backward(): Allocated: 445.130752 MB, Reserved: 1168.113664 MB\n",
      "-----------------\n",
      "points torch.Size([14952, 3])\n",
      "CVT loss:  tensor(0.0076, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.7642, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.0002554550883360207 weighted: 0.2554550766944885 : Allocated: 451.864576 MB, Reserved: 1168.113664 MB\n",
      "SDF loss:  tensor(0.3539, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(353.9019, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 27: loss = 354.66607666015625\n",
      "before loss.backward(): Allocated: 1064.721408 MB, Reserved: 1168.113664 MB\n",
      "After loss.backward(): Allocated: 445.621248 MB, Reserved: 1168.113664 MB\n",
      "-----------------\n",
      "points torch.Size([15739, 3])\n",
      "CVT loss:  tensor(0.0065, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.6498, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.00024677542387507856 weighted: 0.24677541851997375 : Allocated: 451.744768 MB, Reserved: 1168.113664 MB\n",
      "SDF loss:  tensor(0.3479, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(347.9035, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 28: loss = 348.5533142089844\n",
      "before loss.backward(): Allocated: 1082.63168 MB, Reserved: 1168.113664 MB\n",
      "After loss.backward(): Allocated: 445.20448 MB, Reserved: 1168.113664 MB\n",
      "-----------------\n",
      "points torch.Size([15955, 3])\n",
      "CVT loss:  tensor(0.0080, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.8036, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.00023915011843200773 weighted: 0.23915012180805206 : Allocated: 452.301312 MB, Reserved: 1168.113664 MB\n",
      "SDF loss:  tensor(0.3419, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(341.9440, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 29: loss = 342.7475891113281\n",
      "before loss.backward(): Allocated: 1083.308544 MB, Reserved: 1168.113664 MB\n",
      "After loss.backward(): Allocated: 445.679104 MB, Reserved: 1168.113664 MB\n",
      "-----------------\n",
      "points torch.Size([16650, 3])\n",
      "CVT loss:  tensor(0.0078, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.7793, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.0002372457238379866 weighted: 0.23724572360515594 : Allocated: 452.138496 MB, Reserved: 1168.113664 MB\n",
      "SDF loss:  tensor(0.3360, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(336.0323, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 30: loss = 336.8116149902344\n",
      "before loss.backward(): Allocated: 1086.800384 MB, Reserved: 1319.108608 MB\n",
      "After loss.backward(): Allocated: 445.257216 MB, Reserved: 1402.994688 MB\n",
      "-----------------\n",
      "points torch.Size([16865, 3])\n",
      "CVT loss:  tensor(0.0079, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.7907, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.000230054632993415 weighted: 0.23005463182926178 : Allocated: 452.703744 MB, Reserved: 1402.994688 MB\n",
      "SDF loss:  tensor(0.3302, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(330.1554, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 31: loss = 330.9460144042969\n",
      "before loss.backward(): Allocated: 1090.123776 MB, Reserved: 1402.994688 MB\n",
      "After loss.backward(): Allocated: 445.73184 MB, Reserved: 1402.994688 MB\n",
      "-----------------\n",
      "points torch.Size([17448, 3])\n",
      "CVT loss:  tensor(0.0082, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.8188, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.00022881210315972567 weighted: 0.2288120985031128 : Allocated: 452.50304 MB, Reserved: 1402.994688 MB\n",
      "SDF loss:  tensor(0.3243, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(324.3278, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 32: loss = 325.14654541015625\n",
      "before loss.backward(): Allocated: 1097.410048 MB, Reserved: 1402.994688 MB\n",
      "After loss.backward(): Allocated: 445.302784 MB, Reserved: 1402.994688 MB\n",
      "-----------------\n",
      "points torch.Size([17869, 3])\n",
      "CVT loss:  tensor(0.0085, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.8523, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.0002187826030422002 weighted: 0.21878260374069214 : Allocated: 453.15328 MB, Reserved: 1402.994688 MB\n",
      "SDF loss:  tensor(0.3185, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(318.5378, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 33: loss = 319.3901062011719\n",
      "before loss.backward(): Allocated: 1103.46496 MB, Reserved: 1402.994688 MB\n",
      "After loss.backward(): Allocated: 445.789184 MB, Reserved: 1402.994688 MB\n",
      "-----------------\n",
      "points torch.Size([18367, 3])\n",
      "CVT loss:  tensor(0.0108, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(1.0829, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.000212736296816729 weighted: 0.21273629367351532 : Allocated: 452.910592 MB, Reserved: 1402.994688 MB\n",
      "SDF loss:  tensor(0.3128, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(312.7861, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 34: loss = 313.86895751953125\n",
      "before loss.backward(): Allocated: 1109.617152 MB, Reserved: 1402.994688 MB\n",
      "After loss.backward(): Allocated: 445.356544 MB, Reserved: 1405.09184 MB\n",
      "-----------------\n",
      "points torch.Size([19153, 3])\n",
      "CVT loss:  tensor(0.0111, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(1.1085, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.00021303255925886333 weighted: 0.2130325585603714 : Allocated: 453.707264 MB, Reserved: 1405.09184 MB\n",
      "SDF loss:  tensor(0.3071, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(307.0842, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 35: loss = 308.1927185058594\n",
      "before loss.backward(): Allocated: 1120.505344 MB, Reserved: 1405.09184 MB\n",
      "After loss.backward(): Allocated: 445.862912 MB, Reserved: 1405.09184 MB\n",
      "-----------------\n",
      "points torch.Size([19672, 3])\n",
      "CVT loss:  tensor(0.0081, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.8073, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.00020618835696950555 weighted: 0.2061883509159088 : Allocated: 453.481472 MB, Reserved: 1405.09184 MB\n",
      "SDF loss:  tensor(0.3014, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(301.4248, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 36: loss = 302.2320556640625\n",
      "before loss.backward(): Allocated: 1126.943744 MB, Reserved: 1405.09184 MB\n",
      "After loss.backward(): Allocated: 445.431296 MB, Reserved: 1405.09184 MB\n",
      "-----------------\n",
      "points torch.Size([20421, 3])\n",
      "CVT loss:  tensor(0.0105, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(1.0467, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.00019988878921139985 weighted: 0.19988879561424255 : Allocated: 454.272512 MB, Reserved: 1405.09184 MB\n",
      "SDF loss:  tensor(0.2958, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(295.7995, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 37: loss = 296.84613037109375\n",
      "before loss.backward(): Allocated: 1137.352192 MB, Reserved: 1405.09184 MB\n",
      "After loss.backward(): Allocated: 445.93664 MB, Reserved: 1405.09184 MB\n",
      "-----------------\n",
      "points torch.Size([20963, 3])\n",
      "CVT loss:  tensor(0.0093, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.9295, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.000195695785805583 weighted: 0.19569578766822815 : Allocated: 454.047232 MB, Reserved: 1405.09184 MB\n",
      "SDF loss:  tensor(0.2902, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(290.2165, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 38: loss = 291.14605712890625\n",
      "before loss.backward(): Allocated: 1144.085504 MB, Reserved: 1405.09184 MB\n",
      "After loss.backward(): Allocated: 445.505536 MB, Reserved: 1407.188992 MB\n",
      "-----------------\n",
      "points torch.Size([21716, 3])\n",
      "CVT loss:  tensor(0.0113, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(1.1322, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.00019635225180536509 weighted: 0.1963522583246231 : Allocated: 454.844928 MB, Reserved: 1407.188992 MB\n",
      "SDF loss:  tensor(0.2847, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(284.6820, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 39: loss = 285.814208984375\n",
      "before loss.backward(): Allocated: 1154.551808 MB, Reserved: 1407.188992 MB\n",
      "After loss.backward(): Allocated: 446.01088 MB, Reserved: 1407.188992 MB\n",
      "-----------------\n",
      "points torch.Size([22284, 3])\n",
      "CVT loss:  tensor(0.0123, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(1.2339, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.0001895249297376722 weighted: 0.18952493369579315 : Allocated: 454.635008 MB, Reserved: 1407.188992 MB\n",
      "SDF loss:  tensor(0.2792, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(279.1791, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 40: loss = 280.4129638671875\n",
      "before loss.backward(): Allocated: 1162.679808 MB, Reserved: 1407.188992 MB\n",
      "After loss.backward(): Allocated: 445.581824 MB, Reserved: 1407.188992 MB\n",
      "-----------------\n",
      "points torch.Size([22775, 3])\n",
      "CVT loss:  tensor(0.0096, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.9619, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.00017982948338612914 weighted: 0.17982947826385498 : Allocated: 455.304192 MB, Reserved: 1407.188992 MB\n",
      "SDF loss:  tensor(0.2737, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(273.7198, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 41: loss = 274.6816711425781\n",
      "before loss.backward(): Allocated: 1169.398784 MB, Reserved: 1407.188992 MB\n",
      "After loss.backward(): Allocated: 446.071296 MB, Reserved: 1407.188992 MB\n",
      "-----------------\n",
      "points torch.Size([23661, 3])\n",
      "CVT loss:  tensor(0.0186, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(1.8650, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.00017238719738088548 weighted: 0.17238719761371613 : Allocated: 455.220224 MB, Reserved: 1407.188992 MB\n",
      "SDF loss:  tensor(0.2683, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(268.3078, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 42: loss = 270.1727600097656\n",
      "before loss.backward(): Allocated: 1180.237824 MB, Reserved: 1407.188992 MB\n",
      "After loss.backward(): Allocated: 445.66016 MB, Reserved: 1407.188992 MB\n",
      "-----------------\n",
      "points torch.Size([24140, 3])\n",
      "CVT loss:  tensor(0.0087, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.8696, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.00017135022790171206 weighted: 0.17135022580623627 : Allocated: 455.894016 MB, Reserved: 1407.188992 MB\n",
      "SDF loss:  tensor(0.2629, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(262.9377, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 43: loss = 263.80731201171875\n",
      "before loss.backward(): Allocated: 1186.817536 MB, Reserved: 1407.188992 MB\n",
      "After loss.backward(): Allocated: 446.150144 MB, Reserved: 1409.286144 MB\n",
      "-----------------\n",
      "points torch.Size([24867, 3])\n",
      "CVT loss:  tensor(0.0094, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.9369, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.00016991415759548545 weighted: 0.1699141561985016 : Allocated: 455.757312 MB, Reserved: 1409.286144 MB\n",
      "SDF loss:  tensor(0.2576, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(257.6117, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 44: loss = 258.548583984375\n",
      "before loss.backward(): Allocated: 1195.92448 MB, Reserved: 1409.286144 MB\n",
      "After loss.backward(): Allocated: 445.729792 MB, Reserved: 1409.286144 MB\n",
      "-----------------\n",
      "points torch.Size([25690, 3])\n",
      "CVT loss:  tensor(0.0090, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.8953, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.0001674371014814824 weighted: 0.1674371063709259 : Allocated: 456.590336 MB, Reserved: 1409.286144 MB\n",
      "SDF loss:  tensor(0.2523, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(252.3281, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 45: loss = 253.223388671875\n",
      "before loss.backward(): Allocated: 1207.323648 MB, Reserved: 1409.286144 MB\n",
      "After loss.backward(): Allocated: 446.239744 MB, Reserved: 1409.286144 MB\n",
      "-----------------\n",
      "points torch.Size([26308, 3])\n",
      "CVT loss:  tensor(0.0063, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.6341, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.00016315680113621056 weighted: 0.16315680742263794 : Allocated: 456.398848 MB, Reserved: 1409.286144 MB\n",
      "SDF loss:  tensor(0.2471, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(247.0902, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 46: loss = 247.7243194580078\n",
      "before loss.backward(): Allocated: 1215.067648 MB, Reserved: 1409.286144 MB\n",
      "After loss.backward(): Allocated: 445.81376 MB, Reserved: 1409.286144 MB\n",
      "-----------------\n",
      "points torch.Size([26966, 3])\n",
      "CVT loss:  tensor(0.0078, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.7803, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.00015721948875579983 weighted: 0.15721948444843292 : Allocated: 457.14432 MB, Reserved: 1409.286144 MB\n",
      "SDF loss:  tensor(0.2419, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(241.8998, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 47: loss = 242.68011474609375\n",
      "before loss.backward(): Allocated: 1224.261632 MB, Reserved: 1409.286144 MB\n",
      "After loss.backward(): Allocated: 446.313472 MB, Reserved: 1409.286144 MB\n",
      "-----------------\n",
      "points torch.Size([27801, 3])\n",
      "CVT loss:  tensor(0.0076, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.7621, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.00015383638674393296 weighted: 0.15383638441562653 : Allocated: 457.443328 MB, Reserved: 1409.286144 MB\n",
      "SDF loss:  tensor(0.2368, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(236.7609, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 48: loss = 237.52297973632812\n",
      "before loss.backward(): Allocated: 1235.283456 MB, Reserved: 1409.286144 MB\n",
      "After loss.backward(): Allocated: 445.899264 MB, Reserved: 1409.286144 MB\n",
      "-----------------\n",
      "points torch.Size([28396, 3])\n",
      "CVT loss:  tensor(0.0097, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.9721, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.00014947482850402594 weighted: 0.1494748294353485 : Allocated: 458.084864 MB, Reserved: 1409.286144 MB\n",
      "SDF loss:  tensor(0.2317, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(231.6629, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 49: loss = 232.6349334716797\n",
      "before loss.backward(): Allocated: 1243.562496 MB, Reserved: 1409.286144 MB\n",
      "After loss.backward(): Allocated: 445.933568 MB, Reserved: 1409.286144 MB\n",
      "-----------------\n",
      "points torch.Size([28947, 3])\n",
      "CVT loss:  tensor(0.0061, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.6112, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.00014665740309283137 weighted: 0.14665740728378296 : Allocated: 459.286016 MB, Reserved: 1409.286144 MB\n",
      "SDF loss:  tensor(0.2266, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(226.6142, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 50: loss = 227.225341796875\n",
      "before loss.backward(): Allocated: 1251.841024 MB, Reserved: 1409.286144 MB\n",
      "After loss.backward(): Allocated: 446.867456 MB, Reserved: 1409.286144 MB\n",
      "-----------------\n",
      "points torch.Size([29646, 3])\n",
      "CVT loss:  tensor(0.0084, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.8432, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.00014567814650945365 weighted: 0.14567814767360687 : Allocated: 459.519488 MB, Reserved: 1409.286144 MB\n",
      "SDF loss:  tensor(0.2216, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(221.6142, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 51: loss = 222.4573211669922\n",
      "before loss.backward(): Allocated: 1261.047808 MB, Reserved: 1409.286144 MB\n",
      "After loss.backward(): Allocated: 446.004736 MB, Reserved: 1409.286144 MB\n",
      "-----------------\n",
      "points torch.Size([30178, 3])\n",
      "CVT loss:  tensor(0.0067, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.6730, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.00014382496010512114 weighted: 0.143824964761734 : Allocated: 459.383296 MB, Reserved: 1409.286144 MB\n",
      "SDF loss:  tensor(0.2167, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(216.6638, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 52: loss = 217.3367462158203\n",
      "before loss.backward(): Allocated: 1267.742208 MB, Reserved: 1409.286144 MB\n",
      "After loss.backward(): Allocated: 446.743552 MB, Reserved: 1409.286144 MB\n",
      "-----------------\n",
      "points torch.Size([30917, 3])\n",
      "CVT loss:  tensor(0.0054, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.5403, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.00014086886949371547 weighted: 0.1408688724040985 : Allocated: 458.930176 MB, Reserved: 1409.286144 MB\n",
      "SDF loss:  tensor(0.2118, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(211.7614, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 53: loss = 212.30160522460938\n",
      "before loss.backward(): Allocated: 1300.471296 MB, Reserved: 1409.286144 MB\n",
      "After loss.backward(): Allocated: 446.078976 MB, Reserved: 1409.286144 MB\n",
      "-----------------\n",
      "points torch.Size([31549, 3])\n",
      "CVT loss:  tensor(0.0079, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.7925, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.00013685791054740548 weighted: 0.13685791194438934 : Allocated: 459.68128 MB, Reserved: 1409.286144 MB\n",
      "SDF loss:  tensor(0.2069, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(206.9010, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 54: loss = 207.69354248046875\n",
      "before loss.backward(): Allocated: 1301.248 MB, Reserved: 1409.286144 MB\n",
      "After loss.backward(): Allocated: 446.617088 MB, Reserved: 1409.286144 MB\n",
      "-----------------\n",
      "points torch.Size([32184, 3])\n",
      "CVT loss:  tensor(0.0085, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.8508, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.0001359935849905014 weighted: 0.1359935849905014 : Allocated: 459.436544 MB, Reserved: 1409.286144 MB\n",
      "SDF loss:  tensor(0.2021, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(202.0916, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 55: loss = 202.94239807128906\n",
      "before loss.backward(): Allocated: 1301.028864 MB, Reserved: 1409.286144 MB\n",
      "After loss.backward(): Allocated: 446.151168 MB, Reserved: 1409.286144 MB\n",
      "-----------------\n",
      "points torch.Size([33007, 3])\n",
      "CVT loss:  tensor(0.0053, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.5321, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.00013367878273129463 weighted: 0.13367877900600433 : Allocated: 460.04224 MB, Reserved: 1409.286144 MB\n",
      "SDF loss:  tensor(0.1973, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(197.3320, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 56: loss = 197.8640899658203\n",
      "before loss.backward(): Allocated: 1304.724992 MB, Reserved: 1786.773504 MB\n",
      "After loss.backward(): Allocated: 446.479872 MB, Reserved: 1893.728256 MB\n",
      "-----------------\n",
      "points torch.Size([33755, 3])\n",
      "CVT loss:  tensor(0.0062, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.6165, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.0001307199418079108 weighted: 0.13071994483470917 : Allocated: 460.069376 MB, Reserved: 1893.728256 MB\n",
      "SDF loss:  tensor(0.1926, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(192.6207, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 57: loss = 193.23721313476562\n",
      "before loss.backward(): Allocated: 1314.357248 MB, Reserved: 1893.728256 MB\n",
      "After loss.backward(): Allocated: 446.242304 MB, Reserved: 1893.728256 MB\n",
      "-----------------\n",
      "points torch.Size([34333, 3])\n",
      "CVT loss:  tensor(0.0039, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3860, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.00012924944167025387 weighted: 0.1292494386434555 : Allocated: 461.361152 MB, Reserved: 1893.728256 MB\n",
      "SDF loss:  tensor(0.1880, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(187.9562, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 58: loss = 188.34222412109375\n",
      "before loss.backward(): Allocated: 1323.072 MB, Reserved: 1893.728256 MB\n",
      "After loss.backward(): Allocated: 446.295552 MB, Reserved: 1893.728256 MB\n",
      "-----------------\n",
      "points torch.Size([34960, 3])\n",
      "CVT loss:  tensor(0.0066, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.6587, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.00012696717749349773 weighted: 0.1269671767950058 : Allocated: 461.633536 MB, Reserved: 1893.728256 MB\n",
      "SDF loss:  tensor(0.1833, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(183.3397, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 59: loss = 183.9983367919922\n",
      "before loss.backward(): Allocated: 1352.84224 MB, Reserved: 1893.728256 MB\n",
      "After loss.backward(): Allocated: 446.374912 MB, Reserved: 1931.476992 MB\n",
      "-----------------\n",
      "points torch.Size([35687, 3])\n",
      "CVT loss:  tensor(0.0064, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.6352, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.00012505929043982178 weighted: 0.12505929172039032 : Allocated: 461.938688 MB, Reserved: 1931.476992 MB\n",
      "SDF loss:  tensor(0.1788, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(178.7825, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 60: loss = 179.41769409179688\n",
      "before loss.backward(): Allocated: 1354.290688 MB, Reserved: 1931.476992 MB\n",
      "After loss.backward(): Allocated: 446.464512 MB, Reserved: 1931.476992 MB\n",
      "-----------------\n",
      "points torch.Size([36303, 3])\n",
      "CVT loss:  tensor(0.0045, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4507, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.00012404841254465282 weighted: 0.12404841184616089 : Allocated: 463.056384 MB, Reserved: 1931.476992 MB\n",
      "SDF loss:  tensor(0.1743, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(174.2817, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 61: loss = 174.73245239257812\n",
      "before loss.backward(): Allocated: 1356.379648 MB, Reserved: 1931.476992 MB\n",
      "After loss.backward(): Allocated: 446.388224 MB, Reserved: 1931.476992 MB\n",
      "-----------------\n",
      "points torch.Size([37010, 3])\n",
      "CVT loss:  tensor(0.0049, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4901, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.0001229444023920223 weighted: 0.12294439971446991 : Allocated: 463.61856 MB, Reserved: 1931.476992 MB\n",
      "SDF loss:  tensor(0.1698, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(169.8338, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 62: loss = 170.3239288330078\n",
      "before loss.backward(): Allocated: 1359.702528 MB, Reserved: 2287.992832 MB\n",
      "After loss.backward(): Allocated: 446.486528 MB, Reserved: 2403.336192 MB\n",
      "-----------------\n",
      "points torch.Size([37831, 3])\n",
      "CVT loss:  tensor(0.0036, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3647, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.00012201711069792509 weighted: 0.12201710790395737 : Allocated: 463.903744 MB, Reserved: 2403.336192 MB\n",
      "SDF loss:  tensor(0.1654, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(165.4425, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 63: loss = 165.80714416503906\n",
      "before loss.backward(): Allocated: 1370.527744 MB, Reserved: 2403.336192 MB\n",
      "After loss.backward(): Allocated: 446.63552 MB, Reserved: 2403.336192 MB\n",
      "-----------------\n",
      "points torch.Size([38558, 3])\n",
      "CVT loss:  tensor(0.0061, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.6140, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.00012005721509922296 weighted: 0.12005721777677536 : Allocated: 463.872 MB, Reserved: 2403.336192 MB\n",
      "SDF loss:  tensor(0.1611, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(161.1039, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 64: loss = 161.71783447265625\n",
      "before loss.backward(): Allocated: 1379.831808 MB, Reserved: 2403.336192 MB\n",
      "After loss.backward(): Allocated: 446.51776 MB, Reserved: 2403.336192 MB\n",
      "-----------------\n",
      "points torch.Size([39275, 3])\n",
      "CVT loss:  tensor(0.0050, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4983, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.00011865044507430866 weighted: 0.11865044385194778 : Allocated: 464.474624 MB, Reserved: 2403.336192 MB\n",
      "SDF loss:  tensor(0.1568, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(156.8216, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 65: loss = 157.31996154785156\n",
      "before loss.backward(): Allocated: 1406.030336 MB, Reserved: 2403.336192 MB\n",
      "After loss.backward(): Allocated: 446.606848 MB, Reserved: 2445.279232 MB\n",
      "-----------------\n",
      "points torch.Size([39940, 3])\n",
      "CVT loss:  tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3431, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.00011608365457504988 weighted: 0.11608365178108215 : Allocated: 464.431104 MB, Reserved: 2445.279232 MB\n",
      "SDF loss:  tensor(0.1526, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(152.5952, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 66: loss = 152.93832397460938\n",
      "before loss.backward(): Allocated: 1408.059392 MB, Reserved: 2445.279232 MB\n",
      "After loss.backward(): Allocated: 446.823424 MB, Reserved: 2445.279232 MB\n",
      "-----------------\n",
      "points torch.Size([40682, 3])\n",
      "CVT loss:  tensor(0.0033, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3318, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.00011522971908561885 weighted: 0.11522971838712692 : Allocated: 464.646144 MB, Reserved: 2445.279232 MB\n",
      "SDF loss:  tensor(0.1484, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(148.4264, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 67: loss = 148.7582550048828\n",
      "before loss.backward(): Allocated: 1410.58048 MB, Reserved: 2445.279232 MB\n",
      "After loss.backward(): Allocated: 446.914048 MB, Reserved: 2445.279232 MB\n",
      "-----------------\n",
      "points torch.Size([41395, 3])\n",
      "CVT loss:  tensor(0.0046, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4648, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.00011363152589183301 weighted: 0.11363152414560318 : Allocated: 464.501248 MB, Reserved: 2445.279232 MB\n",
      "SDF loss:  tensor(0.1443, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(144.3168, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 68: loss = 144.78163146972656\n",
      "before loss.backward(): Allocated: 1416.887808 MB, Reserved: 2768.24064 MB\n",
      "After loss.backward(): Allocated: 446.682112 MB, Reserved: 2891.972608 MB\n",
      "-----------------\n",
      "points torch.Size([42225, 3])\n",
      "CVT loss:  tensor(0.0076, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.7631, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.00011259400343988091 weighted: 0.11259400099515915 : Allocated: 464.902144 MB, Reserved: 2891.972608 MB\n",
      "SDF loss:  tensor(0.1403, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(140.2628, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 69: loss = 141.02593994140625\n",
      "before loss.backward(): Allocated: 1427.943936 MB, Reserved: 2891.972608 MB\n",
      "After loss.backward(): Allocated: 446.87872 MB, Reserved: 2891.972608 MB\n",
      "-----------------\n",
      "points torch.Size([42948, 3])\n",
      "CVT loss:  tensor(0.0051, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.5132, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.00011377249757060781 weighted: 0.11377249658107758 : Allocated: 464.942592 MB, Reserved: 2891.972608 MB\n",
      "SDF loss:  tensor(0.1363, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(136.2677, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 70: loss = 136.7808380126953\n",
      "before loss.backward(): Allocated: 1437.268992 MB, Reserved: 2891.972608 MB\n",
      "After loss.backward(): Allocated: 446.81728 MB, Reserved: 2891.972608 MB\n",
      "-----------------\n",
      "points torch.Size([43527, 3])\n",
      "CVT loss:  tensor(0.0033, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3322, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.000112865527626127 weighted: 0.11286552995443344 : Allocated: 465.439744 MB, Reserved: 2891.972608 MB\n",
      "SDF loss:  tensor(0.1323, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(132.3325, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 71: loss = 132.66473388671875\n",
      "before loss.backward(): Allocated: 1460.076544 MB, Reserved: 2891.972608 MB\n",
      "After loss.backward(): Allocated: 447.135744 MB, Reserved: 2938.109952 MB\n",
      "-----------------\n",
      "points torch.Size([44438, 3])\n",
      "CVT loss:  tensor(0.0043, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4346, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.00011192535021109506 weighted: 0.11192534863948822 : Allocated: 465.825792 MB, Reserved: 2938.109952 MB\n",
      "SDF loss:  tensor(0.1285, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(128.4560, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 72: loss = 128.89059448242188\n",
      "before loss.backward(): Allocated: 1463.297024 MB, Reserved: 2938.109952 MB\n",
      "After loss.backward(): Allocated: 447.227392 MB, Reserved: 2938.109952 MB\n",
      "-----------------\n",
      "points torch.Size([44878, 3])\n",
      "CVT loss:  tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2741, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.00011106697638751939 weighted: 0.11106697469949722 : Allocated: 465.95072 MB, Reserved: 2938.109952 MB\n",
      "SDF loss:  tensor(0.1246, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(124.6425, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 73: loss = 124.9166488647461\n",
      "before loss.backward(): Allocated: 1464.789504 MB, Reserved: 2938.109952 MB\n",
      "After loss.backward(): Allocated: 447.341056 MB, Reserved: 2938.109952 MB\n",
      "-----------------\n",
      "points torch.Size([45468, 3])\n",
      "CVT loss:  tensor(0.0036, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3623, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.00010885867231991142 weighted: 0.10885867476463318 : Allocated: 466.023424 MB, Reserved: 2938.109952 MB\n",
      "SDF loss:  tensor(0.1209, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(120.8887, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 74: loss = 121.2510986328125\n",
      "before loss.backward(): Allocated: 1470.707712 MB, Reserved: 3290.431488 MB\n",
      "After loss.backward(): Allocated: 447.101952 MB, Reserved: 3422.552064 MB\n",
      "-----------------\n",
      "points torch.Size([46214, 3])\n",
      "CVT loss:  tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2749, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.00010742638551164418 weighted: 0.10742638260126114 : Allocated: 466.503168 MB, Reserved: 3422.552064 MB\n",
      "SDF loss:  tensor(0.1172, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(117.2034, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 75: loss = 117.47834777832031\n",
      "before loss.backward(): Allocated: 1480.766976 MB, Reserved: 3422.552064 MB\n",
      "After loss.backward(): Allocated: 447.33696 MB, Reserved: 3422.552064 MB\n",
      "-----------------\n",
      "points torch.Size([46977, 3])\n",
      "CVT loss:  tensor(0.0018, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1799, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.0001075702894013375 weighted: 0.10757029056549072 : Allocated: 466.539008 MB, Reserved: 3422.552064 MB\n",
      "SDF loss:  tensor(0.1136, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(113.5822, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 76: loss = 113.76205444335938\n",
      "before loss.backward(): Allocated: 1490.599936 MB, Reserved: 3422.552064 MB\n",
      "After loss.backward(): Allocated: 447.41376 MB, Reserved: 3422.552064 MB\n",
      "-----------------\n",
      "points torch.Size([47966, 3])\n",
      "CVT loss:  tensor(0.0040, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.00010783282777993008 weighted: 0.10783282667398453 : Allocated: 467.823104 MB, Reserved: 3422.552064 MB\n",
      "SDF loss:  tensor(0.1100, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(110.0219, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 77: loss = 110.4218978881836\n",
      "before loss.backward(): Allocated: 1514.295808 MB, Reserved: 3422.552064 MB\n",
      "After loss.backward(): Allocated: 447.06048 MB, Reserved: 3472.883712 MB\n",
      "-----------------\n",
      "points torch.Size([48503, 3])\n",
      "CVT loss:  tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2887, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.00010594028572086245 weighted: 0.10594028234481812 : Allocated: 468.105216 MB, Reserved: 3472.883712 MB\n",
      "SDF loss:  tensor(0.1065, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(106.5187, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 78: loss = 106.8073501586914\n",
      "before loss.backward(): Allocated: 1517.072896 MB, Reserved: 3472.883712 MB\n",
      "After loss.backward(): Allocated: 447.091712 MB, Reserved: 3472.883712 MB\n",
      "-----------------\n",
      "points torch.Size([49076, 3])\n",
      "CVT loss:  tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2316, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.00010359285806771368 weighted: 0.10359285771846771 : Allocated: 468.722688 MB, Reserved: 3472.883712 MB\n",
      "SDF loss:  tensor(0.1031, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(103.0735, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 79: loss = 103.30502319335938\n",
      "before loss.backward(): Allocated: 1520.35584 MB, Reserved: 3472.883712 MB\n",
      "After loss.backward(): Allocated: 447.734784 MB, Reserved: 3472.883712 MB\n",
      "-----------------\n",
      "points torch.Size([49853, 3])\n",
      "CVT loss:  tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2887, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.00010274560190737247 weighted: 0.10274560004472733 : Allocated: 468.971008 MB, Reserved: 3472.883712 MB\n",
      "SDF loss:  tensor(0.0997, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(99.6880, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 80: loss = 99.9767074584961\n",
      "before loss.backward(): Allocated: 1529.957888 MB, Reserved: 3772.776448 MB\n",
      "After loss.backward(): Allocated: 447.82336 MB, Reserved: 3913.285632 MB\n",
      "-----------------\n",
      "points torch.Size([50629, 3])\n",
      "CVT loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1717, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.00010331314115319401 weighted: 0.1033131405711174 : Allocated: 468.517888 MB, Reserved: 3913.285632 MB\n",
      "SDF loss:  tensor(0.0964, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(96.3659, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 81: loss = 96.53766632080078\n",
      "before loss.backward(): Allocated: 1539.468288 MB, Reserved: 3913.285632 MB\n",
      "After loss.backward(): Allocated: 447.214592 MB, Reserved: 3913.285632 MB\n",
      "-----------------\n",
      "points torch.Size([51398, 3])\n",
      "CVT loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1672, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.00010235141962766647 weighted: 0.10235141962766647 : Allocated: 469.060608 MB, Reserved: 3913.285632 MB\n",
      "SDF loss:  tensor(0.0931, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(93.1093, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 82: loss = 93.27648162841797\n",
      "before loss.backward(): Allocated: 1562.198528 MB, Reserved: 3913.285632 MB\n",
      "After loss.backward(): Allocated: 447.720448 MB, Reserved: 3967.811584 MB\n",
      "-----------------\n",
      "points torch.Size([52118, 3])\n",
      "CVT loss:  tensor(0.0045, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4492, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.0001005474041448906 weighted: 0.10054740309715271 : Allocated: 469.21472 MB, Reserved: 3967.811584 MB\n",
      "SDF loss:  tensor(0.0899, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(89.9195, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 83: loss = 90.36875915527344\n",
      "before loss.backward(): Allocated: 1566.806528 MB, Reserved: 3967.811584 MB\n",
      "After loss.backward(): Allocated: 447.300608 MB, Reserved: 3967.811584 MB\n",
      "-----------------\n",
      "points torch.Size([52751, 3])\n",
      "CVT loss:  tensor(0.0036, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3639, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 9.842042345553637e-05 weighted: 0.09842042624950409 : Allocated: 469.743104 MB, Reserved: 3967.811584 MB\n",
      "SDF loss:  tensor(0.0868, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(86.7957, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 84: loss = 87.15951538085938\n",
      "before loss.backward(): Allocated: 1571.249664 MB, Reserved: 3967.811584 MB\n",
      "After loss.backward(): Allocated: 448.009728 MB, Reserved: 3967.811584 MB\n",
      "-----------------\n",
      "points torch.Size([53421, 3])\n",
      "CVT loss:  tensor(0.0049, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4913, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 9.833413059823215e-05 weighted: 0.09833413362503052 : Allocated: 470.362112 MB, Reserved: 3967.811584 MB\n",
      "SDF loss:  tensor(0.0837, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(83.7407, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 85: loss = 84.23199462890625\n",
      "before loss.backward(): Allocated: 1577.162752 MB, Reserved: 4202.692608 MB\n",
      "After loss.backward(): Allocated: 448.092672 MB, Reserved: 4351.5904 MB\n",
      "-----------------\n",
      "points torch.Size([54134, 3])\n",
      "CVT loss:  tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2442, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 9.797386883292347e-05 weighted: 0.09797386825084686 : Allocated: 470.391296 MB, Reserved: 4351.5904 MB\n",
      "SDF loss:  tensor(0.0807, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(80.7473, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 86: loss = 80.99153900146484\n",
      "before loss.backward(): Allocated: 1586.344448 MB, Reserved: 4351.5904 MB\n",
      "After loss.backward(): Allocated: 448.183808 MB, Reserved: 4351.5904 MB\n",
      "-----------------\n",
      "points torch.Size([54619, 3])\n",
      "CVT loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1726, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 9.69652392086573e-05 weighted: 0.0969652384519577 : Allocated: 470.391808 MB, Reserved: 4351.5904 MB\n",
      "SDF loss:  tensor(0.0778, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(77.8149, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 87: loss = 77.98746490478516\n",
      "before loss.backward(): Allocated: 1592.57344 MB, Reserved: 4351.5904 MB\n",
      "After loss.backward(): Allocated: 448.275456 MB, Reserved: 4351.5904 MB\n",
      "-----------------\n",
      "points torch.Size([55401, 3])\n",
      "CVT loss:  tensor(0.0051, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.5066, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 9.70626570051536e-05 weighted: 0.09706265479326248 : Allocated: 471.4752 MB, Reserved: 4351.5904 MB\n",
      "SDF loss:  tensor(0.0749, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(74.9451, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 88: loss = 75.45166778564453\n",
      "before loss.backward(): Allocated: 1613.645312 MB, Reserved: 4351.5904 MB\n",
      "After loss.backward(): Allocated: 448.756736 MB, Reserved: 4410.310656 MB\n",
      "-----------------\n",
      "points torch.Size([56231, 3])\n",
      "CVT loss:  tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3426, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 9.801535634323955e-05 weighted: 0.09801535308361053 : Allocated: 471.54176 MB, Reserved: 4410.310656 MB\n",
      "SDF loss:  tensor(0.0721, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(72.1383, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 89: loss = 72.4808578491211\n",
      "before loss.backward(): Allocated: 1620.121088 MB, Reserved: 4410.310656 MB\n",
      "After loss.backward(): Allocated: 448.64256 MB, Reserved: 4410.310656 MB\n",
      "-----------------\n",
      "points torch.Size([56858, 3])\n",
      "CVT loss:  tensor(0.0020, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2042, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 9.663603850640357e-05 weighted: 0.09663604199886322 : Allocated: 469.996544 MB, Reserved: 4410.310656 MB\n",
      "SDF loss:  tensor(0.0694, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(69.4006, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 90: loss = 69.6048355102539\n",
      "before loss.backward(): Allocated: 1623.416832 MB, Reserved: 4410.310656 MB\n",
      "After loss.backward(): Allocated: 447.604224 MB, Reserved: 4410.310656 MB\n",
      "-----------------\n",
      "points torch.Size([57525, 3])\n",
      "CVT loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1582, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 9.576772572472692e-05 weighted: 0.09576772898435593 : Allocated: 471.450624 MB, Reserved: 4410.310656 MB\n",
      "SDF loss:  tensor(0.0667, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(66.7309, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 91: loss = 66.88905334472656\n",
      "before loss.backward(): Allocated: 1630.946304 MB, Reserved: 4567.597056 MB\n",
      "After loss.backward(): Allocated: 448.376832 MB, Reserved: 4724.883456 MB\n",
      "-----------------\n",
      "points torch.Size([57862, 3])\n",
      "CVT loss:  tensor(0.0040, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.4032, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 9.479763684794307e-05 weighted: 0.09479763358831406 : Allocated: 470.380544 MB, Reserved: 4724.883456 MB\n",
      "SDF loss:  tensor(0.0641, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(64.1252, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 92: loss = 64.52835845947266\n",
      "before loss.backward(): Allocated: 1634.204672 MB, Reserved: 4724.883456 MB\n",
      "After loss.backward(): Allocated: 447.642624 MB, Reserved: 4724.883456 MB\n",
      "-----------------\n",
      "points torch.Size([58712, 3])\n",
      "CVT loss:  tensor(0.0021, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2065, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 9.413689258508384e-05 weighted: 0.09413689374923706 : Allocated: 471.650816 MB, Reserved: 4724.883456 MB\n",
      "SDF loss:  tensor(0.0616, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(61.5879, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 93: loss = 61.794410705566406\n",
      "before loss.backward(): Allocated: 1646.386688 MB, Reserved: 4724.883456 MB\n",
      "After loss.backward(): Allocated: 448.2432 MB, Reserved: 4724.883456 MB\n",
      "-----------------\n",
      "points torch.Size([59304, 3])\n",
      "CVT loss:  tensor(0.0053, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.5323, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 9.178856998914853e-05 weighted: 0.09178856760263443 : Allocated: 472.075264 MB, Reserved: 4724.883456 MB\n",
      "SDF loss:  tensor(0.0591, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(59.1177, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 94: loss = 59.64999771118164\n",
      "before loss.backward(): Allocated: 1654.413312 MB, Reserved: 4724.883456 MB\n",
      "After loss.backward(): Allocated: 448.175104 MB, Reserved: 4724.883456 MB\n",
      "-----------------\n",
      "points torch.Size([60107, 3])\n",
      "CVT loss:  tensor(0.0032, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3247, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 9.12467876332812e-05 weighted: 0.09124679118394852 : Allocated: 472.46336 MB, Reserved: 4724.883456 MB\n",
      "SDF loss:  tensor(0.0567, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(56.7105, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 95: loss = 57.03520202636719\n",
      "before loss.backward(): Allocated: 1669.888512 MB, Reserved: 4724.883456 MB\n",
      "After loss.backward(): Allocated: 447.759872 MB, Reserved: 4787.798016 MB\n",
      "-----------------\n",
      "points torch.Size([60890, 3])\n",
      "CVT loss:  tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.2620, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 9.057356510311365e-05 weighted: 0.09057356417179108 : Allocated: 473.479168 MB, Reserved: 4787.798016 MB\n",
      "SDF loss:  tensor(0.0544, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(54.3602, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 96: loss = 54.622161865234375\n",
      "before loss.backward(): Allocated: 1678.15168 MB, Reserved: 4787.798016 MB\n",
      "After loss.backward(): Allocated: 448.295424 MB, Reserved: 4787.798016 MB\n",
      "-----------------\n",
      "points torch.Size([61805, 3])\n",
      "CVT loss:  tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.3145, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 8.909968892112374e-05 weighted: 0.0890996903181076 : Allocated: 473.226752 MB, Reserved: 4787.798016 MB\n",
      "SDF loss:  tensor(0.0521, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(52.0736, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 97: loss = 52.388065338134766\n",
      "before loss.backward(): Allocated: 1687.675904 MB, Reserved: 4854.90688 MB\n",
      "After loss.backward(): Allocated: 448.454144 MB, Reserved: 5020.581888 MB\n",
      "-----------------\n",
      "points torch.Size([62297, 3])\n",
      "CVT loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1524, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 8.859861554810777e-05 weighted: 0.08859861642122269 : Allocated: 473.833472 MB, Reserved: 5020.581888 MB\n",
      "SDF loss:  tensor(0.0498, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(49.8470, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 98: loss = 49.99936294555664\n",
      "before loss.backward(): Allocated: 1694.600704 MB, Reserved: 5020.581888 MB\n",
      "After loss.backward(): Allocated: 448.382464 MB, Reserved: 5020.581888 MB\n",
      "-----------------\n",
      "points torch.Size([62869, 3])\n",
      "CVT loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1103, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 8.851669554132968e-05 weighted: 0.08851669728755951 : Allocated: 474.503168 MB, Reserved: 5020.581888 MB\n",
      "SDF loss:  tensor(0.0477, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(47.6801, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 99: loss = 47.79037857055664\n",
      "before loss.backward(): Allocated: 1702.616576 MB, Reserved: 5020.581888 MB\n",
      "After loss.backward(): Allocated: 448.380928 MB, Reserved: 5020.581888 MB\n",
      "-----------------\n",
      "points torch.Size([63295, 3])\n",
      "CVT loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.0949, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 8.787522529019043e-05 weighted: 0.08787522464990616 : Allocated: 473.732096 MB, Reserved: 5020.581888 MB\n",
      "SDF loss:  tensor(0.0456, device='cuda:0', grad_fn=<AddBackward0>) weighted:  tensor(45.5717, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch 100: loss = 45.666629791259766\n",
      "before loss.backward(): Allocated: 1707.314176 MB, Reserved: 5020.581888 MB\n",
      "After loss.backward(): Allocated: 448.42496 MB, Reserved: 5020.581888 MB\n",
      "-----------------\n",
      "Saved to bunnyvoroloss_to_clip.npz\n",
      "Sites length:  32768\n",
      "min sites:  tensor(-1.1333, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "max sites:  tensor(1.0573, device='cuda:0', grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "site_file_path = f'{destination}{max_iter}_cvt_{lambda_cvt}_chamfer_{lambda_chamfer}_eikonal_{lambda_eikonal}.npy'\n",
    "#check if optimized sites file exists\n",
    "if not os.path.exists(site_file_path):\n",
    "    #import sites\n",
    "    print(\"Importing sites\")\n",
    "    sites = np.load(site_file_path)\n",
    "    sites = torch.from_numpy(sites).to(device).requires_grad_(True)\n",
    "else:\n",
    "    # import cProfile, pstats\n",
    "    # import time\n",
    "    # profiler = cProfile.Profile()\n",
    "    # profiler.enable()\n",
    "\n",
    "#     with torch.profiler.profile(activities=[\n",
    "#             torch.profiler.ProfilerActivity.CPU,\n",
    "#             torch.profiler.ProfilerActivity.CUDA,\n",
    "#         ],\n",
    "#         record_shapes=False,\n",
    "#         with_stack=True  # Captures function calls\n",
    "#     ) as prof:\n",
    "#         sites = autograd(sites, model, max_iter=max_iter, upsampling=0, lambda_weights=lambda_weights)\n",
    "#         torch.cuda.synchronize()\n",
    "# # \n",
    "#     print(prof.key_averages().table(sort_by=\"self_cuda_time_total\"))\n",
    "#     prof.export_chrome_trace(\"trace.json\")\n",
    "    \n",
    "    # \n",
    "    sites = autograd(sites, model, max_iter=max_iter, upsampling=0, lambda_weights=lambda_weights)\n",
    "\n",
    "    \n",
    "    # profiler.disable()\n",
    "    # stats = pstats.Stats(profiler).sort_stats('cumtime')\n",
    "    # stats.print_stats()\n",
    "    # stats.dump_stats(f'{destination}{mesh[0]}{max_iter}_3d_profile_{num_centroids}_chamfer{lambda_chamfer}.prof')\n",
    "    \n",
    "    \n",
    "    sites_np = sites.detach().cpu().numpy()\n",
    "    np.save(site_file_path, sites_np)\n",
    "    \n",
    "    \n",
    "\n",
    "print(\"Sites length: \", len(sites))\n",
    "print(\"min sites: \", torch.min(sites))\n",
    "print(\"max sites: \", torch.max(sites))\n",
    "#ps_cloud = ps.register_point_cloud(\"best_optimized_cvt_grid\",sites.detach().cpu().numpy())\n",
    "    \n",
    "lim=torch.abs(torch.max(sites)).detach().cpu().numpy()*1.1\n",
    "#plot_voronoi_3d(sites,lim,lim,lim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e4fcfff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model ./images/autograd/HotSpot/bunny100_100_3d_model_32768_chamfer1000.pth\n",
      "sites ./images/autograd/HotSpot/bunny100_100_3d_sites_32768_chamfer1000.pth\n"
     ]
    }
   ],
   "source": [
    "epoch = 100\n",
    "\n",
    "model_file_path = f'{destination}{mesh[0]}{max_iter}_{epoch}_3d_model_{num_centroids}_chamfer{lambda_chamfer}.pth'\n",
    "site_file_path = f'{destination}{mesh[0]}{max_iter}_{epoch}_3d_sites_{num_centroids}_chamfer{lambda_chamfer}.pth'\n",
    " \n",
    "sites = torch.load(site_file_path)\n",
    "\n",
    "sites_np = sites.detach().cpu().numpy()\n",
    "model.load_state_dict(torch.load(model_file_path))\n",
    "#\n",
    "#polyscope_sdf(model)\n",
    "#\n",
    "print(\"model\", model_file_path)\n",
    "print(\"sites\", site_file_path)\n",
    "ps_cloud = ps.register_point_cloud(f\"{epoch} epoch_cvt_grid\",sites_np)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72e588cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-Crossing faces final shape:  (38359, 3)\n"
     ]
    }
   ],
   "source": [
    "final_mesh = su.get_zero_crossing_mesh_3d(sites, model)\n",
    "#ps.register_surface_mesh(\"Zero-Crossing faces direct\", final_mesh[0], final_mesh[1])\n",
    "\n",
    "#save to file\n",
    "final_mesh_file = f'{mesh[0]}voroloss_sdf_trained{model_trained_it}.npz'\n",
    "faces = np.array(final_mesh[1], dtype=object)\n",
    "np.savez(final_mesh_file, vertices=final_mesh[0], faces=faces)\n",
    "\n",
    "data = np.load(final_mesh_file, allow_pickle=True)\n",
    "verts = data[\"vertices\"]       # (N_vertices, 3)\n",
    "faces = data[\"faces\"].tolist() # back to a list of lists\n",
    "\n",
    "print(\"Zero-Crossing faces final shape: \", verts.shape)\n",
    "ps.register_surface_mesh(\"Zero-Crossing faces final\", verts, faces)\n",
    "\n",
    "v_vect, f_vect = su.get_clipped_mesh_torch(sites, model, None, batch_size=512)\n",
    "ps.register_surface_mesh(\"polygon clipped mesh\", v_vect.detach().cpu().numpy(), f_vect)\n",
    "\n",
    "# fanning to transform polygon faces to triangle faces\n",
    "triangle_faces = [[f[0], f[i], f[i+1]] for f in f_vect for i in range(1, len(f)-1)]\n",
    "ps.register_surface_mesh(\"triangle clipped mesh\", v_vect.detach().cpu().numpy(), triangle_faces)\n",
    "\n",
    "triangle_faces = torch.tensor(triangle_faces, device=device)\n",
    "s_p = su.sample_mesh_points(v_vect, triangle_faces, num_samples=150*32**2)\n",
    "ps.register_point_cloud(\"sampled clipped mesh\", s_p.detach().cpu().numpy())\n",
    "\n",
    "hs_p = su.sample_mesh_points_heitz(v_vect, triangle_faces, num_samples=150*32**2)\n",
    "ps.register_point_cloud(\"heitz clipped mesh\", hs_p.detach().cpu().numpy())\n",
    "\n",
    "# ##register original mesh\n",
    "# mesh_file = mesh[1]+\".stl\"\n",
    "# #load mesh \n",
    "# m = trimesh.load(mesh_file)\n",
    "# #convert to numpy\n",
    "# mesh_np = np.array(m.vertices)\n",
    "# #normalize mesh\n",
    "# mesh_np = mesh_np - np.mean(mesh_np, axis=0)\n",
    "# mesh_np = mesh_np / np.max(np.abs(mesh_np))\n",
    "# mesh_faces = np.array(m.faces)\n",
    "# ps.register_surface_mesh(\"Original Mesh\", mesh_np, mesh_faces)\n",
    "\n",
    "\n",
    "import scipy.spatial as spatial\n",
    "from scipy.spatial import Delaunay\n",
    "\n",
    "tri = Delaunay(sites_np)\n",
    "delaunay_vertices =torch.tensor(np.array(tri.simplices), device=device)\n",
    "sdf_values = model(sites)\n",
    "\n",
    "# Assuming sites is a PyTorch tensor of shape [M, 3]\n",
    "sites = sites.unsqueeze(0)  # Now shape [1, M, 3]\n",
    "\n",
    "# Assuming SDF_Values is a PyTorch tensor of shape [M]\n",
    "sdf_values = sdf_values.unsqueeze(0)  # Now shape [1, M]\n",
    "\n",
    "marching_tetrehedra_mesh = kaolin.ops.conversions.marching_tetrahedra(sites, delaunay_vertices, sdf_values, return_tet_idx=False)\n",
    "#print(marching_tetrehedra_mesh)\n",
    "vertices_list, faces_list = marching_tetrehedra_mesh\n",
    "vertices = vertices_list[0]\n",
    "faces = faces_list[0]\n",
    "vertices_np = vertices.detach().cpu().numpy()  # Shape [N, 3]\n",
    "faces_np = faces.detach().cpu().numpy()  # Shape [M, 3] (triangles)\n",
    "ps.register_surface_mesh(\"Marching Tetrahedra Mesh final\", vertices_np, faces_np)\n",
    "\n",
    "# clipped_cvt = \"clipped_CVT.obj\"\n",
    "# if os.path.exists(clipped_cvt):\n",
    "#     clipped_cvt_mesh = trimesh.load(clipped_cvt)\n",
    "#     ps.register_surface_mesh(\"Clipped CVT\", clipped_cvt_mesh.vertices, clipped_cvt_mesh.faces)\n",
    "ps.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5deeda7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "End of script",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnd of script\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: End of script"
     ]
    }
   ],
   "source": [
    "assert False, \"End of script\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d940a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the meshed of different sdf trained total epochs and the clipped version \n",
    "import polyscope as ps\n",
    "import numpy as np\n",
    "import trimesh\n",
    "import os \n",
    "\n",
    "ps.init()\n",
    "nb_it = [\"\",\"_1000\",\"_3000\",\"_5000\",\"_7000\"]\n",
    "for it in nb_it:\n",
    "    final_mesh_file = f'gargoyle_sdf_trained{it}.npz'\n",
    "    data = np.load(final_mesh_file, allow_pickle=True)\n",
    "    verts = data[\"vertices\"]       # (N_vertices, 3)\n",
    "    faces = data[\"faces\"].tolist() # back to a list of lists\n",
    "\n",
    "    ps.register_surface_mesh(f\"Zero-Crossing faces final {it}\", verts, faces) \n",
    "\n",
    "for it in nb_it:\n",
    "    clipped_mesh_file = f'gargoyle_to_clip{it}.npz_clipped.obj'\n",
    "    clipped_cvt_mesh = trimesh.load(clipped_mesh_file)\n",
    "    ps.register_surface_mesh(f\"Clipped CVT {it}\", clipped_cvt_mesh.vertices, clipped_cvt_mesh.faces)\n",
    "    \n",
    "for it in nb_it:\n",
    "    final_mesh_file = f'bunnyvoroloss_sdf_trained{it}.npz'\n",
    "    if os.path.exists(final_mesh_file):\n",
    "        data = np.load(final_mesh_file, allow_pickle=True)\n",
    "        verts = data[\"vertices\"]       # (N_vertices, 3)\n",
    "        faces = data[\"faces\"].tolist() # back to a list of lists\n",
    "\n",
    "        ps.register_surface_mesh(f\"Voroloss Zero-Crossing faces final {it}\", verts, faces) \n",
    "\n",
    "for it in nb_it:\n",
    "    clipped_mesh_file = f'bunnyvoroloss_to_clip{it}.npz_clipped.obj'\n",
    "    if os.path.exists(clipped_mesh_file):\n",
    "        clipped_cvt_mesh = trimesh.load(clipped_mesh_file)\n",
    "        ps.register_surface_mesh(f\"Voroloss Clipped CVT {it}\", clipped_cvt_mesh.vertices, clipped_cvt_mesh.faces)\n",
    "    \n",
    "ps.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a193f128",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, \"End of script\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72240a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Voromesh points and values to try and plot the voronoi diagram\n",
    "import numpy as np\n",
    "from scipy.spatial import Voronoi\n",
    "import polyscope as ps\n",
    "def get_zero_crossing_mesh_3d(sites, values):\n",
    "    sites_np = sites\n",
    "    vor = Voronoi(sites_np)  # Compute 3D Voronoi diagram\n",
    "\n",
    "    sdf_values = values\n",
    "\n",
    "    valid_faces = []  # List of polygonal faces\n",
    "    used_vertices = set()  # Set of indices for valid vertices\n",
    "\n",
    "    for (point1, point2), ridge_vertices in zip(vor.ridge_points, vor.ridge_vertices):\n",
    "        if -1 in ridge_vertices:\n",
    "            continue  # Skip infinite ridges\n",
    "\n",
    "        # Check if SDF changes sign across this ridge\n",
    "        if np.sign(sdf_values[point1]) != np.sign(sdf_values[point2]):\n",
    "            valid_faces.append(ridge_vertices)\n",
    "            used_vertices.update(ridge_vertices)\n",
    "\n",
    "    # **Filter Voronoi vertices**\n",
    "    used_vertices = sorted(used_vertices)  # Keep unique, sorted indices\n",
    "    vertex_map = {old_idx: new_idx for new_idx, old_idx in enumerate(used_vertices)}\n",
    "    filtered_vertices = vor.vertices[used_vertices]\n",
    "\n",
    "    # **Re-index faces to match the new filtered vertex list**\n",
    "    filtered_faces = [[vertex_map[v] for v in face] for face in valid_faces]\n",
    "\n",
    "    return filtered_vertices, filtered_faces\n",
    "\n",
    "n_sample = [1, 16, 32, 150, 2400]\n",
    "grid_size = [32,128]\n",
    "voromesh_points = []\n",
    "voromesh_values = []\n",
    "ps.init()\n",
    "# groud plane none\n",
    "ps.set_ground_plane_mode(\"none\") \n",
    "for g in grid_size:\n",
    "    for i in n_sample:\n",
    "        try:\n",
    "            voromesh_points = np.load(f\"/home/wylliam/dev/VoroMesh/points_{i}_{g}.npy\")\n",
    "            voromesh_values = np.load(f\"/home/wylliam/dev/VoroMesh/values_{i}_{g}.npy\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"File not found for points_{i}_{g}.npy or values_{i}_{g}.npy\")\n",
    "            continue\n",
    "        mesh = get_zero_crossing_mesh_3d(voromesh_points, voromesh_values)\n",
    "        ps.register_surface_mesh(f\"mesh_{g}_{i}\", mesh[0], mesh[1])\n",
    "\n",
    "ps.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3355a005",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, \"End of script\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3c340c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#working version of differentiable meshing not vectorized\n",
    "\n",
    "\n",
    "from collections import defaultdict\n",
    "import itertools\n",
    "\n",
    "def sort_face_loop(vertices, face):\n",
    "    pts = vertices[face]                       # shape (N,3)\n",
    "    ctr = pts.mean(axis=0)                     # centroid\n",
    "    # compute a normal for the polygon plane (via PCA/SVD)\n",
    "    _, _, vt = np.linalg.svd(pts - ctr)\n",
    "    normal = vt[2]                             # last singular vector\n",
    "\n",
    "    # pick a reference axis in the plane\n",
    "    ref = pts[0] - ctr\n",
    "    ref -= normal * (normal @ ref)             # project off normal\n",
    "\n",
    "    # compute angles of each point around the centroid\n",
    "    def angle(p):\n",
    "        v = p - ctr\n",
    "        v -= normal * (normal @ v)             # project into plane\n",
    "        a = np.arctan2(np.linalg.norm(np.cross(ref, v)),\n",
    "                    ref @ v)\n",
    "        # sign:\n",
    "        if np.dot(normal, np.cross(ref, v)) < 0:\n",
    "            a = 2*np.pi - a\n",
    "        return a\n",
    "\n",
    "    face_sorted = sorted(face, key=lambda idx: angle(vertices[idx]))\n",
    "    return face_sorted\n",
    "\n",
    "def get_clipped_mesh(sites, model):\n",
    "    sites_np = sites.detach().cpu().numpy()\n",
    "    d3dsimplices = diffvoronoi.get_delaunay_simplices(sites_np.reshape(input_dims*sites_np.shape[0]))\n",
    "    d3dsimplices_np = np.array(d3dsimplices)\n",
    "    \n",
    "    sdf_values = model(sites)\n",
    "    # sdf_gradients = torch.autograd.grad(outputs=sdf_values, inputs=sites, grad_outputs=torch.ones_like(sdf_values), create_graph=True, retain_graph=True,)[0] # (N, 3)\n",
    "    # N, D = sites.shape\n",
    "    # hess_sdf = torch.zeros(N, D, D, device=sites.device)\n",
    "    # for i in range(D):\n",
    "    #     grad2 = torch.autograd.grad(outputs=sdf_gradients[:, i], inputs=sites, grad_outputs=torch.ones_like(sdf_gradients[:, i]), create_graph=False, retain_graph=True,)[0] # (N, 3)\n",
    "    #     hess_sdf[:, i, :] = grad2 # fill row i of each 3Ã—3 Hessian\n",
    "\n",
    "    d3dsimplices_tensor = torch.tensor(d3dsimplices_np, device=device)\n",
    "    voronoi_vertices = su.compute_vertices_3d_vectorized(sites, d3dsimplices_tensor)    \n",
    "    tetra_edges = torch.cat([\n",
    "        d3dsimplices_tensor[:, [0, 1]],\n",
    "        d3dsimplices_tensor[:, [1, 2]],\n",
    "        d3dsimplices_tensor[:, [2, 3]],\n",
    "        d3dsimplices_tensor[:, [3, 0]],\n",
    "        d3dsimplices_tensor[:, [0, 2]],\n",
    "        d3dsimplices_tensor[:, [1, 3]]\n",
    "                                ], dim=0).to(device)\n",
    "    # Sort each edge to ensure uniqueness (because (a, b) and (b, a) are the same)\n",
    "    tetra_edges, _ = torch.sort(tetra_edges, dim=1)\n",
    "    # Get unique edges\n",
    "    voronoi_ridges = torch.unique(tetra_edges, dim=0)\n",
    "    # create a dictionnary to store the d3dsimplices composing the faces\n",
    "    # there is a face for every voronoi_ridges\n",
    "    # every vertices of the face is a simplex containing the two sites of the ridge\n",
    "    face_dict = defaultdict(list)\n",
    "    for simplex_idx, simplex in enumerate(d3dsimplices_np):\n",
    "        for a,b in itertools.combinations(simplex, 2):\n",
    "            key = (a, b) if a < b else (b, a)\n",
    "            face_dict[key].append(simplex_idx)\n",
    "\n",
    "    # Extract the SDF values for each site in the pair\n",
    "    sdf_i = sdf_values[voronoi_ridges[:, 0]]  # First site in each pair\n",
    "    sdf_j = sdf_values[voronoi_ridges[:, 1]]  # Second site in each pair\n",
    "    # Find the indices where SDF values have opposing signs or one is zero\n",
    "    mask_zero_crossing_sites = (sdf_i * sdf_j <= 0).squeeze()\n",
    "    # filter the faces based on the mask\n",
    "    filtered_faces = voronoi_ridges[mask_zero_crossing_sites].detach().cpu().numpy()\n",
    "    faces = []\n",
    "    for a, b in filtered_faces:\n",
    "        key = (a, b) if a < b else (b, a)\n",
    "        match = face_dict.get(key, [])\n",
    "        match = sort_face_loop(voronoi_vertices.detach().cpu().numpy(), match)\n",
    "        faces.append(match)\n",
    "\n",
    "\n",
    "    # Not sure if i should do this at all.\n",
    "    # 1) find every vertex index thatâ€™s actually used\n",
    "    used = set(idx for face in faces for idx in face)\n",
    "    # 2) create old->new mapping\n",
    "    old2new = {old: new for new, old in enumerate(sorted(used))}\n",
    "    # 3) build new, compact vertex array\n",
    "    vertices = voronoi_vertices[sorted(used), :]\n",
    "    # 4) remap faces\n",
    "    faces_new = [[old2new[idx] for idx in face] for face in faces]\n",
    "\n",
    "    print(\"vertices shape: \", vertices)\n",
    "    print(\"faces : \", faces_new)\n",
    "\n",
    "    return vertices, faces_new\n",
    "    return voronoi_vertices, faces"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
