{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed71bbfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "Using device:  NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "import kaolin\n",
    "import torch\n",
    "import math\n",
    "import matplotlib\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import polyscope as ps\n",
    "import trimesh\n",
    "import diffvoronoi\n",
    "\n",
    "from scipy.spatial import Voronoi, voronoi_plot_2d, Delaunay\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import sdfpred_utils.sdfpred_utils as su\n",
    "import sdfpred_utils.sdf_MLP as mlp\n",
    "import sdfpred_utils.sdf_functions as sdf\n",
    "import sdfpred_utils.loss_functions as lf\n",
    "import sdfpred_utils.Steik_data3d as sd3d\n",
    "import sdfpred_utils.Steik_Loss as sl\n",
    "import sdfpred_utils.Steik_utils as Stu \n",
    "import open3d as o3d\n",
    "\n",
    "#cuda devices\n",
    "device = torch.device(\"cuda:0\")\n",
    "print(\"Using device: \", torch.cuda.get_device_name(device))\n",
    "\n",
    "#default tensor types\n",
    "#torch.set_default_tensor_type(torch.cuda.DoubleTensor)\n",
    "\n",
    "multires = 2\n",
    "input_dims = 3\n",
    "lr_sites = 0.005/2\n",
    "lr_model = 0.00005*2\n",
    "destination = \"./images/autograd/HotSpot/\"\n",
    "mesh = [\"gargoyle\",\"/home/wylliam/dev/Kyushu_experiments/data/gargoyle\"]\n",
    "model_trained_it = \"\"\n",
    "trained_model_path = f\"/home/wylliam/dev/HotSpot/log/3D/pc/HotSpot-all-2025-04-24-18-16-03/gargoyle/gargoyle/trained_models/model{model_trained_it}.pth\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a4b4e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new sites\n",
      "Sites shape:  torch.Size([4096, 3])\n",
      "[polyscope] Backend: openGL3_glfw -- Loaded openGL version: 3.3.0 NVIDIA 570.144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wylliam/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1678402412426/work/aten/src/ATen/native/TensorShape.cpp:3483.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<polyscope.point_cloud.PointCloud at 0x7ec1fffad5e0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_centroids = 16**3\n",
    "\n",
    "print(\"Creating new sites\")\n",
    "noise_scale = 0.1\n",
    "domain_limit = 1\n",
    "x = torch.linspace(-domain_limit, domain_limit, int(round(num_centroids**(1/3))))\n",
    "y = torch.linspace(-domain_limit, domain_limit, int(round(num_centroids**(1/3))))\n",
    "z = torch.linspace(-domain_limit, domain_limit, int(round(num_centroids**(1/3))))\n",
    "meshgrid = torch.meshgrid(x, y, z)\n",
    "meshgrid = torch.stack(meshgrid, dim=3).view(-1, 3)\n",
    "#add noise to meshgrid\n",
    "meshgrid += torch.randn_like(meshgrid) * noise_scale\n",
    "sites = meshgrid.to(device, dtype=torch.float32).requires_grad_(True)\n",
    "\n",
    "print(\"Sites shape: \", sites.shape)\n",
    "ps.init()\n",
    "ps.register_point_cloud(\"initial_cvt_grid\",sites.detach().cpu().numpy())\n",
    "\n",
    "# # load pointcloud used for sdf training\n",
    "# pointcloud = o3d.io.read_point_cloud(mesh[1]+\".ply\")\n",
    "# print(\"Pointcloud shape: \", np.asarray(pointcloud.points).shape)\n",
    "# # sample pointcloud to 150*32*32\n",
    "# chamfer_distance_pc_gt = pointcloud.uniform_down_sample(int((128**3)/(150*32*32)))\n",
    "# chamfer_distance_pc_gt = np.asarray(chamfer_distance_pc_gt.points)\n",
    "# print(\"Chamfer distance pointcloud shape: \", chamfer_distance_pc_gt.shape)\n",
    "\n",
    "\n",
    "# ps.register_point_cloud(\"pointcloud_gt\", chamfer_distance_pc_gt)\n",
    "# chamfer_distance_pc_gt = torch.tensor(chamfer_distance_pc_gt, device=device, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe96048f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnfld_points shape:  torch.Size([1, 153600, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wylliam/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LOAD MODEL WITH HOTSPOT\n",
    "import sys\n",
    "sys.path.append(\"3rdparty/HotSpot\")\n",
    "from dataset import shape_3d\n",
    "import models.Net as Net\n",
    "\n",
    "loss_type = \"igr_w_heat\"\n",
    "loss_weights = [350, 0, 0, 1, 0, 0, 20]\n",
    "\n",
    "train_set = shape_3d.ReconDataset(\n",
    "    file_path = mesh[1]+\".ply\",\n",
    "    n_points=32*32*150,#15000, #args.n_points,\n",
    "    n_samples=10001, #args.n_iterations,\n",
    "    grid_res=256, #args.grid_res,\n",
    "    grid_range=1.1, #args.grid_range,\n",
    "    sample_type=\"uniform_central_gaussian\", #args.nonmnfld_sample_type,\n",
    "    sampling_std=0.5, #args.nonmnfld_sample_std,\n",
    "    n_random_samples=7500, #args.n_random_samples,\n",
    "    resample=True,\n",
    "    compute_sal_dist_gt=(\n",
    "        True if \"sal\" in loss_type and loss_weights[5] > 0 else False\n",
    "    ),\n",
    "    scale_method=\"mean\"#\"mean\" #args.pcd_scale_method,\n",
    ")\n",
    "\n",
    "model = Net.Network(\n",
    "    latent_size=0,#args.latent_size,\n",
    "    in_dim=3,\n",
    "    decoder_hidden_dim=128,#args.decoder_hidden_dim,\n",
    "    nl=\"sine\",#args.nl,\n",
    "    encoder_type=\"none\",#args.encoder_type,\n",
    "    decoder_n_hidden_layers=5,#args.decoder_n_hidden_layers,\n",
    "    neuron_type=\"quadratic\",#args.neuron_type,\n",
    "    init_type=\"mfgi\",#args.init_type,\n",
    "    sphere_init_params=[1.6, 0.1],#args.sphere_init_params,\n",
    "    n_repeat_period=30#args.n_repeat_period,\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "######       \n",
    "test_dataloader = torch.utils.data.DataLoader(train_set, batch_size=1, shuffle=False, num_workers=0, pin_memory=False)   \n",
    "test_data = next(iter(test_dataloader))\n",
    "mnfld_points = test_data[\"mnfld_points\"].to(device)\n",
    "mnfld_points.requires_grad_()\n",
    "print(\"mnfld_points shape: \", mnfld_points.shape)\n",
    "if torch.cuda.is_available():\n",
    "    map_location = torch.device(\"cuda\")\n",
    "else:\n",
    "    map_location = torch.device(\"cpu\")\n",
    "model.load_state_dict(torch.load(trained_model_path, weights_only=True, map_location=map_location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5753400f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add mnfld points with random noise to sites \n",
    "N = mnfld_points.squeeze(0).shape[0]\n",
    "num_samples = 16**3\n",
    "idx = torch.randint(0, N, (num_samples,))\n",
    "sampled = mnfld_points.squeeze(0)[idx]\n",
    "perturbed = sampled + (torch.rand_like(sampled)-0.5)*0.1\n",
    "sites = torch.cat((sites, perturbed), dim=0)\n",
    "\n",
    "\n",
    "# sites = torch.cat((sites, mnfld_points.squeeze(0)+(torch.rand_like(mnfld_points.squeeze(0))-0.5)*0.1), dim=0)\n",
    "# sites = torch.cat((sites, mnfld_points.squeeze(0)+(torch.rand_like(mnfld_points.squeeze(0))-0.5)*0.1), dim=0)\n",
    "\n",
    "# make sites a leaf tensor\n",
    "sites = sites.detach().requires_grad_()\n",
    "\n",
    "sites_pred = model(sites)#[\"nonmanifold_pnts_pred\"]\n",
    "mnfld_preds = model(mnfld_points)#[\"nonmanifold_pnts_pred\"]\n",
    "\n",
    "ps_cloud = ps.register_point_cloud(\"initial_cvt_grid+pc_gt\",sites.detach().cpu().numpy())\n",
    "mnf_cloud = ps.register_point_cloud(\"mnfld_points_pred\",mnfld_points.squeeze(0).detach().cpu().numpy())\n",
    "mnf_cloud.add_scalar_quantity(\"mnfld_points_pred\", mnfld_preds.reshape(-1).detach().cpu().numpy(), enabled=True)\n",
    "ps_cloud.add_scalar_quantity(\"vis_grid_pred\", sites_pred.reshape(-1).detach().cpu().numpy(), enabled=True)\n",
    "\n",
    "initial_mesh = su.get_zero_crossing_mesh_3d(sites, model)\n",
    "ps.register_surface_mesh(\"initial Zero-Crossing faces\", initial_mesh[0], initial_mesh[1])\n",
    "\n",
    "ps.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "460a316b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SITES OPTIMISATION LOOP\n",
    "cvt_loss_values = []\n",
    "min_distance_loss_values = []\n",
    "chamfer_distance_loss_values = []\n",
    "eikonal_loss_values = []\n",
    "domain_restriction_loss_values = []\n",
    "sdf_loss_values = []\n",
    "div_loss_values = []\n",
    "loss_values = []\n",
    "\n",
    "\n",
    "\n",
    "def autograd(sites, model, max_iter=100, stop_train_threshold=1e-6, upsampling=0, lambda_weights = [0.1,1.0,0.1,0.1,1.0,1.0,0.1]):\n",
    "    optimizer = torch.optim.Adam([\n",
    "    {'params': [p for _, p in model.named_parameters()], 'lr': 5e-5},\n",
    "    {'params': [sites], 'lr': lr_sites}\n",
    "], betas=(0.9, 0.999))\n",
    "\n",
    "    prev_loss = float(\"inf\")\n",
    "    best_loss = float(\"inf\")\n",
    "    upsampled = 0.0\n",
    "    epoch = 0\n",
    "    lambda_cvt = lambda_weights[0]\n",
    "    # lambda_pc = lambda_weights[1]\n",
    "    lambda_min_distance = lambda_weights[2]\n",
    "    # lambda_laplace = lambda_weights[3]\n",
    "    lamda_chamfer = lambda_weights[4]\n",
    "    lambda_eikonal = lambda_weights[5]\n",
    "    lambda_domain_restriction = lambda_weights[6]\n",
    "    # lambda_target_points = lambda_weights[7]\n",
    "    lambda_sdf = 5e3\n",
    "    lambda_div = 1e2\n",
    "    lambda_eikonal = 5e1\n",
    "    best_sites = sites.clone()\n",
    "    best_sites.best_loss = best_loss\n",
    "    \n",
    "    while epoch <= max_iter:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # compute voronoi and delaunay once for each epoch and pass it around\n",
    "        # Compute Voronoi diagram\n",
    "        sites_np = sites.detach().cpu().numpy()\n",
    "        #vor = Voronoi(sites_np)\n",
    "        #tri = Delaunay(sites_np)\n",
    "      \n",
    "      \n",
    "        d3dsimplices = diffvoronoi.get_delaunay_simplices(sites_np.reshape(input_dims*sites_np.shape[0]))\n",
    "        d3dsimplices = np.array(d3dsimplices)\n",
    "        #print(\"Delaunay simplices shape: \", d3dsimplices.shape)\n",
    "        \n",
    "        vertices_to_compute, bisectors_to_compute = su.compute_zero_crossing_vertices_3d(sites, None, None, d3dsimplices, model)\n",
    "                \n",
    "        #vertices_to_compute, bisectors_to_compute = su.compute_zero_crossing_vertices_3d(sites, None, tri, None, model)\n",
    "        #vertices_to_compute, bisectors_to_compute = su.compute_zero_crossing_vertices_3d(sites, vor, tri, None, model)\n",
    "        \n",
    "        vertices = su.compute_vertices_3d_vectorized(sites, vertices_to_compute)    \n",
    "        bisectors = su.compute_all_bisectors_vectorized(sites, bisectors_to_compute)\n",
    "        points = torch.cat((vertices, bisectors), 0)\n",
    "        print(\"points\", points.shape) \n",
    "\n",
    "        # Compute losses       \n",
    "        #cvt_loss = lf.compute_cvt_loss_vectorized_voronoi(sites, vor)\n",
    "        #cvt_loss = lf.compute_cvt_loss_vectorized_delaunay(sites, tri)\n",
    "    \n",
    "        cvt_loss = lf.compute_cvt_loss_vectorized_delaunay(sites, None, d3dsimplices)\n",
    "        print(\"CVT loss: \", cvt_loss)\n",
    "        #min_distance_loss = lf.sdf_weighted_min_distance_loss(model, sites)\n",
    "        \n",
    "        from pytorch3d.loss import chamfer_distance\n",
    "        chamfer_loss, _ = chamfer_distance(mnfld_points.detach(), points.unsqueeze(0))\n",
    "        print(f\"After Chamfer loss PYTORCH3D {chamfer_loss} : Allocated: {torch.cuda.memory_allocated() / 1e6} MB, Reserved: {torch.cuda.memory_reserved() / 1e6} MB\")\n",
    "            \n",
    "        \n",
    "        # chamfer_loss = lf.chamfer_distance(mnfld_points, points)\n",
    "        \n",
    "        sites_loss = (\n",
    "            lambda_cvt * cvt_loss +\n",
    "            lamda_chamfer * chamfer_loss\n",
    "        )\n",
    "            \n",
    "        loss = sites_loss\n",
    "        loss_values.append(loss.item())\n",
    "        print(f\"Epoch {epoch}: loss = {loss.item()}\")\n",
    "        print(f\"before loss.backward(): Allocated: {torch.cuda.memory_allocated() / 1e6} MB, Reserved: {torch.cuda.memory_reserved() / 1e6} MB\")\n",
    "\n",
    "        loss.backward()\n",
    "        print(f\"After loss.backward(): Allocated: {torch.cuda.memory_allocated() / 1e6} MB, Reserved: {torch.cuda.memory_reserved() / 1e6} MB\")\n",
    "        print(\"-----------------\")\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        if loss.item() < best_loss:\n",
    "            best_loss = loss.item()\n",
    "            best_epoch = epoch\n",
    "            best_sites = sites.clone()\n",
    "            best_sites.best_loss = best_loss\n",
    "            #if upsampled > 0:\n",
    "                #print(f\"UPSAMPLED {upsampled} Best Epoch {best_epoch}: Best loss = {best_loss}\")\n",
    "                #return best_sites\n",
    "        \n",
    "        if abs(prev_loss - loss.item()) < stop_train_threshold:\n",
    "            print(f\"Converged at epoch {epoch} with loss {loss.item()}\")\n",
    "            #break\n",
    "        \n",
    "        prev_loss = loss.item() \n",
    "        \n",
    "        # if epoch>100 and (epoch // 100) == upsampled+1 and loss.item() < 0.5 and upsampled < upsampling:\n",
    "        if epoch/max_iter > (upsampled+1)/(upsampling+1) and upsampled < upsampling:\n",
    "            print(\"sites length BEFORE UPSAMPLING: \",len(sites))\n",
    "            sites = su.upsampling_vectorized(sites, tri=None, vor=None, simplices=d3dsimplices, model=model)\n",
    "            sites = sites.detach().requires_grad_(True)\n",
    "            optimizer = torch.optim.Adam([{'params': [p for _, p in model.named_parameters()], 'lr': lr_model},\n",
    "                                          {'params': [sites], 'lr': lr_sites}])\n",
    "            upsampled += 1.0\n",
    "            print(\"sites length AFTER: \",len(sites))\n",
    "            \n",
    "          \n",
    "        if epoch % (max_iter/50) == 0:\n",
    "            #print(f\"Epoch {epoch}: loss = {loss.item()}\")\n",
    "            #print(f\"Best Epoch {best_epoch}: Best loss = {best_loss}\")\n",
    "            #save model and sites\n",
    "            site_file_path = f'{destination}{mesh[0]}{max_iter}_{epoch}_3d_sites_{num_centroids}_chamfer{lamda_chamfer}.pth'\n",
    "            model_file_path = f'{destination}{mesh[0]}{max_iter}_{epoch}_3d_model_{num_centroids}_chamfer{lamda_chamfer}.pth'\n",
    "            torch.save(model.state_dict(), model_file_path)\n",
    "            torch.save(sites, site_file_path)\n",
    "            \n",
    "        epoch += 1           \n",
    "    \n",
    "    #Export the sites, their sdf values, the gradients of the sdf values and the hessian\n",
    "    sdf_values = model(sites)\n",
    "\n",
    "    sdf_gradients = torch.autograd.grad(outputs=sdf_values, inputs=sites, grad_outputs=torch.ones_like(sdf_values), create_graph=True, retain_graph=True,)[0] # (N, 3)\n",
    "\n",
    "    N, D = sites.shape\n",
    "    hess_sdf = torch.zeros(N, D, D, device=sites.device)\n",
    "    for i in range(D):\n",
    "        grad2 = torch.autograd.grad(outputs=sdf_gradients[:, i], inputs=sites, grad_outputs=torch.ones_like(sdf_gradients[:, i]), create_graph=False, retain_graph=True,)[0] # (N, 3)\n",
    "        hess_sdf[:, i, :] = grad2 # fill row i of each 3Ã—3 Hessian\n",
    "    \n",
    "    np.savez(f'{mesh[0]}_to_clip{model_trained_it}.npz', sites=sites.detach().cpu().numpy(), sdf_values=sdf_values.detach().cpu().numpy(), sdf_gradients=sdf_gradients.detach().cpu().numpy(), sdf_hessians=hess_sdf.detach().cpu().numpy())\n",
    "    print(f\"Saved to {mesh[0]}_to_clip{model_trained_it}.npz\")\n",
    "    return best_sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7e96773",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lambda_weights = [252,0,0,0,10.211111,0,100,0]\n",
    "lambda_weights = [500,0,0,0,1000,0,100,0]\n",
    "\n",
    "\n",
    "lambda_cvt = lambda_weights[0]\n",
    "lambda_sdf = lambda_weights[1]\n",
    "lambda_min_distance = lambda_weights[2]\n",
    "lambda_laplace = lambda_weights[3]\n",
    "lamda_chamfer = lambda_weights[4]\n",
    "lambda_eikonal = lambda_weights[5]\n",
    "lambda_domain_restriction = lambda_weights[6]\n",
    "lambda_true_points = lambda_weights[7]\n",
    "\n",
    "max_iter = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fb2cefd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "points torch.Size([23232, 3])\n",
      "CVT loss:  tensor(0.0525, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 0.00040925934445112944 : Allocated: 2126.526976 MB, Reserved: 2239.758336 MB\n",
      "Epoch 0: loss = 26.658226013183594\n",
      "before loss.backward(): Allocated: 2126.527488 MB, Reserved: 2239.758336 MB\n",
      "After loss.backward(): Allocated: 2124.58752 MB, Reserved: 2243.95264 MB\n",
      "-----------------\n",
      "points torch.Size([22813, 3])\n",
      "CVT loss:  tensor(0.0516, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 0.0003023114113602787 : Allocated: 2135.04 MB, Reserved: 2264.92416 MB\n",
      "Epoch 1: loss = 26.096540451049805\n",
      "before loss.backward(): Allocated: 2135.04 MB, Reserved: 2264.92416 MB\n",
      "After loss.backward(): Allocated: 2124.762624 MB, Reserved: 2264.92416 MB\n",
      "-----------------\n",
      "points torch.Size([22473, 3])\n",
      "CVT loss:  tensor(0.0626, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 0.00023457770294044167 : Allocated: 2134.876672 MB, Reserved: 2264.92416 MB\n",
      "Epoch 2: loss = 31.54093360900879\n",
      "before loss.backward(): Allocated: 2134.876672 MB, Reserved: 2264.92416 MB\n",
      "After loss.backward(): Allocated: 2124.745728 MB, Reserved: 2264.92416 MB\n",
      "-----------------\n",
      "points torch.Size([22412, 3])\n",
      "CVT loss:  tensor(0.0565, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 0.0001867798564489931 : Allocated: 2134.833152 MB, Reserved: 2264.92416 MB\n",
      "Epoch 3: loss = 28.415077209472656\n",
      "before loss.backward(): Allocated: 2134.833152 MB, Reserved: 2264.92416 MB\n",
      "After loss.backward(): Allocated: 2124.742656 MB, Reserved: 2264.92416 MB\n",
      "-----------------\n",
      "points torch.Size([22440, 3])\n",
      "CVT loss:  tensor(0.0399, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 0.00015708785213064402 : Allocated: 2134.829056 MB, Reserved: 2264.92416 MB\n",
      "Epoch 4: loss = 20.1179141998291\n",
      "before loss.backward(): Allocated: 2134.829056 MB, Reserved: 2264.92416 MB\n",
      "After loss.backward(): Allocated: 2124.742656 MB, Reserved: 2264.92416 MB\n",
      "-----------------\n",
      "points torch.Size([22553, 3])\n",
      "CVT loss:  tensor(0.0469, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 0.0001377226726617664 : Allocated: 2134.864384 MB, Reserved: 2264.92416 MB\n",
      "Epoch 5: loss = 23.564712524414062\n",
      "before loss.backward(): Allocated: 2134.864384 MB, Reserved: 2264.92416 MB\n",
      "After loss.backward(): Allocated: 2124.748288 MB, Reserved: 2264.92416 MB\n",
      "-----------------\n",
      "points torch.Size([22492, 3])\n",
      "CVT loss:  tensor(0.0511, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 0.00012413010699674487 : Allocated: 2134.841344 MB, Reserved: 2264.92416 MB\n",
      "Epoch 6: loss = 25.679895401000977\n",
      "before loss.backward(): Allocated: 2134.841344 MB, Reserved: 2264.92416 MB\n",
      "After loss.backward(): Allocated: 2124.745728 MB, Reserved: 2264.92416 MB\n",
      "-----------------\n",
      "points torch.Size([22491, 3])\n",
      "CVT loss:  tensor(0.0429, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 0.0001151733158621937 : Allocated: 2134.83264 MB, Reserved: 2264.92416 MB\n",
      "Epoch 7: loss = 21.566184997558594\n",
      "before loss.backward(): Allocated: 2134.83264 MB, Reserved: 2264.92416 MB\n",
      "After loss.backward(): Allocated: 2124.745728 MB, Reserved: 2264.92416 MB\n",
      "-----------------\n",
      "points torch.Size([22450, 3])\n",
      "CVT loss:  tensor(0.0570, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 0.00010934869351331145 : Allocated: 2134.818304 MB, Reserved: 2264.92416 MB\n",
      "Epoch 8: loss = 28.622522354125977\n",
      "before loss.backward(): Allocated: 2134.818304 MB, Reserved: 2264.92416 MB\n",
      "After loss.backward(): Allocated: 2124.743168 MB, Reserved: 2264.92416 MB\n",
      "-----------------\n",
      "points torch.Size([22433, 3])\n",
      "CVT loss:  tensor(0.0751, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 0.00010513700544834137 : Allocated: 2134.808576 MB, Reserved: 2264.92416 MB\n",
      "Epoch 9: loss = 37.66560745239258\n",
      "before loss.backward(): Allocated: 2134.808576 MB, Reserved: 2264.92416 MB\n",
      "After loss.backward(): Allocated: 2124.742144 MB, Reserved: 2264.92416 MB\n",
      "-----------------\n",
      "points torch.Size([22441, 3])\n",
      "CVT loss:  tensor(0.0835, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 0.00010124965774593875 : Allocated: 2134.808576 MB, Reserved: 2264.92416 MB\n",
      "Epoch 10: loss = 41.875648498535156\n",
      "before loss.backward(): Allocated: 2134.808576 MB, Reserved: 2264.92416 MB\n",
      "After loss.backward(): Allocated: 2124.742144 MB, Reserved: 2264.92416 MB\n",
      "-----------------\n",
      "points torch.Size([22510, 3])\n",
      "CVT loss:  tensor(0.0861, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 9.80456024990417e-05 : Allocated: 2134.83264 MB, Reserved: 2264.92416 MB\n",
      "Epoch 11: loss = 43.15945816040039\n",
      "before loss.backward(): Allocated: 2134.83264 MB, Reserved: 2264.92416 MB\n",
      "After loss.backward(): Allocated: 2124.745728 MB, Reserved: 2264.92416 MB\n",
      "-----------------\n",
      "points torch.Size([22533, 3])\n",
      "CVT loss:  tensor(0.1011, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 9.486822818871588e-05 : Allocated: 2134.839296 MB, Reserved: 2264.92416 MB\n",
      "Epoch 12: loss = 50.634490966796875\n",
      "before loss.backward(): Allocated: 2134.839296 MB, Reserved: 2264.92416 MB\n",
      "After loss.backward(): Allocated: 2124.747264 MB, Reserved: 2264.92416 MB\n",
      "-----------------\n",
      "points torch.Size([22615, 3])\n",
      "CVT loss:  tensor(0.0632, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 9.179810876958072e-05 : Allocated: 2134.874624 MB, Reserved: 2264.92416 MB\n",
      "Epoch 13: loss = 31.68480110168457\n",
      "before loss.backward(): Allocated: 2134.874624 MB, Reserved: 2264.92416 MB\n",
      "After loss.backward(): Allocated: 2124.75136 MB, Reserved: 2264.92416 MB\n",
      "-----------------\n",
      "points torch.Size([22629, 3])\n",
      "CVT loss:  tensor(0.0708, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 8.911009354051203e-05 : Allocated: 2134.874624 MB, Reserved: 2264.92416 MB\n",
      "Epoch 14: loss = 35.483787536621094\n",
      "before loss.backward(): Allocated: 2134.874624 MB, Reserved: 2264.92416 MB\n",
      "After loss.backward(): Allocated: 2124.75136 MB, Reserved: 2264.92416 MB\n",
      "-----------------\n",
      "points torch.Size([22615, 3])\n",
      "CVT loss:  tensor(0.0635, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 8.657742000650615e-05 : Allocated: 2134.867456 MB, Reserved: 2264.92416 MB\n",
      "Epoch 15: loss = 31.816112518310547\n",
      "before loss.backward(): Allocated: 2134.867456 MB, Reserved: 2264.92416 MB\n",
      "After loss.backward(): Allocated: 2124.750848 MB, Reserved: 2264.92416 MB\n",
      "-----------------\n",
      "points torch.Size([22609, 3])\n",
      "CVT loss:  tensor(0.0432, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 8.431269088760018e-05 : Allocated: 2134.866944 MB, Reserved: 2264.92416 MB\n",
      "Epoch 16: loss = 21.707958221435547\n",
      "before loss.backward(): Allocated: 2134.866944 MB, Reserved: 2264.92416 MB\n",
      "After loss.backward(): Allocated: 2124.750336 MB, Reserved: 2264.92416 MB\n",
      "-----------------\n",
      "points torch.Size([22623, 3])\n",
      "CVT loss:  tensor(0.0798, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 8.223004988394678e-05 : Allocated: 2134.874624 MB, Reserved: 2264.92416 MB\n",
      "Epoch 17: loss = 39.958919525146484\n",
      "before loss.backward(): Allocated: 2134.874624 MB, Reserved: 2264.92416 MB\n",
      "After loss.backward(): Allocated: 2124.75136 MB, Reserved: 2264.92416 MB\n",
      "-----------------\n",
      "points torch.Size([22553, 3])\n",
      "CVT loss:  tensor(0.0881, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 8.045213326113299e-05 : Allocated: 2134.851072 MB, Reserved: 2264.92416 MB\n",
      "Epoch 18: loss = 44.129310607910156\n",
      "before loss.backward(): Allocated: 2134.851072 MB, Reserved: 2264.92416 MB\n",
      "After loss.backward(): Allocated: 2124.748288 MB, Reserved: 2264.92416 MB\n",
      "-----------------\n",
      "points torch.Size([22560, 3])\n",
      "CVT loss:  tensor(0.0769, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 7.91136480984278e-05 : Allocated: 2134.851072 MB, Reserved: 2264.92416 MB\n",
      "Epoch 19: loss = 38.50707244873047\n",
      "before loss.backward(): Allocated: 2134.851072 MB, Reserved: 2264.92416 MB\n",
      "After loss.backward(): Allocated: 2124.748288 MB, Reserved: 2264.92416 MB\n",
      "-----------------\n",
      "points torch.Size([22592, 3])\n",
      "CVT loss:  tensor(0.0872, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 7.716521213296801e-05 : Allocated: 2134.856704 MB, Reserved: 2264.92416 MB\n",
      "Epoch 20: loss = 43.68931579589844\n",
      "before loss.backward(): Allocated: 2134.856704 MB, Reserved: 2264.92416 MB\n",
      "After loss.backward(): Allocated: 2124.749312 MB, Reserved: 2264.92416 MB\n",
      "-----------------\n",
      "points torch.Size([22584, 3])\n",
      "CVT loss:  tensor(0.0841, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 7.570846355520189e-05 : Allocated: 2134.856704 MB, Reserved: 2264.92416 MB\n",
      "Epoch 21: loss = 42.110572814941406\n",
      "before loss.backward(): Allocated: 2134.856704 MB, Reserved: 2264.92416 MB\n",
      "After loss.backward(): Allocated: 2124.749312 MB, Reserved: 2264.92416 MB\n",
      "-----------------\n",
      "sites length BEFORE UPSAMPLING:  8192\n",
      "Sites to upsample  torch.Size([3817])\n",
      "sites length AFTER:  23460\n",
      "points torch.Size([51511, 3])\n",
      "CVT loss:  tensor(0.0226, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 6.947499059606344e-05 : Allocated: 2149.336064 MB, Reserved: 2503.999488 MB\n",
      "Epoch 22: loss = 11.353322982788086\n",
      "before loss.backward(): Allocated: 2149.336064 MB, Reserved: 2503.999488 MB\n",
      "After loss.backward(): Allocated: 2126.555136 MB, Reserved: 2503.999488 MB\n",
      "-----------------\n",
      "points torch.Size([55605, 3])\n",
      "CVT loss:  tensor(0.0198, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 4.9440535804023966e-05 : Allocated: 2151.44704 MB, Reserved: 2503.999488 MB\n",
      "Epoch 23: loss = 9.974201202392578\n",
      "before loss.backward(): Allocated: 2151.44704 MB, Reserved: 2503.999488 MB\n",
      "After loss.backward(): Allocated: 2127.501312 MB, Reserved: 2503.999488 MB\n",
      "-----------------\n",
      "points torch.Size([58851, 3])\n",
      "CVT loss:  tensor(0.0130, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 4.2066527385031804e-05 : Allocated: 2153.602048 MB, Reserved: 2503.999488 MB\n",
      "Epoch 24: loss = 6.5623579025268555\n",
      "before loss.backward(): Allocated: 2153.602048 MB, Reserved: 2503.999488 MB\n",
      "After loss.backward(): Allocated: 2127.661568 MB, Reserved: 2503.999488 MB\n",
      "-----------------\n",
      "points torch.Size([60256, 3])\n",
      "CVT loss:  tensor(0.0190, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 3.939354792237282e-05 : Allocated: 2154.033152 MB, Reserved: 2503.999488 MB\n",
      "Epoch 25: loss = 9.551053047180176\n",
      "before loss.backward(): Allocated: 2154.033152 MB, Reserved: 2503.999488 MB\n",
      "After loss.backward(): Allocated: 2127.730176 MB, Reserved: 2503.999488 MB\n",
      "-----------------\n",
      "points torch.Size([60664, 3])\n",
      "CVT loss:  tensor(0.0200, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 3.7913836422376335e-05 : Allocated: 2154.997248 MB, Reserved: 2503.999488 MB\n",
      "Epoch 26: loss = 10.049946784973145\n",
      "before loss.backward(): Allocated: 2154.997248 MB, Reserved: 2503.999488 MB\n",
      "After loss.backward(): Allocated: 2128.109056 MB, Reserved: 2503.999488 MB\n",
      "-----------------\n",
      "points torch.Size([60569, 3])\n",
      "CVT loss:  tensor(0.0183, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 3.694248152896762e-05 : Allocated: 2153.04704 MB, Reserved: 2503.999488 MB\n",
      "Epoch 27: loss = 9.177057266235352\n",
      "before loss.backward(): Allocated: 2153.04704 MB, Reserved: 2503.999488 MB\n",
      "After loss.backward(): Allocated: 2127.745024 MB, Reserved: 2503.999488 MB\n",
      "-----------------\n",
      "points torch.Size([60465, 3])\n",
      "CVT loss:  tensor(0.0189, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 3.5827171814162284e-05 : Allocated: 2154.907136 MB, Reserved: 2503.999488 MB\n",
      "Epoch 28: loss = 9.49742317199707\n",
      "before loss.backward(): Allocated: 2154.907136 MB, Reserved: 2503.999488 MB\n",
      "After loss.backward(): Allocated: 2127.740928 MB, Reserved: 2503.999488 MB\n",
      "-----------------\n",
      "points torch.Size([60290, 3])\n",
      "CVT loss:  tensor(0.0209, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 3.467476199148223e-05 : Allocated: 2153.979904 MB, Reserved: 2503.999488 MB\n",
      "Epoch 29: loss = 10.49463176727295\n",
      "before loss.backward(): Allocated: 2153.979904 MB, Reserved: 2503.999488 MB\n",
      "After loss.backward(): Allocated: 2127.732224 MB, Reserved: 2503.999488 MB\n",
      "-----------------\n",
      "points torch.Size([60253, 3])\n",
      "CVT loss:  tensor(0.0192, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 3.3733151212800294e-05 : Allocated: 2154.883584 MB, Reserved: 2503.999488 MB\n",
      "Epoch 30: loss = 9.609599113464355\n",
      "before loss.backward(): Allocated: 2154.883584 MB, Reserved: 2503.999488 MB\n",
      "After loss.backward(): Allocated: 2128.031744 MB, Reserved: 2503.999488 MB\n",
      "-----------------\n",
      "points torch.Size([60225, 3])\n",
      "CVT loss:  tensor(0.0181, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 3.283518162788823e-05 : Allocated: 2152.933376 MB, Reserved: 2503.999488 MB\n",
      "Epoch 31: loss = 9.079978942871094\n",
      "before loss.backward(): Allocated: 2152.933376 MB, Reserved: 2503.999488 MB\n",
      "After loss.backward(): Allocated: 2127.728128 MB, Reserved: 2503.999488 MB\n",
      "-----------------\n",
      "points torch.Size([60358, 3])\n",
      "CVT loss:  tensor(0.0307, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 3.200328865204938e-05 : Allocated: 2154.907648 MB, Reserved: 2503.999488 MB\n",
      "Epoch 32: loss = 15.404280662536621\n",
      "before loss.backward(): Allocated: 2154.907648 MB, Reserved: 2503.999488 MB\n",
      "After loss.backward(): Allocated: 2127.734272 MB, Reserved: 2503.999488 MB\n",
      "-----------------\n",
      "points torch.Size([60529, 3])\n",
      "CVT loss:  tensor(0.0257, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 3.130499680992216e-05 : Allocated: 2154.034688 MB, Reserved: 2503.999488 MB\n",
      "Epoch 33: loss = 12.896973609924316\n",
      "before loss.backward(): Allocated: 2154.034688 MB, Reserved: 2503.999488 MB\n",
      "After loss.backward(): Allocated: 2127.742464 MB, Reserved: 2503.999488 MB\n",
      "-----------------\n",
      "points torch.Size([60483, 3])\n",
      "CVT loss:  tensor(0.0243, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 3.07117952615954e-05 : Allocated: 2154.919936 MB, Reserved: 2503.999488 MB\n",
      "Epoch 34: loss = 12.203500747680664\n",
      "before loss.backward(): Allocated: 2154.919936 MB, Reserved: 2503.999488 MB\n",
      "After loss.backward(): Allocated: 2128.052224 MB, Reserved: 2503.999488 MB\n",
      "-----------------\n",
      "points torch.Size([60525, 3])\n",
      "CVT loss:  tensor(0.0222, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 3.014592766703572e-05 : Allocated: 2153.046528 MB, Reserved: 2503.999488 MB\n",
      "Epoch 35: loss = 11.14275074005127\n",
      "before loss.backward(): Allocated: 2153.046528 MB, Reserved: 2503.999488 MB\n",
      "After loss.backward(): Allocated: 2127.741952 MB, Reserved: 2503.999488 MB\n",
      "-----------------\n",
      "points torch.Size([60583, 3])\n",
      "CVT loss:  tensor(0.0204, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 2.952052454929799e-05 : Allocated: 2154.981888 MB, Reserved: 2503.999488 MB\n",
      "Epoch 36: loss = 10.22968578338623\n",
      "before loss.backward(): Allocated: 2154.981888 MB, Reserved: 2503.999488 MB\n",
      "After loss.backward(): Allocated: 2127.745024 MB, Reserved: 2503.999488 MB\n",
      "-----------------\n",
      "points torch.Size([60551, 3])\n",
      "CVT loss:  tensor(0.0376, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 2.90481184492819e-05 : Allocated: 2154.090496 MB, Reserved: 2503.999488 MB\n",
      "Epoch 37: loss = 18.829809188842773\n",
      "before loss.backward(): Allocated: 2154.090496 MB, Reserved: 2503.999488 MB\n",
      "After loss.backward(): Allocated: 2127.744512 MB, Reserved: 2503.999488 MB\n",
      "-----------------\n",
      "points torch.Size([60689, 3])\n",
      "CVT loss:  tensor(0.0301, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 2.8556623874465004e-05 : Allocated: 2154.994176 MB, Reserved: 2503.999488 MB\n",
      "Epoch 38: loss = 15.095841407775879\n",
      "before loss.backward(): Allocated: 2154.994176 MB, Reserved: 2503.999488 MB\n",
      "After loss.backward(): Allocated: 2128.109568 MB, Reserved: 2503.999488 MB\n",
      "-----------------\n",
      "points torch.Size([60665, 3])\n",
      "CVT loss:  tensor(0.0317, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 2.8067861421732232e-05 : Allocated: 2153.145856 MB, Reserved: 2503.999488 MB\n",
      "Epoch 39: loss = 15.854034423828125\n",
      "before loss.backward(): Allocated: 2153.145856 MB, Reserved: 2503.999488 MB\n",
      "After loss.backward(): Allocated: 2127.749632 MB, Reserved: 2503.999488 MB\n",
      "-----------------\n",
      "points torch.Size([60735, 3])\n",
      "CVT loss:  tensor(0.0370, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 2.7622423658613116e-05 : Allocated: 2155.066368 MB, Reserved: 2503.999488 MB\n",
      "Epoch 40: loss = 18.540058135986328\n",
      "before loss.backward(): Allocated: 2155.066368 MB, Reserved: 2503.999488 MB\n",
      "After loss.backward(): Allocated: 2127.753216 MB, Reserved: 2503.999488 MB\n",
      "-----------------\n",
      "points torch.Size([60681, 3])\n",
      "CVT loss:  tensor(0.0331, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 2.7264346499578096e-05 : Allocated: 2154.187264 MB, Reserved: 2503.999488 MB\n",
      "Epoch 41: loss = 16.554065704345703\n",
      "before loss.backward(): Allocated: 2154.187264 MB, Reserved: 2503.999488 MB\n",
      "After loss.backward(): Allocated: 2127.750144 MB, Reserved: 2503.999488 MB\n",
      "-----------------\n",
      "sites length BEFORE UPSAMPLING:  23460\n",
      "Sites to upsample  torch.Size([11072])\n",
      "sites length AFTER:  67748\n",
      "points torch.Size([130054, 3])\n",
      "CVT loss:  tensor(0.0107, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 2.8755797757185064e-05 : Allocated: 2186.720256 MB, Reserved: 3521.118208 MB\n",
      "Epoch 42: loss = 5.3688530921936035\n",
      "before loss.backward(): Allocated: 2186.720256 MB, Reserved: 3521.118208 MB\n",
      "After loss.backward(): Allocated: 2133.290496 MB, Reserved: 3521.118208 MB\n",
      "-----------------\n",
      "points torch.Size([142781, 3])\n",
      "CVT loss:  tensor(0.0134, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 2.3283922928385437e-05 : Allocated: 2193.586176 MB, Reserved: 3653.238784 MB\n",
      "Epoch 43: loss = 6.747554779052734\n",
      "before loss.backward(): Allocated: 2193.586176 MB, Reserved: 3653.238784 MB\n",
      "After loss.backward(): Allocated: 2134.479872 MB, Reserved: 3653.238784 MB\n",
      "-----------------\n",
      "points torch.Size([144542, 3])\n",
      "CVT loss:  tensor(0.0130, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 2.206021235906519e-05 : Allocated: 2194.870272 MB, Reserved: 3653.238784 MB\n",
      "Epoch 44: loss = 6.536130905151367\n",
      "before loss.backward(): Allocated: 2194.870272 MB, Reserved: 3653.238784 MB\n",
      "After loss.backward(): Allocated: 2135.532544 MB, Reserved: 3653.238784 MB\n",
      "-----------------\n",
      "points torch.Size([143079, 3])\n",
      "CVT loss:  tensor(0.0090, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 2.1177476810407825e-05 : Allocated: 2193.846784 MB, Reserved: 3653.238784 MB\n",
      "Epoch 45: loss = 4.543821811676025\n",
      "before loss.backward(): Allocated: 2193.846784 MB, Reserved: 3653.238784 MB\n",
      "After loss.backward(): Allocated: 2134.528 MB, Reserved: 3653.238784 MB\n",
      "-----------------\n",
      "points torch.Size([142395, 3])\n",
      "CVT loss:  tensor(0.0110, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 2.0428840798558667e-05 : Allocated: 2194.40896 MB, Reserved: 3653.238784 MB\n",
      "Epoch 46: loss = 5.501081466674805\n",
      "before loss.backward(): Allocated: 2194.40896 MB, Reserved: 3653.238784 MB\n",
      "After loss.backward(): Allocated: 2135.222272 MB, Reserved: 3653.238784 MB\n",
      "-----------------\n",
      "points torch.Size([141816, 3])\n",
      "CVT loss:  tensor(0.0124, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.984898881346453e-05 : Allocated: 2193.416704 MB, Reserved: 3653.238784 MB\n",
      "Epoch 47: loss = 6.224701881408691\n",
      "before loss.backward(): Allocated: 2193.416704 MB, Reserved: 3653.238784 MB\n",
      "After loss.backward(): Allocated: 2134.467072 MB, Reserved: 3653.238784 MB\n",
      "-----------------\n",
      "points torch.Size([141449, 3])\n",
      "CVT loss:  tensor(0.0107, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.9299603081890382e-05 : Allocated: 2193.369088 MB, Reserved: 3653.238784 MB\n",
      "Epoch 48: loss = 5.349460601806641\n",
      "before loss.backward(): Allocated: 2193.369088 MB, Reserved: 3653.238784 MB\n",
      "After loss.backward(): Allocated: 2134.408704 MB, Reserved: 3653.238784 MB\n",
      "-----------------\n",
      "points torch.Size([141268, 3])\n",
      "CVT loss:  tensor(0.0110, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.8753300537355244e-05 : Allocated: 2194.490368 MB, Reserved: 3653.238784 MB\n",
      "Epoch 49: loss = 5.521262168884277\n",
      "before loss.backward(): Allocated: 2194.490368 MB, Reserved: 3653.238784 MB\n",
      "After loss.backward(): Allocated: 2135.40608 MB, Reserved: 3653.238784 MB\n",
      "-----------------\n",
      "points torch.Size([141240, 3])\n",
      "CVT loss:  tensor(0.0115, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.8321428797207773e-05 : Allocated: 2193.978368 MB, Reserved: 3653.238784 MB\n",
      "Epoch 50: loss = 5.772979736328125\n",
      "before loss.backward(): Allocated: 2193.978368 MB, Reserved: 3653.238784 MB\n",
      "After loss.backward(): Allocated: 2135.233536 MB, Reserved: 3653.238784 MB\n",
      "-----------------\n",
      "points torch.Size([140973, 3])\n",
      "CVT loss:  tensor(0.0147, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.7907663277583197e-05 : Allocated: 2193.90464 MB, Reserved: 3653.238784 MB\n",
      "Epoch 51: loss = 7.3807053565979\n",
      "before loss.backward(): Allocated: 2193.90464 MB, Reserved: 3653.238784 MB\n",
      "After loss.backward(): Allocated: 2134.38464 MB, Reserved: 3653.238784 MB\n",
      "-----------------\n",
      "points torch.Size([140751, 3])\n",
      "CVT loss:  tensor(0.0124, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.7475027561886236e-05 : Allocated: 2193.117184 MB, Reserved: 3653.238784 MB\n",
      "Epoch 52: loss = 6.2276930809021\n",
      "before loss.backward(): Allocated: 2193.117184 MB, Reserved: 3653.238784 MB\n",
      "After loss.backward(): Allocated: 2134.373376 MB, Reserved: 3653.238784 MB\n",
      "-----------------\n",
      "points torch.Size([140783, 3])\n",
      "CVT loss:  tensor(0.0117, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.7145815945696086e-05 : Allocated: 2193.038336 MB, Reserved: 3653.238784 MB\n",
      "Epoch 53: loss = 5.886742115020752\n",
      "before loss.backward(): Allocated: 2193.038336 MB, Reserved: 3653.238784 MB\n",
      "After loss.backward(): Allocated: 2134.538752 MB, Reserved: 3653.238784 MB\n",
      "-----------------\n",
      "points torch.Size([140916, 3])\n",
      "CVT loss:  tensor(0.0110, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.6824043996166438e-05 : Allocated: 2193.302528 MB, Reserved: 3653.238784 MB\n",
      "Epoch 54: loss = 5.499993324279785\n",
      "before loss.backward(): Allocated: 2193.302528 MB, Reserved: 3653.238784 MB\n",
      "After loss.backward(): Allocated: 2134.547968 MB, Reserved: 3653.238784 MB\n",
      "-----------------\n",
      "points torch.Size([140673, 3])\n",
      "CVT loss:  tensor(0.0109, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.655593041505199e-05 : Allocated: 2192.992256 MB, Reserved: 3653.238784 MB\n",
      "Epoch 55: loss = 5.453552722930908\n",
      "before loss.backward(): Allocated: 2192.992256 MB, Reserved: 3653.238784 MB\n",
      "After loss.backward(): Allocated: 2134.381568 MB, Reserved: 3653.238784 MB\n",
      "-----------------\n",
      "points torch.Size([140743, 3])\n",
      "CVT loss:  tensor(0.0110, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.626092489459552e-05 : Allocated: 2192.957952 MB, Reserved: 3653.238784 MB\n",
      "Epoch 56: loss = 5.511257171630859\n",
      "before loss.backward(): Allocated: 2192.957952 MB, Reserved: 3653.238784 MB\n",
      "After loss.backward(): Allocated: 2134.41536 MB, Reserved: 3653.238784 MB\n",
      "-----------------\n",
      "points torch.Size([140369, 3])\n",
      "CVT loss:  tensor(0.0122, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.5949959561112337e-05 : Allocated: 2194.119168 MB, Reserved: 3653.238784 MB\n",
      "Epoch 57: loss = 6.106908798217773\n",
      "before loss.backward(): Allocated: 2194.119168 MB, Reserved: 3653.238784 MB\n",
      "After loss.backward(): Allocated: 2135.302144 MB, Reserved: 3653.238784 MB\n",
      "-----------------\n",
      "points torch.Size([140295, 3])\n",
      "CVT loss:  tensor(0.0115, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.563049227115698e-05 : Allocated: 2194.174464 MB, Reserved: 3653.238784 MB\n",
      "Epoch 58: loss = 5.745336055755615\n",
      "before loss.backward(): Allocated: 2194.174464 MB, Reserved: 3653.238784 MB\n",
      "After loss.backward(): Allocated: 2135.341056 MB, Reserved: 3653.238784 MB\n",
      "-----------------\n",
      "points torch.Size([140263, 3])\n",
      "CVT loss:  tensor(0.0154, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.5365600120276213e-05 : Allocated: 2193.605632 MB, Reserved: 3653.238784 MB\n",
      "Epoch 59: loss = 7.7254133224487305\n",
      "before loss.backward(): Allocated: 2193.605632 MB, Reserved: 3653.238784 MB\n",
      "After loss.backward(): Allocated: 2134.370816 MB, Reserved: 3653.238784 MB\n",
      "-----------------\n",
      "points torch.Size([140196, 3])\n",
      "CVT loss:  tensor(0.0121, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.5102190445759334e-05 : Allocated: 2195.702784 MB, Reserved: 3653.238784 MB\n",
      "Epoch 60: loss = 6.064270973205566\n",
      "before loss.backward(): Allocated: 2195.702784 MB, Reserved: 3653.238784 MB\n",
      "After loss.backward(): Allocated: 2136.316928 MB, Reserved: 3653.238784 MB\n",
      "-----------------\n",
      "points torch.Size([140259, 3])\n",
      "CVT loss:  tensor(0.0137, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.4917181033524685e-05 : Allocated: 2193.782784 MB, Reserved: 3653.238784 MB\n",
      "Epoch 61: loss = 6.8423991203308105\n",
      "before loss.backward(): Allocated: 2193.782784 MB, Reserved: 3653.238784 MB\n",
      "After loss.backward(): Allocated: 2134.369792 MB, Reserved: 3653.238784 MB\n",
      "-----------------\n",
      "sites length BEFORE UPSAMPLING:  67748\n",
      "Sites to upsample  torch.Size([26377])\n",
      "sites length AFTER:  173256\n",
      "points torch.Size([311757, 3])\n",
      "CVT loss:  tensor(0.0058, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.699684071354568e-05 : Allocated: 2278.3872 MB, Reserved: 6222.249984 MB\n",
      "Epoch 62: loss = 2.9162042140960693\n",
      "before loss.backward(): Allocated: 2278.3872 MB, Reserved: 6222.249984 MB\n",
      "After loss.backward(): Allocated: 2146.039808 MB, Reserved: 6222.249984 MB\n",
      "-----------------\n",
      "points torch.Size([339348, 3])\n",
      "CVT loss:  tensor(0.0055, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.6328345736837946e-05 : Allocated: 2289.968128 MB, Reserved: 6549.405696 MB\n",
      "Epoch 63: loss = 2.751628875732422\n",
      "before loss.backward(): Allocated: 2289.968128 MB, Reserved: 6549.405696 MB\n",
      "After loss.backward(): Allocated: 2151.547904 MB, Reserved: 6549.405696 MB\n",
      "-----------------\n",
      "points torch.Size([328396, 3])\n",
      "CVT loss:  tensor(0.0056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.5916901247692294e-05 : Allocated: 2286.226944 MB, Reserved: 6549.405696 MB\n",
      "Epoch 64: loss = 2.8241662979125977\n",
      "before loss.backward(): Allocated: 2286.226944 MB, Reserved: 6549.405696 MB\n",
      "After loss.backward(): Allocated: 2150.585344 MB, Reserved: 6549.405696 MB\n",
      "-----------------\n",
      "points torch.Size([323761, 3])\n",
      "CVT loss:  tensor(0.0061, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.5381452612928115e-05 : Allocated: 2283.027968 MB, Reserved: 6549.405696 MB\n",
      "Epoch 65: loss = 3.0663435459136963\n",
      "before loss.backward(): Allocated: 2283.027968 MB, Reserved: 6549.405696 MB\n",
      "After loss.backward(): Allocated: 2150.609408 MB, Reserved: 6549.405696 MB\n",
      "-----------------\n",
      "points torch.Size([321321, 3])\n",
      "CVT loss:  tensor(0.0061, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.516658448963426e-05 : Allocated: 2283.3664 MB, Reserved: 6549.405696 MB\n",
      "Epoch 66: loss = 3.0730295181274414\n",
      "before loss.backward(): Allocated: 2283.3664 MB, Reserved: 6549.405696 MB\n",
      "After loss.backward(): Allocated: 2151.205888 MB, Reserved: 6549.405696 MB\n",
      "-----------------\n",
      "points torch.Size([320465, 3])\n",
      "CVT loss:  tensor(0.0055, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.4841615666227881e-05 : Allocated: 2283.990016 MB, Reserved: 6549.405696 MB\n",
      "Epoch 67: loss = 2.7766051292419434\n",
      "before loss.backward(): Allocated: 2283.990016 MB, Reserved: 6549.405696 MB\n",
      "After loss.backward(): Allocated: 2151.822336 MB, Reserved: 6549.405696 MB\n",
      "-----------------\n",
      "points torch.Size([318829, 3])\n",
      "CVT loss:  tensor(0.0043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.4437503523367923e-05 : Allocated: 2282.258432 MB, Reserved: 6549.405696 MB\n",
      "Epoch 68: loss = 2.182906150817871\n",
      "before loss.backward(): Allocated: 2282.258432 MB, Reserved: 6549.405696 MB\n",
      "After loss.backward(): Allocated: 2149.750784 MB, Reserved: 6549.405696 MB\n",
      "-----------------\n",
      "points torch.Size([316973, 3])\n",
      "CVT loss:  tensor(0.0054, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.4135775018075947e-05 : Allocated: 2282.589696 MB, Reserved: 6549.405696 MB\n",
      "Epoch 69: loss = 2.7271857261657715\n",
      "before loss.backward(): Allocated: 2282.589696 MB, Reserved: 6549.405696 MB\n",
      "After loss.backward(): Allocated: 2151.151104 MB, Reserved: 6549.405696 MB\n",
      "-----------------\n",
      "points torch.Size([315997, 3])\n",
      "CVT loss:  tensor(0.0054, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.3838171071256511e-05 : Allocated: 2283.974144 MB, Reserved: 6549.405696 MB\n",
      "Epoch 70: loss = 2.7258355617523193\n",
      "before loss.backward(): Allocated: 2283.974144 MB, Reserved: 6549.405696 MB\n",
      "After loss.backward(): Allocated: 2150.816256 MB, Reserved: 6549.405696 MB\n",
      "-----------------\n",
      "points torch.Size([315186, 3])\n",
      "CVT loss:  tensor(0.0062, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.3596858480013907e-05 : Allocated: 2281.742336 MB, Reserved: 6549.405696 MB\n",
      "Epoch 71: loss = 3.1170811653137207\n",
      "before loss.backward(): Allocated: 2281.742336 MB, Reserved: 6549.405696 MB\n",
      "After loss.backward(): Allocated: 2149.345792 MB, Reserved: 6549.405696 MB\n",
      "-----------------\n",
      "points torch.Size([313459, 3])\n",
      "CVT loss:  tensor(0.0066, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.3440292605082504e-05 : Allocated: 2281.508352 MB, Reserved: 6549.405696 MB\n",
      "Epoch 72: loss = 3.328185796737671\n",
      "before loss.backward(): Allocated: 2281.508352 MB, Reserved: 6549.405696 MB\n",
      "After loss.backward(): Allocated: 2149.85728 MB, Reserved: 6549.405696 MB\n",
      "-----------------\n",
      "points torch.Size([312394, 3])\n",
      "CVT loss:  tensor(0.0066, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.3152151950635016e-05 : Allocated: 2282.993664 MB, Reserved: 6549.405696 MB\n",
      "Epoch 73: loss = 3.3302571773529053\n",
      "before loss.backward(): Allocated: 2282.993664 MB, Reserved: 6549.405696 MB\n",
      "After loss.backward(): Allocated: 2151.096832 MB, Reserved: 6549.405696 MB\n",
      "-----------------\n",
      "points torch.Size([311076, 3])\n",
      "CVT loss:  tensor(0.0074, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.2822760254493915e-05 : Allocated: 2282.277376 MB, Reserved: 6549.405696 MB\n",
      "Epoch 74: loss = 3.6881015300750732\n",
      "before loss.backward(): Allocated: 2282.277376 MB, Reserved: 6549.405696 MB\n",
      "After loss.backward(): Allocated: 2150.366208 MB, Reserved: 6549.405696 MB\n",
      "-----------------\n",
      "points torch.Size([309619, 3])\n",
      "CVT loss:  tensor(0.0084, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.2627032447198872e-05 : Allocated: 2281.225216 MB, Reserved: 6549.405696 MB\n",
      "Epoch 75: loss = 4.194132328033447\n",
      "before loss.backward(): Allocated: 2281.225216 MB, Reserved: 6549.405696 MB\n",
      "After loss.backward(): Allocated: 2149.806592 MB, Reserved: 6549.405696 MB\n",
      "-----------------\n",
      "points torch.Size([308296, 3])\n",
      "CVT loss:  tensor(0.0059, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.2496853742050007e-05 : Allocated: 2281.673728 MB, Reserved: 6549.405696 MB\n",
      "Epoch 76: loss = 2.9867379665374756\n",
      "before loss.backward(): Allocated: 2281.673728 MB, Reserved: 6549.405696 MB\n",
      "After loss.backward(): Allocated: 2150.37184 MB, Reserved: 6549.405696 MB\n",
      "-----------------\n",
      "points torch.Size([306780, 3])\n",
      "CVT loss:  tensor(0.0066, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.2271852028788999e-05 : Allocated: 2282.130944 MB, Reserved: 6549.405696 MB\n",
      "Epoch 77: loss = 3.3333287239074707\n",
      "before loss.backward(): Allocated: 2282.130944 MB, Reserved: 6549.405696 MB\n",
      "After loss.backward(): Allocated: 2149.292032 MB, Reserved: 6549.405696 MB\n",
      "-----------------\n",
      "points torch.Size([305002, 3])\n",
      "CVT loss:  tensor(0.0049, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.2055480510753114e-05 : Allocated: 2281.654272 MB, Reserved: 6549.405696 MB\n",
      "Epoch 78: loss = 2.451561689376831\n",
      "before loss.backward(): Allocated: 2281.654272 MB, Reserved: 6549.405696 MB\n",
      "After loss.backward(): Allocated: 2149.80864 MB, Reserved: 6549.405696 MB\n",
      "-----------------\n",
      "points torch.Size([303713, 3])\n",
      "CVT loss:  tensor(0.0044, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.1898716365976725e-05 : Allocated: 2281.304064 MB, Reserved: 6549.405696 MB\n",
      "Epoch 79: loss = 2.2334179878234863\n",
      "before loss.backward(): Allocated: 2281.304064 MB, Reserved: 6549.405696 MB\n",
      "After loss.backward(): Allocated: 2149.528576 MB, Reserved: 6549.405696 MB\n",
      "-----------------\n",
      "points torch.Size([302038, 3])\n",
      "CVT loss:  tensor(0.0046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.1760408597183414e-05 : Allocated: 2271.455744 MB, Reserved: 6549.405696 MB\n",
      "Epoch 80: loss = 2.3280746936798096\n",
      "before loss.backward(): Allocated: 2271.455744 MB, Reserved: 6549.405696 MB\n",
      "After loss.backward(): Allocated: 2149.883392 MB, Reserved: 6549.405696 MB\n",
      "-----------------\n",
      "points torch.Size([300436, 3])\n",
      "CVT loss:  tensor(0.0048, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.1583590094232932e-05 : Allocated: 2270.387712 MB, Reserved: 6549.405696 MB\n",
      "Epoch 81: loss = 2.407421350479126\n",
      "before loss.backward(): Allocated: 2270.387712 MB, Reserved: 6549.405696 MB\n",
      "After loss.backward(): Allocated: 2149.250048 MB, Reserved: 6549.405696 MB\n",
      "-----------------\n",
      "sites length BEFORE UPSAMPLING:  173256\n",
      "Sites to upsample  torch.Size([57012])\n",
      "sites length AFTER:  401304\n",
      "points torch.Size([701640, 3])\n",
      "CVT loss:  tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.3063590813544579e-05 : Allocated: 2461.684224 MB, Reserved: 12410.945536 MB\n",
      "Epoch 82: loss = 1.22237229347229\n",
      "before loss.backward(): Allocated: 2461.684224 MB, Reserved: 12410.945536 MB\n",
      "After loss.backward(): Allocated: 2175.527936 MB, Reserved: 12410.945536 MB\n",
      "-----------------\n",
      "points torch.Size([757175, 3])\n",
      "CVT loss:  tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.4783404367335606e-05 : Allocated: 2495.909888 MB, Reserved: 13172.211712 MB\n",
      "Epoch 83: loss = 1.112710952758789\n",
      "before loss.backward(): Allocated: 2495.909888 MB, Reserved: 13172.211712 MB\n",
      "After loss.backward(): Allocated: 2189.04832 MB, Reserved: 13172.211712 MB\n",
      "-----------------\n",
      "points torch.Size([739311, 3])\n",
      "CVT loss:  tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.513212191639468e-05 : Allocated: 2485.996544 MB, Reserved: 13172.211712 MB\n",
      "Epoch 84: loss = 1.3337403535842896\n",
      "before loss.backward(): Allocated: 2485.996544 MB, Reserved: 13172.211712 MB\n",
      "After loss.backward(): Allocated: 2187.360256 MB, Reserved: 13172.211712 MB\n",
      "-----------------\n",
      "points torch.Size([729702, 3])\n",
      "CVT loss:  tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.498850997450063e-05 : Allocated: 2483.5584 MB, Reserved: 13172.211712 MB\n",
      "Epoch 85: loss = 1.1065599918365479\n",
      "before loss.backward(): Allocated: 2483.5584 MB, Reserved: 13172.211712 MB\n",
      "After loss.backward(): Allocated: 2186.412032 MB, Reserved: 13172.211712 MB\n",
      "-----------------\n",
      "points torch.Size([721072, 3])\n",
      "CVT loss:  tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.4912994629412424e-05 : Allocated: 2477.190656 MB, Reserved: 13172.211712 MB\n",
      "Epoch 86: loss = 1.2279249429702759\n",
      "before loss.backward(): Allocated: 2477.190656 MB, Reserved: 13172.211712 MB\n",
      "After loss.backward(): Allocated: 2184.968192 MB, Reserved: 13172.211712 MB\n",
      "-----------------\n",
      "points torch.Size([709185, 3])\n",
      "CVT loss:  tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.4892773833707906e-05 : Allocated: 2472.236032 MB, Reserved: 13172.211712 MB\n",
      "Epoch 87: loss = 1.502662181854248\n",
      "before loss.backward(): Allocated: 2472.236032 MB, Reserved: 13172.211712 MB\n",
      "After loss.backward(): Allocated: 2184.896 MB, Reserved: 13172.211712 MB\n",
      "-----------------\n",
      "points torch.Size([696594, 3])\n",
      "CVT loss:  tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.4529693544318434e-05 : Allocated: 2470.431744 MB, Reserved: 13172.211712 MB\n",
      "Epoch 88: loss = 1.5550493001937866\n",
      "before loss.backward(): Allocated: 2470.431744 MB, Reserved: 13172.211712 MB\n",
      "After loss.backward(): Allocated: 2184.312832 MB, Reserved: 13172.211712 MB\n",
      "-----------------\n",
      "points torch.Size([683795, 3])\n",
      "CVT loss:  tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.4347884643939324e-05 : Allocated: 2462.218752 MB, Reserved: 13172.211712 MB\n",
      "Epoch 89: loss = 1.2840907573699951\n",
      "before loss.backward(): Allocated: 2462.218752 MB, Reserved: 13172.211712 MB\n",
      "After loss.backward(): Allocated: 2184.73216 MB, Reserved: 13172.211712 MB\n",
      "-----------------\n",
      "points torch.Size([671246, 3])\n",
      "CVT loss:  tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.4170002032187767e-05 : Allocated: 2456.737792 MB, Reserved: 13172.211712 MB\n",
      "Epoch 90: loss = 1.4477492570877075\n",
      "before loss.backward(): Allocated: 2456.737792 MB, Reserved: 13172.211712 MB\n",
      "After loss.backward(): Allocated: 2182.37696 MB, Reserved: 13172.211712 MB\n",
      "-----------------\n",
      "points torch.Size([659034, 3])\n",
      "CVT loss:  tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.3955694157630205e-05 : Allocated: 2451.1488 MB, Reserved: 13172.211712 MB\n",
      "Epoch 91: loss = 1.3765363693237305\n",
      "before loss.backward(): Allocated: 2451.1488 MB, Reserved: 13172.211712 MB\n",
      "After loss.backward(): Allocated: 2182.829568 MB, Reserved: 13172.211712 MB\n",
      "-----------------\n",
      "points torch.Size([647015, 3])\n",
      "CVT loss:  tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.3737435438088141e-05 : Allocated: 2445.63456 MB, Reserved: 13172.211712 MB\n",
      "Epoch 92: loss = 1.3644222021102905\n",
      "before loss.backward(): Allocated: 2445.63456 MB, Reserved: 13172.211712 MB\n",
      "After loss.backward(): Allocated: 2181.383168 MB, Reserved: 13172.211712 MB\n",
      "-----------------\n",
      "points torch.Size([634886, 3])\n",
      "CVT loss:  tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.3602905710285995e-05 : Allocated: 2441.467392 MB, Reserved: 13172.211712 MB\n",
      "Epoch 93: loss = 1.5545207262039185\n",
      "before loss.backward(): Allocated: 2441.467392 MB, Reserved: 13172.211712 MB\n",
      "After loss.backward(): Allocated: 2181.68064 MB, Reserved: 13172.211712 MB\n",
      "-----------------\n",
      "points torch.Size([624983, 3])\n",
      "CVT loss:  tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.34006359076011e-05 : Allocated: 2437.815808 MB, Reserved: 13172.211712 MB\n",
      "Epoch 94: loss = 1.5589371919631958\n",
      "before loss.backward(): Allocated: 2437.815808 MB, Reserved: 13172.211712 MB\n",
      "After loss.backward(): Allocated: 2181.124608 MB, Reserved: 13172.211712 MB\n",
      "-----------------\n",
      "points torch.Size([613910, 3])\n",
      "CVT loss:  tensor(0.0033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.3180189853301272e-05 : Allocated: 2430.137856 MB, Reserved: 13172.211712 MB\n",
      "Epoch 95: loss = 1.6669080257415771\n",
      "before loss.backward(): Allocated: 2430.137856 MB, Reserved: 13172.211712 MB\n",
      "After loss.backward(): Allocated: 2180.358656 MB, Reserved: 13172.211712 MB\n",
      "-----------------\n",
      "points torch.Size([602676, 3])\n",
      "CVT loss:  tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.3068523912806995e-05 : Allocated: 2429.236224 MB, Reserved: 13172.211712 MB\n",
      "Epoch 96: loss = 1.1969654560089111\n",
      "before loss.backward(): Allocated: 2429.236224 MB, Reserved: 13172.211712 MB\n",
      "After loss.backward(): Allocated: 2180.526592 MB, Reserved: 13172.211712 MB\n",
      "-----------------\n",
      "points torch.Size([592995, 3])\n",
      "CVT loss:  tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.2946392416779418e-05 : Allocated: 2422.083584 MB, Reserved: 13172.211712 MB\n",
      "Epoch 97: loss = 1.3816784620285034\n",
      "before loss.backward(): Allocated: 2422.083584 MB, Reserved: 13172.211712 MB\n",
      "After loss.backward(): Allocated: 2180.265984 MB, Reserved: 13172.211712 MB\n",
      "-----------------\n",
      "points torch.Size([583488, 3])\n",
      "CVT loss:  tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.274893838854041e-05 : Allocated: 2415.652864 MB, Reserved: 13172.211712 MB\n",
      "Epoch 98: loss = 1.5289087295532227\n",
      "before loss.backward(): Allocated: 2415.652864 MB, Reserved: 13172.211712 MB\n",
      "After loss.backward(): Allocated: 2179.555328 MB, Reserved: 13172.211712 MB\n",
      "-----------------\n",
      "points torch.Size([575309, 3])\n",
      "CVT loss:  tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.2489503205870278e-05 : Allocated: 2412.263936 MB, Reserved: 13172.211712 MB\n",
      "Epoch 99: loss = 1.414842128753662\n",
      "before loss.backward(): Allocated: 2412.263936 MB, Reserved: 13172.211712 MB\n",
      "After loss.backward(): Allocated: 2177.724416 MB, Reserved: 13172.211712 MB\n",
      "-----------------\n",
      "points torch.Size([566387, 3])\n",
      "CVT loss:  tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.2311958926147781e-05 : Allocated: 2409.199104 MB, Reserved: 13172.211712 MB\n",
      "Epoch 100: loss = 1.27302086353302\n",
      "before loss.backward(): Allocated: 2409.199104 MB, Reserved: 13172.211712 MB\n",
      "After loss.backward(): Allocated: 2178.359296 MB, Reserved: 13172.211712 MB\n",
      "-----------------\n",
      "Saved to gargoyle_to_clip_7000.npz\n",
      "Sites length:  401304\n",
      "min sites:  tensor(-1.4970, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "max sites:  tensor(1.5120, device='cuda:0', grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "site_file_path = f'{destination}{max_iter}_cvt_{lambda_cvt}_chamfer_{lamda_chamfer}_eikonal_{lambda_eikonal}.npy'\n",
    "#check if optimized sites file exists\n",
    "if not os.path.exists(site_file_path):\n",
    "    #import sites\n",
    "    print(\"Importing sites\")\n",
    "    sites = np.load(site_file_path)\n",
    "    sites = torch.from_numpy(sites).to(device).requires_grad_(True)\n",
    "else:\n",
    "    # import cProfile, pstats\n",
    "    # import time\n",
    "    # profiler = cProfile.Profile()\n",
    "    # profiler.enable()\n",
    "\n",
    "#     with torch.profiler.profile(activities=[\n",
    "#             torch.profiler.ProfilerActivity.CPU,\n",
    "#             torch.profiler.ProfilerActivity.CUDA,\n",
    "#         ],\n",
    "#         record_shapes=False,\n",
    "#         with_stack=True  # Captures function calls\n",
    "#     ) as prof:\n",
    "#         sites = autograd(sites, model, max_iter=max_iter, upsampling=0, lambda_weights=lambda_weights)\n",
    "#         torch.cuda.synchronize()\n",
    "# # \n",
    "#     print(prof.key_averages().table(sort_by=\"self_cuda_time_total\"))\n",
    "#     prof.export_chrome_trace(\"trace.json\")\n",
    "    \n",
    "    # \n",
    "    sites = autograd(sites, model, max_iter=max_iter, upsampling=4, lambda_weights=lambda_weights)\n",
    "\n",
    "    \n",
    "    # profiler.disable()\n",
    "    # stats = pstats.Stats(profiler).sort_stats('cumtime')\n",
    "    # stats.print_stats()\n",
    "    # stats.dump_stats(f'{destination}{mesh[0]}{max_iter}_3d_profile_{num_centroids}_chamfer{lamda_chamfer}.prof')\n",
    "    \n",
    "    \n",
    "    sites_np = sites.detach().cpu().numpy()\n",
    "    np.save(site_file_path, sites_np)\n",
    "    \n",
    "    \n",
    "\n",
    "print(\"Sites length: \", len(sites))\n",
    "print(\"min sites: \", torch.min(sites))\n",
    "print(\"max sites: \", torch.max(sites))\n",
    "#ps_cloud = ps.register_point_cloud(\"best_optimized_cvt_grid\",sites.detach().cpu().numpy())\n",
    "    \n",
    "lim=torch.abs(torch.max(sites)).detach().cpu().numpy()*1.1\n",
    "#plot_voronoi_3d(sites,lim,lim,lim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e4fcfff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model ./images/autograd/HotSpot/gargoyle100_100_3d_model_4096_chamfer1000.pth\n",
      "sites ./images/autograd/HotSpot/gargoyle100_100_3d_sites_4096_chamfer1000.pth\n"
     ]
    }
   ],
   "source": [
    "epoch = 100\n",
    "\n",
    "model_file_path = f'{destination}{mesh[0]}{max_iter}_{epoch}_3d_model_{num_centroids}_chamfer{lamda_chamfer}.pth'\n",
    "site_file_path = f'{destination}{mesh[0]}{max_iter}_{epoch}_3d_sites_{num_centroids}_chamfer{lamda_chamfer}.pth'\n",
    " \n",
    "sites = torch.load(site_file_path)\n",
    "\n",
    "sites_np = sites.detach().cpu().numpy()\n",
    "model.load_state_dict(torch.load(model_file_path))\n",
    "#\n",
    "#polyscope_sdf(model)\n",
    "#\n",
    "print(\"model\", model_file_path)\n",
    "print(\"sites\", site_file_path)\n",
    "ps_cloud = ps.register_point_cloud(f\"{epoch} epoch_cvt_grid\",sites_np)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72e588cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(tensor([[-0.1732, -0.0606,  0.3991],\n",
      "        [-0.2919,  0.0535, -0.1814],\n",
      "        [-0.2881,  0.0512, -0.1821],\n",
      "        ...,\n",
      "        [ 0.0700, -0.0404,  0.4791],\n",
      "        [ 0.0420, -0.0511,  0.1226],\n",
      "        [ 0.1852,  0.0295, -0.1509]], device='cuda:0', grad_fn=<SumBackward1>),), (tensor([[193983, 193984, 193982],\n",
      "        [152068,  31122, 152063],\n",
      "        [163680, 199326,  79968],\n",
      "        ...,\n",
      "        [ 93336, 114667, 127478],\n",
      "        [117334,  93339,  93338],\n",
      "        [117334, 127477,  93339]], device='cuda:0'),)]\n"
     ]
    }
   ],
   "source": [
    "final_mesh = su.get_zero_crossing_mesh_3d(sites, model)\n",
    "#save to file\n",
    "final_mesh_file = f'{mesh[0]}_sdf_trained{model_trained_it}.npz'\n",
    "faces = np.array(final_mesh[1], dtype=object)\n",
    "np.savez(final_mesh_file, vertices=final_mesh[0], faces=faces)\n",
    "\n",
    "data = np.load(final_mesh_file, allow_pickle=True)\n",
    "verts = data[\"vertices\"]       # (N_vertices, 3)\n",
    "faces = data[\"faces\"].tolist() # back to a list of lists\n",
    "\n",
    "ps.register_surface_mesh(\"Zero-Crossing faces final\", verts, faces)\n",
    "\n",
    "import scipy.spatial as spatial\n",
    "from scipy.spatial import Delaunay\n",
    "\n",
    "tri = Delaunay(sites_np)\n",
    "delaunay_vertices =torch.tensor(np.array(tri.simplices), device=device)\n",
    "sdf_values = model(sites)\n",
    "\n",
    "\n",
    "# Assuming sites is a PyTorch tensor of shape [M, 3]\n",
    "sites = sites.unsqueeze(0)  # Now shape [1, M, 3]\n",
    "\n",
    "# Assuming SDF_Values is a PyTorch tensor of shape [M]\n",
    "sdf_values = sdf_values.unsqueeze(0)  # Now shape [1, M]\n",
    "\n",
    "marching_tetrehedra_mesh = kaolin.ops.conversions.marching_tetrahedra(sites, delaunay_vertices, sdf_values, return_tet_idx=False)\n",
    "print(marching_tetrehedra_mesh)\n",
    "vertices_list, faces_list = marching_tetrehedra_mesh\n",
    "vertices = vertices_list[0]\n",
    "faces = faces_list[0]\n",
    "vertices_np = vertices.detach().cpu().numpy()  # Shape [N, 3]\n",
    "faces_np = faces.detach().cpu().numpy()  # Shape [M, 3] (triangles)\n",
    "ps.register_surface_mesh(\"Marching Tetrahedra Mesh final\", vertices_np, faces_np)\n",
    "\n",
    "# clipped_cvt = \"clipped_CVT.obj\"\n",
    "# if os.path.exists(clipped_cvt):\n",
    "#     clipped_cvt_mesh = trimesh.load(clipped_cvt)\n",
    "#     ps.register_surface_mesh(\"Clipped CVT\", clipped_cvt_mesh.vertices, clipped_cvt_mesh.faces)\n",
    "ps.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5deeda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, \"End of script\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69d940a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the meshed of different sdf trained total epochs and the clipped version \n",
    "import polyscope as ps\n",
    "import numpy as np\n",
    "import trimesh\n",
    "\n",
    "ps.init()\n",
    "nb_it = [\"\",\"_1000\",\"_3000\",\"_5000\",\"_7000\"]\n",
    "for it in nb_it:\n",
    "    final_mesh_file = f'gargoyle_sdf_trained{it}.npz'\n",
    "    data = np.load(final_mesh_file, allow_pickle=True)\n",
    "    verts = data[\"vertices\"]       # (N_vertices, 3)\n",
    "    faces = data[\"faces\"].tolist() # back to a list of lists\n",
    "\n",
    "    ps.register_surface_mesh(f\"Zero-Crossing faces final {it}\", verts, faces) \n",
    "\n",
    "for it in nb_it:\n",
    "    clipped_mesh_file = f'gargoyle_to_clip{it}.npz_clipped.obj'\n",
    "    clipped_cvt_mesh = trimesh.load(clipped_mesh_file)\n",
    "    ps.register_surface_mesh(f\"Clipped CVT {it}\", clipped_cvt_mesh.vertices, clipped_cvt_mesh.faces)\n",
    "    \n",
    "ps.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
