{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ed71bbfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device:  NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "import kaolin\n",
    "import torch\n",
    "import math\n",
    "import matplotlib\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import polyscope as ps\n",
    "import trimesh\n",
    "import diffvoronoi\n",
    "\n",
    "from scipy.spatial import Voronoi, voronoi_plot_2d, Delaunay\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import sdfpred_utils.sdfpred_utils as su\n",
    "import sdfpred_utils.sdf_MLP as mlp\n",
    "import sdfpred_utils.sdf_functions as sdf\n",
    "import sdfpred_utils.loss_functions as lf\n",
    "import sdfpred_utils.Steik_data3d as sd3d\n",
    "import sdfpred_utils.Steik_Loss as sl\n",
    "import sdfpred_utils.Steik_utils as Stu \n",
    "import open3d as o3d\n",
    "\n",
    "#cuda devices\n",
    "device = torch.device(\"cuda:0\")\n",
    "print(\"Using device: \", torch.cuda.get_device_name(device))\n",
    "\n",
    "#default tensor types\n",
    "#torch.set_default_tensor_type(torch.cuda.DoubleTensor)\n",
    "\n",
    "multires = 2\n",
    "input_dims = 3\n",
    "lr_sites = 0.005/2\n",
    "lr_model = 0.00005*2\n",
    "destination = \"./images/autograd/HotSpot/\"\n",
    "mesh = [\"gargoyle\",\"/home/wylliam/dev/Kyushu_experiments/data/gargoyle\"]\n",
    "trained_model_path = \"/home/wylliam/dev/HotSpot/log/3D/pc/HotSpot-all-2025-04-24-18-16-03/gargoyle/gargoyle/trained_models/model.pth\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2a4b4e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new sites\n",
      "Sites shape:  torch.Size([32768, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<polyscope.point_cloud.PointCloud at 0x7865702f4640>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_centroids = 32**3\n",
    "\n",
    "print(\"Creating new sites\")\n",
    "noise_scale = 0.1\n",
    "domain_limit = 1\n",
    "x = torch.linspace(-domain_limit, domain_limit, int(round(num_centroids**(1/3))))\n",
    "y = torch.linspace(-domain_limit, domain_limit, int(round(num_centroids**(1/3))))\n",
    "z = torch.linspace(-domain_limit, domain_limit, int(round(num_centroids**(1/3))))\n",
    "meshgrid = torch.meshgrid(x, y, z)\n",
    "meshgrid = torch.stack(meshgrid, dim=3).view(-1, 3)\n",
    "#add noise to meshgrid\n",
    "meshgrid += torch.randn_like(meshgrid) * noise_scale\n",
    "sites = meshgrid.to(device, dtype=torch.float32).requires_grad_(True)\n",
    "\n",
    "print(\"Sites shape: \", sites.shape)\n",
    "ps.init()\n",
    "ps.register_point_cloud(\"initial_cvt_grid\",sites.detach().cpu().numpy())\n",
    "\n",
    "# # load pointcloud used for sdf training\n",
    "# pointcloud = o3d.io.read_point_cloud(mesh[1]+\".ply\")\n",
    "# print(\"Pointcloud shape: \", np.asarray(pointcloud.points).shape)\n",
    "# # sample pointcloud to 150*32*32\n",
    "# chamfer_distance_pc_gt = pointcloud.uniform_down_sample(int((128**3)/(150*32*32)))\n",
    "# chamfer_distance_pc_gt = np.asarray(chamfer_distance_pc_gt.points)\n",
    "# print(\"Chamfer distance pointcloud shape: \", chamfer_distance_pc_gt.shape)\n",
    "\n",
    "\n",
    "# ps.register_point_cloud(\"pointcloud_gt\", chamfer_distance_pc_gt)\n",
    "# chamfer_distance_pc_gt = torch.tensor(chamfer_distance_pc_gt, device=device, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fe96048f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnfld_points shape:  torch.Size([1, 153600, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LOAD MODEL WITH HOTSPOT\n",
    "import sys\n",
    "sys.path.append(\"3rdparty/HotSpot\")\n",
    "from dataset import shape_3d\n",
    "import models.Net as Net\n",
    "\n",
    "loss_type = \"igr_w_heat\"\n",
    "loss_weights = [350, 0, 0, 1, 0, 0, 20]\n",
    "\n",
    "train_set = shape_3d.ReconDataset(\n",
    "    file_path = mesh[1]+\".ply\",\n",
    "    n_points=32*32*150,#15000, #args.n_points,\n",
    "    n_samples=10001, #args.n_iterations,\n",
    "    grid_res=256, #args.grid_res,\n",
    "    grid_range=1.1, #args.grid_range,\n",
    "    sample_type=\"uniform_central_gaussian\", #args.nonmnfld_sample_type,\n",
    "    sampling_std=0.5, #args.nonmnfld_sample_std,\n",
    "    n_random_samples=7500, #args.n_random_samples,\n",
    "    resample=True,\n",
    "    compute_sal_dist_gt=(\n",
    "        True if \"sal\" in loss_type and loss_weights[5] > 0 else False\n",
    "    ),\n",
    "    scale_method=\"mean\"#\"mean\" #args.pcd_scale_method,\n",
    ")\n",
    "\n",
    "model = Net.Network(\n",
    "    latent_size=0,#args.latent_size,\n",
    "    in_dim=3,\n",
    "    decoder_hidden_dim=128,#args.decoder_hidden_dim,\n",
    "    nl=\"sine\",#args.nl,\n",
    "    encoder_type=\"none\",#args.encoder_type,\n",
    "    decoder_n_hidden_layers=5,#args.decoder_n_hidden_layers,\n",
    "    neuron_type=\"quadratic\",#args.neuron_type,\n",
    "    init_type=\"mfgi\",#args.init_type,\n",
    "    sphere_init_params=[1.6, 0.1],#args.sphere_init_params,\n",
    "    n_repeat_period=30#args.n_repeat_period,\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "######       \n",
    "test_dataloader = torch.utils.data.DataLoader(train_set, batch_size=1, shuffle=False, num_workers=0, pin_memory=False)   \n",
    "test_data = next(iter(test_dataloader))\n",
    "mnfld_points = test_data[\"mnfld_points\"].to(device)\n",
    "mnfld_points.requires_grad_()\n",
    "print(\"mnfld_points shape: \", mnfld_points.shape)\n",
    "if torch.cuda.is_available():\n",
    "    map_location = torch.device(\"cuda\")\n",
    "else:\n",
    "    map_location = torch.device(\"cpu\")\n",
    "model.load_state_dict(torch.load(trained_model_path, weights_only=True, map_location=map_location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5753400f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add mnfld points with random noise to sites \n",
    "\n",
    "sites = torch.cat((sites, mnfld_points.squeeze(0)+(torch.rand_like(mnfld_points.squeeze(0))-0.5)*0.1), dim=0)\n",
    "# make sites a leaf tensor\n",
    "sites = sites.detach().requires_grad_()\n",
    "\n",
    "sites_pred = model(sites)#[\"nonmanifold_pnts_pred\"]\n",
    "mnfld_preds = model(mnfld_points)#[\"nonmanifold_pnts_pred\"]\n",
    "\n",
    "ps_cloud = ps.register_point_cloud(\"initial_cvt_grid+pc_gt\",sites.detach().cpu().numpy())\n",
    "mnf_cloud = ps.register_point_cloud(\"mnfld_points_pred\",mnfld_points.squeeze(0).detach().cpu().numpy())\n",
    "mnf_cloud.add_scalar_quantity(\"mnfld_points_pred\", mnfld_preds.reshape(-1).detach().cpu().numpy(), enabled=True)\n",
    "ps_cloud.add_scalar_quantity(\"vis_grid_pred\", sites_pred.reshape(-1).detach().cpu().numpy(), enabled=True)\n",
    "\n",
    "initial_mesh = su.get_zero_crossing_mesh_3d(sites, model)\n",
    "ps.register_surface_mesh(\"initial Zero-Crossing faces\", initial_mesh[0], initial_mesh[1])\n",
    "\n",
    "ps.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "460a316b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SITES OPTIMISATION LOOP\n",
    "cvt_loss_values = []\n",
    "min_distance_loss_values = []\n",
    "chamfer_distance_loss_values = []\n",
    "eikonal_loss_values = []\n",
    "domain_restriction_loss_values = []\n",
    "sdf_loss_values = []\n",
    "div_loss_values = []\n",
    "loss_values = []\n",
    "\n",
    "\n",
    "\n",
    "def autograd(sites, model, max_iter=100, stop_train_threshold=1e-6, upsampling=0, lambda_weights = [0.1,1.0,0.1,0.1,1.0,1.0,0.1]):\n",
    "    optimizer = torch.optim.Adam([\n",
    "    {'params': [p for _, p in model.named_parameters()], 'lr': 5e-5},\n",
    "    {'params': [sites], 'lr': lr_sites}\n",
    "], betas=(0.9, 0.999))\n",
    "\n",
    "    prev_loss = float(\"inf\")\n",
    "    best_loss = float(\"inf\")\n",
    "    upsampled = 0.0\n",
    "    epoch = 0\n",
    "    lambda_cvt = lambda_weights[0]\n",
    "    # lambda_pc = lambda_weights[1]\n",
    "    lambda_min_distance = lambda_weights[2]\n",
    "    # lambda_laplace = lambda_weights[3]\n",
    "    lamda_chamfer = lambda_weights[4]\n",
    "    lambda_eikonal = lambda_weights[5]\n",
    "    lambda_domain_restriction = lambda_weights[6]\n",
    "    # lambda_target_points = lambda_weights[7]\n",
    "    lambda_sdf = 5e3\n",
    "    lambda_div = 1e2\n",
    "    lambda_eikonal = 5e1\n",
    "    best_sites = sites.clone()\n",
    "    best_sites.best_loss = best_loss\n",
    "    \n",
    "    while epoch <= max_iter:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # compute voronoi and delaunay once for each epoch and pass it around\n",
    "        # Compute Voronoi diagram\n",
    "        sites_np = sites.detach().cpu().numpy()\n",
    "        #vor = Voronoi(sites_np)\n",
    "        #tri = Delaunay(sites_np)\n",
    "      \n",
    "      \n",
    "        d3dsimplices = diffvoronoi.get_delaunay_simplices(sites_np.reshape(input_dims*sites_np.shape[0]))\n",
    "        d3dsimplices = np.array(d3dsimplices)\n",
    "        #print(\"Delaunay simplices shape: \", d3dsimplices.shape)\n",
    "        \n",
    "        vertices_to_compute, bisectors_to_compute = su.compute_zero_crossing_vertices_3d(sites, None, None, d3dsimplices, model)\n",
    "                \n",
    "        #vertices_to_compute, bisectors_to_compute = su.compute_zero_crossing_vertices_3d(sites, None, tri, None, model)\n",
    "        #vertices_to_compute, bisectors_to_compute = su.compute_zero_crossing_vertices_3d(sites, vor, tri, None, model)\n",
    "        \n",
    "        vertices = su.compute_vertices_3d_vectorized(sites, vertices_to_compute)    \n",
    "        bisectors = su.compute_all_bisectors_vectorized(sites, bisectors_to_compute)\n",
    "        points = torch.cat((vertices, bisectors), 0)\n",
    "        print(\"points\", points.shape) \n",
    "\n",
    "        # Compute losses       \n",
    "        #cvt_loss = lf.compute_cvt_loss_vectorized_voronoi(sites, vor)\n",
    "        #cvt_loss = lf.compute_cvt_loss_vectorized_delaunay(sites, tri)\n",
    "    \n",
    "        cvt_loss = lf.compute_cvt_loss_vectorized_delaunay(sites, None, d3dsimplices)\n",
    "        print(\"CVT loss: \", cvt_loss)\n",
    "        #min_distance_loss = lf.sdf_weighted_min_distance_loss(model, sites)\n",
    "        \n",
    "        from pytorch3d.loss import chamfer_distance\n",
    "        chamfer_loss, _ = chamfer_distance(mnfld_points.detach(), points.unsqueeze(0))\n",
    "        print(f\"After Chamfer loss PYTORCH3D {chamfer_loss} : Allocated: {torch.cuda.memory_allocated() / 1e6} MB, Reserved: {torch.cuda.memory_reserved() / 1e6} MB\")\n",
    "            \n",
    "        \n",
    "        # chamfer_loss = lf.chamfer_distance(mnfld_points, points)\n",
    "        \n",
    "        sites_loss = (\n",
    "            lambda_cvt * cvt_loss +\n",
    "            lamda_chamfer * chamfer_loss\n",
    "        )\n",
    "            \n",
    "        loss = sites_loss\n",
    "        loss_values.append(loss.item())\n",
    "        print(f\"Epoch {epoch}: loss = {loss.item()}\")\n",
    "        print(f\"before loss.backward(): Allocated: {torch.cuda.memory_allocated() / 1e6} MB, Reserved: {torch.cuda.memory_reserved() / 1e6} MB\")\n",
    "\n",
    "        loss.backward()\n",
    "        print(f\"After loss.backward(): Allocated: {torch.cuda.memory_allocated() / 1e6} MB, Reserved: {torch.cuda.memory_reserved() / 1e6} MB\")\n",
    "        print(\"-----------------\")\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        if loss.item() < best_loss:\n",
    "            best_loss = loss.item()\n",
    "            best_epoch = epoch\n",
    "            best_sites = sites.clone()\n",
    "            best_sites.best_loss = best_loss\n",
    "            #if upsampled > 0:\n",
    "                #print(f\"UPSAMPLED {upsampled} Best Epoch {best_epoch}: Best loss = {best_loss}\")\n",
    "                #return best_sites\n",
    "        \n",
    "        if abs(prev_loss - loss.item()) < stop_train_threshold:\n",
    "            print(f\"Converged at epoch {epoch} with loss {loss.item()}\")\n",
    "            #break\n",
    "        \n",
    "        prev_loss = loss.item() \n",
    "        \n",
    "        # if epoch>100 and (epoch // 100) == upsampled+1 and loss.item() < 0.5 and upsampled < upsampling:\n",
    "        if epoch/max_iter > (upsampled+1)/(upsampling+1) and upsampled < upsampling:\n",
    "            print(\"sites length BEFORE UPSAMPLING: \",len(sites))\n",
    "            sites = su.upsampling_vectorized(sites, tri=None, vor=None, simplices=d3dsimplices, model=model)\n",
    "            sites = sites.detach().requires_grad_(True)\n",
    "            optimizer = torch.optim.Adam([{'params': [p for _, p in model.named_parameters()], 'lr': lr_model},\n",
    "                                          {'params': [sites], 'lr': lr_sites}])\n",
    "            upsampled += 1.0\n",
    "            print(\"sites length AFTER: \",len(sites))\n",
    "            \n",
    "          \n",
    "        if epoch % (max_iter/50) == 0:\n",
    "            #print(f\"Epoch {epoch}: loss = {loss.item()}\")\n",
    "            #print(f\"Best Epoch {best_epoch}: Best loss = {best_loss}\")\n",
    "            #save model and sites\n",
    "            site_file_path = f'{destination}{mesh[0]}{max_iter}_{epoch}_3d_sites_{num_centroids}_chamfer{lamda_chamfer}.pth'\n",
    "            model_file_path = f'{destination}{mesh[0]}{max_iter}_{epoch}_3d_model_{num_centroids}_chamfer{lamda_chamfer}.pth'\n",
    "            torch.save(model.state_dict(), model_file_path)\n",
    "            torch.save(sites, site_file_path)\n",
    "            \n",
    "        epoch += 1           \n",
    "    \n",
    "    #Export the sites, their sdf values, the gradients of the sdf values and the hessian\n",
    "    sdf_values = model(sites)\n",
    "\n",
    "    sdf_gradients = torch.autograd.grad(outputs=sdf_values, inputs=sites, grad_outputs=torch.ones_like(sdf_values), create_graph=True, retain_graph=True,)[0] # (N, 3)\n",
    "\n",
    "    N, D = sites.shape\n",
    "    hess_sdf = torch.zeros(N, D, D, device=sites.device)\n",
    "    for i in range(D):\n",
    "        grad2 = torch.autograd.grad(outputs=sdf_gradients[:, i], inputs=sites, grad_outputs=torch.ones_like(sdf_gradients[:, i]), create_graph=False, retain_graph=True,)[0] # (N, 3)\n",
    "        hess_sdf[:, i, :] = grad2 # fill row i of each 3Ã—3 Hessian\n",
    "    \n",
    "    np.savez(f'{mesh[0]}_to_clip.npz', sites=sites.detach().cpu().numpy(), sdf_values=sdf_values.detach().cpu().numpy(), sdf_gradients=sdf_gradients.detach().cpu().numpy(), sdf_hessians=hess_sdf.detach().cpu().numpy())\n",
    "\n",
    "    return best_sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d7e96773",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lambda_weights = [252,0,0,0,10.211111,0,100,0]\n",
    "lambda_weights = [100,0,0,0,1000,0,100,0]\n",
    "\n",
    "\n",
    "lambda_cvt = lambda_weights[0]\n",
    "lambda_sdf = lambda_weights[1]\n",
    "lambda_min_distance = lambda_weights[2]\n",
    "lambda_laplace = lambda_weights[3]\n",
    "lamda_chamfer = lambda_weights[4]\n",
    "lambda_eikonal = lambda_weights[5]\n",
    "lambda_domain_restriction = lambda_weights[6]\n",
    "lambda_true_points = lambda_weights[7]\n",
    "\n",
    "max_iter = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6fb2cefd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "points torch.Size([307157, 3])\n",
      "CVT loss:  tensor(0.0016, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 4.0332721255254e-05 : Allocated: 7037.378048 MB, Reserved: 15267.26656 MB\n",
      "Epoch 0: loss = 0.20451991260051727\n",
      "before loss.backward(): Allocated: 7037.37856 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6911.032832 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([296504, 3])\n",
      "CVT loss:  tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 2.269097967655398e-05 : Allocated: 7036.62336 MB, Reserved: 15267.26656 MB\n",
      "Epoch 1: loss = 0.2583116590976715\n",
      "before loss.backward(): Allocated: 7036.62336 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6915.184128 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([298571, 3])\n",
      "CVT loss:  tensor(0.0017, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.7870372175821103e-05 : Allocated: 7036.694528 MB, Reserved: 15267.26656 MB\n",
      "Epoch 2: loss = 0.1927952915430069\n",
      "before loss.backward(): Allocated: 7036.694528 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6915.984896 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([298902, 3])\n",
      "CVT loss:  tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.7223052054760046e-05 : Allocated: 7036.315648 MB, Reserved: 15267.26656 MB\n",
      "Epoch 3: loss = 0.26291632652282715\n",
      "before loss.backward(): Allocated: 7036.315648 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6915.711488 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([297501, 3])\n",
      "CVT loss:  tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.7072221453418024e-05 : Allocated: 7037.103616 MB, Reserved: 15267.26656 MB\n",
      "Epoch 4: loss = 0.31342118978500366\n",
      "before loss.backward(): Allocated: 7037.103616 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6915.742208 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([295188, 3])\n",
      "CVT loss:  tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.6613532352494076e-05 : Allocated: 7036.947456 MB, Reserved: 15267.26656 MB\n",
      "Epoch 5: loss = 0.25166845321655273\n",
      "before loss.backward(): Allocated: 7036.947456 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6916.014592 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([292978, 3])\n",
      "CVT loss:  tensor(0.0015, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.5917701603029855e-05 : Allocated: 7034.174464 MB, Reserved: 15267.26656 MB\n",
      "Epoch 6: loss = 0.16998136043548584\n",
      "before loss.backward(): Allocated: 7034.174464 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6915.469312 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([291266, 3])\n",
      "CVT loss:  tensor(0.0019, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.5158702808548696e-05 : Allocated: 7033.417728 MB, Reserved: 15267.26656 MB\n",
      "Epoch 7: loss = 0.20501041412353516\n",
      "before loss.backward(): Allocated: 7033.417728 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6915.269632 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([289477, 3])\n",
      "CVT loss:  tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.4486649888567626e-05 : Allocated: 7033.55392 MB, Reserved: 15267.26656 MB\n",
      "Epoch 8: loss = 0.28970208764076233\n",
      "before loss.backward(): Allocated: 7033.55392 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6915.771904 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([288433, 3])\n",
      "CVT loss:  tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.3924187442171387e-05 : Allocated: 7033.666048 MB, Reserved: 15267.26656 MB\n",
      "Epoch 9: loss = 0.30156996846199036\n",
      "before loss.backward(): Allocated: 7033.666048 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6916.366848 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([287325, 3])\n",
      "CVT loss:  tensor(0.0038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.3511911674868315e-05 : Allocated: 7034.094592 MB, Reserved: 15267.26656 MB\n",
      "Epoch 10: loss = 0.3898078203201294\n",
      "before loss.backward(): Allocated: 7034.094592 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6916.072448 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([286397, 3])\n",
      "CVT loss:  tensor(0.0034, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.3111706721247174e-05 : Allocated: 7033.432576 MB, Reserved: 15267.26656 MB\n",
      "Epoch 11: loss = 0.3529790937900543\n",
      "before loss.backward(): Allocated: 7033.432576 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6916.842496 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([285069, 3])\n",
      "CVT loss:  tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.2804057405446656e-05 : Allocated: 7033.147392 MB, Reserved: 15267.26656 MB\n",
      "Epoch 12: loss = 0.30885574221611023\n",
      "before loss.backward(): Allocated: 7033.147392 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6916.611584 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([283789, 3])\n",
      "CVT loss:  tensor(0.0035, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.2548498489195481e-05 : Allocated: 7031.362048 MB, Reserved: 15267.26656 MB\n",
      "Epoch 13: loss = 0.3616067171096802\n",
      "before loss.backward(): Allocated: 7031.362048 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6916.195328 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([281831, 3])\n",
      "CVT loss:  tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.2292281098780222e-05 : Allocated: 7030.76352 MB, Reserved: 15267.26656 MB\n",
      "Epoch 14: loss = 0.3226608633995056\n",
      "before loss.backward(): Allocated: 7030.76352 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6916.713984 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([280281, 3])\n",
      "CVT loss:  tensor(0.0039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.2044718459947035e-05 : Allocated: 7031.68256 MB, Reserved: 15267.26656 MB\n",
      "Epoch 15: loss = 0.40603822469711304\n",
      "before loss.backward(): Allocated: 7031.68256 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6917.207552 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([278427, 3])\n",
      "CVT loss:  tensor(0.0047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.1827563866972923e-05 : Allocated: 7029.192704 MB, Reserved: 15267.26656 MB\n",
      "Epoch 16: loss = 0.4840707778930664\n",
      "before loss.backward(): Allocated: 7029.192704 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6915.869184 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([276891, 3])\n",
      "CVT loss:  tensor(0.0047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.1613005881372374e-05 : Allocated: 7028.6976 MB, Reserved: 15267.26656 MB\n",
      "Epoch 17: loss = 0.4829086661338806\n",
      "before loss.backward(): Allocated: 7028.6976 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6916.3776 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([275454, 3])\n",
      "CVT loss:  tensor(0.0048, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.1437459761509672e-05 : Allocated: 7025.800704 MB, Reserved: 15267.26656 MB\n",
      "Epoch 18: loss = 0.49596285820007324\n",
      "before loss.backward(): Allocated: 7025.800704 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6914.457088 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([273562, 3])\n",
      "CVT loss:  tensor(0.0048, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.1238740626140498e-05 : Allocated: 7025.686016 MB, Reserved: 15267.26656 MB\n",
      "Epoch 19: loss = 0.4942842423915863\n",
      "before loss.backward(): Allocated: 7025.686016 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6914.626048 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([272567, 3])\n",
      "CVT loss:  tensor(0.0054, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.1098491995653603e-05 : Allocated: 7026.545152 MB, Reserved: 15267.26656 MB\n",
      "Epoch 20: loss = 0.5493713617324829\n",
      "before loss.backward(): Allocated: 7026.545152 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6915.017728 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([270958, 3])\n",
      "CVT loss:  tensor(0.0057, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.0941152140730992e-05 : Allocated: 7024.493056 MB, Reserved: 15267.26656 MB\n",
      "Epoch 21: loss = 0.580349326133728\n",
      "before loss.backward(): Allocated: 7024.493056 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6913.999872 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([269688, 3])\n",
      "CVT loss:  tensor(0.0049, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.080521906260401e-05 : Allocated: 7025.245184 MB, Reserved: 15267.26656 MB\n",
      "Epoch 22: loss = 0.5014312267303467\n",
      "before loss.backward(): Allocated: 7025.245184 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6914.210816 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([267796, 3])\n",
      "CVT loss:  tensor(0.0047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.0680029845389072e-05 : Allocated: 7025.637376 MB, Reserved: 15267.26656 MB\n",
      "Epoch 23: loss = 0.4758668839931488\n",
      "before loss.backward(): Allocated: 7025.637376 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6915.2128 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([265787, 3])\n",
      "CVT loss:  tensor(0.0053, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.0593436854833271e-05 : Allocated: 7024.2688 MB, Reserved: 15267.26656 MB\n",
      "Epoch 24: loss = 0.5372163653373718\n",
      "before loss.backward(): Allocated: 7024.2688 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6915.426304 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([264751, 3])\n",
      "CVT loss:  tensor(0.0051, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.048034755513072e-05 : Allocated: 7023.246848 MB, Reserved: 15267.26656 MB\n",
      "Epoch 25: loss = 0.5248491764068604\n",
      "before loss.backward(): Allocated: 7023.246848 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6914.70592 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([263680, 3])\n",
      "CVT loss:  tensor(0.0048, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.035881541611161e-05 : Allocated: 7023.963136 MB, Reserved: 15267.26656 MB\n",
      "Epoch 26: loss = 0.4872293174266815\n",
      "before loss.backward(): Allocated: 7023.963136 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6914.919424 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([262313, 3])\n",
      "CVT loss:  tensor(0.0036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.0279859452566598e-05 : Allocated: 7022.99648 MB, Reserved: 15267.26656 MB\n",
      "Epoch 27: loss = 0.3722415566444397\n",
      "before loss.backward(): Allocated: 7022.99648 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6914.155008 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([261209, 3])\n",
      "CVT loss:  tensor(0.0050, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.0214314897893928e-05 : Allocated: 7023.027712 MB, Reserved: 15267.26656 MB\n",
      "Epoch 28: loss = 0.5081462264060974\n",
      "before loss.backward(): Allocated: 7023.027712 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6915.54048 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([260297, 3])\n",
      "CVT loss:  tensor(0.0043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.0135216143680736e-05 : Allocated: 7021.1456 MB, Reserved: 15267.26656 MB\n",
      "Epoch 29: loss = 0.43946048617362976\n",
      "before loss.backward(): Allocated: 7021.1456 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6913.954816 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([259668, 3])\n",
      "CVT loss:  tensor(0.0053, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.0061300599772949e-05 : Allocated: 7020.918272 MB, Reserved: 15267.26656 MB\n",
      "Epoch 30: loss = 0.5410047769546509\n",
      "before loss.backward(): Allocated: 7020.918272 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6914.318336 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([258081, 3])\n",
      "CVT loss:  tensor(0.0047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.0027906682807952e-05 : Allocated: 7020.665856 MB, Reserved: 15267.26656 MB\n",
      "Epoch 31: loss = 0.47757574915885925\n",
      "before loss.backward(): Allocated: 7020.665856 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6915.55584 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([256779, 3])\n",
      "CVT loss:  tensor(0.0045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 9.988971214625053e-06 : Allocated: 7019.420672 MB, Reserved: 15267.26656 MB\n",
      "Epoch 32: loss = 0.4614589512348175\n",
      "before loss.backward(): Allocated: 7019.420672 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6914.440704 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([255299, 3])\n",
      "CVT loss:  tensor(0.0042, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 9.929621228366159e-06 : Allocated: 7018.663936 MB, Reserved: 15267.26656 MB\n",
      "Epoch 33: loss = 0.4310702085494995\n",
      "before loss.backward(): Allocated: 7018.663936 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6913.831936 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([254288, 3])\n",
      "CVT loss:  tensor(0.0052, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 9.866284926829394e-06 : Allocated: 7019.529216 MB, Reserved: 15267.26656 MB\n",
      "Epoch 34: loss = 0.5278742909431458\n",
      "before loss.backward(): Allocated: 7019.529216 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6914.84672 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([252812, 3])\n",
      "CVT loss:  tensor(0.0054, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 9.82822894002311e-06 : Allocated: 7017.437696 MB, Reserved: 15267.26656 MB\n",
      "Epoch 35: loss = 0.5491679906845093\n",
      "before loss.backward(): Allocated: 7017.437696 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6913.243136 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([251738, 3])\n",
      "CVT loss:  tensor(0.0040, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 9.783703717403114e-06 : Allocated: 7019.145728 MB, Reserved: 15267.26656 MB\n",
      "Epoch 36: loss = 0.40997177362442017\n",
      "before loss.backward(): Allocated: 7019.145728 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6914.595328 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([250934, 3])\n",
      "CVT loss:  tensor(0.0041, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 9.74832619249355e-06 : Allocated: 7016.973824 MB, Reserved: 15267.26656 MB\n",
      "Epoch 37: loss = 0.4237402677536011\n",
      "before loss.backward(): Allocated: 7016.973824 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6913.70752 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([249760, 3])\n",
      "CVT loss:  tensor(0.0066, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 9.728988516144454e-06 : Allocated: 7018.031104 MB, Reserved: 15267.26656 MB\n",
      "Epoch 38: loss = 0.6681355834007263\n",
      "before loss.backward(): Allocated: 7018.031104 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6913.85856 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([249031, 3])\n",
      "CVT loss:  tensor(0.0058, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 9.696404958958738e-06 : Allocated: 7017.240576 MB, Reserved: 15267.26656 MB\n",
      "Epoch 39: loss = 0.5887726545333862\n",
      "before loss.backward(): Allocated: 7017.240576 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6915.516928 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([247726, 3])\n",
      "CVT loss:  tensor(0.0065, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 9.669326573202852e-06 : Allocated: 7016.141824 MB, Reserved: 15267.26656 MB\n",
      "Epoch 40: loss = 0.6621062755584717\n",
      "before loss.backward(): Allocated: 7016.141824 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6914.551808 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([246442, 3])\n",
      "CVT loss:  tensor(0.0068, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 9.666544428910129e-06 : Allocated: 7013.908992 MB, Reserved: 15267.26656 MB\n",
      "Epoch 41: loss = 0.6945460438728333\n",
      "before loss.backward(): Allocated: 7013.908992 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6912.968192 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([245540, 3])\n",
      "CVT loss:  tensor(0.0041, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 9.650402716943063e-06 : Allocated: 7014.249984 MB, Reserved: 15267.26656 MB\n",
      "Epoch 42: loss = 0.42350390553474426\n",
      "before loss.backward(): Allocated: 7014.249984 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6913.357824 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([244461, 3])\n",
      "CVT loss:  tensor(0.0053, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 9.637651601224206e-06 : Allocated: 7013.988864 MB, Reserved: 15267.26656 MB\n",
      "Epoch 43: loss = 0.5382755398750305\n",
      "before loss.backward(): Allocated: 7013.988864 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6913.001984 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([243825, 3])\n",
      "CVT loss:  tensor(0.0061, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 9.60736178967636e-06 : Allocated: 7013.855744 MB, Reserved: 15267.26656 MB\n",
      "Epoch 44: loss = 0.6167882084846497\n",
      "before loss.backward(): Allocated: 7013.855744 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6913.990656 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([242659, 3])\n",
      "CVT loss:  tensor(0.0033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 9.59062253969023e-06 : Allocated: 7014.11328 MB, Reserved: 15267.26656 MB\n",
      "Epoch 45: loss = 0.3435714840888977\n",
      "before loss.backward(): Allocated: 7014.11328 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6913.819136 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([241581, 3])\n",
      "CVT loss:  tensor(0.0042, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 9.587916792952456e-06 : Allocated: 7013.339648 MB, Reserved: 15267.26656 MB\n",
      "Epoch 46: loss = 0.428727924823761\n",
      "before loss.backward(): Allocated: 7013.339648 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6912.758784 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([240892, 3])\n",
      "CVT loss:  tensor(0.0047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 9.585786756360903e-06 : Allocated: 7013.118464 MB, Reserved: 15267.26656 MB\n",
      "Epoch 47: loss = 0.48398372530937195\n",
      "before loss.backward(): Allocated: 7013.118464 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6913.745408 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([239969, 3])\n",
      "CVT loss:  tensor(0.0045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 9.588654393155593e-06 : Allocated: 7014.3488 MB, Reserved: 15267.26656 MB\n",
      "Epoch 48: loss = 0.45806965231895447\n",
      "before loss.backward(): Allocated: 7014.3488 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6913.49248 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([238881, 3])\n",
      "CVT loss:  tensor(0.0057, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 9.595642040949315e-06 : Allocated: 7012.780544 MB, Reserved: 15267.26656 MB\n",
      "Epoch 49: loss = 0.5792093873023987\n",
      "before loss.backward(): Allocated: 7012.780544 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6913.903616 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([238100, 3])\n",
      "CVT loss:  tensor(0.0038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 9.617586329113692e-06 : Allocated: 7011.154432 MB, Reserved: 15267.26656 MB\n",
      "Epoch 50: loss = 0.3887026607990265\n",
      "before loss.backward(): Allocated: 7011.154432 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6913.142784 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([236932, 3])\n",
      "CVT loss:  tensor(0.0038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 9.619027878216002e-06 : Allocated: 7010.820608 MB, Reserved: 15267.26656 MB\n",
      "Epoch 51: loss = 0.3941665291786194\n",
      "before loss.backward(): Allocated: 7010.820608 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6913.078784 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([236317, 3])\n",
      "CVT loss:  tensor(0.0038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 9.609140761313029e-06 : Allocated: 7010.884608 MB, Reserved: 15267.26656 MB\n",
      "Epoch 52: loss = 0.3902391493320465\n",
      "before loss.backward(): Allocated: 7010.884608 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6913.454592 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([235391, 3])\n",
      "CVT loss:  tensor(0.0037, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 9.606736057321541e-06 : Allocated: 7009.530368 MB, Reserved: 15267.26656 MB\n",
      "Epoch 53: loss = 0.38271990418434143\n",
      "before loss.backward(): Allocated: 7009.530368 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6912.635392 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([234788, 3])\n",
      "CVT loss:  tensor(0.0038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 9.606814273865893e-06 : Allocated: 7011.37408 MB, Reserved: 15267.26656 MB\n",
      "Epoch 54: loss = 0.38869813084602356\n",
      "before loss.backward(): Allocated: 7011.37408 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6913.96864 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([233864, 3])\n",
      "CVT loss:  tensor(0.0035, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 9.613062502467074e-06 : Allocated: 7008.214528 MB, Reserved: 15267.26656 MB\n",
      "Epoch 55: loss = 0.3578580915927887\n",
      "before loss.backward(): Allocated: 7008.214528 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6912.426496 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([232935, 3])\n",
      "CVT loss:  tensor(0.0049, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 9.63638103712583e-06 : Allocated: 7008.20224 MB, Reserved: 15267.26656 MB\n",
      "Epoch 56: loss = 0.49510470032691956\n",
      "before loss.backward(): Allocated: 7008.20224 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6912.967168 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([232022, 3])\n",
      "CVT loss:  tensor(0.0051, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 9.633242370910011e-06 : Allocated: 7009.162752 MB, Reserved: 15267.26656 MB\n",
      "Epoch 57: loss = 0.5177979469299316\n",
      "before loss.backward(): Allocated: 7009.162752 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6913.792512 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([231251, 3])\n",
      "CVT loss:  tensor(0.0045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 9.657405826146714e-06 : Allocated: 7008.111616 MB, Reserved: 15267.26656 MB\n",
      "Epoch 58: loss = 0.4622953236103058\n",
      "before loss.backward(): Allocated: 7008.111616 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6913.07776 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([229992, 3])\n",
      "CVT loss:  tensor(0.0052, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 9.688103091320954e-06 : Allocated: 7009.18784 MB, Reserved: 15267.26656 MB\n",
      "Epoch 59: loss = 0.5255109667778015\n",
      "before loss.backward(): Allocated: 7009.18784 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6913.08032 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([229616, 3])\n",
      "CVT loss:  tensor(0.0040, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 9.72180441749515e-06 : Allocated: 7008.502784 MB, Reserved: 15267.26656 MB\n",
      "Epoch 60: loss = 0.4135953485965729\n",
      "before loss.backward(): Allocated: 7008.502784 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6913.992192 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([228625, 3])\n",
      "CVT loss:  tensor(0.0036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 9.721241440274753e-06 : Allocated: 7006.320128 MB, Reserved: 15267.26656 MB\n",
      "Epoch 61: loss = 0.3725713789463043\n",
      "before loss.backward(): Allocated: 7006.320128 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6912.444928 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([227802, 3])\n",
      "CVT loss:  tensor(0.0040, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 9.71467852650676e-06 : Allocated: 7006.09536 MB, Reserved: 15267.26656 MB\n",
      "Epoch 62: loss = 0.4082719385623932\n",
      "before loss.backward(): Allocated: 7006.09536 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6912.406016 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([227106, 3])\n",
      "CVT loss:  tensor(0.0033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 9.745821444084868e-06 : Allocated: 7006.57408 MB, Reserved: 15267.26656 MB\n",
      "Epoch 63: loss = 0.3368031978607178\n",
      "before loss.backward(): Allocated: 7006.57408 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6912.502272 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([226453, 3])\n",
      "CVT loss:  tensor(0.0047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 9.772496923687868e-06 : Allocated: 7005.07904 MB, Reserved: 15267.26656 MB\n",
      "Epoch 64: loss = 0.4803434908390045\n",
      "before loss.backward(): Allocated: 7005.07904 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6912.107008 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([225345, 3])\n",
      "CVT loss:  tensor(0.0048, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 9.786732334760018e-06 : Allocated: 7005.292032 MB, Reserved: 15267.26656 MB\n",
      "Epoch 65: loss = 0.49367815256118774\n",
      "before loss.backward(): Allocated: 7005.292032 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6911.770624 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([224909, 3])\n",
      "CVT loss:  tensor(0.0052, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 9.803936336538754e-06 : Allocated: 7006.393856 MB, Reserved: 15267.26656 MB\n",
      "Epoch 66: loss = 0.5334861874580383\n",
      "before loss.backward(): Allocated: 7006.393856 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6912.791552 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([224323, 3])\n",
      "CVT loss:  tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 9.818247235671151e-06 : Allocated: 7004.644864 MB, Reserved: 15267.26656 MB\n",
      "Epoch 67: loss = 0.2973214387893677\n",
      "before loss.backward(): Allocated: 7004.644864 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6912.18432 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([223632, 3])\n",
      "CVT loss:  tensor(0.0041, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 9.852949006017298e-06 : Allocated: 7004.752384 MB, Reserved: 15267.26656 MB\n",
      "Epoch 68: loss = 0.42451921105384827\n",
      "before loss.backward(): Allocated: 7004.752384 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6912.308736 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([222891, 3])\n",
      "CVT loss:  tensor(0.0047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 9.87585553957615e-06 : Allocated: 7005.2224 MB, Reserved: 15267.26656 MB\n",
      "Epoch 69: loss = 0.48368802666664124\n",
      "before loss.backward(): Allocated: 7005.2224 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6912.539648 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([222280, 3])\n",
      "CVT loss:  tensor(0.0053, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 9.864626917988062e-06 : Allocated: 7005.15072 MB, Reserved: 15267.26656 MB\n",
      "Epoch 70: loss = 0.5411999225616455\n",
      "before loss.backward(): Allocated: 7005.15072 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6913.506816 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([221260, 3])\n",
      "CVT loss:  tensor(0.0041, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 9.895165931084193e-06 : Allocated: 7004.8512 MB, Reserved: 15267.26656 MB\n",
      "Epoch 71: loss = 0.41661348938941956\n",
      "before loss.backward(): Allocated: 7004.8512 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6912.164352 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([220647, 3])\n",
      "CVT loss:  tensor(0.0042, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 9.924087862600572e-06 : Allocated: 7003.516416 MB, Reserved: 15267.26656 MB\n",
      "Epoch 72: loss = 0.42658624053001404\n",
      "before loss.backward(): Allocated: 7003.516416 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6912.321024 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([219644, 3])\n",
      "CVT loss:  tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 9.966801371774636e-06 : Allocated: 7005.149184 MB, Reserved: 15267.26656 MB\n",
      "Epoch 73: loss = 0.2979087233543396\n",
      "before loss.backward(): Allocated: 7005.149184 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6913.786368 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([219062, 3])\n",
      "CVT loss:  tensor(0.0037, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 9.995706022891682e-06 : Allocated: 7002.857472 MB, Reserved: 15267.26656 MB\n",
      "Epoch 74: loss = 0.3821662366390228\n",
      "before loss.backward(): Allocated: 7002.857472 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6912.036864 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([218090, 3])\n",
      "CVT loss:  tensor(0.0050, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.0048786862171255e-05 : Allocated: 7002.304512 MB, Reserved: 15267.26656 MB\n",
      "Epoch 75: loss = 0.510857105255127\n",
      "before loss.backward(): Allocated: 7002.304512 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6913.168384 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([217293, 3])\n",
      "CVT loss:  tensor(0.0047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.0088349881698377e-05 : Allocated: 7001.756672 MB, Reserved: 15267.26656 MB\n",
      "Epoch 76: loss = 0.4767615795135498\n",
      "before loss.backward(): Allocated: 7001.756672 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6912.722944 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([216860, 3])\n",
      "CVT loss:  tensor(0.0054, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.0135032425750978e-05 : Allocated: 7003.270144 MB, Reserved: 15267.26656 MB\n",
      "Epoch 77: loss = 0.5473050475120544\n",
      "before loss.backward(): Allocated: 7003.270144 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6913.526272 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([215769, 3])\n",
      "CVT loss:  tensor(0.0036, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.0149471563636325e-05 : Allocated: 7000.278016 MB, Reserved: 15267.26656 MB\n",
      "Epoch 78: loss = 0.37280887365341187\n",
      "before loss.backward(): Allocated: 7000.278016 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6911.670784 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([215277, 3])\n",
      "CVT loss:  tensor(0.0037, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.0171121175517328e-05 : Allocated: 6999.94624 MB, Reserved: 15267.26656 MB\n",
      "Epoch 79: loss = 0.3819030523300171\n",
      "before loss.backward(): Allocated: 6999.94624 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6911.586304 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([214702, 3])\n",
      "CVT loss:  tensor(0.0055, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.0187070074607618e-05 : Allocated: 7000.8832 MB, Reserved: 15267.26656 MB\n",
      "Epoch 80: loss = 0.5578940510749817\n",
      "before loss.backward(): Allocated: 7000.8832 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6911.697408 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([214015, 3])\n",
      "CVT loss:  tensor(0.0050, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.0185336577706039e-05 : Allocated: 6999.855616 MB, Reserved: 15267.26656 MB\n",
      "Epoch 81: loss = 0.5126764178276062\n",
      "before loss.backward(): Allocated: 6999.855616 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6912.329216 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([213115, 3])\n",
      "CVT loss:  tensor(0.0039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.023766708385665e-05 : Allocated: 6999.439872 MB, Reserved: 15267.26656 MB\n",
      "Epoch 82: loss = 0.39857983589172363\n",
      "before loss.backward(): Allocated: 6999.439872 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6912.077312 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([212548, 3])\n",
      "CVT loss:  tensor(0.0044, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.0287215445714537e-05 : Allocated: 6999.379968 MB, Reserved: 15267.26656 MB\n",
      "Epoch 83: loss = 0.4484296441078186\n",
      "before loss.backward(): Allocated: 6999.379968 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6912.198144 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([211731, 3])\n",
      "CVT loss:  tensor(0.0051, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.0308789569535293e-05 : Allocated: 6998.841344 MB, Reserved: 15267.26656 MB\n",
      "Epoch 84: loss = 0.5228373408317566\n",
      "before loss.backward(): Allocated: 6998.841344 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6911.93344 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([211206, 3])\n",
      "CVT loss:  tensor(0.0033, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.032349518936826e-05 : Allocated: 6998.190592 MB, Reserved: 15267.26656 MB\n",
      "Epoch 85: loss = 0.34047576785087585\n",
      "before loss.backward(): Allocated: 6998.190592 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6911.835648 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([210807, 3])\n",
      "CVT loss:  tensor(0.0039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.0337383173464332e-05 : Allocated: 6998.46656 MB, Reserved: 15267.26656 MB\n",
      "Epoch 86: loss = 0.3963271975517273\n",
      "before loss.backward(): Allocated: 6998.46656 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6911.86432 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([210235, 3])\n",
      "CVT loss:  tensor(0.0042, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.0355826816521585e-05 : Allocated: 6998.472704 MB, Reserved: 15267.26656 MB\n",
      "Epoch 87: loss = 0.4303373694419861\n",
      "before loss.backward(): Allocated: 6998.472704 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6912.260096 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([209137, 3])\n",
      "CVT loss:  tensor(0.0049, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.045059434545692e-05 : Allocated: 6999.116288 MB, Reserved: 15267.26656 MB\n",
      "Epoch 88: loss = 0.4997483789920807\n",
      "before loss.backward(): Allocated: 6999.116288 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6912.669696 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([208703, 3])\n",
      "CVT loss:  tensor(0.0046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.048175818141317e-05 : Allocated: 6997.95456 MB, Reserved: 15267.26656 MB\n",
      "Epoch 89: loss = 0.4656136929988861\n",
      "before loss.backward(): Allocated: 6997.95456 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6911.502336 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([208219, 3])\n",
      "CVT loss:  tensor(0.0048, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.0478093827259727e-05 : Allocated: 6997.381632 MB, Reserved: 15267.26656 MB\n",
      "Epoch 90: loss = 0.4945068955421448\n",
      "before loss.backward(): Allocated: 6997.381632 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6911.273472 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([207688, 3])\n",
      "CVT loss:  tensor(0.0043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.0474677765159868e-05 : Allocated: 6998.46144 MB, Reserved: 15267.26656 MB\n",
      "Epoch 91: loss = 0.44115543365478516\n",
      "before loss.backward(): Allocated: 6998.46144 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6912.848896 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([207246, 3])\n",
      "CVT loss:  tensor(0.0058, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.0483166988706216e-05 : Allocated: 6997.869056 MB, Reserved: 15267.26656 MB\n",
      "Epoch 92: loss = 0.5896520018577576\n",
      "before loss.backward(): Allocated: 6997.869056 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6911.282688 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([206481, 3])\n",
      "CVT loss:  tensor(0.0044, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.0495798051124439e-05 : Allocated: 6997.313536 MB, Reserved: 15267.26656 MB\n",
      "Epoch 93: loss = 0.4506272077560425\n",
      "before loss.backward(): Allocated: 6997.313536 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6912.173056 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([205823, 3])\n",
      "CVT loss:  tensor(0.0058, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.0533063687034883e-05 : Allocated: 6996.680704 MB, Reserved: 15267.26656 MB\n",
      "Epoch 94: loss = 0.5909962058067322\n",
      "before loss.backward(): Allocated: 6996.680704 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6911.640576 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([205515, 3])\n",
      "CVT loss:  tensor(0.0044, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.0558299436524976e-05 : Allocated: 6996.268032 MB, Reserved: 15267.26656 MB\n",
      "Epoch 95: loss = 0.45519861578941345\n",
      "before loss.backward(): Allocated: 6996.268032 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6911.382528 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([204903, 3])\n",
      "CVT loss:  tensor(0.0038, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.0570824997557793e-05 : Allocated: 6997.029376 MB, Reserved: 15267.26656 MB\n",
      "Epoch 96: loss = 0.38841119408607483\n",
      "before loss.backward(): Allocated: 6997.029376 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6911.609856 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([204414, 3])\n",
      "CVT loss:  tensor(0.0042, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.0587695214780979e-05 : Allocated: 6997.33248 MB, Reserved: 15267.26656 MB\n",
      "Epoch 97: loss = 0.43192118406295776\n",
      "before loss.backward(): Allocated: 6997.33248 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6912.5632 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([203653, 3])\n",
      "CVT loss:  tensor(0.0041, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.0609664968797006e-05 : Allocated: 6996.38528 MB, Reserved: 15267.26656 MB\n",
      "Epoch 98: loss = 0.41595137119293213\n",
      "before loss.backward(): Allocated: 6996.38528 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6912.032768 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([203082, 3])\n",
      "CVT loss:  tensor(0.0037, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.0652873243088834e-05 : Allocated: 6995.80416 MB, Reserved: 15267.26656 MB\n",
      "Epoch 99: loss = 0.37663254141807556\n",
      "before loss.backward(): Allocated: 6995.80416 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6911.59808 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "points torch.Size([202071, 3])\n",
      "CVT loss:  tensor(0.0043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.072418217518134e-05 : Allocated: 6995.516928 MB, Reserved: 15267.26656 MB\n",
      "Epoch 100: loss = 0.4412729740142822\n",
      "before loss.backward(): Allocated: 6995.516928 MB, Reserved: 15267.26656 MB\n",
      "After loss.backward(): Allocated: 6911.212544 MB, Reserved: 15267.26656 MB\n",
      "-----------------\n",
      "Sites length:  186368\n",
      "min sites:  tensor(-1.3264, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "max sites:  tensor(1.3839, device='cuda:0', grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "site_file_path = f'{destination}{max_iter}_cvt_{lambda_cvt}_chamfer_{lamda_chamfer}_eikonal_{lambda_eikonal}.npy'\n",
    "#check if optimized sites file exists\n",
    "if not os.path.exists(site_file_path):\n",
    "    #import sites\n",
    "    print(\"Importing sites\")\n",
    "    sites = np.load(site_file_path)\n",
    "    sites = torch.from_numpy(sites).to(device).requires_grad_(True)\n",
    "else:\n",
    "    # import cProfile, pstats\n",
    "    # import time\n",
    "    # profiler = cProfile.Profile()\n",
    "    # profiler.enable()\n",
    "\n",
    "#     with torch.profiler.profile(activities=[\n",
    "#             torch.profiler.ProfilerActivity.CPU,\n",
    "#             torch.profiler.ProfilerActivity.CUDA,\n",
    "#         ],\n",
    "#         record_shapes=False,\n",
    "#         with_stack=True  # Captures function calls\n",
    "#     ) as prof:\n",
    "#         sites = autograd(sites, model, max_iter=max_iter, upsampling=0, lambda_weights=lambda_weights)\n",
    "#         torch.cuda.synchronize()\n",
    "# # \n",
    "#     print(prof.key_averages().table(sort_by=\"self_cuda_time_total\"))\n",
    "#     prof.export_chrome_trace(\"trace.json\")\n",
    "    \n",
    "    # \n",
    "    sites = autograd(sites, model, max_iter=max_iter, upsampling=0, lambda_weights=lambda_weights)\n",
    "\n",
    "    \n",
    "    # profiler.disable()\n",
    "    # stats = pstats.Stats(profiler).sort_stats('cumtime')\n",
    "    # stats.print_stats()\n",
    "    # stats.dump_stats(f'{destination}{mesh[0]}{max_iter}_3d_profile_{num_centroids}_chamfer{lamda_chamfer}.prof')\n",
    "    \n",
    "    \n",
    "    sites_np = sites.detach().cpu().numpy()\n",
    "    np.save(site_file_path, sites_np)\n",
    "    \n",
    "    \n",
    "\n",
    "print(\"Sites length: \", len(sites))\n",
    "print(\"min sites: \", torch.min(sites))\n",
    "print(\"max sites: \", torch.max(sites))\n",
    "#ps_cloud = ps.register_point_cloud(\"best_optimized_cvt_grid\",sites.detach().cpu().numpy())\n",
    "    \n",
    "lim=torch.abs(torch.max(sites)).detach().cpu().numpy()*1.1\n",
    "#plot_voronoi_3d(sites,lim,lim,lim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4e4fcfff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model ./images/autograd/HotSpot/gargoyle100_100_3d_model_32768_chamfer1000.pth\n",
      "sites ./images/autograd/HotSpot/gargoyle100_100_3d_sites_32768_chamfer1000.pth\n"
     ]
    }
   ],
   "source": [
    "epoch = 100\n",
    "\n",
    "model_file_path = f'{destination}{mesh[0]}{max_iter}_{epoch}_3d_model_{num_centroids}_chamfer{lamda_chamfer}.pth'\n",
    "site_file_path = f'{destination}{mesh[0]}{max_iter}_{epoch}_3d_sites_{num_centroids}_chamfer{lamda_chamfer}.pth'\n",
    " \n",
    "sites = torch.load(site_file_path)\n",
    "\n",
    "sites_np = sites.detach().cpu().numpy()\n",
    "model.load_state_dict(torch.load(model_file_path))\n",
    "#\n",
    "#polyscope_sdf(model)\n",
    "#\n",
    "print(\"model\", model_file_path)\n",
    "print(\"sites\", site_file_path)\n",
    "ps_cloud = ps.register_point_cloud(f\"{epoch} epoch_cvt_grid\",sites_np)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "72e588cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(tensor([[-0.3156, -0.0883, -0.2731],\n",
      "        [-0.3131, -0.0829, -0.2821],\n",
      "        [-0.3166, -0.0795, -0.2744],\n",
      "        ...,\n",
      "        [ 0.2041, -0.0145, -0.0040],\n",
      "        [ 0.3079, -0.1212, -0.2902],\n",
      "        [-0.1589, -0.1193,  0.3620]], device='cuda:0', grad_fn=<SumBackward1>),), (tensor([[35080,  5432, 54927],\n",
      "        [17121, 62631,  4579],\n",
      "        [31444, 68665, 56083],\n",
      "        ...,\n",
      "        [ 7913,  7915, 64509],\n",
      "        [58882, 46005, 64510],\n",
      "        [58882, 46003, 46005]], device='cuda:0'),)]\n"
     ]
    }
   ],
   "source": [
    "final_mesh = su.get_zero_crossing_mesh_3d(sites, model)\n",
    "ps.register_surface_mesh(\"Zero-Crossing faces final\", final_mesh[0], final_mesh[1])\n",
    "\n",
    "import scipy.spatial as spatial\n",
    "from scipy.spatial import Delaunay\n",
    "\n",
    "tri = Delaunay(sites_np)\n",
    "delaunay_vertices =torch.tensor(np.array(tri.simplices), device=device)\n",
    "sdf_values = model(sites)\n",
    "\n",
    "\n",
    "# Assuming sites is a PyTorch tensor of shape [M, 3]\n",
    "sites = sites.unsqueeze(0)  # Now shape [1, M, 3]\n",
    "\n",
    "# Assuming SDF_Values is a PyTorch tensor of shape [M]\n",
    "sdf_values = sdf_values.unsqueeze(0)  # Now shape [1, M]\n",
    "\n",
    "marching_tetrehedra_mesh = kaolin.ops.conversions.marching_tetrahedra(sites, delaunay_vertices, sdf_values, return_tet_idx=False)\n",
    "print(marching_tetrehedra_mesh)\n",
    "vertices_list, faces_list = marching_tetrehedra_mesh\n",
    "vertices = vertices_list[0]\n",
    "faces = faces_list[0]\n",
    "vertices_np = vertices.detach().cpu().numpy()  # Shape [N, 3]\n",
    "faces_np = faces.detach().cpu().numpy()  # Shape [M, 3] (triangles)\n",
    "ps.register_surface_mesh(\"Marching Tetrahedra Mesh final\", vertices_np, faces_np)\n",
    "\n",
    "\n",
    "ps.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "69d940a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
