{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed71bbfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "Using device:  NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "import kaolin\n",
    "import torch\n",
    "import math\n",
    "import matplotlib\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import polyscope as ps\n",
    "import trimesh\n",
    "import diffvoronoi\n",
    "\n",
    "from scipy.spatial import Voronoi, voronoi_plot_2d, Delaunay\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import sdfpred_utils.sdfpred_utils as su\n",
    "import sdfpred_utils.sdf_MLP as mlp\n",
    "import sdfpred_utils.sdf_functions as sdf\n",
    "import sdfpred_utils.loss_functions as lf\n",
    "import sdfpred_utils.Steik_data3d as sd3d\n",
    "import sdfpred_utils.Steik_Loss as sl\n",
    "import sdfpred_utils.Steik_utils as Stu \n",
    "import open3d as o3d\n",
    "\n",
    "#cuda devices\n",
    "device = torch.device(\"cuda:0\")\n",
    "print(\"Using device: \", torch.cuda.get_device_name(device))\n",
    "\n",
    "#default tensor types\n",
    "#torch.set_default_tensor_type(torch.cuda.DoubleTensor)\n",
    "\n",
    "multires = 2\n",
    "input_dims = 3\n",
    "lr_sites = 0.005/2\n",
    "lr_model = 0.00005*2\n",
    "destination = \"./images/autograd/HotSpot/\"\n",
    "mesh = [\"gargoyle\",\"/home/wylliam/dev/Kyushu_experiments/data/gargoyle\"]\n",
    "trained_model_path = \"/home/wylliam/dev/HotSpot/log/3D/pc/HotSpot-all-2025-04-24-18-16-03/gargoyle/gargoyle/trained_models/model.pth\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a4b4e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new sites\n",
      "Sites shape:  torch.Size([4096, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wylliam/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1678402412426/work/aten/src/ATen/native/TensorShape.cpp:3483.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[polyscope] Backend: openGL3_glfw -- Loaded openGL version: 3.3.0 NVIDIA 570.144\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<polyscope.point_cloud.PointCloud at 0x792a3afd4dc0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_centroids = 16**3\n",
    "\n",
    "print(\"Creating new sites\")\n",
    "noise_scale = 0.1\n",
    "domain_limit = 1\n",
    "x = torch.linspace(-domain_limit, domain_limit, int(round(num_centroids**(1/3))))\n",
    "y = torch.linspace(-domain_limit, domain_limit, int(round(num_centroids**(1/3))))\n",
    "z = torch.linspace(-domain_limit, domain_limit, int(round(num_centroids**(1/3))))\n",
    "meshgrid = torch.meshgrid(x, y, z)\n",
    "meshgrid = torch.stack(meshgrid, dim=3).view(-1, 3)\n",
    "#add noise to meshgrid\n",
    "meshgrid += torch.randn_like(meshgrid) * noise_scale\n",
    "sites = meshgrid.to(device, dtype=torch.float32).requires_grad_(True)\n",
    "\n",
    "print(\"Sites shape: \", sites.shape)\n",
    "ps.init()\n",
    "ps.register_point_cloud(\"initial_cvt_grid\",sites.detach().cpu().numpy())\n",
    "\n",
    "# # load pointcloud used for sdf training\n",
    "# pointcloud = o3d.io.read_point_cloud(mesh[1]+\".ply\")\n",
    "# print(\"Pointcloud shape: \", np.asarray(pointcloud.points).shape)\n",
    "# # sample pointcloud to 150*32*32\n",
    "# chamfer_distance_pc_gt = pointcloud.uniform_down_sample(int((128**3)/(150*32*32)))\n",
    "# chamfer_distance_pc_gt = np.asarray(chamfer_distance_pc_gt.points)\n",
    "# print(\"Chamfer distance pointcloud shape: \", chamfer_distance_pc_gt.shape)\n",
    "\n",
    "\n",
    "# ps.register_point_cloud(\"pointcloud_gt\", chamfer_distance_pc_gt)\n",
    "# chamfer_distance_pc_gt = torch.tensor(chamfer_distance_pc_gt, device=device, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe96048f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnfld_points shape:  torch.Size([1, 153600, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wylliam/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LOAD MODEL WITH HOTSPOT\n",
    "import sys\n",
    "sys.path.append(\"3rdparty/HotSpot\")\n",
    "from dataset import shape_3d\n",
    "import models.Net as Net\n",
    "\n",
    "loss_type = \"igr_w_heat\"\n",
    "loss_weights = [350, 0, 0, 1, 0, 0, 20]\n",
    "\n",
    "train_set = shape_3d.ReconDataset(\n",
    "    file_path = mesh[1]+\".ply\",\n",
    "    n_points=32*32*150,#15000, #args.n_points,\n",
    "    n_samples=10001, #args.n_iterations,\n",
    "    grid_res=256, #args.grid_res,\n",
    "    grid_range=1.1, #args.grid_range,\n",
    "    sample_type=\"uniform_central_gaussian\", #args.nonmnfld_sample_type,\n",
    "    sampling_std=0.5, #args.nonmnfld_sample_std,\n",
    "    n_random_samples=7500, #args.n_random_samples,\n",
    "    resample=True,\n",
    "    compute_sal_dist_gt=(\n",
    "        True if \"sal\" in loss_type and loss_weights[5] > 0 else False\n",
    "    ),\n",
    "    scale_method=\"mean\"#\"mean\" #args.pcd_scale_method,\n",
    ")\n",
    "\n",
    "model = Net.Network(\n",
    "    latent_size=0,#args.latent_size,\n",
    "    in_dim=3,\n",
    "    decoder_hidden_dim=128,#args.decoder_hidden_dim,\n",
    "    nl=\"sine\",#args.nl,\n",
    "    encoder_type=\"none\",#args.encoder_type,\n",
    "    decoder_n_hidden_layers=5,#args.decoder_n_hidden_layers,\n",
    "    neuron_type=\"quadratic\",#args.neuron_type,\n",
    "    init_type=\"mfgi\",#args.init_type,\n",
    "    sphere_init_params=[1.6, 0.1],#args.sphere_init_params,\n",
    "    n_repeat_period=30#args.n_repeat_period,\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "######       \n",
    "test_dataloader = torch.utils.data.DataLoader(train_set, batch_size=1, shuffle=False, num_workers=0, pin_memory=False)   \n",
    "test_data = next(iter(test_dataloader))\n",
    "mnfld_points = test_data[\"mnfld_points\"].to(device)\n",
    "mnfld_points.requires_grad_()\n",
    "print(\"mnfld_points shape: \", mnfld_points.shape)\n",
    "if torch.cuda.is_available():\n",
    "    map_location = torch.device(\"cuda\")\n",
    "else:\n",
    "    map_location = torch.device(\"cpu\")\n",
    "model.load_state_dict(torch.load(trained_model_path, weights_only=True, map_location=map_location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5753400f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add mnfld points with random noise to sites \n",
    "N = mnfld_points.squeeze(0).shape[0]\n",
    "num_samples = 2*(16**3)\n",
    "idx = torch.randint(0, N, (num_samples,))\n",
    "sampled = mnfld_points.squeeze(0)[idx]\n",
    "perturbed = sampled + (torch.rand_like(sampled)-0.5)*0.1\n",
    "sites = torch.cat((sites, perturbed), dim=0)\n",
    "\n",
    "\n",
    "# sites = torch.cat((sites, mnfld_points.squeeze(0)+(torch.rand_like(mnfld_points.squeeze(0))-0.5)*0.1), dim=0)\n",
    "# sites = torch.cat((sites, mnfld_points.squeeze(0)+(torch.rand_like(mnfld_points.squeeze(0))-0.5)*0.1), dim=0)\n",
    "\n",
    "# make sites a leaf tensor\n",
    "sites = sites.detach().requires_grad_()\n",
    "\n",
    "sites_pred = model(sites)#[\"nonmanifold_pnts_pred\"]\n",
    "mnfld_preds = model(mnfld_points)#[\"nonmanifold_pnts_pred\"]\n",
    "\n",
    "ps_cloud = ps.register_point_cloud(\"initial_cvt_grid+pc_gt\",sites.detach().cpu().numpy())\n",
    "mnf_cloud = ps.register_point_cloud(\"mnfld_points_pred\",mnfld_points.squeeze(0).detach().cpu().numpy())\n",
    "mnf_cloud.add_scalar_quantity(\"mnfld_points_pred\", mnfld_preds.reshape(-1).detach().cpu().numpy(), enabled=True)\n",
    "ps_cloud.add_scalar_quantity(\"vis_grid_pred\", sites_pred.reshape(-1).detach().cpu().numpy(), enabled=True)\n",
    "\n",
    "initial_mesh = su.get_zero_crossing_mesh_3d(sites, model)\n",
    "ps.register_surface_mesh(\"initial Zero-Crossing faces\", initial_mesh[0], initial_mesh[1])\n",
    "\n",
    "ps.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "460a316b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SITES OPTIMISATION LOOP\n",
    "cvt_loss_values = []\n",
    "min_distance_loss_values = []\n",
    "chamfer_distance_loss_values = []\n",
    "eikonal_loss_values = []\n",
    "domain_restriction_loss_values = []\n",
    "sdf_loss_values = []\n",
    "div_loss_values = []\n",
    "loss_values = []\n",
    "\n",
    "\n",
    "\n",
    "def autograd(sites, model, max_iter=100, stop_train_threshold=1e-6, upsampling=0, lambda_weights = [0.1,1.0,0.1,0.1,1.0,1.0,0.1]):\n",
    "    optimizer = torch.optim.Adam([\n",
    "    {'params': [p for _, p in model.named_parameters()], 'lr': 5e-5},\n",
    "    {'params': [sites], 'lr': lr_sites}\n",
    "], betas=(0.9, 0.999))\n",
    "\n",
    "    prev_loss = float(\"inf\")\n",
    "    best_loss = float(\"inf\")\n",
    "    upsampled = 0.0\n",
    "    epoch = 0\n",
    "    lambda_cvt = lambda_weights[0]\n",
    "    # lambda_pc = lambda_weights[1]\n",
    "    lambda_min_distance = lambda_weights[2]\n",
    "    # lambda_laplace = lambda_weights[3]\n",
    "    lamda_chamfer = lambda_weights[4]\n",
    "    lambda_eikonal = lambda_weights[5]\n",
    "    lambda_domain_restriction = lambda_weights[6]\n",
    "    # lambda_target_points = lambda_weights[7]\n",
    "    lambda_sdf = 5e3\n",
    "    lambda_div = 1e2\n",
    "    lambda_eikonal = 5e1\n",
    "    best_sites = sites.clone()\n",
    "    best_sites.best_loss = best_loss\n",
    "    \n",
    "    while epoch <= max_iter:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # compute voronoi and delaunay once for each epoch and pass it around\n",
    "        # Compute Voronoi diagram\n",
    "        sites_np = sites.detach().cpu().numpy()\n",
    "        #vor = Voronoi(sites_np)\n",
    "        #tri = Delaunay(sites_np)\n",
    "      \n",
    "      \n",
    "        d3dsimplices = diffvoronoi.get_delaunay_simplices(sites_np.reshape(input_dims*sites_np.shape[0]))\n",
    "        d3dsimplices = np.array(d3dsimplices)\n",
    "        #print(\"Delaunay simplices shape: \", d3dsimplices.shape)\n",
    "        \n",
    "        vertices_to_compute, bisectors_to_compute = su.compute_zero_crossing_vertices_3d(sites, None, None, d3dsimplices, model)\n",
    "                \n",
    "        #vertices_to_compute, bisectors_to_compute = su.compute_zero_crossing_vertices_3d(sites, None, tri, None, model)\n",
    "        #vertices_to_compute, bisectors_to_compute = su.compute_zero_crossing_vertices_3d(sites, vor, tri, None, model)\n",
    "        \n",
    "        vertices = su.compute_vertices_3d_vectorized(sites, vertices_to_compute)    \n",
    "        bisectors = su.compute_all_bisectors_vectorized(sites, bisectors_to_compute)\n",
    "        points = torch.cat((vertices, bisectors), 0)\n",
    "        print(\"points\", points.shape) \n",
    "\n",
    "        # Compute losses       \n",
    "        #cvt_loss = lf.compute_cvt_loss_vectorized_voronoi(sites, vor)\n",
    "        #cvt_loss = lf.compute_cvt_loss_vectorized_delaunay(sites, tri)\n",
    "    \n",
    "        cvt_loss = lf.compute_cvt_loss_vectorized_delaunay(sites, None, d3dsimplices)\n",
    "        print(\"CVT loss: \", cvt_loss)\n",
    "        #min_distance_loss = lf.sdf_weighted_min_distance_loss(model, sites)\n",
    "        \n",
    "        from pytorch3d.loss import chamfer_distance\n",
    "        chamfer_loss, _ = chamfer_distance(mnfld_points.detach(), points.unsqueeze(0))\n",
    "        print(f\"After Chamfer loss PYTORCH3D {chamfer_loss} : Allocated: {torch.cuda.memory_allocated() / 1e6} MB, Reserved: {torch.cuda.memory_reserved() / 1e6} MB\")\n",
    "            \n",
    "        \n",
    "        # chamfer_loss = lf.chamfer_distance(mnfld_points, points)\n",
    "        \n",
    "        sites_loss = (\n",
    "            lambda_cvt * cvt_loss +\n",
    "            lamda_chamfer * chamfer_loss\n",
    "        )\n",
    "            \n",
    "        loss = sites_loss\n",
    "        loss_values.append(loss.item())\n",
    "        print(f\"Epoch {epoch}: loss = {loss.item()}\")\n",
    "        print(f\"before loss.backward(): Allocated: {torch.cuda.memory_allocated() / 1e6} MB, Reserved: {torch.cuda.memory_reserved() / 1e6} MB\")\n",
    "\n",
    "        loss.backward()\n",
    "        print(f\"After loss.backward(): Allocated: {torch.cuda.memory_allocated() / 1e6} MB, Reserved: {torch.cuda.memory_reserved() / 1e6} MB\")\n",
    "        print(\"-----------------\")\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        if loss.item() < best_loss:\n",
    "            best_loss = loss.item()\n",
    "            best_epoch = epoch\n",
    "            best_sites = sites.clone()\n",
    "            best_sites.best_loss = best_loss\n",
    "            #if upsampled > 0:\n",
    "                #print(f\"UPSAMPLED {upsampled} Best Epoch {best_epoch}: Best loss = {best_loss}\")\n",
    "                #return best_sites\n",
    "        \n",
    "        if abs(prev_loss - loss.item()) < stop_train_threshold:\n",
    "            print(f\"Converged at epoch {epoch} with loss {loss.item()}\")\n",
    "            #break\n",
    "        \n",
    "        prev_loss = loss.item() \n",
    "        \n",
    "        # if epoch>100 and (epoch // 100) == upsampled+1 and loss.item() < 0.5 and upsampled < upsampling:\n",
    "        if epoch/max_iter > (upsampled+1)/(upsampling+1) and upsampled < upsampling:\n",
    "            print(\"sites length BEFORE UPSAMPLING: \",len(sites))\n",
    "            sites = su.upsampling_vectorized(sites, tri=None, vor=None, simplices=d3dsimplices, model=model)\n",
    "            sites = sites.detach().requires_grad_(True)\n",
    "            optimizer = torch.optim.Adam([{'params': [p for _, p in model.named_parameters()], 'lr': lr_model},\n",
    "                                          {'params': [sites], 'lr': lr_sites}])\n",
    "            upsampled += 1.0\n",
    "            print(\"sites length AFTER: \",len(sites))\n",
    "            \n",
    "          \n",
    "        if epoch % (max_iter/50) == 0:\n",
    "            #print(f\"Epoch {epoch}: loss = {loss.item()}\")\n",
    "            #print(f\"Best Epoch {best_epoch}: Best loss = {best_loss}\")\n",
    "            #save model and sites\n",
    "            site_file_path = f'{destination}{mesh[0]}{max_iter}_{epoch}_3d_sites_{num_centroids}_chamfer{lamda_chamfer}.pth'\n",
    "            model_file_path = f'{destination}{mesh[0]}{max_iter}_{epoch}_3d_model_{num_centroids}_chamfer{lamda_chamfer}.pth'\n",
    "            torch.save(model.state_dict(), model_file_path)\n",
    "            torch.save(sites, site_file_path)\n",
    "            \n",
    "        epoch += 1           \n",
    "    \n",
    "    #Export the sites, their sdf values, the gradients of the sdf values and the hessian\n",
    "    sdf_values = model(sites)\n",
    "\n",
    "    sdf_gradients = torch.autograd.grad(outputs=sdf_values, inputs=sites, grad_outputs=torch.ones_like(sdf_values), create_graph=True, retain_graph=True,)[0] # (N, 3)\n",
    "\n",
    "    N, D = sites.shape\n",
    "    hess_sdf = torch.zeros(N, D, D, device=sites.device)\n",
    "    for i in range(D):\n",
    "        grad2 = torch.autograd.grad(outputs=sdf_gradients[:, i], inputs=sites, grad_outputs=torch.ones_like(sdf_gradients[:, i]), create_graph=False, retain_graph=True,)[0] # (N, 3)\n",
    "        hess_sdf[:, i, :] = grad2 # fill row i of each 3Ã—3 Hessian\n",
    "    \n",
    "    np.savez(f'{mesh[0]}_to_clip.npz', sites=sites.detach().cpu().numpy(), sdf_values=sdf_values.detach().cpu().numpy(), sdf_gradients=sdf_gradients.detach().cpu().numpy(), sdf_hessians=hess_sdf.detach().cpu().numpy())\n",
    "\n",
    "    return best_sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7e96773",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lambda_weights = [252,0,0,0,10.211111,0,100,0]\n",
    "lambda_weights = [100,0,0,0,1000,0,100,0]\n",
    "\n",
    "\n",
    "lambda_cvt = lambda_weights[0]\n",
    "lambda_sdf = lambda_weights[1]\n",
    "lambda_min_distance = lambda_weights[2]\n",
    "lambda_laplace = lambda_weights[3]\n",
    "lamda_chamfer = lambda_weights[4]\n",
    "lambda_eikonal = lambda_weights[5]\n",
    "lambda_domain_restriction = lambda_weights[6]\n",
    "lambda_true_points = lambda_weights[7]\n",
    "\n",
    "max_iter = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6fb2cefd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "points torch.Size([40148, 3])\n",
      "CVT loss:  tensor(0.0272, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 0.000237521919189021 : Allocated: 2363.958784 MB, Reserved: 4798.283776 MB\n",
      "Epoch 0: loss = 2.962113618850708\n",
      "before loss.backward(): Allocated: 2363.959296 MB, Reserved: 4798.283776 MB\n",
      "After loss.backward(): Allocated: 2341.059072 MB, Reserved: 4798.283776 MB\n",
      "-----------------\n",
      "points torch.Size([38986, 3])\n",
      "CVT loss:  tensor(0.0276, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 0.0001589616440469399 : Allocated: 2364.122112 MB, Reserved: 4798.283776 MB\n",
      "Epoch 1: loss = 2.920193910598755\n",
      "before loss.backward(): Allocated: 2364.122112 MB, Reserved: 4798.283776 MB\n",
      "After loss.backward(): Allocated: 2341.294592 MB, Reserved: 4798.283776 MB\n",
      "-----------------\n",
      "points torch.Size([38688, 3])\n",
      "CVT loss:  tensor(0.0261, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 0.00011403585085645318 : Allocated: 2364.082688 MB, Reserved: 4798.283776 MB\n",
      "Epoch 2: loss = 2.72753643989563\n",
      "before loss.backward(): Allocated: 2364.082688 MB, Reserved: 4798.283776 MB\n",
      "After loss.backward(): Allocated: 2341.278208 MB, Reserved: 4798.283776 MB\n",
      "-----------------\n",
      "points torch.Size([38766, 3])\n",
      "CVT loss:  tensor(0.0305, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 8.872054604580626e-05 : Allocated: 2364.086784 MB, Reserved: 4798.283776 MB\n",
      "Epoch 3: loss = 3.1412360668182373\n",
      "before loss.backward(): Allocated: 2364.086784 MB, Reserved: 4798.283776 MB\n",
      "After loss.backward(): Allocated: 2341.281792 MB, Reserved: 4798.283776 MB\n",
      "-----------------\n",
      "points torch.Size([38906, 3])\n",
      "CVT loss:  tensor(0.0296, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 7.515964534832165e-05 : Allocated: 2364.096 MB, Reserved: 4798.283776 MB\n",
      "Epoch 4: loss = 3.0381064414978027\n",
      "before loss.backward(): Allocated: 2364.096 MB, Reserved: 4798.283776 MB\n",
      "After loss.backward(): Allocated: 2341.287936 MB, Reserved: 4798.283776 MB\n",
      "-----------------\n",
      "points torch.Size([39244, 3])\n",
      "CVT loss:  tensor(0.0388, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 6.815897359047085e-05 : Allocated: 2364.132352 MB, Reserved: 4798.283776 MB\n",
      "Epoch 5: loss = 3.947082757949829\n",
      "before loss.backward(): Allocated: 2364.132352 MB, Reserved: 4798.283776 MB\n",
      "After loss.backward(): Allocated: 2341.304832 MB, Reserved: 4798.283776 MB\n",
      "-----------------\n",
      "points torch.Size([39335, 3])\n",
      "CVT loss:  tensor(0.0297, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 6.480757292592898e-05 : Allocated: 2364.139008 MB, Reserved: 4798.283776 MB\n",
      "Epoch 6: loss = 3.031325578689575\n",
      "before loss.backward(): Allocated: 2364.139008 MB, Reserved: 4798.283776 MB\n",
      "After loss.backward(): Allocated: 2341.308928 MB, Reserved: 4798.283776 MB\n",
      "-----------------\n",
      "points torch.Size([39387, 3])\n",
      "CVT loss:  tensor(0.0264, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 6.269668665481731e-05 : Allocated: 2364.14464 MB, Reserved: 4798.283776 MB\n",
      "Epoch 7: loss = 2.700333833694458\n",
      "before loss.backward(): Allocated: 2364.14464 MB, Reserved: 4798.283776 MB\n",
      "After loss.backward(): Allocated: 2341.312 MB, Reserved: 4800.380928 MB\n",
      "-----------------\n",
      "points torch.Size([39374, 3])\n",
      "CVT loss:  tensor(0.0277, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 6.104283966124058e-05 : Allocated: 2364.143616 MB, Reserved: 4800.380928 MB\n",
      "Epoch 8: loss = 2.8282976150512695\n",
      "before loss.backward(): Allocated: 2364.143616 MB, Reserved: 4800.380928 MB\n",
      "After loss.backward(): Allocated: 2341.310976 MB, Reserved: 4800.380928 MB\n",
      "-----------------\n",
      "points torch.Size([39400, 3])\n",
      "CVT loss:  tensor(0.0339, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 5.9334237448638305e-05 : Allocated: 2364.14464 MB, Reserved: 4800.380928 MB\n",
      "Epoch 9: loss = 3.446861743927002\n",
      "before loss.backward(): Allocated: 2364.14464 MB, Reserved: 4800.380928 MB\n",
      "After loss.backward(): Allocated: 2341.312 MB, Reserved: 4800.380928 MB\n",
      "-----------------\n",
      "points torch.Size([39528, 3])\n",
      "CVT loss:  tensor(0.0407, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 5.739347398048267e-05 : Allocated: 2364.157952 MB, Reserved: 4800.380928 MB\n",
      "Epoch 10: loss = 4.131797790527344\n",
      "before loss.backward(): Allocated: 2364.157952 MB, Reserved: 4800.380928 MB\n",
      "After loss.backward(): Allocated: 2341.318144 MB, Reserved: 4800.380928 MB\n",
      "-----------------\n",
      "points torch.Size([39570, 3])\n",
      "CVT loss:  tensor(0.0374, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 5.5401105782948434e-05 : Allocated: 2364.163072 MB, Reserved: 4800.380928 MB\n",
      "Epoch 11: loss = 3.798250198364258\n",
      "before loss.backward(): Allocated: 2364.163072 MB, Reserved: 4800.380928 MB\n",
      "After loss.backward(): Allocated: 2341.320704 MB, Reserved: 4800.380928 MB\n",
      "-----------------\n",
      "points torch.Size([39648, 3])\n",
      "CVT loss:  tensor(0.0382, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 5.350336869014427e-05 : Allocated: 2364.169216 MB, Reserved: 4800.380928 MB\n",
      "Epoch 12: loss = 3.873392105102539\n",
      "before loss.backward(): Allocated: 2364.169216 MB, Reserved: 4800.380928 MB\n",
      "After loss.backward(): Allocated: 2341.324288 MB, Reserved: 4800.380928 MB\n",
      "-----------------\n",
      "points torch.Size([39742, 3])\n",
      "CVT loss:  tensor(0.0497, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 5.162852903595194e-05 : Allocated: 2364.18048 MB, Reserved: 4800.380928 MB\n",
      "Epoch 13: loss = 5.019022464752197\n",
      "before loss.backward(): Allocated: 2364.18048 MB, Reserved: 4800.380928 MB\n",
      "After loss.backward(): Allocated: 2341.328896 MB, Reserved: 4800.380928 MB\n",
      "-----------------\n",
      "points torch.Size([39653, 3])\n",
      "CVT loss:  tensor(0.0442, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 5.005513230571523e-05 : Allocated: 2364.169728 MB, Reserved: 4800.380928 MB\n",
      "Epoch 14: loss = 4.46972131729126\n",
      "before loss.backward(): Allocated: 2364.169728 MB, Reserved: 4800.380928 MB\n",
      "After loss.backward(): Allocated: 2341.3248 MB, Reserved: 4800.380928 MB\n",
      "-----------------\n",
      "points torch.Size([39647, 3])\n",
      "CVT loss:  tensor(0.0398, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 4.8732275899965316e-05 : Allocated: 2364.169728 MB, Reserved: 4800.380928 MB\n",
      "Epoch 15: loss = 4.0262770652771\n",
      "before loss.backward(): Allocated: 2364.169728 MB, Reserved: 4800.380928 MB\n",
      "After loss.backward(): Allocated: 2341.3248 MB, Reserved: 4800.380928 MB\n",
      "-----------------\n",
      "points torch.Size([39747, 3])\n",
      "CVT loss:  tensor(0.0422, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 4.7502493544016033e-05 : Allocated: 2364.180992 MB, Reserved: 4800.380928 MB\n",
      "Epoch 16: loss = 4.26441764831543\n",
      "before loss.backward(): Allocated: 2364.180992 MB, Reserved: 4800.380928 MB\n",
      "After loss.backward(): Allocated: 2341.328896 MB, Reserved: 4800.380928 MB\n",
      "-----------------\n",
      "points torch.Size([39726, 3])\n",
      "CVT loss:  tensor(0.0391, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 4.6463366743410006e-05 : Allocated: 2364.179968 MB, Reserved: 4800.380928 MB\n",
      "Epoch 17: loss = 3.954157590866089\n",
      "before loss.backward(): Allocated: 2364.179968 MB, Reserved: 4800.380928 MB\n",
      "After loss.backward(): Allocated: 2341.328384 MB, Reserved: 4800.380928 MB\n",
      "-----------------\n",
      "points torch.Size([39804, 3])\n",
      "CVT loss:  tensor(0.0315, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 4.539268775261007e-05 : Allocated: 2364.1856 MB, Reserved: 4800.380928 MB\n",
      "Epoch 18: loss = 3.192317485809326\n",
      "before loss.backward(): Allocated: 2364.1856 MB, Reserved: 4800.380928 MB\n",
      "After loss.backward(): Allocated: 2341.331456 MB, Reserved: 4800.380928 MB\n",
      "-----------------\n",
      "points torch.Size([39902, 3])\n",
      "CVT loss:  tensor(0.0281, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 4.439413532963954e-05 : Allocated: 2364.19584 MB, Reserved: 4800.380928 MB\n",
      "Epoch 19: loss = 2.8551254272460938\n",
      "before loss.backward(): Allocated: 2364.19584 MB, Reserved: 4800.380928 MB\n",
      "After loss.backward(): Allocated: 2341.336576 MB, Reserved: 4800.380928 MB\n",
      "-----------------\n",
      "points torch.Size([39855, 3])\n",
      "CVT loss:  tensor(0.0312, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 4.349931623437442e-05 : Allocated: 2364.191232 MB, Reserved: 4800.380928 MB\n",
      "Epoch 20: loss = 3.167057991027832\n",
      "before loss.backward(): Allocated: 2364.191232 MB, Reserved: 4800.380928 MB\n",
      "After loss.backward(): Allocated: 2341.334528 MB, Reserved: 4800.380928 MB\n",
      "-----------------\n",
      "points torch.Size([39842, 3])\n",
      "CVT loss:  tensor(0.0408, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 4.265104143996723e-05 : Allocated: 2364.190208 MB, Reserved: 4800.380928 MB\n",
      "Epoch 21: loss = 4.124367713928223\n",
      "before loss.backward(): Allocated: 2364.190208 MB, Reserved: 4800.380928 MB\n",
      "After loss.backward(): Allocated: 2341.333504 MB, Reserved: 4800.380928 MB\n",
      "-----------------\n",
      "sites length BEFORE UPSAMPLING:  12288\n",
      "Sites to upsample  torch.Size([6924])\n",
      "sites length AFTER:  39984\n",
      "points torch.Size([84722, 3])\n",
      "CVT loss:  tensor(0.0103, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 4.1528939618729055e-05 : Allocated: 2379.838976 MB, Reserved: 4802.47808 MB\n",
      "Epoch 22: loss = 1.0749115943908691\n",
      "before loss.backward(): Allocated: 2379.838976 MB, Reserved: 4802.47808 MB\n",
      "After loss.backward(): Allocated: 2344.700416 MB, Reserved: 4806.672384 MB\n",
      "-----------------\n",
      "points torch.Size([92593, 3])\n",
      "CVT loss:  tensor(0.0147, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 3.1025650969240814e-05 : Allocated: 2387.732992 MB, Reserved: 4806.672384 MB\n",
      "Epoch 23: loss = 1.500763177871704\n",
      "before loss.backward(): Allocated: 2387.732992 MB, Reserved: 4806.672384 MB\n",
      "After loss.backward(): Allocated: 2346.708992 MB, Reserved: 4806.672384 MB\n",
      "-----------------\n",
      "points torch.Size([96069, 3])\n",
      "CVT loss:  tensor(0.0166, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 2.859139203792438e-05 : Allocated: 2388.120576 MB, Reserved: 4806.672384 MB\n",
      "Epoch 24: loss = 1.6841249465942383\n",
      "before loss.backward(): Allocated: 2388.120576 MB, Reserved: 4806.672384 MB\n",
      "After loss.backward(): Allocated: 2346.753536 MB, Reserved: 4806.672384 MB\n",
      "-----------------\n",
      "points torch.Size([96014, 3])\n",
      "CVT loss:  tensor(0.0159, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 2.743222466961015e-05 : Allocated: 2388.105728 MB, Reserved: 4806.672384 MB\n",
      "Epoch 25: loss = 1.6189875602722168\n",
      "before loss.backward(): Allocated: 2388.105728 MB, Reserved: 4806.672384 MB\n",
      "After loss.backward(): Allocated: 2346.774016 MB, Reserved: 4806.672384 MB\n",
      "-----------------\n",
      "points torch.Size([95579, 3])\n",
      "CVT loss:  tensor(0.0130, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 2.640404272824526e-05 : Allocated: 2388.056576 MB, Reserved: 4806.672384 MB\n",
      "Epoch 26: loss = 1.3257708549499512\n",
      "before loss.backward(): Allocated: 2388.056576 MB, Reserved: 4806.672384 MB\n",
      "After loss.backward(): Allocated: 2346.760192 MB, Reserved: 4806.672384 MB\n",
      "-----------------\n",
      "points torch.Size([95478, 3])\n",
      "CVT loss:  tensor(0.0190, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 2.5518831535009667e-05 : Allocated: 2388.03968 MB, Reserved: 4806.672384 MB\n",
      "Epoch 27: loss = 1.9234312772750854\n",
      "before loss.backward(): Allocated: 2388.03968 MB, Reserved: 4806.672384 MB\n",
      "After loss.backward(): Allocated: 2346.763776 MB, Reserved: 4806.672384 MB\n",
      "-----------------\n",
      "points torch.Size([95596, 3])\n",
      "CVT loss:  tensor(0.0161, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 2.4725963157834485e-05 : Allocated: 2388.052992 MB, Reserved: 4806.672384 MB\n",
      "Epoch 28: loss = 1.6352699995040894\n",
      "before loss.backward(): Allocated: 2388.052992 MB, Reserved: 4806.672384 MB\n",
      "After loss.backward(): Allocated: 2346.763264 MB, Reserved: 4806.672384 MB\n",
      "-----------------\n",
      "points torch.Size([95620, 3])\n",
      "CVT loss:  tensor(0.0159, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 2.4011202185647562e-05 : Allocated: 2388.050944 MB, Reserved: 4806.672384 MB\n",
      "Epoch 29: loss = 1.6150346994400024\n",
      "before loss.backward(): Allocated: 2388.050944 MB, Reserved: 4806.672384 MB\n",
      "After loss.backward(): Allocated: 2346.767872 MB, Reserved: 4806.672384 MB\n",
      "-----------------\n",
      "points torch.Size([95492, 3])\n",
      "CVT loss:  tensor(0.0154, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 2.3352549760602415e-05 : Allocated: 2388.034048 MB, Reserved: 4806.672384 MB\n",
      "Epoch 30: loss = 1.5614110231399536\n",
      "before loss.backward(): Allocated: 2388.034048 MB, Reserved: 4806.672384 MB\n",
      "After loss.backward(): Allocated: 2346.767872 MB, Reserved: 4806.672384 MB\n",
      "-----------------\n",
      "points torch.Size([95553, 3])\n",
      "CVT loss:  tensor(0.0185, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 2.2786629415350035e-05 : Allocated: 2387.36128 MB, Reserved: 4806.672384 MB\n",
      "Epoch 31: loss = 1.8757778406143188\n",
      "before loss.backward(): Allocated: 2387.36128 MB, Reserved: 4806.672384 MB\n",
      "After loss.backward(): Allocated: 2346.767872 MB, Reserved: 4806.672384 MB\n",
      "-----------------\n",
      "points torch.Size([95632, 3])\n",
      "CVT loss:  tensor(0.0203, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 2.216581196989864e-05 : Allocated: 2388.041728 MB, Reserved: 4806.672384 MB\n",
      "Epoch 32: loss = 2.0490944385528564\n",
      "before loss.backward(): Allocated: 2388.041728 MB, Reserved: 4806.672384 MB\n",
      "After loss.backward(): Allocated: 2346.770432 MB, Reserved: 4806.672384 MB\n",
      "-----------------\n",
      "points torch.Size([95456, 3])\n",
      "CVT loss:  tensor(0.0205, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 2.1713847672799602e-05 : Allocated: 2388.022272 MB, Reserved: 4806.672384 MB\n",
      "Epoch 33: loss = 2.0707719326019287\n",
      "before loss.backward(): Allocated: 2388.022272 MB, Reserved: 4806.672384 MB\n",
      "After loss.backward(): Allocated: 2346.765824 MB, Reserved: 4806.672384 MB\n",
      "-----------------\n",
      "points torch.Size([95323, 3])\n",
      "CVT loss:  tensor(0.0197, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 2.1302726963767782e-05 : Allocated: 2388.007424 MB, Reserved: 4806.672384 MB\n",
      "Epoch 34: loss = 1.988385796546936\n",
      "before loss.backward(): Allocated: 2388.007424 MB, Reserved: 4806.672384 MB\n",
      "After loss.backward(): Allocated: 2346.773504 MB, Reserved: 4806.672384 MB\n",
      "-----------------\n",
      "points torch.Size([95289, 3])\n",
      "CVT loss:  tensor(0.0219, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 2.0914470951538533e-05 : Allocated: 2388.000768 MB, Reserved: 4806.672384 MB\n",
      "Epoch 35: loss = 2.2072808742523193\n",
      "before loss.backward(): Allocated: 2388.000768 MB, Reserved: 4806.672384 MB\n",
      "After loss.backward(): Allocated: 2346.763264 MB, Reserved: 4806.672384 MB\n",
      "-----------------\n",
      "points torch.Size([95314, 3])\n",
      "CVT loss:  tensor(0.0227, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 2.0493369447649457e-05 : Allocated: 2388.006912 MB, Reserved: 4806.672384 MB\n",
      "Epoch 36: loss = 2.2854974269866943\n",
      "before loss.backward(): Allocated: 2388.006912 MB, Reserved: 4806.672384 MB\n",
      "After loss.backward(): Allocated: 2346.774016 MB, Reserved: 4806.672384 MB\n",
      "-----------------\n",
      "points torch.Size([95316, 3])\n",
      "CVT loss:  tensor(0.0163, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 2.017166480072774e-05 : Allocated: 2388.001792 MB, Reserved: 4806.672384 MB\n",
      "Epoch 37: loss = 1.6476374864578247\n",
      "before loss.backward(): Allocated: 2388.001792 MB, Reserved: 4806.672384 MB\n",
      "After loss.backward(): Allocated: 2346.763264 MB, Reserved: 4806.672384 MB\n",
      "-----------------\n",
      "points torch.Size([95287, 3])\n",
      "CVT loss:  tensor(0.0186, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.9820878151222132e-05 : Allocated: 2388.000768 MB, Reserved: 4806.672384 MB\n",
      "Epoch 38: loss = 1.8780874013900757\n",
      "before loss.backward(): Allocated: 2388.000768 MB, Reserved: 4806.672384 MB\n",
      "After loss.backward(): Allocated: 2346.774528 MB, Reserved: 4806.672384 MB\n",
      "-----------------\n",
      "points torch.Size([95191, 3])\n",
      "CVT loss:  tensor(0.0183, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.953537321242038e-05 : Allocated: 2387.990016 MB, Reserved: 4806.672384 MB\n",
      "Epoch 39: loss = 1.8449431657791138\n",
      "before loss.backward(): Allocated: 2387.990016 MB, Reserved: 4806.672384 MB\n",
      "After loss.backward(): Allocated: 2346.761728 MB, Reserved: 4806.672384 MB\n",
      "-----------------\n",
      "points torch.Size([95043, 3])\n",
      "CVT loss:  tensor(0.0187, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.9251154299126938e-05 : Allocated: 2387.97312 MB, Reserved: 4806.672384 MB\n",
      "Epoch 40: loss = 1.8931525945663452\n",
      "before loss.backward(): Allocated: 2387.97312 MB, Reserved: 4806.672384 MB\n",
      "After loss.backward(): Allocated: 2346.7776 MB, Reserved: 4806.672384 MB\n",
      "-----------------\n",
      "points torch.Size([94821, 3])\n",
      "CVT loss:  tensor(0.0220, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.8990918761119246e-05 : Allocated: 2387.950592 MB, Reserved: 4806.672384 MB\n",
      "Epoch 41: loss = 2.217061996459961\n",
      "before loss.backward(): Allocated: 2387.950592 MB, Reserved: 4806.672384 MB\n",
      "After loss.backward(): Allocated: 2346.754048 MB, Reserved: 4806.672384 MB\n",
      "-----------------\n",
      "sites length BEFORE UPSAMPLING:  39984\n",
      "Sites to upsample  torch.Size([17627])\n",
      "sites length AFTER:  110492\n",
      "points torch.Size([192492, 3])\n",
      "CVT loss:  tensor(0.0067, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 2.0788949768757448e-05 : Allocated: 2436.235264 MB, Reserved: 4806.672384 MB\n",
      "Epoch 42: loss = 0.6918166279792786\n",
      "before loss.backward(): Allocated: 2436.235264 MB, Reserved: 4806.672384 MB\n",
      "After loss.backward(): Allocated: 2354.73664 MB, Reserved: 4806.672384 MB\n",
      "-----------------\n",
      "points torch.Size([205839, 3])\n",
      "CVT loss:  tensor(0.0058, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.9059647456742823e-05 : Allocated: 2447.42144 MB, Reserved: 4806.672384 MB\n",
      "Epoch 43: loss = 0.5949885249137878\n",
      "before loss.backward(): Allocated: 2447.42144 MB, Reserved: 4806.672384 MB\n",
      "After loss.backward(): Allocated: 2360.52736 MB, Reserved: 4806.672384 MB\n",
      "-----------------\n",
      "points torch.Size([201199, 3])\n",
      "CVT loss:  tensor(0.0093, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.851931301644072e-05 : Allocated: 2443.495424 MB, Reserved: 4806.672384 MB\n",
      "Epoch 44: loss = 0.9535057544708252\n",
      "before loss.backward(): Allocated: 2443.495424 MB, Reserved: 4806.672384 MB\n",
      "After loss.backward(): Allocated: 2359.493632 MB, Reserved: 4806.672384 MB\n",
      "-----------------\n",
      "points torch.Size([198435, 3])\n",
      "CVT loss:  tensor(0.0046, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.772057294147089e-05 : Allocated: 2442.157056 MB, Reserved: 4806.672384 MB\n",
      "Epoch 45: loss = 0.4749002158641815\n",
      "before loss.backward(): Allocated: 2442.157056 MB, Reserved: 4806.672384 MB\n",
      "After loss.backward(): Allocated: 2359.341056 MB, Reserved: 4806.672384 MB\n",
      "-----------------\n",
      "points torch.Size([196374, 3])\n",
      "CVT loss:  tensor(0.0057, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.7133097571786493e-05 : Allocated: 2442.903552 MB, Reserved: 4806.672384 MB\n",
      "Epoch 46: loss = 0.5865204930305481\n",
      "before loss.backward(): Allocated: 2442.903552 MB, Reserved: 4806.672384 MB\n",
      "After loss.backward(): Allocated: 2360.267264 MB, Reserved: 4806.672384 MB\n",
      "-----------------\n",
      "points torch.Size([195572, 3])\n",
      "CVT loss:  tensor(0.0082, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.6690210031811148e-05 : Allocated: 2441.872384 MB, Reserved: 4806.672384 MB\n",
      "Epoch 47: loss = 0.8352972865104675\n",
      "before loss.backward(): Allocated: 2441.872384 MB, Reserved: 4806.672384 MB\n",
      "After loss.backward(): Allocated: 2359.134208 MB, Reserved: 4806.672384 MB\n",
      "-----------------\n",
      "points torch.Size([195325, 3])\n",
      "CVT loss:  tensor(0.0087, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.623763091629371e-05 : Allocated: 2441.020928 MB, Reserved: 4806.672384 MB\n",
      "Epoch 48: loss = 0.8863734006881714\n",
      "before loss.backward(): Allocated: 2441.020928 MB, Reserved: 4806.672384 MB\n",
      "After loss.backward(): Allocated: 2359.372288 MB, Reserved: 4806.672384 MB\n",
      "-----------------\n",
      "points torch.Size([194840, 3])\n",
      "CVT loss:  tensor(0.0089, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.5827075912966393e-05 : Allocated: 2440.738816 MB, Reserved: 4806.672384 MB\n",
      "Epoch 49: loss = 0.9067103266716003\n",
      "before loss.backward(): Allocated: 2440.738816 MB, Reserved: 4806.672384 MB\n",
      "After loss.backward(): Allocated: 2358.769152 MB, Reserved: 4806.672384 MB\n",
      "-----------------\n",
      "points torch.Size([194581, 3])\n",
      "CVT loss:  tensor(0.0079, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.5470626749447547e-05 : Allocated: 2440.790528 MB, Reserved: 4806.672384 MB\n",
      "Epoch 50: loss = 0.8024179935455322\n",
      "before loss.backward(): Allocated: 2440.790528 MB, Reserved: 4806.672384 MB\n",
      "After loss.backward(): Allocated: 2358.969344 MB, Reserved: 4806.672384 MB\n",
      "-----------------\n",
      "points torch.Size([194876, 3])\n",
      "CVT loss:  tensor(0.0099, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.510244510427583e-05 : Allocated: 2441.92 MB, Reserved: 4806.672384 MB\n",
      "Epoch 51: loss = 1.0036343336105347\n",
      "before loss.backward(): Allocated: 2441.92 MB, Reserved: 4806.672384 MB\n",
      "After loss.backward(): Allocated: 2359.337984 MB, Reserved: 4806.672384 MB\n",
      "-----------------\n",
      "points torch.Size([194844, 3])\n",
      "CVT loss:  tensor(0.0087, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.4842911696177907e-05 : Allocated: 2441.515008 MB, Reserved: 4806.672384 MB\n",
      "Epoch 52: loss = 0.8882956504821777\n",
      "before loss.backward(): Allocated: 2441.515008 MB, Reserved: 4806.672384 MB\n",
      "After loss.backward(): Allocated: 2359.246848 MB, Reserved: 4806.672384 MB\n",
      "-----------------\n",
      "points torch.Size([194482, 3])\n",
      "CVT loss:  tensor(0.0102, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.4574987289961427e-05 : Allocated: 2440.857088 MB, Reserved: 4806.672384 MB\n",
      "Epoch 53: loss = 1.0378952026367188\n",
      "before loss.backward(): Allocated: 2440.857088 MB, Reserved: 4806.672384 MB\n",
      "After loss.backward(): Allocated: 2359.506432 MB, Reserved: 4806.672384 MB\n",
      "-----------------\n",
      "points torch.Size([194236, 3])\n",
      "CVT loss:  tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.429378789907787e-05 : Allocated: 2440.22016 MB, Reserved: 4806.672384 MB\n",
      "Epoch 54: loss = 1.0145329236984253\n",
      "before loss.backward(): Allocated: 2440.22016 MB, Reserved: 4806.672384 MB\n",
      "After loss.backward(): Allocated: 2358.578176 MB, Reserved: 4806.672384 MB\n",
      "-----------------\n",
      "points torch.Size([193682, 3])\n",
      "CVT loss:  tensor(0.0107, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.4023589756106958e-05 : Allocated: 2440.570368 MB, Reserved: 4806.672384 MB\n",
      "Epoch 55: loss = 1.0842561721801758\n",
      "before loss.backward(): Allocated: 2440.570368 MB, Reserved: 4806.672384 MB\n",
      "After loss.backward(): Allocated: 2359.112704 MB, Reserved: 4806.672384 MB\n",
      "-----------------\n",
      "points torch.Size([193631, 3])\n",
      "CVT loss:  tensor(0.0100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.3729137208429165e-05 : Allocated: 2442.169856 MB, Reserved: 4806.672384 MB\n",
      "Epoch 56: loss = 1.0142128467559814\n",
      "before loss.backward(): Allocated: 2442.169856 MB, Reserved: 4806.672384 MB\n",
      "After loss.backward(): Allocated: 2359.8848 MB, Reserved: 4806.672384 MB\n",
      "-----------------\n",
      "points torch.Size([193480, 3])\n",
      "CVT loss:  tensor(0.0101, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.3520289940061048e-05 : Allocated: 2441.060864 MB, Reserved: 4806.672384 MB\n",
      "Epoch 57: loss = 1.0270322561264038\n",
      "before loss.backward(): Allocated: 2441.060864 MB, Reserved: 4806.672384 MB\n",
      "After loss.backward(): Allocated: 2359.42912 MB, Reserved: 4806.672384 MB\n",
      "-----------------\n",
      "points torch.Size([193218, 3])\n",
      "CVT loss:  tensor(0.0125, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.3354315342439804e-05 : Allocated: 2441.218048 MB, Reserved: 4806.672384 MB\n",
      "Epoch 58: loss = 1.2653802633285522\n",
      "before loss.backward(): Allocated: 2441.218048 MB, Reserved: 4806.672384 MB\n",
      "After loss.backward(): Allocated: 2359.947264 MB, Reserved: 4806.672384 MB\n",
      "-----------------\n",
      "points torch.Size([192713, 3])\n",
      "CVT loss:  tensor(0.0101, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.3193694030633196e-05 : Allocated: 2441.074688 MB, Reserved: 4806.672384 MB\n",
      "Epoch 59: loss = 1.02582585811615\n",
      "before loss.backward(): Allocated: 2441.074688 MB, Reserved: 4806.672384 MB\n",
      "After loss.backward(): Allocated: 2359.205888 MB, Reserved: 4806.672384 MB\n",
      "-----------------\n",
      "points torch.Size([192694, 3])\n",
      "CVT loss:  tensor(0.0105, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.3031491107540205e-05 : Allocated: 2442.033664 MB, Reserved: 4806.672384 MB\n",
      "Epoch 60: loss = 1.0667475461959839\n",
      "before loss.backward(): Allocated: 2442.033664 MB, Reserved: 4806.672384 MB\n",
      "After loss.backward(): Allocated: 2359.954944 MB, Reserved: 4806.672384 MB\n",
      "-----------------\n",
      "points torch.Size([192304, 3])\n",
      "CVT loss:  tensor(0.0084, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.282514858758077e-05 : Allocated: 2440.67328 MB, Reserved: 4806.672384 MB\n",
      "Epoch 61: loss = 0.8509629964828491\n",
      "before loss.backward(): Allocated: 2440.67328 MB, Reserved: 4806.672384 MB\n",
      "After loss.backward(): Allocated: 2359.584768 MB, Reserved: 4806.672384 MB\n",
      "-----------------\n",
      "sites length BEFORE UPSAMPLING:  110492\n",
      "Sites to upsample  torch.Size([36291])\n",
      "sites length AFTER:  255656\n",
      "points torch.Size([418927, 3])\n",
      "CVT loss:  tensor(0.0053, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.4325676602311432e-05 : Allocated: 2546.4448 MB, Reserved: 8568.963072 MB\n",
      "Epoch 62: loss = 0.5478207468986511\n",
      "before loss.backward(): Allocated: 2546.4448 MB, Reserved: 8568.963072 MB\n",
      "After loss.backward(): Allocated: 2371.53024 MB, Reserved: 8568.963072 MB\n",
      "-----------------\n",
      "points torch.Size([441959, 3])\n",
      "CVT loss:  tensor(0.0042, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.4865039702272043e-05 : Allocated: 2563.760128 MB, Reserved: 9053.405184 MB\n",
      "Epoch 63: loss = 0.4330674409866333\n",
      "before loss.backward(): Allocated: 2563.760128 MB, Reserved: 9053.405184 MB\n",
      "After loss.backward(): Allocated: 2379.629056 MB, Reserved: 9053.405184 MB\n",
      "-----------------\n",
      "points torch.Size([429546, 3])\n",
      "CVT loss:  tensor(0.0047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.4346090210892726e-05 : Allocated: 2554.290176 MB, Reserved: 9053.405184 MB\n",
      "Epoch 64: loss = 0.4892835319042206\n",
      "before loss.backward(): Allocated: 2554.290176 MB, Reserved: 9053.405184 MB\n",
      "After loss.backward(): Allocated: 2376.670208 MB, Reserved: 9053.405184 MB\n",
      "-----------------\n",
      "points torch.Size([424087, 3])\n",
      "CVT loss:  tensor(0.0048, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.3831939213559963e-05 : Allocated: 2548.867584 MB, Reserved: 9053.405184 MB\n",
      "Epoch 65: loss = 0.491763174533844\n",
      "before loss.backward(): Allocated: 2548.867584 MB, Reserved: 9053.405184 MB\n",
      "After loss.backward(): Allocated: 2375.333376 MB, Reserved: 9053.405184 MB\n",
      "-----------------\n",
      "points torch.Size([422966, 3])\n",
      "CVT loss:  tensor(0.0052, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.3619654055219144e-05 : Allocated: 2548.534784 MB, Reserved: 9053.405184 MB\n",
      "Epoch 66: loss = 0.5302002429962158\n",
      "before loss.backward(): Allocated: 2548.534784 MB, Reserved: 9053.405184 MB\n",
      "After loss.backward(): Allocated: 2375.27808 MB, Reserved: 9053.405184 MB\n",
      "-----------------\n",
      "points torch.Size([421821, 3])\n",
      "CVT loss:  tensor(0.0055, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.3291677532834001e-05 : Allocated: 2548.197888 MB, Reserved: 9053.405184 MB\n",
      "Epoch 67: loss = 0.5657842755317688\n",
      "before loss.backward(): Allocated: 2548.197888 MB, Reserved: 9053.405184 MB\n",
      "After loss.backward(): Allocated: 2375.222272 MB, Reserved: 9053.405184 MB\n",
      "-----------------\n",
      "points torch.Size([421386, 3])\n",
      "CVT loss:  tensor(0.0045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.291531134484103e-05 : Allocated: 2548.027392 MB, Reserved: 9053.405184 MB\n",
      "Epoch 68: loss = 0.4630279242992401\n",
      "before loss.backward(): Allocated: 2548.027392 MB, Reserved: 9053.405184 MB\n",
      "After loss.backward(): Allocated: 2375.197184 MB, Reserved: 9053.405184 MB\n",
      "-----------------\n",
      "points torch.Size([419750, 3])\n",
      "CVT loss:  tensor(0.0053, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.2575154869409744e-05 : Allocated: 2547.595776 MB, Reserved: 9053.405184 MB\n",
      "Epoch 69: loss = 0.5410170555114746\n",
      "before loss.backward(): Allocated: 2547.595776 MB, Reserved: 9053.405184 MB\n",
      "After loss.backward(): Allocated: 2375.120896 MB, Reserved: 9053.405184 MB\n",
      "-----------------\n",
      "points torch.Size([418603, 3])\n",
      "CVT loss:  tensor(0.0059, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.2273276297491975e-05 : Allocated: 2547.494912 MB, Reserved: 9053.405184 MB\n",
      "Epoch 70: loss = 0.6052274703979492\n",
      "before loss.backward(): Allocated: 2547.494912 MB, Reserved: 9053.405184 MB\n",
      "After loss.backward(): Allocated: 2375.593472 MB, Reserved: 9053.405184 MB\n",
      "-----------------\n",
      "points torch.Size([417386, 3])\n",
      "CVT loss:  tensor(0.0061, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.1984879165538587e-05 : Allocated: 2543.072768 MB, Reserved: 9053.405184 MB\n",
      "Epoch 71: loss = 0.6205831170082092\n",
      "before loss.backward(): Allocated: 2543.072768 MB, Reserved: 9053.405184 MB\n",
      "After loss.backward(): Allocated: 2375.49312 MB, Reserved: 9053.405184 MB\n",
      "-----------------\n",
      "points torch.Size([415691, 3])\n",
      "CVT loss:  tensor(0.0048, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.176980458694743e-05 : Allocated: 2543.320576 MB, Reserved: 9053.405184 MB\n",
      "Epoch 72: loss = 0.4935201108455658\n",
      "before loss.backward(): Allocated: 2543.320576 MB, Reserved: 9053.405184 MB\n",
      "After loss.backward(): Allocated: 2376.508416 MB, Reserved: 9053.405184 MB\n",
      "-----------------\n",
      "points torch.Size([413404, 3])\n",
      "CVT loss:  tensor(0.0062, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.1553962394827977e-05 : Allocated: 2541.167104 MB, Reserved: 9053.405184 MB\n",
      "Epoch 73: loss = 0.6357256174087524\n",
      "before loss.backward(): Allocated: 2541.167104 MB, Reserved: 9053.405184 MB\n",
      "After loss.backward(): Allocated: 2374.900736 MB, Reserved: 9053.405184 MB\n",
      "-----------------\n",
      "points torch.Size([411214, 3])\n",
      "CVT loss:  tensor(0.0055, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.1281892511760816e-05 : Allocated: 2541.216768 MB, Reserved: 9053.405184 MB\n",
      "Epoch 74: loss = 0.563389778137207\n",
      "before loss.backward(): Allocated: 2541.216768 MB, Reserved: 9053.405184 MB\n",
      "After loss.backward(): Allocated: 2376.036352 MB, Reserved: 9053.405184 MB\n",
      "-----------------\n",
      "points torch.Size([409568, 3])\n",
      "CVT loss:  tensor(0.0062, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.1114130757050589e-05 : Allocated: 2539.70432 MB, Reserved: 9053.405184 MB\n",
      "Epoch 75: loss = 0.6334735155105591\n",
      "before loss.backward(): Allocated: 2539.70432 MB, Reserved: 9053.405184 MB\n",
      "After loss.backward(): Allocated: 2375.588352 MB, Reserved: 9053.405184 MB\n",
      "-----------------\n",
      "points torch.Size([407100, 3])\n",
      "CVT loss:  tensor(0.0050, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.0915341590589378e-05 : Allocated: 2538.759168 MB, Reserved: 9053.405184 MB\n",
      "Epoch 76: loss = 0.5095312595367432\n",
      "before loss.backward(): Allocated: 2538.759168 MB, Reserved: 9053.405184 MB\n",
      "After loss.backward(): Allocated: 2375.45984 MB, Reserved: 9053.405184 MB\n",
      "-----------------\n",
      "points torch.Size([404410, 3])\n",
      "CVT loss:  tensor(0.0054, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.0705281056289095e-05 : Allocated: 2537.409536 MB, Reserved: 9053.405184 MB\n",
      "Epoch 77: loss = 0.5521382689476013\n",
      "before loss.backward(): Allocated: 2537.409536 MB, Reserved: 9053.405184 MB\n",
      "After loss.backward(): Allocated: 2374.603264 MB, Reserved: 9053.405184 MB\n",
      "-----------------\n",
      "points torch.Size([401768, 3])\n",
      "CVT loss:  tensor(0.0049, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.0539092727412935e-05 : Allocated: 2537.056256 MB, Reserved: 9053.405184 MB\n",
      "Epoch 78: loss = 0.5040911436080933\n",
      "before loss.backward(): Allocated: 2537.056256 MB, Reserved: 9053.405184 MB\n",
      "After loss.backward(): Allocated: 2375.674368 MB, Reserved: 9053.405184 MB\n",
      "-----------------\n",
      "points torch.Size([398699, 3])\n",
      "CVT loss:  tensor(0.0063, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.0402133739262354e-05 : Allocated: 2536.07168 MB, Reserved: 9053.405184 MB\n",
      "Epoch 79: loss = 0.6442732810974121\n",
      "before loss.backward(): Allocated: 2536.07168 MB, Reserved: 9053.405184 MB\n",
      "After loss.backward(): Allocated: 2375.644672 MB, Reserved: 9053.405184 MB\n",
      "-----------------\n",
      "points torch.Size([395252, 3])\n",
      "CVT loss:  tensor(0.0054, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.0238407412543893e-05 : Allocated: 2533.343744 MB, Reserved: 9053.405184 MB\n",
      "Epoch 80: loss = 0.5494886040687561\n",
      "before loss.backward(): Allocated: 2533.343744 MB, Reserved: 9053.405184 MB\n",
      "After loss.backward(): Allocated: 2374.247424 MB, Reserved: 9053.405184 MB\n",
      "-----------------\n",
      "points torch.Size([391834, 3])\n",
      "CVT loss:  tensor(0.0055, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.013697237794986e-05 : Allocated: 2532.31616 MB, Reserved: 9053.405184 MB\n",
      "Epoch 81: loss = 0.557061493396759\n",
      "before loss.backward(): Allocated: 2532.31616 MB, Reserved: 9053.405184 MB\n",
      "After loss.backward(): Allocated: 2374.424064 MB, Reserved: 9053.405184 MB\n",
      "-----------------\n",
      "sites length BEFORE UPSAMPLING:  255656\n",
      "Sites to upsample  torch.Size([74627])\n",
      "sites length AFTER:  554164\n",
      "points torch.Size([921237, 3])\n",
      "CVT loss:  tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.1270270988461562e-05 : Allocated: 2781.933568 MB, Reserved: 17184.063488 MB\n",
      "Epoch 82: loss = 0.24418172240257263\n",
      "before loss.backward(): Allocated: 2781.933568 MB, Reserved: 17184.063488 MB\n",
      "After loss.backward(): Allocated: 2408.33792 MB, Reserved: 17184.063488 MB\n",
      "-----------------\n",
      "points torch.Size([987678, 3])\n",
      "CVT loss:  tensor(0.0022, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.321592390013393e-05 : Allocated: 2821.236224 MB, Reserved: 18234.73664 MB\n",
      "Epoch 83: loss = 0.2301173061132431\n",
      "before loss.backward(): Allocated: 2821.236224 MB, Reserved: 18234.73664 MB\n",
      "After loss.backward(): Allocated: 2422.306816 MB, Reserved: 18234.73664 MB\n",
      "-----------------\n",
      "points torch.Size([977717, 3])\n",
      "CVT loss:  tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.2895710824523121e-05 : Allocated: 2817.283584 MB, Reserved: 18234.73664 MB\n",
      "Epoch 84: loss = 0.25818583369255066\n",
      "before loss.backward(): Allocated: 2817.283584 MB, Reserved: 18234.73664 MB\n",
      "After loss.backward(): Allocated: 2422.81472 MB, Reserved: 18234.73664 MB\n",
      "-----------------\n",
      "points torch.Size([971695, 3])\n",
      "CVT loss:  tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.2553095984912943e-05 : Allocated: 2814.31296 MB, Reserved: 18234.73664 MB\n",
      "Epoch 85: loss = 0.24718649685382843\n",
      "before loss.backward(): Allocated: 2814.31296 MB, Reserved: 18234.73664 MB\n",
      "After loss.backward(): Allocated: 2423.371264 MB, Reserved: 18234.73664 MB\n",
      "-----------------\n",
      "points torch.Size([962081, 3])\n",
      "CVT loss:  tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.2330383469816297e-05 : Allocated: 2809.81248 MB, Reserved: 18234.73664 MB\n",
      "Epoch 86: loss = 0.27248603105545044\n",
      "before loss.backward(): Allocated: 2809.81248 MB, Reserved: 18234.73664 MB\n",
      "After loss.backward(): Allocated: 2422.246912 MB, Reserved: 18234.73664 MB\n",
      "-----------------\n",
      "points torch.Size([945874, 3])\n",
      "CVT loss:  tensor(0.0023, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.2035286090394948e-05 : Allocated: 2805.318144 MB, Reserved: 18234.73664 MB\n",
      "Epoch 87: loss = 0.2468281090259552\n",
      "before loss.backward(): Allocated: 2805.318144 MB, Reserved: 18234.73664 MB\n",
      "After loss.backward(): Allocated: 2422.288896 MB, Reserved: 18234.73664 MB\n",
      "-----------------\n",
      "points torch.Size([930102, 3])\n",
      "CVT loss:  tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.1720964721462224e-05 : Allocated: 2794.966016 MB, Reserved: 18234.73664 MB\n",
      "Epoch 88: loss = 0.24766330420970917\n",
      "before loss.backward(): Allocated: 2794.966016 MB, Reserved: 18234.73664 MB\n",
      "After loss.backward(): Allocated: 2420.766208 MB, Reserved: 18234.73664 MB\n",
      "-----------------\n",
      "points torch.Size([912738, 3])\n",
      "CVT loss:  tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.1458853805379476e-05 : Allocated: 2790.185472 MB, Reserved: 18234.73664 MB\n",
      "Epoch 89: loss = 0.26692619919776917\n",
      "before loss.backward(): Allocated: 2790.185472 MB, Reserved: 18234.73664 MB\n",
      "After loss.backward(): Allocated: 2418.972672 MB, Reserved: 18234.73664 MB\n",
      "-----------------\n",
      "points torch.Size([894649, 3])\n",
      "CVT loss:  tensor(0.0031, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.1117273970739916e-05 : Allocated: 2780.905984 MB, Reserved: 18234.73664 MB\n",
      "Epoch 90: loss = 0.31746819615364075\n",
      "before loss.backward(): Allocated: 2780.905984 MB, Reserved: 18234.73664 MB\n",
      "After loss.backward(): Allocated: 2419.34848 MB, Reserved: 18234.73664 MB\n",
      "-----------------\n",
      "points torch.Size([876323, 3])\n",
      "CVT loss:  tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.0890557859966066e-05 : Allocated: 2770.19648 MB, Reserved: 18234.73664 MB\n",
      "Epoch 91: loss = 0.2502412796020508\n",
      "before loss.backward(): Allocated: 2770.19648 MB, Reserved: 18234.73664 MB\n",
      "After loss.backward(): Allocated: 2417.47712 MB, Reserved: 18234.73664 MB\n",
      "-----------------\n",
      "points torch.Size([861760, 3])\n",
      "CVT loss:  tensor(0.0030, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.0673991710064001e-05 : Allocated: 2764.957184 MB, Reserved: 18234.73664 MB\n",
      "Epoch 92: loss = 0.30931779742240906\n",
      "before loss.backward(): Allocated: 2764.957184 MB, Reserved: 18234.73664 MB\n",
      "After loss.backward(): Allocated: 2416.890368 MB, Reserved: 18234.73664 MB\n",
      "-----------------\n",
      "points torch.Size([844068, 3])\n",
      "CVT loss:  tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.0470907000126317e-05 : Allocated: 2757.930496 MB, Reserved: 18234.73664 MB\n",
      "Epoch 93: loss = 0.2998386025428772\n",
      "before loss.backward(): Allocated: 2757.930496 MB, Reserved: 18234.73664 MB\n",
      "After loss.backward(): Allocated: 2416.426496 MB, Reserved: 18234.73664 MB\n",
      "-----------------\n",
      "points torch.Size([827550, 3])\n",
      "CVT loss:  tensor(0.0028, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.0299145287717693e-05 : Allocated: 2751.742976 MB, Reserved: 18234.73664 MB\n",
      "Epoch 94: loss = 0.2881758511066437\n",
      "before loss.backward(): Allocated: 2751.742976 MB, Reserved: 18234.73664 MB\n",
      "After loss.backward(): Allocated: 2416.443392 MB, Reserved: 18234.73664 MB\n",
      "-----------------\n",
      "points torch.Size([813040, 3])\n",
      "CVT loss:  tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 1.0148335604753811e-05 : Allocated: 2742.151168 MB, Reserved: 18234.73664 MB\n",
      "Epoch 95: loss = 0.2969155013561249\n",
      "before loss.backward(): Allocated: 2742.151168 MB, Reserved: 18234.73664 MB\n",
      "After loss.backward(): Allocated: 2414.020608 MB, Reserved: 18234.73664 MB\n",
      "-----------------\n",
      "points torch.Size([797241, 3])\n",
      "CVT loss:  tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 9.979810783988796e-06 : Allocated: 2736.649728 MB, Reserved: 18234.73664 MB\n",
      "Epoch 96: loss = 0.26352232694625854\n",
      "before loss.backward(): Allocated: 2736.649728 MB, Reserved: 18234.73664 MB\n",
      "After loss.backward(): Allocated: 2413.237248 MB, Reserved: 18234.73664 MB\n",
      "-----------------\n",
      "points torch.Size([783585, 3])\n",
      "CVT loss:  tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 9.841340215643868e-06 : Allocated: 2732.626432 MB, Reserved: 18234.73664 MB\n",
      "Epoch 97: loss = 0.28469038009643555\n",
      "before loss.backward(): Allocated: 2732.626432 MB, Reserved: 18234.73664 MB\n",
      "After loss.backward(): Allocated: 2415.589376 MB, Reserved: 18234.73664 MB\n",
      "-----------------\n",
      "points torch.Size([769601, 3])\n",
      "CVT loss:  tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 9.737535947351716e-06 : Allocated: 2726.756352 MB, Reserved: 18234.73664 MB\n",
      "Epoch 98: loss = 0.29943305253982544\n",
      "before loss.backward(): Allocated: 2726.756352 MB, Reserved: 18234.73664 MB\n",
      "After loss.backward(): Allocated: 2413.850624 MB, Reserved: 18234.73664 MB\n",
      "-----------------\n",
      "points torch.Size([758104, 3])\n",
      "CVT loss:  tensor(0.0025, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 9.644139936426654e-06 : Allocated: 2719.371264 MB, Reserved: 18234.73664 MB\n",
      "Epoch 99: loss = 0.25666743516921997\n",
      "before loss.backward(): Allocated: 2719.371264 MB, Reserved: 18234.73664 MB\n",
      "After loss.backward(): Allocated: 2411.293696 MB, Reserved: 18234.73664 MB\n",
      "-----------------\n",
      "points torch.Size([745762, 3])\n",
      "CVT loss:  tensor(0.0032, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "After Chamfer loss PYTORCH3D 9.546578439767472e-06 : Allocated: 2714.925056 MB, Reserved: 18234.73664 MB\n",
      "Epoch 100: loss = 0.32863107323646545\n",
      "before loss.backward(): Allocated: 2714.925056 MB, Reserved: 18234.73664 MB\n",
      "After loss.backward(): Allocated: 2410.679808 MB, Reserved: 18234.73664 MB\n",
      "-----------------\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 272.00 MiB (GPU 0; 23.57 GiB total capacity; 22.41 GiB already allocated; 78.38 MiB free; 22.86 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 28\u001b[0m\n\u001b[1;32m      7\u001b[0m     sites \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(sites)\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mrequires_grad_(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# import cProfile, pstats\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# import time\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m# \u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m     sites \u001b[38;5;241m=\u001b[39m \u001b[43mautograd\u001b[49m\u001b[43m(\u001b[49m\u001b[43msites\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupsampling\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlambda_weights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m# profiler.disable()\u001b[39;00m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;66;03m# stats = pstats.Stats(profiler).sort_stats('cumtime')\u001b[39;00m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;66;03m# stats.print_stats()\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;66;03m# stats.dump_stats(f'{destination}{mesh[0]}{max_iter}_3d_profile_{num_centroids}_chamfer{lamda_chamfer}.prof')\u001b[39;00m\n\u001b[1;32m     37\u001b[0m     sites_np \u001b[38;5;241m=\u001b[39m sites\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "Cell \u001b[0;32mIn[15], line 137\u001b[0m, in \u001b[0;36mautograd\u001b[0;34m(sites, model, max_iter, stop_train_threshold, upsampling, lambda_weights)\u001b[0m\n\u001b[1;32m    135\u001b[0m hess_sdf \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(N, D, D, device\u001b[38;5;241m=\u001b[39msites\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(D):\n\u001b[0;32m--> 137\u001b[0m     grad2 \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msdf_gradients\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msites\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43msdf_gradients\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;66;03m# (N, 3)\u001b[39;00m\n\u001b[1;32m    138\u001b[0m     hess_sdf[:, i, :] \u001b[38;5;241m=\u001b[39m grad2 \u001b[38;5;66;03m# fill row i of each 3Ã—3 Hessian\u001b[39;00m\n\u001b[1;32m    140\u001b[0m np\u001b[38;5;241m.\u001b[39msavez(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmesh[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_to_clip.npz\u001b[39m\u001b[38;5;124m'\u001b[39m, sites\u001b[38;5;241m=\u001b[39msites\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(), sdf_values\u001b[38;5;241m=\u001b[39msdf_values\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(), sdf_gradients\u001b[38;5;241m=\u001b[39msdf_gradients\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(), sdf_hessians\u001b[38;5;241m=\u001b[39mhess_sdf\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/autograd/__init__.py:303\u001b[0m, in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched)\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _vmap_internals\u001b[38;5;241m.\u001b[39m_vmap(vjp, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, allow_none_pass_through\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)(grad_outputs_)\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    304\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_outputs_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 272.00 MiB (GPU 0; 23.57 GiB total capacity; 22.41 GiB already allocated; 78.38 MiB free; 22.86 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "site_file_path = f'{destination}{max_iter}_cvt_{lambda_cvt}_chamfer_{lamda_chamfer}_eikonal_{lambda_eikonal}.npy'\n",
    "#check if optimized sites file exists\n",
    "if not os.path.exists(site_file_path):\n",
    "    #import sites\n",
    "    print(\"Importing sites\")\n",
    "    sites = np.load(site_file_path)\n",
    "    sites = torch.from_numpy(sites).to(device).requires_grad_(True)\n",
    "else:\n",
    "    # import cProfile, pstats\n",
    "    # import time\n",
    "    # profiler = cProfile.Profile()\n",
    "    # profiler.enable()\n",
    "\n",
    "#     with torch.profiler.profile(activities=[\n",
    "#             torch.profiler.ProfilerActivity.CPU,\n",
    "#             torch.profiler.ProfilerActivity.CUDA,\n",
    "#         ],\n",
    "#         record_shapes=False,\n",
    "#         with_stack=True  # Captures function calls\n",
    "#     ) as prof:\n",
    "#         sites = autograd(sites, model, max_iter=max_iter, upsampling=0, lambda_weights=lambda_weights)\n",
    "#         torch.cuda.synchronize()\n",
    "# # \n",
    "#     print(prof.key_averages().table(sort_by=\"self_cuda_time_total\"))\n",
    "#     prof.export_chrome_trace(\"trace.json\")\n",
    "    \n",
    "    # \n",
    "    sites = autograd(sites, model, max_iter=max_iter, upsampling=4, lambda_weights=lambda_weights)\n",
    "\n",
    "    \n",
    "    # profiler.disable()\n",
    "    # stats = pstats.Stats(profiler).sort_stats('cumtime')\n",
    "    # stats.print_stats()\n",
    "    # stats.dump_stats(f'{destination}{mesh[0]}{max_iter}_3d_profile_{num_centroids}_chamfer{lamda_chamfer}.prof')\n",
    "    \n",
    "    \n",
    "    sites_np = sites.detach().cpu().numpy()\n",
    "    np.save(site_file_path, sites_np)\n",
    "    \n",
    "    \n",
    "\n",
    "print(\"Sites length: \", len(sites))\n",
    "print(\"min sites: \", torch.min(sites))\n",
    "print(\"max sites: \", torch.max(sites))\n",
    "#ps_cloud = ps.register_point_cloud(\"best_optimized_cvt_grid\",sites.detach().cpu().numpy())\n",
    "    \n",
    "lim=torch.abs(torch.max(sites)).detach().cpu().numpy()*1.1\n",
    "#plot_voronoi_3d(sites,lim,lim,lim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e4fcfff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model ./images/autograd/HotSpot/gargoyle100_100_3d_model_4096_chamfer1000.pth\n",
      "sites ./images/autograd/HotSpot/gargoyle100_100_3d_sites_4096_chamfer1000.pth\n"
     ]
    }
   ],
   "source": [
    "epoch = 100\n",
    "\n",
    "model_file_path = f'{destination}{mesh[0]}{max_iter}_{epoch}_3d_model_{num_centroids}_chamfer{lamda_chamfer}.pth'\n",
    "site_file_path = f'{destination}{mesh[0]}{max_iter}_{epoch}_3d_sites_{num_centroids}_chamfer{lamda_chamfer}.pth'\n",
    " \n",
    "sites = torch.load(site_file_path)\n",
    "\n",
    "sites_np = sites.detach().cpu().numpy()\n",
    "model.load_state_dict(torch.load(model_file_path))\n",
    "#\n",
    "#polyscope_sdf(model)\n",
    "#\n",
    "print(\"model\", model_file_path)\n",
    "print(\"sites\", site_file_path)\n",
    "ps_cloud = ps.register_point_cloud(f\"{epoch} epoch_cvt_grid\",sites_np)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72e588cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(tensor([[-0.2605, -0.0325, -0.2909],\n",
      "        [-0.2692, -0.0325, -0.2851],\n",
      "        [-0.2632, -0.0325, -0.2870],\n",
      "        ...,\n",
      "        [-0.1071,  0.2690, -0.4059],\n",
      "        [-0.3353,  0.1806, -0.3975],\n",
      "        [-0.1064, -0.0076,  0.2529]], device='cuda:0', grad_fn=<SumBackward1>),), (tensor([[ 45182, 238339, 238338],\n",
      "        [ 73328, 247634,  77377],\n",
      "        [242809, 158427, 242810],\n",
      "        ...,\n",
      "        [ 38375,  22600,  22606],\n",
      "        [ 15779,  38375,  96871],\n",
      "        [ 15779,  15776,  38375]], device='cuda:0'),)]\n",
      "[polyscope] To render large point clouds efficiently, set their render mode to 'quad' instead of 'sphere'. (disable these warnings by setting Polyscope's verbosity < 2)\n"
     ]
    }
   ],
   "source": [
    "final_mesh = su.get_zero_crossing_mesh_3d(sites, model)\n",
    "ps.register_surface_mesh(\"Zero-Crossing faces final\", final_mesh[0], final_mesh[1])\n",
    "\n",
    "import scipy.spatial as spatial\n",
    "from scipy.spatial import Delaunay\n",
    "\n",
    "tri = Delaunay(sites_np)\n",
    "delaunay_vertices =torch.tensor(np.array(tri.simplices), device=device)\n",
    "sdf_values = model(sites)\n",
    "\n",
    "\n",
    "# Assuming sites is a PyTorch tensor of shape [M, 3]\n",
    "sites = sites.unsqueeze(0)  # Now shape [1, M, 3]\n",
    "\n",
    "# Assuming SDF_Values is a PyTorch tensor of shape [M]\n",
    "sdf_values = sdf_values.unsqueeze(0)  # Now shape [1, M]\n",
    "\n",
    "marching_tetrehedra_mesh = kaolin.ops.conversions.marching_tetrahedra(sites, delaunay_vertices, sdf_values, return_tet_idx=False)\n",
    "print(marching_tetrehedra_mesh)\n",
    "vertices_list, faces_list = marching_tetrehedra_mesh\n",
    "vertices = vertices_list[0]\n",
    "faces = faces_list[0]\n",
    "vertices_np = vertices.detach().cpu().numpy()  # Shape [N, 3]\n",
    "faces_np = faces.detach().cpu().numpy()  # Shape [M, 3] (triangles)\n",
    "ps.register_surface_mesh(\"Marching Tetrahedra Mesh final\", vertices_np, faces_np)\n",
    "\n",
    "# clipped_cvt = \"clipped_CVT.obj\"\n",
    "# if os.path.exists(clipped_cvt):\n",
    "#     clipped_cvt_mesh = trimesh.load(clipped_cvt)\n",
    "#     ps.register_surface_mesh(\"Clipped CVT\", clipped_cvt_mesh.vertices, clipped_cvt_mesh.faces)\n",
    "ps.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d940a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
