{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device:  NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import kaolin\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#cuda devices\n",
    "device = torch.device(\"cuda:0\")\n",
    "print(\"Using device: \", torch.cuda.get_device_name(device))\n",
    "\n",
    "multires = 2\n",
    "lr = 1e-3\n",
    "iterations = 5000\n",
    "save_every = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP + Positional Encoding\n",
    "class Decoder(torch.nn.Module):\n",
    "    def __init__(self, input_dims = 3, internal_dims = 128, output_dims = 4, hidden = 5, multires = 2):\n",
    "        super().__init__()\n",
    "        self.embed_fn = None\n",
    "        if multires > 0:\n",
    "            embed_fn, input_ch = get_embedder(multires)\n",
    "            self.embed_fn = embed_fn\n",
    "            input_dims = input_ch\n",
    "\n",
    "        net = (torch.nn.Linear(input_dims, internal_dims, bias=False), torch.nn.ReLU())\n",
    "        for i in range(hidden-1):\n",
    "            net = net + (torch.nn.Linear(internal_dims, internal_dims, bias=False), torch.nn.ReLU())\n",
    "        net = net + (torch.nn.Linear(internal_dims, output_dims, bias=False),)\n",
    "        self.net = torch.nn.Sequential(*net)\n",
    "\n",
    "    def forward(self, p):\n",
    "        if self.embed_fn is not None:\n",
    "            p = self.embed_fn(p)\n",
    "        out = self.net(p)\n",
    "        return out\n",
    "\n",
    "    def pre_train_sphere(self, iter):\n",
    "        print (\"Initialize SDF to sphere\")\n",
    "        loss_fn = torch.nn.MSELoss()\n",
    "        optimizer = torch.optim.Adam(list(self.parameters()), lr=1e-4)\n",
    "\n",
    "        for i in tqdm(range(iter)):\n",
    "            p = torch.rand((1024,3), device='cuda') - 0.5\n",
    "            ref_value  = torch.sqrt((p**2).sum(-1)) - 0.3\n",
    "            output = self(p)\n",
    "            loss = loss_fn(output[...,0], ref_value)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(\"Pre-trained MLP\", loss.item())\n",
    "\n",
    "    def pre_train_circle(self, iter):\n",
    "        print(\"Initialize SDF to circle\")\n",
    "        loss_fn = torch.nn.MSELoss()\n",
    "        optimizer = torch.optim.Adam(list(self.parameters()), lr=1e-4)\n",
    "\n",
    "        for i in tqdm(range(iter)):\n",
    "            # Generate random points in the 2D plane (x, y)\n",
    "            p = torch.rand((1024, 2), device='cuda') - 0.5  # x and y values in the range [-0.5, 0.5]\n",
    "\n",
    "            # Calculate the reference value (SDF for circle)\n",
    "            ref_value = torch.sqrt((p**2).sum(-1)) - 0.3  # Distance from origin (0, 0) minus the circle radius (0.3)\n",
    "\n",
    "            # Get the network output\n",
    "            output = self(p)\n",
    "            \n",
    "            # Compute the loss\n",
    "            loss = loss_fn(output[..., 0], ref_value)\n",
    "            \n",
    "            # Perform backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(\"Pre-trained MLP\", loss.item())\n",
    "\n",
    "\n",
    "# Positional Encoding from https://github.com/yenchenlin/nerf-pytorch/blob/1f064835d2cca26e4df2d7d130daa39a8cee1795/run_nerf_helpers.py\n",
    "class Embedder:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.kwargs = kwargs\n",
    "        self.create_embedding_fn()\n",
    "        \n",
    "    def create_embedding_fn(self):\n",
    "        embed_fns = []\n",
    "        d = self.kwargs['input_dims']\n",
    "        out_dim = 0\n",
    "        if self.kwargs['include_input']:\n",
    "            embed_fns.append(lambda x : x)\n",
    "            out_dim += d\n",
    "            \n",
    "        max_freq = self.kwargs['max_freq_log2']\n",
    "        N_freqs = self.kwargs['num_freqs']\n",
    "        \n",
    "        if self.kwargs['log_sampling']:\n",
    "            freq_bands = 2.**torch.linspace(0., max_freq, steps=N_freqs)\n",
    "        else:\n",
    "            freq_bands = torch.linspace(2.**0., 2.**max_freq, steps=N_freqs)\n",
    "            \n",
    "        for freq in freq_bands:\n",
    "            for p_fn in self.kwargs['periodic_fns']:\n",
    "                embed_fns.append(lambda x, p_fn=p_fn, freq=freq : p_fn(x * freq))\n",
    "                out_dim += d\n",
    "                    \n",
    "        self.embed_fns = embed_fns\n",
    "        self.out_dim = out_dim\n",
    "        \n",
    "    def embed(self, inputs):\n",
    "        return torch.cat([fn(inputs) for fn in self.embed_fns], -1)\n",
    "\n",
    "def get_embedder(multires):\n",
    "    embed_kwargs = {\n",
    "                'include_input' : True,\n",
    "                #'input_dims' : 3,\n",
    "                'input_dims' : 2,\n",
    "                'max_freq_log2' : multires-1,\n",
    "                'num_freqs' : multires,\n",
    "                'log_sampling' : True,\n",
    "                'periodic_fns' : [torch.sin, torch.cos],\n",
    "    }\n",
    "    \n",
    "    embedder_obj = Embedder(**embed_kwargs)\n",
    "    embed = lambda x, eo=embedder_obj : eo.embed(x)\n",
    "    return embed, embedder_obj.out_dim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd_path = \"./data/eabxhqb82fxu.usd\"\n",
    "\n",
    "points = kaolin.io.usd.import_pointclouds(pcd_path)[0].points.to(device)\n",
    "if points.shape[0] > 100000:\n",
    "    idx = list(range(points.shape[0]))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = torch.tensor(idx[:100000], device=points.device, dtype=torch.long)    \n",
    "    points = points[idx]\n",
    "\n",
    "# The reconstructed object needs to be slightly smaller than the grid to get watertight surface after MT.\n",
    "points = kaolin.ops.pointcloud.center_points(points.unsqueeze(0), normalize=True).squeeze(0) * 0.9\n",
    "#timelapse.add_pointcloud_batch(category='input', pointcloud_list=[points.cpu()], points_type = \"usd_geom_points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize SDF to circle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 1205.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-trained MLP 1.0863743682421045e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize model and create optimizer\n",
    "model = Decoder(multires=multires).to(device)\n",
    "model.pre_train_circle(1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_f(mesh_verts, mesh_faces, points, it):\n",
    "    pred_points = kaolin.ops.mesh.sample_points(mesh_verts.unsqueeze(0), mesh_faces, 50000)[0][0]\n",
    "    chamfer = kaolin.metrics.pointcloud.chamfer_distance(pred_points.unsqueeze(0), points.unsqueeze(0)).mean()\n",
    "    #if it > iterations//2:\n",
    "        #lap = laplace_regularizer_const(mesh_verts, mesh_faces)\n",
    "        #return chamfer + lap * laplacian_weight\n",
    "    return chamfer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = [p for _, p in model.named_parameters()]\n",
    "optimizer = torch.optim.Adam(vars, lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda x: max(0.0, 10**(-x*0.0002))) # LR decay over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for it in range(iterations):\n",
    "    pred = model(tet_verts) # predict SDF and per-vertex deformation\n",
    "    sdf, deform = pred[:,0], pred[:,1:]\n",
    "    verts_deformed = tet_verts + torch.tanh(deform) / grid_res # constraint deformation to avoid flipping tets\n",
    "    mesh_verts, mesh_faces = kaolin.ops.conversions.marching_tetrahedra(verts_deformed.unsqueeze(0), tets, sdf.unsqueeze(0)) # running MT (batched) to extract surface mesh\n",
    "    mesh_verts, mesh_faces = mesh_verts[0], mesh_faces[0]\n",
    " \n",
    "    loss = loss_f(mesh_verts, mesh_faces, points, it)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    if (it) % save_every == 0 or it == (iterations - 1): \n",
    "        print ('Iteration {} - loss: {}, # of mesh vertices: {}, # of mesh faces: {}'.format(it, loss, mesh_verts.shape[0], mesh_faces.shape[0]))\n",
    "        # save reconstructed mesh\n",
    "        #timelapse.add_mesh_batch(iteration=it+1,category='extracted_mesh',vertices_list=[mesh_verts.cpu()],faces_list=[mesh_faces.cpu()])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
