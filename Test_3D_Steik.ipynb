{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "Using device:  NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "import kaolin\n",
    "import torch\n",
    "import math\n",
    "import matplotlib\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import polyscope as ps\n",
    "import trimesh\n",
    "\n",
    "from scipy.spatial import Voronoi, voronoi_plot_2d, Delaunay\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import sdfpred_utils.sdfpred_utils as su\n",
    "import sdfpred_utils.sdf_MLP as mlp\n",
    "import sdfpred_utils.sdf_functions as sdf\n",
    "import sdfpred_utils.loss_functions as lf\n",
    "import sdfpred_utils.Steik_data3d as sd3d\n",
    "import sdfpred_utils.Steik_Loss as sl\n",
    "import sdfpred_utils.Steik_utils as Stu \n",
    "\n",
    "#cuda devices\n",
    "device = torch.device(\"cuda:0\")\n",
    "print(\"Using device: \", torch.cuda.get_device_name(device))\n",
    "\n",
    "#default tensor types\n",
    "torch.set_default_tensor_type(torch.cuda.DoubleTensor)\n",
    "\n",
    "multires = 2\n",
    "input_dims = 3\n",
    "lr_sites = 0.005/2\n",
    "lr_model = 0.00005*2\n",
    "destination = \"./images/autograd/3Dsteik/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new sites\n",
      "Meshgrid shape: torch.Size([4096, 3])\n",
      "Meshgrid 1st 5: tensor([[-1.5000, -1.5000, -1.5000],\n",
      "        [-1.5000, -1.5000, -1.3000],\n",
      "        [-1.5000, -1.5000, -1.1000],\n",
      "        [-1.5000, -1.5000, -0.9000],\n",
      "        [-1.5000, -1.5000, -0.7000]])\n",
      "Meshgrid 1st 5: tensor([[-1.3439, -1.6130, -1.3673],\n",
      "        [-1.4276, -1.5825, -1.3349],\n",
      "        [-1.4299, -1.5721, -1.2085],\n",
      "        [-1.4404, -1.5605, -0.7878],\n",
      "        [-1.4415, -1.5551, -0.8328]])\n",
      "Sites min: tensor([-1.7681, -1.7501, -1.7641], grad_fn=<MinBackward0>)\n",
      "Sites max: tensor([1.8419, 1.7887, 1.8176], grad_fn=<MaxBackward0>)\n",
      "Sites shape: torch.Size([4096, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wylliam/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1678402412426/work/aten/src/ATen/native/TensorShape.cpp:3483.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "#currently sites are between -5 and 5 in all 3 dimensions\n",
    "# check if sites exists\n",
    "#num_centroids = 16*16*16\n",
    "#num_centroids =16*16*16*8\n",
    "num_centroids = 16*16*16#*8 \n",
    "#num_centroids = 128*128*128\n",
    "\n",
    "site_fp = f'sites_{num_centroids}_{input_dims}.pt'\n",
    "\n",
    "# if os.path.exists(site_fp):\n",
    "#     sites = torch.load(site_fp)\n",
    "#     print(\"Sites loaded:\", sites.shape)\n",
    "# else:\n",
    "print(\"Creating new sites\")\n",
    "noise_scale = 0.1\n",
    "domain_limit = 1.5\n",
    "x = torch.linspace(-domain_limit, domain_limit, int(round(num_centroids**(1/3))))\n",
    "y = torch.linspace(-domain_limit, domain_limit, int(round(num_centroids**(1/3))))\n",
    "z = torch.linspace(-domain_limit, domain_limit, int(round(num_centroids**(1/3))))\n",
    "meshgrid = torch.meshgrid(x, y, z)\n",
    "meshgrid = torch.stack(meshgrid, dim=3).view(-1, 3)\n",
    "print(\"Meshgrid shape:\", meshgrid.shape)\n",
    "print(\"Meshgrid 1st 5:\", meshgrid[:5])\n",
    "#add noise to meshgrid\n",
    "meshgrid += torch.randn_like(meshgrid) * noise_scale\n",
    "print(\"Meshgrid 1st 5:\", meshgrid[:5])\n",
    "sites = meshgrid.to(device, dtype=torch.double).requires_grad_(True)\n",
    "\n",
    "#print min max sites \n",
    "print(\"Sites min:\", sites.min(dim=0).values)\n",
    "print(\"Sites max:\", sites.max(dim=0).values)\n",
    "print(\"Sites shape:\", sites.shape)\n",
    "\n",
    "#sites = su.createCVTgrid(num_centroids=num_centroids, dimensionality=input_dims)\n",
    "#save the initial sites torch tensor\n",
    "#torch.save(sites, site_fp)\n",
    "\n",
    "\n",
    "def plot_voronoi_3d(sites, xlim=5, ylim=5, zlim=5):\n",
    "    import numpy as np\n",
    "    import pyvoro\n",
    "    import matplotlib.pyplot as plt\n",
    "    from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "    # initialize random number generator\n",
    "    rng = np.random.default_rng(11)\n",
    "    # create a set of points in 3D\n",
    "    points = sites.detach().cpu().numpy()\n",
    "\n",
    "    # use pyvoro to compute the Voronoi tessellation\n",
    "    # the second argument gives the the axis limits in x,y and z direction\n",
    "    # in this case all between 0 and 1.\n",
    "    # the third argument gives \"dispersion = max distance between two points\n",
    "    # that might be adjacent\" (not sure how exactly this works)\n",
    "    voronoi = pyvoro.compute_voronoi(points,[[-xlim,xlim],[-ylim,ylim],[-zlim,zlim]],1)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # for each Voronoi cell, plot all the faces of the corresponding polygon\n",
    "    for vnoicell in voronoi:\n",
    "        faces = []\n",
    "        # the vertices are the corner points of the Voronoi cell\n",
    "        vertices = np.array(vnoicell['vertices'])\n",
    "        # cycle through all faces of the polygon\n",
    "        for face in vnoicell['faces']:\n",
    "            faces.append(vertices[np.array(face['vertices'])])\n",
    "            \n",
    "        # join the faces into a 3D polygon\n",
    "        polygon = Poly3DCollection(faces, alpha=0.5, \n",
    "                                facecolors=rng.uniform(0,1,3),\n",
    "                                linewidths=0.5,edgecolors='black')\n",
    "        ax.add_collection3d(polygon)\n",
    "    \n",
    "    ax.set_xlim([-xlim,xlim])\n",
    "    ax.set_ylim([-ylim,ylim])\n",
    "    ax.set_zlim([-zlim,zlim])\n",
    "            \n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def polyscope_sdf(model,i):\n",
    "    # Render the SDF as an implicit surface (zero-level set)\n",
    "    def model_sdf(pts):\n",
    "        pts_tensor = torch.tensor(pts, dtype=torch.float64, device=device)\n",
    "        sdf_values = model(pts_tensor)\n",
    "        sdf_values_np = sdf_values.detach().cpu().numpy().flatten()  # Convert to NumPy\n",
    "        \n",
    "        return sdf_values_np\n",
    "\n",
    "    ps.render_implicit_surface(f\"SDF Surface {i}\", model_sdf, mode=\"sphere_march\", enabled=True, subsample_factor=2)\n",
    "    \n",
    "def polyscope_marching_tet(model, sites, i=\"\"):\n",
    "    import scipy.spatial as spatial\n",
    "    from scipy.spatial import Delaunay\n",
    "\n",
    "    sites_np = sites.detach().cpu().numpy()\n",
    "    tri = Delaunay(sites_np)\n",
    "    delaunay_vertices =torch.tensor(np.array(tri.simplices), device=device)\n",
    "    sdf_values = model(sites)\n",
    "\n",
    "\n",
    "    # Assuming sites is a PyTorch tensor of shape [M, 3]\n",
    "    sites = sites.unsqueeze(0)  # Now shape [1, M, 3]\n",
    "\n",
    "    # Assuming SDF_Values is a PyTorch tensor of shape [M]\n",
    "    sdf_values = sdf_values.unsqueeze(0)  # Now shape [1, M]\n",
    "\n",
    "    marching_tetrehedra_mesh = kaolin.ops.conversions.marching_tetrahedra(sites, delaunay_vertices, sdf_values, return_tet_idx=False)\n",
    "    print(marching_tetrehedra_mesh)\n",
    "    vertices_list, faces_list = marching_tetrehedra_mesh\n",
    "    vertices = vertices_list[0]\n",
    "    faces = faces_list[0]\n",
    "    vertices_np = vertices.detach().cpu().numpy()  # Shape [N, 3]\n",
    "    faces_np = faces.detach().cpu().numpy()  # Shape [M, 3] (triangles)\n",
    "    ps.register_surface_mesh(f\"Marching Tetrahedra Mesh{i}\", vertices_np, faces_np)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#plot_voronoi_3d(sites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[polyscope] Backend: openGL3_glfw -- Loaded openGL version: 3.3.0 NVIDIA 570.133.07\n"
     ]
    }
   ],
   "source": [
    "ps.init()\n",
    "#ps_cloud = ps.register_point_cloud(\"initial_cvt_grid\",sites.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the mesh\n",
    "mesh = [\"bunny\", \"Resources/stanford-bunny.obj\"]\n",
    "# # #mesh = [\"staryu\", \"Resources/staryu.obj\"]\n",
    "# mesh = [\"chair\", \"Resources/chair_low.obj\"]\n",
    "\n",
    "# bunny = trimesh.load(mesh[1])\n",
    "# #target_points = bunny.sample(16*16*16)\n",
    "\n",
    "# target_points = bunny.sample(16*16*16 * 4)\n",
    "# target_points = target_points - np.mean(target_points, axis=0)\n",
    "# target_points = target_points / np.max(np.abs(target_points))\n",
    "\n",
    "\n",
    "# target_points = torch.tensor(target_points, device=device)\n",
    "# print(\"Target points:\", target_points.shape)\n",
    "# min_target = target_points.min(0)[0]\n",
    "# max_target = target_points.max(0)[0]\n",
    "# print(\"min_target\", min_target)\n",
    "# print(\"max_target\", max_target)\n",
    "\n",
    "# ps.register_point_cloud(\"Target_points\",target_points.detach().cpu().numpy())\n",
    "\n",
    "# #ps.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manifold points shape:  torch.Size([32768, 3])\n",
      "Manifold points normals GT shape:  torch.Size([32768, 3])\n",
      "Non-manifold points shape:  torch.Size([32768, 3])\n",
      "Manifold points min: tensor([-0.7309, -0.6531, -0.7540])\n",
      "Manifold points max: tensor([0.9407, 1.0000, 0.5411])\n"
     ]
    }
   ],
   "source": [
    "shape_type = 'bunny'\n",
    "res = 128 # has to be even\n",
    "example_idx = 0\n",
    "sample_type = 'grid'\n",
    "n_samples = 1\n",
    "n_points = 16*16*16*8\n",
    "#TODO: change to 3D look into Steik to make it work \n",
    "# dataset = sd2d.get2D_dataset(n_points, n_samples, res, sample_type, 0.005, shape_type=shape_type)  # BasicShape2D(100, 20, res=50)\n",
    "# dataloader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=False, num_workers=0, pin_memory=False)\n",
    "\n",
    "dataset = sd3d.ReconDataset(\"Resources/stanford-bunny.obj\", n_points, n_samples=n_samples)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False, num_workers=0 ,pin_memory=False)\n",
    "data = next(iter(dataloader))\n",
    "# print(\"Data keys: \", data.keys())\n",
    "# mnfld_points, normals_gt, nonmnfld_dist_gt, nonmnfld_points, nonmnfld_n_gt= data['points'].to(device), data['mnfld_n'].to(device), \\\n",
    "#                                                                             data['nonmnfld_dist'].to(device), \\\n",
    "#                                                                             data['nonmnfld_points'].to(device), data['nonmnfld_n'].to(device),\n",
    "mnfld_points, mnfld_n_gt, nonmnfld_points = data['points'].to(device), data['mnfld_n'].to(device),  data['nonmnfld_points'].to(device)\n",
    "\n",
    "mnfld_points = mnfld_points[0]\n",
    "mnfld_points = mnfld_points.double()\n",
    "mnfld_n_gt = mnfld_n_gt[0]\n",
    "mnfld_n_gt = mnfld_n_gt.double()\n",
    "nonmnfld_points = nonmnfld_points[0]\n",
    "nonmnfld_points = nonmnfld_points.double()\n",
    "\n",
    "#print min max values of manifold\n",
    "\n",
    "print(\"Manifold points shape: \", mnfld_points.shape)\n",
    "print(\"Manifold points normals GT shape: \", mnfld_n_gt.shape)\n",
    "print(\"Non-manifold points shape: \", nonmnfld_points.shape)\n",
    "print(\"Manifold points min:\", torch.min(mnfld_points, dim=0).values)\n",
    "print(\"Manifold points max:\", torch.max(mnfld_points, dim=0).values)\n",
    "mnfld_points.requires_grad_()\n",
    "nonmnfld_points.requires_grad_()\n",
    "\n",
    "small_mnfl_points = mnfld_points*0.99\n",
    "big_mnfl_points = mnfld_points*1.01\n",
    "\n",
    "ps.register_point_cloud(\"mnfld\", mnfld_points.detach().cpu().numpy())\n",
    "#ps.register_point_cloud(\"normals\", mnfld_n_gt.detach().cpu().numpy())\n",
    "#ps.register_point_cloud(\"big_mnfl_points\", big_mnfl_points.detach().cpu().numpy())\n",
    "#ps.register_point_cloud(\"small_mnfl_points\", small_mnfl_points.detach().cpu().numpy())\n",
    "#ps.register_point_cloud(\"non mnfld\", nonmnfld_points.detach().cpu().numpy())\n",
    "ps.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import open3d as o3d\n",
    "# import numpy as np\n",
    "\n",
    "# # Load point cloud\n",
    "# mesh = o3d.io.read_triangle_mesh(\"Resources/stanford-bunny.obj\")\n",
    "# pcd = mesh.sample_points_uniformly(16*16*16*8)\n",
    "\n",
    "# points = np.asarray(pcd.points, dtype=np.float32)\n",
    "# #min max values of points\n",
    "# print(\"Points min:\", points.min(axis=0))\n",
    "# print(\"Points max:\", points.max(axis=0))\n",
    "\n",
    "# # center and scale point cloud\n",
    "# center = points.mean(axis=0)\n",
    "# points = points - center[None, :]\n",
    "# # self.scale = np.linalg.norm(points, axis=-1).max(-1)\n",
    "# scale = np.abs(points).max()\n",
    "# points = points / scale\n",
    "# pcd.points = o3d.utility.Vector3dVector(points)\n",
    "\n",
    "\n",
    "# #min max values of points\n",
    "# print(\"Points min:\", points.min(axis=0))\n",
    "# print(\"Points max:\", points.max(axis=0))\n",
    "\n",
    "\n",
    "# # Estimate normals\n",
    "# pcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamKNN(knn=30))\n",
    "# # Flip normals towards a common viewpoint (optional)\n",
    "# pcd.orient_normals_consistent_tangent_plane(k=30)\n",
    "# # Visualize\n",
    "# #o3d.visualization.draw_geometries([pcd], point_show_normal=True)\n",
    "\n",
    "\n",
    "# # Convert point cloud to numpy\n",
    "# points = np.asarray(pcd.points)\n",
    "# normals = np.asarray(pcd.normals)\n",
    "\n",
    "# # Define offset distance\n",
    "# d = 0.003   # Adjust as needed\n",
    "\n",
    "# # Create outer and inner point clouds\n",
    "# points_outer = points + d * normals\n",
    "# points_inner = points - d * normals\n",
    "\n",
    "# # Create Open3D point clouds\n",
    "# pcd_outer = o3d.geometry.PointCloud()\n",
    "# pcd_outer.points = o3d.utility.Vector3dVector(points_outer)\n",
    "\n",
    "# pcd_inner = o3d.geometry.PointCloud()\n",
    "# pcd_inner.points = o3d.utility.Vector3dVector(points_inner)\n",
    "\n",
    "# ps.register_point_cloud(\"points\",points)\n",
    "# ps.register_point_cloud(\"points_inner\", np.asarray(pcd_inner.points))\n",
    "# ps.register_point_cloud(\"points_outer\", np.asarray(pcd_outer.points))\n",
    "\n",
    "\n",
    "\n",
    "# # uniformely sample from points\n",
    "# num_points = points.shape[0]\n",
    "# indices = torch.randperm(num_points)[:16**3].cpu().numpy()\n",
    "# # Subsample\n",
    "# sub_points = points[indices]  # (N^3, 3)\n",
    "# sub_points_inner = points_inner[indices]  # (N^3, 3)\n",
    "# sub_points_outer = points_outer[indices]  # (N^3, 3)\n",
    "\n",
    "# ps.register_point_cloud(\"sub_points\",sub_points)\n",
    "# ps.register_point_cloud(\"sub_points_inner\", sub_points_inner)\n",
    "# ps.register_point_cloud(\"sub_points_outer\", sub_points_outer)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ps.show()\n",
    "\n",
    "# # Save or visualize\n",
    "# o3d.io.write_point_cloud(\"bunny_outer.ply\", pcd_outer)\n",
    "# o3d.io.write_point_cloud(\"bunny_inner.ply\", pcd_inner)\n",
    "# o3d.visualization.draw_geometries([pcd_inner, pcd_outer])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model\n"
     ]
    }
   ],
   "source": [
    "model = mlp.Decoder(multires=multires, input_dims=input_dims).to(device)\n",
    "radius = 1\n",
    "it = 1000\n",
    "#model_path = 'models_resources/pretrained_sphere_small.pth'\n",
    "model_path = f'models_resources/pretrained_sphere_{radius}.pth'\n",
    "#model_path = f'models_resources/pc_bunny_{it}.pth'\n",
    "#model_path = 'models_resources/pc_chair.pth'\n",
    "\n",
    "\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    print('loaded model')   \n",
    "else:\n",
    "    print(\"no model found, pretraining\")\n",
    "    model.pre_train_sphere(it*3, radius)\n",
    "    \n",
    "    #model.pre_train_pc_scaling(it*10, mnfld_points)\n",
    "    #model.pre_train_pc_scaling(it*3, mnfld_points, lr = 0.00001)\n",
    "    \n",
    "    polyscope_marching_tet(model, sites, i=f\"{it}_scaling\")\n",
    "    \n",
    "    #model.pre_train_pc(it*6)\n",
    "    #polyscope_marching_tet(model, sites, i=f\"{it}_pcn\")\n",
    "    \n",
    "    torch.save(model.state_dict(),model_path)\n",
    "\n",
    "#polyscope_marching_tet(model, sites, i=f\"_{it}_pc\")\n",
    "\n",
    "#ps.show()\n",
    "\n",
    "\n",
    "#polyscope_marching_tet(model, sites)\n",
    "#final_mesh = su.get_zero_crossing_mesh_3d(sites, model)\n",
    "#ps.register_surface_mesh(\"Zero-Crossing faces pretrained\", final_mesh[0], final_mesh[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsampling_vectorized(sites, tri=None, vor=None, model=None):\n",
    "    sdf_values = model(sites)\n",
    "    sites_np = sites.detach().cpu().numpy()\n",
    "\n",
    "    if vor is None:\n",
    "        vor = Voronoi(sites_np)\n",
    "    if tri is None:\n",
    "        tri = Delaunay(sites_np)\n",
    "    \n",
    "    neighbors = torch.tensor(np.array(vor.ridge_points), device=device)\n",
    "    \n",
    "    # Extract the SDF values for each site in the pair\n",
    "    sdf_i = sdf_values[neighbors[:, 0]]  # First site in each pair\n",
    "    sdf_j = sdf_values[neighbors[:, 1]]  # Second site in each pair\n",
    "    # Find the indices where SDF values have opposing signs or one is zero\n",
    "    mask_zero_crossing_sites = (sdf_i * sdf_j <= 0).squeeze()\n",
    "    sites_to_upsample = torch.unique(neighbors[mask_zero_crossing_sites].view(-1))\n",
    "    \n",
    "    print(\"Sites to upsample \",sites_to_upsample.shape)\n",
    "    \n",
    "    tet_centroids = sites[sites_to_upsample]\n",
    "\n",
    "    # Tetrahedron relative positions (unit tetrahedron)\n",
    "    basic_tet_1 = torch.tensor([[1, 1, 1]], device=device, dtype=torch.float64)\n",
    "    basic_tet_1 = basic_tet_1.repeat(len(tet_centroids), 1)\n",
    "    basic_tet_2 = torch.tensor([-1, -1, 1], device=device, dtype=torch.float64)    \n",
    "    basic_tet_2 = basic_tet_2.repeat(len(tet_centroids), 1)\n",
    "    basic_tet_3 = torch.tensor([-1, 1, -1], device=device, dtype=torch.float64)    \n",
    "    basic_tet_3 = basic_tet_3.repeat(len(tet_centroids), 1)\n",
    "    basic_tet_4 = torch.tensor([1, -1, -1], device=device, dtype=torch.float64)\n",
    "    basic_tet_4 = basic_tet_4.repeat(len(tet_centroids), 1)\n",
    "\n",
    "\n",
    "    #compute scale based on cell volume\n",
    "    #centroids = torch.tensor(np.array([vor.vertices[vor.regions[vor.point_region[i]]].mean(axis=0) for i in range(len(sites_np))]), device=device)\n",
    "    centroids = lf.compute_voronoi_cell_centers_index_based_torch(tri)\n",
    "    \n",
    "    #centroids = torch.tensor(np.array(centroids), device=sites.device, dtype=sites.dtype)\n",
    "    cells_vertices = [vor.vertices[vor.regions[vor.point_region[i]]] for i in range(len(sites_np))]\n",
    "\n",
    "    #compute the distance between each centroid  and each vertex in cells_vertices row\n",
    "    distances = []\n",
    "    for i in range(len(cells_vertices)):\n",
    "        min_dist = 100000000000\n",
    "        for j in range(len(cells_vertices[i])):\n",
    "            dist = torch.norm(centroids[i] - torch.tensor(cells_vertices[i][j], device=device), p=2)\n",
    "            if dist < min_dist:\n",
    "                min_dist = dist\n",
    "        distances.append(min_dist)\n",
    "    distances = torch.tensor(distances, device=device)\n",
    " \n",
    "    \n",
    "    scale = distances[sites_to_upsample] / 2\n",
    "    \n",
    "    scale = scale.unsqueeze(1)\n",
    "    \n",
    "    \n",
    "    new_sites = torch.cat((tet_centroids + basic_tet_1 * scale, tet_centroids + basic_tet_2 * scale, tet_centroids + basic_tet_3 * scale, tet_centroids + basic_tet_4 * scale), dim=0)\n",
    "\n",
    "    updated_sites = torch.cat((sites, new_sites), dim=0)\n",
    "\n",
    "    return updated_sites\n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvt_loss_values = []\n",
    "min_distance_loss_values = []\n",
    "chamfer_distance_loss_values = []\n",
    "eikonal_loss_values = []\n",
    "domain_restriction_loss_values = []\n",
    "sdf_loss_values = []\n",
    "div_loss_values = []\n",
    "loss_values = []\n",
    "\n",
    "\n",
    "def autograd(sites, model, max_iter=100, stop_train_threshold=1e-6, upsampling=0, lambda_weights = [0.1,1.0,0.1,0.1,1.0,1.0,0.1]):\n",
    "    optimizer = torch.optim.Adam([\n",
    "    {'params': [p for _, p in model.named_parameters()], 'lr': 5e-5},\n",
    "    {'params': [sites], 'lr': lr_sites}\n",
    "], betas=(0.9, 0.999))\n",
    "\n",
    "    prev_loss = float(\"inf\")\n",
    "    best_loss = float(\"inf\")\n",
    "    upsampled = 0.0\n",
    "    epoch = 0\n",
    "    lambda_cvt = lambda_weights[0]\n",
    "    # lambda_pc = lambda_weights[1]\n",
    "    lambda_min_distance = lambda_weights[2]\n",
    "    # lambda_laplace = lambda_weights[3]\n",
    "    lamda_chamfer = lambda_weights[4]\n",
    "    lambda_eikonal = lambda_weights[5]\n",
    "    lambda_domain_restriction = lambda_weights[6]\n",
    "    # lambda_target_points = lambda_weights[7]\n",
    "    lambda_sdf = 5e3\n",
    "    lambda_div = 1e3\n",
    "    lambda_eikonal = 5e1\n",
    "    best_sites = sites.clone()\n",
    "    best_sites.best_loss = best_loss\n",
    "    \n",
    "    while epoch <= max_iter:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # compute voronoi and delaunay once for each epoch and pass it around\n",
    "        # Compute Voronoi diagram\n",
    "        sites_np = sites.detach().cpu().numpy()\n",
    "        #vor = Voronoi(sites_np)\n",
    "        tri = Delaunay(sites_np)\n",
    "                \n",
    "        vertices_to_compute, bisectors_to_compute = su.compute_zero_crossing_vertices_3d(sites, None, tri, model)\n",
    "        #vertices_to_compute, bisectors_to_compute = su.compute_zero_crossing_vertices_3d(sites, vor, tri, model)\n",
    "        \n",
    "        vertices = su.compute_vertices_3d_vectorized(sites, vertices_to_compute)    \n",
    "        bisectors = su.compute_all_bisectors_vectorized(sites, bisectors_to_compute)\n",
    "        points = torch.cat((vertices, bisectors), 0)\n",
    "\n",
    "        # Compute losses       \n",
    "        #cvt_loss = lf.compute_cvt_loss_vectorized_voronoi(sites, vor)\n",
    "        cvt_loss = lf.compute_cvt_loss_vectorized_delaunay(sites, tri)\n",
    "        \n",
    "        #min_distance_loss = lf.sdf_weighted_min_distance_loss(model, sites)\n",
    "        print(\"mnfld\", mnfld_points.shape)\n",
    "        print(\"points\", points.shape) \n",
    "        \n",
    "        from pytorch3d.loss import chamfer_distance\n",
    "        chamfer_loss, _ = chamfer_distance(mnfld_points.unsqueeze(0).detach(), points.unsqueeze(0))\n",
    "        print(f\"After Chamfer loss PYTORCH3D {chamfer_loss} : Allocated: {torch.cuda.memory_allocated() / 1e6} MB,\\\n",
    "                  Reserved: {torch.cuda.memory_reserved() / 1e6} MB\")\n",
    "            \n",
    "        \n",
    "        # chamfer_loss = lf.chamfer_distance(mnfld_points, points)\n",
    "        \n",
    "        sites_loss = (\n",
    "            lambda_cvt * cvt_loss +\n",
    "            lamda_chamfer * chamfer_loss\n",
    "        )\n",
    "        print(f\"After site loss and Before model loss : Allocated: {torch.cuda.memory_allocated() / 1e6} MB,\\\n",
    "                  Reserved: {torch.cuda.memory_reserved() / 1e6} MB\")\n",
    "            \n",
    "        # Compute model loss               \n",
    "        non_manifold_pred = model(nonmnfld_points)\n",
    "        manifold_pred = model(mnfld_points)\n",
    "        div_loss = torch.tensor([0.0], device=mnfld_points.device)\n",
    "        # compute gradients for div (divergence), curl and curv (curvature)\n",
    "        if manifold_pred is not None:\n",
    "            mnfld_grad = Stu.gradient(mnfld_points, manifold_pred)\n",
    "        else:\n",
    "            mnfld_grad = None\n",
    "\n",
    "        nonmnfld_grad = Stu.gradient(nonmnfld_points, non_manifold_pred)\n",
    "        div_loss = torch.abs(lf.directional_div(nonmnfld_points, nonmnfld_grad)).mean() #+ mnfld_divergence_term.mean()\n",
    "        eikonal_term = lf.eikonal_loss(nonmnfld_grad, mnfld_grad=mnfld_grad, eikonal_type='abs')\n",
    "        sdf_term = torch.abs(manifold_pred).mean()\n",
    "        domain_restriction_loss = lf.domain_restriction_sphere(mnfld_points, model, input_dim=input_dims)\n",
    "        \n",
    "\n",
    "        model_loss = (\n",
    "            lambda_sdf*sdf_term +\n",
    "            lambda_eikonal*eikonal_term +\n",
    "            lambda_div*div_loss +\n",
    "            lambda_domain_restriction * domain_restriction_loss\n",
    "        )\n",
    "        #print weights\n",
    "        print(f\"lambda_sdf: {lambda_sdf}, lambda_eikonal: {lambda_eikonal}, lambda_div: {lambda_div}, lambda_domain_restriction: {lambda_domain_restriction}\")\n",
    "        print(f\"sdf_term: {sdf_term}, eikonal_term: {eikonal_term}, div_loss: {div_loss}, domain_restriction_loss: {domain_restriction_loss}\")\n",
    "        print(f\"Epoch {epoch}: model_loss = {model_loss.item()}\")\n",
    "        \n",
    "        #DIVDECAY='linear' # 'linear' | 'quintic' | 'step'\n",
    "        div_decay_params = [1e2, 0.2, 1e2, 0.4, 0.0, 0.0]\n",
    "        \n",
    "        div_decay_params = [5e2, 0.2, 5e2, 0.8, 0.0, 0.0]\n",
    "        \n",
    "        # div_decay_params = [lambda_div, 0.5, lambda_div/2, 0.8, 0.0, 0.0]\n",
    "        \n",
    "        #div_decay_params = [300, 0.5, 100, 0.8, 0.0, 0.0]\n",
    "        lambda_div = lf.update_div_weight(epoch, max_iter, lambda_div, 'linear', div_decay_params)\n",
    "               \n",
    "\n",
    "        #print weights\n",
    "        print(f\"cvt_loss: {cvt_loss}, chamfer_loss: {chamfer_loss}\")\n",
    "              #, min_distance_loss: {min_distance_loss}, \n",
    "        print(f\"Epoch {epoch}: site_loss = {sites_loss.item()}\")\n",
    "\n",
    "        print(f\"lambda_cvt: {lambda_cvt}, lambda_min_distance: {lambda_min_distance}, lambda_chamfer: {lamda_chamfer}\")\n",
    "         \n",
    "        loss = model_loss + sites_loss\n",
    "        loss_values.append(loss.item())\n",
    "        print(f\"Epoch {epoch}: loss = {loss.item()}\")\n",
    "        print(f\"before loss.backward(): Allocated: {torch.cuda.memory_allocated() / 1e6} MB, Reserved: {torch.cuda.memory_reserved() / 1e6} MB\")\n",
    "\n",
    "        loss.backward()\n",
    "        print(f\"After loss.backward(): Allocated: {torch.cuda.memory_allocated() / 1e6} MB, Reserved: {torch.cuda.memory_reserved() / 1e6} MB\")\n",
    "        print(\"-----------------\")\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        if loss.item() < best_loss:\n",
    "            best_loss = loss.item()\n",
    "            best_epoch = epoch\n",
    "            best_sites = sites.clone()\n",
    "            best_sites.best_loss = best_loss\n",
    "            #if upsampled > 0:\n",
    "                #print(f\"UPSAMPLED {upsampled} Best Epoch {best_epoch}: Best loss = {best_loss}\")\n",
    "                #return best_sites\n",
    "        \n",
    "        if abs(prev_loss - loss.item()) < stop_train_threshold:\n",
    "            print(f\"Converged at epoch {epoch} with loss {loss.item()}\")\n",
    "            #break\n",
    "        \n",
    "        prev_loss = loss.item() \n",
    "        \n",
    "        # if epoch>100 and (epoch // 100) == upsampled+1 and loss.item() < 0.5 and upsampled < upsampling:\n",
    "        if epoch/max_iter > (upsampled+1)/(upsampling+1) and upsampled < upsampling:\n",
    "            print(\"sites length BEFORE UPSAMPLING: \",len(sites))\n",
    "            \n",
    "            #new_sites = su.upsampling_inside(best_sites, model)\n",
    "            #new_sites = su.adaptive_density_upsampling(best_sites, model)\n",
    "            \n",
    "            #sites = su.add_upsampled_sites(best_sites, new_sites)\n",
    "            \n",
    "            sites = upsampling_vectorized(sites, tri, None, model)\n",
    "            \n",
    "            sites = sites.detach().requires_grad_(True)\n",
    "            #print(\"upsampled sites length: \",len(sites))\n",
    "            \n",
    "            #best_sites = sites.clone()\n",
    "            #best_sites.best_loss = best_loss\n",
    "            \n",
    "            optimizer = torch.optim.Adam([{'params': [p for _, p in model.named_parameters()], 'lr': lr_model},\n",
    "                                          {'params': [sites], 'lr': lr_sites}])\n",
    "            upsampled += 1.0\n",
    "            print(\"sites length AFTER: \",len(sites))\n",
    "            \n",
    "          \n",
    "        if epoch % (max_iter/50) == 0:\n",
    "            #print(f\"Epoch {epoch}: loss = {loss.item()}\")\n",
    "            #print(f\"Best Epoch {best_epoch}: Best loss = {best_loss}\")\n",
    "            #save model and sites\n",
    "            site_file_path = f'{destination}{mesh[0]}{max_iter}_{epoch}_3d_sites_{num_centroids}_chamfer{lamda_chamfer}.pth'\n",
    "            model_file_path = f'{destination}{mesh[0]}{max_iter}_{epoch}_3d_model_{num_centroids}_chamfer{lamda_chamfer}.pth'\n",
    "            torch.save(model.state_dict(), model_file_path)\n",
    "            torch.save(sites, site_file_path)\n",
    "            \n",
    "        epoch += 1           \n",
    "        \n",
    "    return best_sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-04-03 17:13:52 92541:92541 ActivityProfilerController.cpp:311] Completed Stage: Warm Up\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnfld torch.Size([32768, 3])\n",
      "points torch.Size([3185, 3])\n",
      "After Chamfer loss PYTORCH3D 0.11348692513868075 : Allocated: 17.416704 MB,                  Reserved: 56.623104 MB\n",
      "After site loss and Before model loss : Allocated: 17.417216 MB,                  Reserved: 56.623104 MB\n",
      "lambda_sdf: 5000.0, lambda_eikonal: 50.0, lambda_div: 1000.0, lambda_domain_restriction: 100\n",
      "sdf_term: 0.16743862734010934, eikonal_term: 0.30457573497037943, div_loss: 0.43503558288858546, domain_restriction_loss: 0.0\n",
      "Epoch 0: model_loss = 1287.457506337651\n",
      "cvt_loss: 0.12799401905054558, chamfer_loss: 0.11348692513868075\n",
      "Epoch 0: site_loss = 33.413307793328556\n",
      "lambda_cvt: 252, lambda_min_distance: 0, lambda_chamfer: 10.211\n",
      "Epoch 0: loss = 1320.8708141309796\n",
      "before loss.backward(): Allocated: 934.442496 MB, Reserved: 1098.907648 MB\n",
      "After loss.backward(): Allocated: 60.956672 MB, Reserved: 1107.296256 MB\n",
      "-----------------\n",
      "mnfld torch.Size([32768, 3])\n",
      "points torch.Size([2965, 3])\n",
      "After Chamfer loss PYTORCH3D 0.09018213549944498 : Allocated: 64.257024 MB,                  Reserved: 1107.296256 MB\n",
      "After site loss and Before model loss : Allocated: 64.257024 MB,                  Reserved: 1107.296256 MB\n",
      "lambda_sdf: 5000.0, lambda_eikonal: 50.0, lambda_div: 500.0, lambda_domain_restriction: 100\n",
      "sdf_term: 0.1480062428466339, eikonal_term: 0.28696243128245114, div_loss: 0.4301589945436598, domain_restriction_loss: 0.0\n",
      "Epoch 1: model_loss = 969.458833069122\n",
      "cvt_loss: 0.1428849266030841, chamfer_loss: 0.09018213549944498\n",
      "Epoch 1: site_loss = 36.92785128956203\n",
      "lambda_cvt: 252, lambda_min_distance: 0, lambda_chamfer: 10.211\n",
      "Epoch 1: loss = 1006.386684358684\n",
      "before loss.backward(): Allocated: 937.107968 MB, Reserved: 1107.296256 MB\n",
      "After loss.backward(): Allocated: 62.223872 MB, Reserved: 1109.393408 MB\n",
      "-----------------\n",
      "mnfld torch.Size([32768, 3])\n",
      "points torch.Size([2700, 3])\n",
      "After Chamfer loss PYTORCH3D 0.07029879992484842 : Allocated: 64.045056 MB,                  Reserved: 1109.393408 MB\n",
      "After site loss and Before model loss : Allocated: 64.045056 MB,                  Reserved: 1109.393408 MB\n",
      "lambda_sdf: 5000.0, lambda_eikonal: 50.0, lambda_div: 500.0, lambda_domain_restriction: 100\n",
      "sdf_term: 0.12989786746059284, eikonal_term: 0.27109033911447455, div_loss: 0.42568153470305203, domain_restriction_loss: 0.0\n",
      "Epoch 2: model_loss = 875.884621610214\n",
      "cvt_loss: 0.15450976566037727, chamfer_loss: 0.07029879992484842\n",
      "Epoch 2: site_loss = 39.6542819924477\n",
      "lambda_cvt: 252, lambda_min_distance: 0, lambda_chamfer: 10.211\n",
      "Epoch 2: loss = 915.5389036026618\n",
      "before loss.backward(): Allocated: 936.896 MB, Reserved: 1109.393408 MB\n",
      "After loss.backward(): Allocated: 62.208 MB, Reserved: 1109.393408 MB\n",
      "-----------------\n",
      "mnfld torch.Size([32768, 3])\n",
      "points torch.Size([2462, 3])\n",
      "After Chamfer loss PYTORCH3D 0.06088362192130052 : Allocated: 63.855616 MB,                  Reserved: 1109.393408 MB\n",
      "After site loss and Before model loss : Allocated: 63.855616 MB,                  Reserved: 1109.393408 MB\n",
      "lambda_sdf: 5000.0, lambda_eikonal: 50.0, lambda_div: 500.0, lambda_domain_restriction: 100\n",
      "sdf_term: 0.11567909918790385, eikonal_term: 0.25782622420894136, div_loss: 0.4211582697230732, domain_restriction_loss: 0.0\n",
      "Epoch 3: model_loss = 801.865942011503\n",
      "cvt_loss: 0.1482608291689177, chamfer_loss: 0.06088362192130052\n",
      "Epoch 3: site_loss = 37.98341161400566\n",
      "lambda_cvt: 252, lambda_min_distance: 0, lambda_chamfer: 10.211\n",
      "Epoch 3: loss = 839.8493536255087\n",
      "before loss.backward(): Allocated: 936.70656 MB, Reserved: 1109.393408 MB\n",
      "After loss.backward(): Allocated: 62.193664 MB, Reserved: 1109.393408 MB\n",
      "-----------------\n",
      "mnfld torch.Size([32768, 3])\n",
      "points torch.Size([2294, 3])\n",
      "After Chamfer loss PYTORCH3D 0.048577553539622204 : Allocated: 63.716864 MB,                  Reserved: 1109.393408 MB\n",
      "After site loss and Before model loss : Allocated: 63.716864 MB,                  Reserved: 1109.393408 MB\n",
      "lambda_sdf: 5000.0, lambda_eikonal: 50.0, lambda_div: 416.6666666666667, lambda_domain_restriction: 100\n",
      "sdf_term: 0.10612533097169616, eikonal_term: 0.247392923944563, div_loss: 0.41719164050025026, domain_restriction_loss: 0.0\n",
      "Epoch 4: model_loss = 716.8261512641466\n",
      "cvt_loss: 0.1543705111130832, chamfer_loss: 0.048577553539622204\n",
      "Epoch 4: site_loss = 39.39739419969005\n",
      "lambda_cvt: 252, lambda_min_distance: 0, lambda_chamfer: 10.211\n",
      "Epoch 4: loss = 756.2235454638367\n",
      "before loss.backward(): Allocated: 936.567808 MB, Reserved: 1109.393408 MB\n",
      "After loss.backward(): Allocated: 62.183424 MB, Reserved: 1109.393408 MB\n",
      "-----------------\n",
      "mnfld torch.Size([32768, 3])\n",
      "points torch.Size([2053, 3])\n",
      "After Chamfer loss PYTORCH3D 0.03875284130952079 : Allocated: 63.524864 MB,                  Reserved: 1109.393408 MB\n",
      "After site loss and Before model loss : Allocated: 63.524864 MB,                  Reserved: 1109.393408 MB\n",
      "lambda_sdf: 5000.0, lambda_eikonal: 50.0, lambda_div: 333.33333333333337, lambda_domain_restriction: 100\n",
      "sdf_term: 0.10086931581479375, eikonal_term: 0.23922034845529944, div_loss: 0.4134864044771591, domain_restriction_loss: 0.0\n",
      "Epoch 5: model_loss = 654.13639798912\n",
      "cvt_loss: 0.1245151425061641, chamfer_loss: 0.03875284130952079\n",
      "Epoch 5: site_loss = 31.773521174164873\n",
      "lambda_cvt: 252, lambda_min_distance: 0, lambda_chamfer: 10.211\n",
      "Epoch 5: loss = 685.9099191632849\n",
      "before loss.backward(): Allocated: 936.375808 MB, Reserved: 1109.393408 MB\n",
      "After loss.backward(): Allocated: 62.168576 MB, Reserved: 1109.393408 MB\n",
      "-----------------\n",
      "mnfld torch.Size([32768, 3])\n",
      "points torch.Size([1884, 3])\n",
      "After Chamfer loss PYTORCH3D 0.03449786746719531 : Allocated: 63.387136 MB,                  Reserved: 1109.393408 MB\n",
      "After site loss and Before model loss : Allocated: 63.387136 MB,                  Reserved: 1109.393408 MB\n",
      "lambda_sdf: 5000.0, lambda_eikonal: 50.0, lambda_div: 250.00000000000003, lambda_domain_restriction: 100\n",
      "sdf_term: 0.0990351002208535, eikonal_term: 0.23314981479241834, div_loss: 0.41008321168799355, domain_restriction_loss: 0.0\n",
      "Epoch 6: model_loss = 609.3537947658868\n",
      "cvt_loss: 0.1645484591080586, chamfer_loss: 0.03449786746719531\n",
      "Epoch 6: site_loss = 41.8184694199383\n",
      "lambda_cvt: 252, lambda_min_distance: 0, lambda_chamfer: 10.211\n",
      "Epoch 6: loss = 651.1722641858252\n",
      "before loss.backward(): Allocated: 936.23808 MB, Reserved: 1109.393408 MB\n",
      "After loss.backward(): Allocated: 62.158848 MB, Reserved: 1109.393408 MB\n",
      "-----------------\n",
      "sites length BEFORE UPSAMPLING:  4096\n",
      "Sites to upsample  torch.Size([344])\n",
      "sites length AFTER:  5472\n",
      "mnfld torch.Size([32768, 3])\n",
      "points torch.Size([4975, 3])\n",
      "After Chamfer loss PYTORCH3D 0.030985184130366154 : Allocated: 64.89344 MB,                  Reserved: 1109.393408 MB\n",
      "After site loss and Before model loss : Allocated: 64.89344 MB,                  Reserved: 1109.393408 MB\n",
      "lambda_sdf: 5000.0, lambda_eikonal: 50.0, lambda_div: 166.66666666666674, lambda_domain_restriction: 100\n",
      "sdf_term: 0.09930031924052482, eikonal_term: 0.22934975535865215, div_loss: 0.40682800206969916, domain_restriction_loss: 0.0\n",
      "Epoch 7: model_loss = 575.7737509821733\n",
      "cvt_loss: 0.14758990719782475, chamfer_loss: 0.030985184130366154\n",
      "Epoch 7: site_loss = 37.509046329007006\n",
      "lambda_cvt: 252, lambda_min_distance: 0, lambda_chamfer: 10.211\n",
      "Epoch 7: loss = 613.2827973111803\n",
      "before loss.backward(): Allocated: 937.744384 MB, Reserved: 1109.393408 MB\n",
      "After loss.backward(): Allocated: 61.327872 MB, Reserved: 1109.393408 MB\n",
      "-----------------\n",
      "mnfld torch.Size([32768, 3])\n",
      "points torch.Size([5601, 3])\n",
      "After Chamfer loss PYTORCH3D 0.031992760707614615 : Allocated: 66.78016 MB,                  Reserved: 1109.393408 MB\n",
      "After site loss and Before model loss : Allocated: 66.78016 MB,                  Reserved: 1109.393408 MB\n",
      "lambda_sdf: 5000.0, lambda_eikonal: 50.0, lambda_div: 83.33333333333343, lambda_domain_restriction: 100\n",
      "sdf_term: 0.09119414229297423, eikonal_term: 0.24193230502081817, div_loss: 0.4096104629313, domain_restriction_loss: 0.0\n",
      "Epoch 8: model_loss = 502.20153196018714\n",
      "cvt_loss: 0.15421666135396075, chamfer_loss: 0.031992760707614615\n",
      "Epoch 8: site_loss = 39.18927674078357\n",
      "lambda_cvt: 252, lambda_min_distance: 0, lambda_chamfer: 10.211\n",
      "Epoch 8: loss = 541.3908087009708\n",
      "before loss.backward(): Allocated: 939.631104 MB, Reserved: 1109.393408 MB\n",
      "After loss.backward(): Allocated: 62.747648 MB, Reserved: 1113.587712 MB\n",
      "-----------------\n",
      "mnfld torch.Size([32768, 3])\n",
      "points torch.Size([5557, 3])\n",
      "After Chamfer loss PYTORCH3D 0.03076445156066761 : Allocated: 66.748416 MB,                  Reserved: 1113.587712 MB\n",
      "After site loss and Before model loss : Allocated: 66.748416 MB,                  Reserved: 1113.587712 MB\n",
      "lambda_sdf: 5000.0, lambda_eikonal: 50.0, lambda_div: 0.0, lambda_domain_restriction: 100\n",
      "sdf_term: 0.08571845199582756, eikonal_term: 0.24855580645809178, div_loss: 0.4079015335218872, domain_restriction_loss: 0.0\n",
      "Epoch 9: model_loss = 441.02005030204236\n",
      "cvt_loss: 0.1596990752221596, chamfer_loss: 0.03076445156066761\n",
      "Epoch 9: site_loss = 40.5583027708702\n",
      "lambda_cvt: 252, lambda_min_distance: 0, lambda_chamfer: 10.211\n",
      "Epoch 9: loss = 481.5783530729126\n",
      "before loss.backward(): Allocated: 939.59936 MB, Reserved: 1113.587712 MB\n",
      "After loss.backward(): Allocated: 62.745088 MB, Reserved: 1113.587712 MB\n",
      "-----------------\n",
      "mnfld torch.Size([32768, 3])\n",
      "points torch.Size([5284, 3])\n",
      "After Chamfer loss PYTORCH3D 0.027015702044383357 : Allocated: 66.515968 MB,                  Reserved: 1113.587712 MB\n",
      "After site loss and Before model loss : Allocated: 66.515968 MB,                  Reserved: 1113.587712 MB\n",
      "lambda_sdf: 5000.0, lambda_eikonal: 50.0, lambda_div: 0.0, lambda_domain_restriction: 100\n",
      "sdf_term: 0.08009477485229306, eikonal_term: 0.25205283631670655, div_loss: 0.40559498787058923, domain_restriction_loss: 0.0\n",
      "Epoch 10: model_loss = 413.07651607730065\n",
      "cvt_loss: 0.15792227176114385, chamfer_loss: 0.027015702044383357\n",
      "Epoch 10: site_loss = 40.07226981738344\n",
      "lambda_cvt: 252, lambda_min_distance: 0, lambda_chamfer: 10.211\n",
      "Epoch 10: loss = 453.1487858946841\n",
      "before loss.backward(): Allocated: 939.366912 MB, Reserved: 1113.587712 MB\n",
      "After loss.backward(): Allocated: 62.728192 MB, Reserved: 1113.587712 MB\n",
      "-----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-04-03 17:14:05 92541:92541 ActivityProfilerController.cpp:317] Completed Stage: Collection\n",
      "STAGE:2025-04-03 17:14:05 92541:92541 ActivityProfilerController.cpp:321] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                               aten::mm         0.30%      28.603ms         1.15%     109.429ms      88.392us        1.632s        43.91%        1.671s       1.349ms          1238  \n",
      "void cutlass::Kernel<cutlass_80_tensorop_d884gemm_64...         0.00%       0.000us         0.00%       0.000us       0.000us     549.633ms        14.79%     549.633ms       2.082ms           264  \n",
      "void cutlass::Kernel<cutlass_80_tensorop_d884gemm_64...         0.00%       0.000us         0.00%       0.000us       0.000us     490.405ms        13.19%     490.405ms       2.229ms           220  \n",
      "void cutlass::Kernel<cutlass_80_tensorop_d884gemm_64...         0.00%       0.000us         0.00%       0.000us       0.000us     457.608ms        12.31%     457.608ms       2.080ms           220  \n",
      "                               aten::linalg_vector_norm         6.25%     595.437ms         8.99%     856.129ms       8.108us     423.614ms        11.40%     477.540ms       4.522us        105597  \n",
      "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us     423.614ms        11.40%     423.614ms       4.012us        105597  \n",
      "                                            _knn_points         0.01%       1.416ms         0.21%      19.719ms     896.318us     417.862ms        11.24%     418.155ms      19.007ms            22  \n",
      "void KNearestNeighborKernelV3<double, 3, 1>(double c...         0.00%       0.000us         0.00%       0.000us       0.000us     417.862ms        11.24%     417.862ms      18.994ms            22  \n",
      "                                              aten::sub         3.73%     355.487ms         6.16%     586.494ms       5.557us     319.744ms         8.60%     362.398ms       3.434us        105545  \n",
      "void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us     319.518ms         8.60%     319.518ms       3.029us        105487  \n",
      "                                               aten::lt         3.50%     333.558ms         5.88%     559.762ms       5.307us     317.320ms         8.54%     359.573ms       3.409us        105476  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     304.971ms         8.21%     304.971ms       3.009us        101369  \n",
      "                                       cudaLaunchKernel        10.45%     995.743ms        10.45%     995.743ms       3.020us     293.637ms         7.90%     299.302ms       0.908us        329665  \n",
      "                                            aten::copy_         2.98%     283.421ms        21.34%        2.033s      19.039us     227.243ms         6.11%     342.692ms       3.210us        106765  \n",
      "                       Memcpy HtoD (Pageable -> Device)         0.00%       0.000us         0.00%       0.000us       0.000us     221.921ms         5.97%     221.921ms       2.101us        105620  \n",
      "                       Memcpy DtoH (Device -> Pageable)         0.00%       0.000us         0.00%       0.000us       0.000us     221.000ms         5.95%     221.000ms       2.009us        109991  \n",
      "                              aten::_local_scalar_dense         2.67%     253.832ms        37.56%        3.577s      32.538us     220.299ms         5.93%     304.088ms       2.766us        109938  \n",
      "                                        cudaMemcpyAsync        36.38%        3.465s        36.38%        3.465s      16.040us     105.333ms         2.83%     105.335ms       0.488us        216008  \n",
      "                                  cudaStreamSynchronize        16.82%        1.602s        16.82%        1.602s       7.431us      93.555ms         2.52%      93.643ms       0.434us        215633  \n",
      "                               aten::threshold_backward         0.03%       2.835ms         0.11%      10.136ms      18.805us      57.129ms         1.54%      66.914ms     124.145us           539  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      57.129ms         1.54%      57.129ms     105.991us           539  \n",
      "void cutlass::Kernel<cutlass_80_tensorop_d884gemm_32...         0.00%       0.000us         0.00%       0.000us       0.000us      39.338ms         1.06%      39.338ms     357.618us           110  \n",
      "void cutlass::Kernel<cutlass_80_tensorop_d884gemm_32...         0.00%       0.000us         0.00%       0.000us       0.000us      31.817ms         0.86%      31.817ms     482.076us            66  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      30.937ms         0.83%      30.937ms      19.921us          1553  \n",
      "void cutlass::Kernel<cutlass_80_tensorop_d884gemm_64...         0.00%       0.000us         0.00%       0.000us       0.000us      28.390ms         0.76%      28.390ms     246.870us           115  \n",
      "                                             aten::add_         0.02%       2.210ms         0.05%       4.348ms       3.907us      23.501ms         0.63%      28.925ms      25.988us          1113  \n",
      "                                  ampere_dgemm_64x64_tn         0.00%       0.000us         0.00%       0.000us       0.000us      17.285ms         0.47%      17.285ms     261.894us            66  \n",
      "                                            aten::fill_         0.03%       2.660ms         0.12%      11.807ms       9.568us      13.088ms         0.35%      24.003ms      19.451us          1234  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      12.644ms         0.34%      12.644ms      11.505us          1099  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      12.600ms         0.34%      12.600ms       3.011us          4185  \n",
      "                                              aten::mul         0.12%      11.312ms         0.20%      18.588ms       7.356us      11.824ms         0.32%      62.124ms      24.584us          2527  \n",
      "void cutlass::Kernel<cutlass_80_tensorop_d884gemm_64...         0.00%       0.000us         0.00%       0.000us       0.000us      10.696ms         0.29%      10.696ms     243.091us            44  \n",
      "                                   cudaFuncSetAttribute         0.00%      75.000us         0.00%      75.000us       0.087us      10.373ms         0.28%      10.373ms      12.020us           863  \n",
      "cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFla...         0.27%      25.637ms         0.27%      25.637ms      21.031us      10.210ms         0.27%      10.212ms       8.377us          1219  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      10.036ms         0.27%      10.036ms      40.468us           248  \n",
      "                                        aten::clamp_min         0.02%       1.475ms         0.09%       8.854ms      37.517us       9.998ms         0.27%      19.897ms      84.309us           236  \n",
      "                                              aten::add         0.04%       4.273ms         0.06%       6.190ms       7.855us       8.869ms         0.24%      14.473ms      18.367us           788  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       6.946ms         0.19%       6.946ms       5.104us          1361  \n",
      "                                 cudaDeviceGetAttribute         0.00%      35.000us         0.00%      35.000us       0.140us       4.725ms         0.13%       4.725ms      18.900us           250  \n",
      "                                    cudaPeekAtLastError         0.00%       0.000us         0.00%       0.000us       0.000us       4.008ms         0.11%       4.008ms       5.726us           700  \n",
      "                                              aten::sin         0.02%       1.925ms         0.13%      12.738ms      38.367us       3.505ms         0.09%       5.399ms      16.262us           332  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       3.505ms         0.09%       3.505ms      10.557us           332  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       3.462ms         0.09%       3.462ms       4.555us           760  \n",
      "                                              aten::cos         0.03%       2.995ms         0.10%       9.114ms      27.452us       3.434ms         0.09%       8.469ms      25.509us           332  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       3.434ms         0.09%       3.434ms      10.343us           332  \n",
      "                                       aten::unique_dim         0.01%       1.345ms         0.41%      39.371ms       3.579ms       2.738ms         0.07%      15.456ms       1.405ms            11  \n",
      "                                  cudaStreamIsCapturing         0.00%      41.000us         0.00%      41.000us       0.228us       2.683ms         0.07%       2.683ms      14.906us           180  \n",
      "void splitKreduce_kernel<32, 16, int, double, double...         0.00%       0.000us         0.00%       0.000us       0.000us       2.175ms         0.06%       2.175ms       5.816us           374  \n",
      "          cudaOccupancyMaxActiveBlocksPerMultiprocessor         0.01%     767.000us         0.01%     767.000us      11.448us       2.121ms         0.06%       2.121ms      31.657us            67  \n",
      "                                             aten::sort         0.02%       1.640ms         0.21%      19.974ms       1.665ms       2.112ms         0.06%       3.086ms     257.167us            12  \n",
      "void at::native::bitonicSortKVInPlace<2, -1, 16, 16,...         0.00%       0.000us         0.00%       0.000us       0.000us       2.112ms         0.06%       2.112ms     192.000us            11  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       1.949ms         0.05%       1.949ms       5.156us           378  \n",
      "                                              aten::neg         0.02%       2.078ms         0.12%      11.440ms      26.000us       1.869ms         0.05%       2.109ms       4.793us           440  \n",
      "                                              aten::div         0.02%       2.079ms         0.03%       3.320ms       7.444us       1.808ms         0.05%       6.433ms      14.424us           446  \n",
      "                                              aten::sum         0.04%       3.995ms         0.12%      11.881ms      40.969us       1.762ms         0.05%       4.281ms      14.762us           290  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       1.742ms         0.05%       1.742ms       4.280us           407  \n",
      "void gemvNSP_kernel<double, double, double, double, ...         0.00%       0.000us         0.00%       0.000us       0.000us       1.623ms         0.04%       1.623ms      36.886us            44  \n",
      "                                aten::_foreach_addcdiv_         0.00%     347.000us         0.00%     446.000us      20.273us       1.618ms         0.04%       1.620ms      73.636us            22  \n",
      "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us       1.618ms         0.04%       1.618ms      73.545us            22  \n",
      "void gemv2T_kernel_val<int, int, double, double, dou...         0.00%       0.000us         0.00%       0.000us       0.000us       1.584ms         0.04%       1.584ms      35.200us            45  \n",
      "                                    aten::_foreach_div_         0.01%     489.000us         0.06%       5.914ms     268.818us       1.496ms         0.04%       1.508ms      68.545us            22  \n",
      "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us       1.496ms         0.04%       1.496ms      68.000us            22  \n",
      "void gemmk1_kernel<int, double, 256, 5, false, false...         0.00%       0.000us         0.00%       0.000us       0.000us       1.410ms         0.04%       1.410ms      32.045us            44  \n",
      "                         Memcpy DtoD (Device -> Device)         0.00%       0.000us         0.00%       0.000us       0.000us       1.382ms         0.04%       1.382ms       3.481us           397  \n",
      "                                            aten::index         0.02%       2.112ms         0.07%       6.600ms      27.500us       1.341ms         0.04%       7.108ms      29.617us           240  \n",
      "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us       1.340ms         0.04%       1.340ms       6.768us           198  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       1.202ms         0.03%       1.202ms       4.553us           264  \n",
      "void thrust::cuda_cub::core::_kernel_agent<thrust::c...         0.00%       0.000us         0.00%       0.000us       0.000us       1.193ms         0.03%       1.193ms      15.494us            77  \n",
      "                                             aten::mean         0.01%     850.000us         0.14%      13.107ms     187.243us       1.120ms         0.03%       1.158ms      16.543us            70  \n",
      "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us       1.120ms         0.03%       1.120ms      16.970us            66  \n",
      "                                 aten::_index_put_impl_         0.01%       1.201ms         0.37%      35.608ms       1.079ms       1.006ms         0.03%       3.905ms     118.333us            33  \n",
      "                                          aten::normal_         0.01%     553.000us         0.01%     833.000us       7.573us     988.000us         0.03%       1.750ms      15.909us           110  \n",
      "void at::native::(anonymous namespace)::distribution...         0.00%       0.000us         0.00%       0.000us       0.000us     988.000us         0.03%     988.000us       8.982us           110  \n",
      "                                              aten::cat         0.02%       1.745ms         0.02%       2.309ms      15.815us     969.000us         0.03%       1.121ms       7.678us           146  \n",
      "                                    aten::_foreach_sqrt         0.01%     951.000us         0.19%      17.719ms     805.409us     954.000us         0.03%       3.023ms     137.409us            22  \n",
      "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us     954.000us         0.03%     954.000us      43.364us            22  \n",
      "                                           aten::arange         0.01%       1.407ms         0.09%       8.965ms      17.717us     787.000us         0.02%       6.966ms      13.767us           506  \n",
      "void at::native::index_elementwise_kernel<128, 4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     759.000us         0.02%     759.000us       5.540us           137  \n",
      "void thrust::cuda_cub::core::_kernel_agent<thrust::c...         0.00%       0.000us         0.00%       0.000us       0.000us     734.000us         0.02%     734.000us       9.532us            77  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     689.000us         0.02%     689.000us       3.297us           209  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     687.000us         0.02%     687.000us       4.461us           154  \n",
      "void at::native::(anonymous namespace)::CatArrayBatc...         0.00%       0.000us         0.00%       0.000us       0.000us     662.000us         0.02%     662.000us       7.275us            91  \n",
      "void (anonymous namespace)::elementwise_kernel_with_...         0.00%       0.000us         0.00%       0.000us       0.000us     655.000us         0.02%     655.000us       3.134us           209  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     612.000us         0.02%     612.000us       4.280us           143  \n",
      "void thrust::cuda_cub::core::_kernel_agent<thrust::c...         0.00%       0.000us         0.00%       0.000us       0.000us     606.000us         0.02%     606.000us      55.091us            11  \n",
      "                                  aten::linalg_lu_solve         0.01%       1.246ms         0.10%       9.489ms     215.659us     597.000us         0.02%       4.016ms      91.273us            44  \n",
      "void at::native::index_elementwise_kernel<128, 4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     582.000us         0.02%     582.000us       5.650us           103  \n",
      "                                             cudaMalloc         0.05%       4.338ms         0.05%       4.338ms      66.738us     523.000us         0.01%     540.000us       8.308us            65  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     503.000us         0.01%     503.000us       4.491us           112  \n",
      "void (anonymous namespace)::indexing_backward_kernel...         0.00%       0.000us         0.00%       0.000us       0.000us     407.000us         0.01%     407.000us      12.333us            33  \n",
      "                                          aten::nonzero         0.01%     637.000us         0.02%       1.561ms      67.870us     398.000us         0.01%       4.924ms     214.087us            23  \n",
      "                                    aten::_foreach_mul_         0.00%     200.000us         0.00%     352.000us       8.000us     384.000us         0.01%     413.000us       9.386us            44  \n",
      "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us     384.000us         0.01%     384.000us       8.727us            44  \n",
      "                                             aten::div_         0.02%       1.522ms         0.23%      21.633ms     240.367us     346.000us         0.01%       2.450ms      27.222us            90  \n",
      "                              aten::linalg_lu_factor_ex         0.18%      17.400ms         0.27%      25.457ms     578.568us     310.000us         0.01%       3.218ms      73.136us            44  \n",
      "void getrf_semiwarp<double, double, 2, 3, true>(int,...         0.00%       0.000us         0.00%       0.000us       0.000us     310.000us         0.01%     310.000us       7.045us            44  \n",
      "                                              aten::max         0.00%     117.000us         0.00%     166.000us      15.091us     309.000us         0.01%     311.000us      28.273us            11  \n",
      "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us     309.000us         0.01%     309.000us      28.091us            11  \n",
      "void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us     307.000us         0.01%     307.000us       4.515us            68  \n",
      "void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us     306.000us         0.01%     306.000us       4.636us            66  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 9.524s\n",
      "Self CUDA time total: 3.717s\n",
      "\n",
      "Sites length:  5472\n",
      "min sites:  tensor(-1.7825, grad_fn=<MinBackward1>)\n",
      "max sites:  tensor(1.8594, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "lambda_weights = [252,0,0,0,10.211,0,100,0]\n",
    "\n",
    "lambda_cvt = lambda_weights[0]\n",
    "lambda_sdf = lambda_weights[1]\n",
    "lambda_min_distance = lambda_weights[2]\n",
    "lambda_laplace = lambda_weights[3]\n",
    "lamda_chamfer = lambda_weights[4]\n",
    "lambda_eikonal = lambda_weights[5]\n",
    "lambda_domain_restriction = lambda_weights[6]\n",
    "lambda_true_points = lambda_weights[7]\n",
    "\n",
    "max_iter = 10\n",
    "\n",
    "site_file_path = f'{destination}{max_iter}_cvt_{lambda_cvt}_chamfer_{lamda_chamfer}_eikonal_{lambda_eikonal}.npy'\n",
    "#check if optimized sites file exists\n",
    "if os.path.exists(site_file_path):\n",
    "    #import sites\n",
    "    print(\"Importing sites\")\n",
    "    sites = np.load(site_file_path)\n",
    "    sites = torch.from_numpy(sites).to(device).requires_grad_(True)\n",
    "else:\n",
    "    # import cProfile, pstats\n",
    "    # import time\n",
    "    # profiler = cProfile.Profile()\n",
    "    # profiler.enable()\n",
    "    with torch.profiler.profile(activities=[\n",
    "            torch.profiler.ProfilerActivity.CPU,\n",
    "            torch.profiler.ProfilerActivity.CUDA,\n",
    "        ],\n",
    "        record_shapes=False,\n",
    "        with_stack=True  # Captures function calls\n",
    "    ) as prof:\n",
    "        sites = autograd(sites, model, max_iter=max_iter, upsampling=1, lambda_weights=lambda_weights)\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "    print(prof.key_averages().table(sort_by=\"self_cuda_time_total\"))\n",
    "    prof.export_chrome_trace(\"trace.json\")\n",
    "\n",
    "    \n",
    "    # profiler.disable()\n",
    "    # stats = pstats.Stats(profiler).sort_stats('cumtime')\n",
    "    # stats.print_stats()\n",
    "    # stats.dump_stats(f'{destination}{mesh[0]}{max_iter}_3d_profile_{num_centroids}_chamfer{lamda_chamfer}.prof')\n",
    "    \n",
    "    \n",
    "    sites_np = sites.detach().cpu().numpy()\n",
    "    np.save(site_file_path, sites_np)\n",
    "    \n",
    "    \n",
    "\n",
    "print(\"Sites length: \", len(sites))\n",
    "print(\"min sites: \", torch.min(sites))\n",
    "print(\"max sites: \", torch.max(sites))\n",
    "#ps_cloud = ps.register_point_cloud(\"best_optimized_cvt_grid\",sites.detach().cpu().numpy())\n",
    "    \n",
    "lim=torch.abs(torch.max(sites)).detach().cpu().numpy()*1.1\n",
    "#plot_voronoi_3d(sites,lim,lim,lim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './images/autograd/3Dsteik/bunny10_80_3d_sites_4096_chamfer10.211.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m model_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdestination\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmesh[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmax_iter\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_3d_model_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_centroids\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_chamfer\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlamda_chamfer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m site_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdestination\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmesh[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmax_iter\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_3d_sites_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_centroids\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_chamfer\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlamda_chamfer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 5\u001b[0m sites \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43msite_file_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m sites_np \u001b[38;5;241m=\u001b[39m sites\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(model_file_path))\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/serialization.py:791\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    789\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 791\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    792\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    793\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    794\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    795\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    796\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/serialization.py:271\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 271\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    273\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/serialization.py:252\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 252\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './images/autograd/3Dsteik/bunny10_80_3d_sites_4096_chamfer10.211.pth'"
     ]
    }
   ],
   "source": [
    "epoch = 80\n",
    "model_file_path = f'{destination}{mesh[0]}{max_iter}_{epoch}_3d_model_{num_centroids}_chamfer{lamda_chamfer}.pth'\n",
    "site_file_path = f'{destination}{mesh[0]}{max_iter}_{epoch}_3d_sites_{num_centroids}_chamfer{lamda_chamfer}.pth'\n",
    " \n",
    "sites = torch.load(site_file_path)\n",
    "sites_np = sites.detach().cpu().numpy()\n",
    "model.load_state_dict(torch.load(model_file_path))\n",
    "#\n",
    "#polyscope_sdf(model)\n",
    "#\n",
    "print(\"model\", model_file_path)\n",
    "print(\"sites\", site_file_path)\n",
    "ps_cloud = ps.register_point_cloud(f\"{epoch} epoch_cvt_grid\",sites_np)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(tensor([[-0.7514,  0.3576,  0.1730],\n",
      "        [-0.7510,  0.3492,  0.1581],\n",
      "        [-0.7354,  0.2278,  0.1657],\n",
      "        ...,\n",
      "        [ 0.0471, -0.6209,  0.1085],\n",
      "        [ 0.5156, -0.6165, -0.2341],\n",
      "        [ 0.5821, -0.5595, -0.2387]], grad_fn=<SumBackward1>),), (tensor([[34328,    72,   415],\n",
      "        [  416,   414,   415],\n",
      "        [34379, 24851, 34385],\n",
      "        ...,\n",
      "        [31334, 28718, 27681],\n",
      "        [27684, 28721, 27681],\n",
      "        [27684, 46654, 28721]]),)]\n"
     ]
    }
   ],
   "source": [
    "final_mesh = su.get_zero_crossing_mesh_3d(sites, model)\n",
    "ps.register_point_cloud(\"mnfld\", mnfld_points.detach().cpu().numpy())\n",
    "\n",
    "ps.register_surface_mesh(\"Zero-Crossing faces final\", final_mesh[0], final_mesh[1])\n",
    "#polyscope_sdf(model,2)\n",
    "\n",
    "import scipy.spatial as spatial\n",
    "from scipy.spatial import Delaunay\n",
    "\n",
    "tri = Delaunay(sites_np)\n",
    "delaunay_vertices =torch.tensor(np.array(tri.simplices), device=device)\n",
    "sdf_values = model(sites)\n",
    "\n",
    "\n",
    "# Assuming sites is a PyTorch tensor of shape [M, 3]\n",
    "sites = sites.unsqueeze(0)  # Now shape [1, M, 3]\n",
    "\n",
    "# Assuming SDF_Values is a PyTorch tensor of shape [M]\n",
    "sdf_values = sdf_values.unsqueeze(0)  # Now shape [1, M]\n",
    "\n",
    "marching_tetrehedra_mesh = kaolin.ops.conversions.marching_tetrahedra(sites, delaunay_vertices, sdf_values, return_tet_idx=False)\n",
    "print(marching_tetrehedra_mesh)\n",
    "vertices_list, faces_list = marching_tetrehedra_mesh\n",
    "vertices = vertices_list[0]\n",
    "faces = faces_list[0]\n",
    "vertices_np = vertices.detach().cpu().numpy()  # Shape [N, 3]\n",
    "faces_np = faces.detach().cpu().numpy()  # Shape [M, 3] (triangles)\n",
    "ps.register_surface_mesh(\"Marching Tetrahedra Mesh final\", vertices_np, faces_np)\n",
    "\n",
    "\n",
    "ps.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_visualisation_3d():\n",
    "    import imageio\n",
    "    img_buffer_mesh = []\n",
    "    img_buffer_model = []\n",
    "    for i in range(int(max_iter/10)+1):\n",
    "        epoch = i*int(max_iter/10)\n",
    "        \n",
    "        site_file_path = f'{destination}{mesh[0]}{max_iter}_{epoch}_3d_sites_{num_centroids}_chamfer{lamda_chamfer}.pth'\n",
    "        model_file_path = f'{destination}{mesh[0]}{max_iter}_{epoch}_3d_model_{num_centroids}_chamfer{lamda_chamfer}.pth'\n",
    "        if os.path.exists(site_file_path) and os.path.exists(model_file_path):\n",
    "            print(\"importing sites and model\")\n",
    "        else:\n",
    "            print(\"files not found\")\n",
    "            continue\n",
    "        print(\"mesh of epoch: \", epoch)\n",
    "        \n",
    "        model.load_state_dict(torch.load(model_file_path))\n",
    "    \n",
    "        current_mesh = su.get_zero_crossing_mesh_3d(torch.load(site_file_path), model)\n",
    "        ps.remove_all_structures()\n",
    "        ps.register_surface_mesh(\"Zero-Crossing faces\", current_mesh[0], current_mesh[1])\n",
    "        ps.register_point_cloud(\"Mesh vertices\", current_mesh[0])\n",
    "        img_buffer_mesh.append(ps.screenshot_to_buffer(transparent_bg=False))\n",
    "        \n",
    "        ps.remove_all_structures()\n",
    "        #polyscope_sdf(model)\n",
    "        img_buffer_model.append(ps.screenshot_to_buffer(transparent_bg=False))\n",
    "\n",
    "\n",
    "    imageio.mimsave(f'{destination}{max_iter}_3d_{num_centroids}_optimization_mesh.gif',img_buffer_mesh, fps=1, duration=1, loop=0)\n",
    "    imageio.mimsave(f'{destination}{max_iter}_3d_{num_centroids}_optimization_sdf.gif', img_buffer_model, fps=1, duration=1, loop=0)\n",
    "\n",
    "#export_visualisation_3d()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
