{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "Using device:  NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "import kaolin\n",
    "import torch\n",
    "import math\n",
    "import matplotlib\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import polyscope as ps\n",
    "import trimesh\n",
    "\n",
    "from scipy.spatial import Voronoi, voronoi_plot_2d, Delaunay\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import sdfpred_utils.sdfpred_utils as su\n",
    "import sdfpred_utils.sdf_MLP as mlp\n",
    "import sdfpred_utils.sdf_functions as sdf\n",
    "import sdfpred_utils.loss_functions as lf\n",
    "import sdfpred_utils.Steik_data3d as sd3d\n",
    "import sdfpred_utils.Steik_Loss as sl\n",
    "import sdfpred_utils.Steik_utils as Stu \n",
    "\n",
    "#cuda devices\n",
    "device = torch.device(\"cuda:0\")\n",
    "print(\"Using device: \", torch.cuda.get_device_name(device))\n",
    "\n",
    "#default tensor types\n",
    "torch.set_default_tensor_type(torch.cuda.DoubleTensor)\n",
    "\n",
    "multires = 2\n",
    "input_dims = 3\n",
    "lr_sites = 0.005/2\n",
    "lr_model = 0.00005*2\n",
    "destination = \"./images/autograd/3Dsteik/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new sites\n",
      "Meshgrid shape: torch.Size([13824, 3])\n",
      "Meshgrid 1st 5: tensor([[-1.5000, -1.5000, -1.5000],\n",
      "        [-1.5000, -1.5000, -1.3696],\n",
      "        [-1.5000, -1.5000, -1.2391],\n",
      "        [-1.5000, -1.5000, -1.1087],\n",
      "        [-1.5000, -1.5000, -0.9783]])\n",
      "Meshgrid 1st 5: tensor([[-1.2858, -1.4462, -1.5383],\n",
      "        [-1.5515, -1.6107, -1.5644],\n",
      "        [-1.4286, -1.4863, -1.1930],\n",
      "        [-1.7226, -1.4836, -1.1384],\n",
      "        [-1.4905, -1.4718, -0.9344]])\n",
      "Sites min: tensor([-1.8240, -1.8273, -1.8113], grad_fn=<MinBackward0>)\n",
      "Sites max: tensor([1.8093, 1.8716, 1.7822], grad_fn=<MaxBackward0>)\n",
      "Sites shape: torch.Size([13824, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wylliam/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1678402412426/work/aten/src/ATen/native/TensorShape.cpp:3483.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "#currently sites are between -5 and 5 in all 3 dimensions\n",
    "# check if sites exists\n",
    "#num_centroids = 16*16*16\n",
    "#num_centroids =16*16*16*8\n",
    "num_centroids = 24*24*24\n",
    "#num_centroids = 128*128*128\n",
    "\n",
    "site_fp = f'sites_{num_centroids}_{input_dims}.pt'\n",
    "\n",
    "# if os.path.exists(site_fp):\n",
    "#     sites = torch.load(site_fp)\n",
    "#     print(\"Sites loaded:\", sites.shape)\n",
    "# else:\n",
    "print(\"Creating new sites\")\n",
    "noise_scale = 0.1\n",
    "domain_limit = 1.5\n",
    "x = torch.linspace(-domain_limit, domain_limit, int(round(num_centroids**(1/3))))\n",
    "y = torch.linspace(-domain_limit, domain_limit, int(round(num_centroids**(1/3))))\n",
    "z = torch.linspace(-domain_limit, domain_limit, int(round(num_centroids**(1/3))))\n",
    "meshgrid = torch.meshgrid(x, y, z)\n",
    "meshgrid = torch.stack(meshgrid, dim=3).view(-1, 3)\n",
    "print(\"Meshgrid shape:\", meshgrid.shape)\n",
    "print(\"Meshgrid 1st 5:\", meshgrid[:5])\n",
    "#add noise to meshgrid\n",
    "meshgrid += torch.randn_like(meshgrid) * noise_scale\n",
    "print(\"Meshgrid 1st 5:\", meshgrid[:5])\n",
    "sites = meshgrid.to(device, dtype=torch.double).requires_grad_(True)\n",
    "\n",
    "#print min max sites \n",
    "print(\"Sites min:\", sites.min(dim=0).values)\n",
    "print(\"Sites max:\", sites.max(dim=0).values)\n",
    "print(\"Sites shape:\", sites.shape)\n",
    "\n",
    "#sites = su.createCVTgrid(num_centroids=num_centroids, dimensionality=input_dims)\n",
    "#save the initial sites torch tensor\n",
    "#torch.save(sites, site_fp)\n",
    "\n",
    "\n",
    "def plot_voronoi_3d(sites, xlim=5, ylim=5, zlim=5):\n",
    "    import numpy as np\n",
    "    import pyvoro\n",
    "    import matplotlib.pyplot as plt\n",
    "    from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "    # initialize random number generator\n",
    "    rng = np.random.default_rng(11)\n",
    "    # create a set of points in 3D\n",
    "    points = sites.detach().cpu().numpy()\n",
    "\n",
    "    # use pyvoro to compute the Voronoi tessellation\n",
    "    # the second argument gives the the axis limits in x,y and z direction\n",
    "    # in this case all between 0 and 1.\n",
    "    # the third argument gives \"dispersion = max distance between two points\n",
    "    # that might be adjacent\" (not sure how exactly this works)\n",
    "    voronoi = pyvoro.compute_voronoi(points,[[-xlim,xlim],[-ylim,ylim],[-zlim,zlim]],1)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # for each Voronoi cell, plot all the faces of the corresponding polygon\n",
    "    for vnoicell in voronoi:\n",
    "        faces = []\n",
    "        # the vertices are the corner points of the Voronoi cell\n",
    "        vertices = np.array(vnoicell['vertices'])\n",
    "        # cycle through all faces of the polygon\n",
    "        for face in vnoicell['faces']:\n",
    "            faces.append(vertices[np.array(face['vertices'])])\n",
    "            \n",
    "        # join the faces into a 3D polygon\n",
    "        polygon = Poly3DCollection(faces, alpha=0.5, \n",
    "                                facecolors=rng.uniform(0,1,3),\n",
    "                                linewidths=0.5,edgecolors='black')\n",
    "        ax.add_collection3d(polygon)\n",
    "    \n",
    "    ax.set_xlim([-xlim,xlim])\n",
    "    ax.set_ylim([-ylim,ylim])\n",
    "    ax.set_zlim([-zlim,zlim])\n",
    "            \n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def polyscope_sdf(model,i):\n",
    "    # Render the SDF as an implicit surface (zero-level set)\n",
    "    def model_sdf(pts):\n",
    "        pts_tensor = torch.tensor(pts, dtype=torch.float64, device=device)\n",
    "        sdf_values = model(pts_tensor)\n",
    "        sdf_values_np = sdf_values.detach().cpu().numpy().flatten()  # Convert to NumPy\n",
    "        \n",
    "        return sdf_values_np\n",
    "\n",
    "    ps.render_implicit_surface(f\"SDF Surface {i}\", model_sdf, mode=\"sphere_march\", enabled=True, subsample_factor=2)\n",
    "    \n",
    "def polyscope_marching_tet(model, sites, i=\"\"):\n",
    "    import scipy.spatial as spatial\n",
    "    from scipy.spatial import Delaunay\n",
    "\n",
    "    sites_np = sites.detach().cpu().numpy()\n",
    "    tri = Delaunay(sites_np)\n",
    "    delaunay_vertices =torch.tensor(np.array(tri.simplices), device=device)\n",
    "    sdf_values = model(sites)\n",
    "\n",
    "\n",
    "    # Assuming sites is a PyTorch tensor of shape [M, 3]\n",
    "    sites = sites.unsqueeze(0)  # Now shape [1, M, 3]\n",
    "\n",
    "    # Assuming SDF_Values is a PyTorch tensor of shape [M]\n",
    "    sdf_values = sdf_values.unsqueeze(0)  # Now shape [1, M]\n",
    "\n",
    "    marching_tetrehedra_mesh = kaolin.ops.conversions.marching_tetrahedra(sites, delaunay_vertices, sdf_values, return_tet_idx=False)\n",
    "    print(marching_tetrehedra_mesh)\n",
    "    vertices_list, faces_list = marching_tetrehedra_mesh\n",
    "    vertices = vertices_list[0]\n",
    "    faces = faces_list[0]\n",
    "    vertices_np = vertices.detach().cpu().numpy()  # Shape [N, 3]\n",
    "    faces_np = faces.detach().cpu().numpy()  # Shape [M, 3] (triangles)\n",
    "    ps.register_surface_mesh(f\"Marching Tetrahedra Mesh{i}\", vertices_np, faces_np)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#plot_voronoi_3d(sites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[polyscope] Backend: openGL3_glfw -- Loaded openGL version: 3.3.0 NVIDIA 570.133.07\n"
     ]
    }
   ],
   "source": [
    "ps.init()\n",
    "#ps_cloud = ps.register_point_cloud(\"initial_cvt_grid\",sites.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the mesh\n",
    "mesh = [\"bunny\", \"Resources/stanford-bunny.obj\"]\n",
    "# # #mesh = [\"staryu\", \"Resources/staryu.obj\"]\n",
    "# mesh = [\"chair\", \"Resources/chair_low.obj\"]\n",
    "\n",
    "# bunny = trimesh.load(mesh[1])\n",
    "# #target_points = bunny.sample(16*16*16)\n",
    "\n",
    "# target_points = bunny.sample(16*16*16 * 4)\n",
    "# target_points = target_points - np.mean(target_points, axis=0)\n",
    "# target_points = target_points / np.max(np.abs(target_points))\n",
    "\n",
    "\n",
    "# target_points = torch.tensor(target_points, device=device)\n",
    "# print(\"Target points:\", target_points.shape)\n",
    "# min_target = target_points.min(0)[0]\n",
    "# max_target = target_points.max(0)[0]\n",
    "# print(\"min_target\", min_target)\n",
    "# print(\"max_target\", max_target)\n",
    "\n",
    "# ps.register_point_cloud(\"Target_points\",target_points.detach().cpu().numpy())\n",
    "\n",
    "# #ps.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manifold points shape:  torch.Size([32768, 3])\n",
      "Manifold points normals GT shape:  torch.Size([32768, 3])\n",
      "Non-manifold points shape:  torch.Size([32768, 3])\n",
      "Manifold points min: tensor([-0.7275, -0.6536, -0.7516])\n",
      "Manifold points max: tensor([0.9453, 1.0000, 0.5421])\n"
     ]
    }
   ],
   "source": [
    "shape_type = 'bunny'\n",
    "res = 128 # has to be even\n",
    "example_idx = 0\n",
    "sample_type = 'grid'\n",
    "n_samples = 1\n",
    "n_points = 16*16*16*8\n",
    "#TODO: change to 3D look into Steik to make it work \n",
    "# dataset = sd2d.get2D_dataset(n_points, n_samples, res, sample_type, 0.005, shape_type=shape_type)  # BasicShape2D(100, 20, res=50)\n",
    "# dataloader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=False, num_workers=0, pin_memory=False)\n",
    "\n",
    "dataset = sd3d.ReconDataset(\"Resources/stanford-bunny.obj\", n_points, n_samples=n_samples)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False, num_workers=0 ,pin_memory=False)\n",
    "data = next(iter(dataloader))\n",
    "# print(\"Data keys: \", data.keys())\n",
    "# mnfld_points, normals_gt, nonmnfld_dist_gt, nonmnfld_points, nonmnfld_n_gt= data['points'].to(device), data['mnfld_n'].to(device), \\\n",
    "#                                                                             data['nonmnfld_dist'].to(device), \\\n",
    "#                                                                             data['nonmnfld_points'].to(device), data['nonmnfld_n'].to(device),\n",
    "mnfld_points, mnfld_n_gt, nonmnfld_points = data['points'].to(device), data['mnfld_n'].to(device),  data['nonmnfld_points'].to(device)\n",
    "\n",
    "mnfld_points = mnfld_points[0]\n",
    "mnfld_points = mnfld_points.double()\n",
    "mnfld_n_gt = mnfld_n_gt[0]\n",
    "mnfld_n_gt = mnfld_n_gt.double()\n",
    "nonmnfld_points = nonmnfld_points[0]\n",
    "nonmnfld_points = nonmnfld_points.double()\n",
    "\n",
    "#print min max values of manifold\n",
    "\n",
    "print(\"Manifold points shape: \", mnfld_points.shape)\n",
    "print(\"Manifold points normals GT shape: \", mnfld_n_gt.shape)\n",
    "print(\"Non-manifold points shape: \", nonmnfld_points.shape)\n",
    "print(\"Manifold points min:\", torch.min(mnfld_points, dim=0).values)\n",
    "print(\"Manifold points max:\", torch.max(mnfld_points, dim=0).values)\n",
    "mnfld_points.requires_grad_()\n",
    "nonmnfld_points.requires_grad_()\n",
    "\n",
    "small_mnfl_points = mnfld_points*0.99\n",
    "big_mnfl_points = mnfld_points*1.01\n",
    "\n",
    "ps.register_point_cloud(\"mnfld\", mnfld_points.detach().cpu().numpy())\n",
    "#ps.register_point_cloud(\"normals\", mnfld_n_gt.detach().cpu().numpy())\n",
    "#ps.register_point_cloud(\"big_mnfl_points\", big_mnfl_points.detach().cpu().numpy())\n",
    "#ps.register_point_cloud(\"small_mnfl_points\", small_mnfl_points.detach().cpu().numpy())\n",
    "#ps.register_point_cloud(\"non mnfld\", nonmnfld_points.detach().cpu().numpy())\n",
    "ps.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import open3d as o3d\n",
    "# import numpy as np\n",
    "\n",
    "# # Load point cloud\n",
    "# mesh = o3d.io.read_triangle_mesh(\"Resources/stanford-bunny.obj\")\n",
    "# pcd = mesh.sample_points_uniformly(16*16*16*8)\n",
    "\n",
    "# points = np.asarray(pcd.points, dtype=np.float32)\n",
    "# #min max values of points\n",
    "# print(\"Points min:\", points.min(axis=0))\n",
    "# print(\"Points max:\", points.max(axis=0))\n",
    "\n",
    "# # center and scale point cloud\n",
    "# center = points.mean(axis=0)\n",
    "# points = points - center[None, :]\n",
    "# # self.scale = np.linalg.norm(points, axis=-1).max(-1)\n",
    "# scale = np.abs(points).max()\n",
    "# points = points / scale\n",
    "# pcd.points = o3d.utility.Vector3dVector(points)\n",
    "\n",
    "\n",
    "# #min max values of points\n",
    "# print(\"Points min:\", points.min(axis=0))\n",
    "# print(\"Points max:\", points.max(axis=0))\n",
    "\n",
    "\n",
    "# # Estimate normals\n",
    "# pcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamKNN(knn=30))\n",
    "# # Flip normals towards a common viewpoint (optional)\n",
    "# pcd.orient_normals_consistent_tangent_plane(k=30)\n",
    "# # Visualize\n",
    "# #o3d.visualization.draw_geometries([pcd], point_show_normal=True)\n",
    "\n",
    "\n",
    "# # Convert point cloud to numpy\n",
    "# points = np.asarray(pcd.points)\n",
    "# normals = np.asarray(pcd.normals)\n",
    "\n",
    "# # Define offset distance\n",
    "# d = 0.003   # Adjust as needed\n",
    "\n",
    "# # Create outer and inner point clouds\n",
    "# points_outer = points + d * normals\n",
    "# points_inner = points - d * normals\n",
    "\n",
    "# # Create Open3D point clouds\n",
    "# pcd_outer = o3d.geometry.PointCloud()\n",
    "# pcd_outer.points = o3d.utility.Vector3dVector(points_outer)\n",
    "\n",
    "# pcd_inner = o3d.geometry.PointCloud()\n",
    "# pcd_inner.points = o3d.utility.Vector3dVector(points_inner)\n",
    "\n",
    "# ps.register_point_cloud(\"points\",points)\n",
    "# ps.register_point_cloud(\"points_inner\", np.asarray(pcd_inner.points))\n",
    "# ps.register_point_cloud(\"points_outer\", np.asarray(pcd_outer.points))\n",
    "\n",
    "\n",
    "\n",
    "# # uniformely sample from points\n",
    "# num_points = points.shape[0]\n",
    "# indices = torch.randperm(num_points)[:16**3].cpu().numpy()\n",
    "# # Subsample\n",
    "# sub_points = points[indices]  # (N^3, 3)\n",
    "# sub_points_inner = points_inner[indices]  # (N^3, 3)\n",
    "# sub_points_outer = points_outer[indices]  # (N^3, 3)\n",
    "\n",
    "# ps.register_point_cloud(\"sub_points\",sub_points)\n",
    "# ps.register_point_cloud(\"sub_points_inner\", sub_points_inner)\n",
    "# ps.register_point_cloud(\"sub_points_outer\", sub_points_outer)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ps.show()\n",
    "\n",
    "# # Save or visualize\n",
    "# o3d.io.write_point_cloud(\"bunny_outer.ply\", pcd_outer)\n",
    "# o3d.io.write_point_cloud(\"bunny_inner.ply\", pcd_inner)\n",
    "# o3d.visualization.draw_geometries([pcd_inner, pcd_outer])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model\n"
     ]
    }
   ],
   "source": [
    "model = mlp.Decoder(multires=multires, input_dims=input_dims).to(device)\n",
    "radius = 1\n",
    "it = 1000\n",
    "#model_path = 'models_resources/pretrained_sphere_small.pth'\n",
    "model_path = f'models_resources/pretrained_sphere_{radius}.pth'\n",
    "#model_path = f'models_resources/pc_bunny_{it}.pth'\n",
    "#model_path = 'models_resources/pc_chair.pth'\n",
    "\n",
    "\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    print('loaded model')   \n",
    "else:\n",
    "    print(\"no model found, pretraining\")\n",
    "    model.pre_train_sphere(it*3, radius)\n",
    "    \n",
    "    #model.pre_train_pc_scaling(it*10, mnfld_points)\n",
    "    #model.pre_train_pc_scaling(it*3, mnfld_points, lr = 0.00001)\n",
    "    \n",
    "    polyscope_marching_tet(model, sites, i=f\"{it}_scaling\")\n",
    "    \n",
    "    #model.pre_train_pc(it*6)\n",
    "    #polyscope_marching_tet(model, sites, i=f\"{it}_pcn\")\n",
    "    \n",
    "    torch.save(model.state_dict(),model_path)\n",
    "\n",
    "#polyscope_marching_tet(model, sites, i=f\"_{it}_pc\")\n",
    "\n",
    "#ps.show()\n",
    "\n",
    "\n",
    "#polyscope_marching_tet(model, sites)\n",
    "#final_mesh = su.get_zero_crossing_mesh_3d(sites, model)\n",
    "#ps.register_surface_mesh(\"Zero-Crossing faces pretrained\", final_mesh[0], final_mesh[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsampling_vectorized(sites, model):\n",
    "    sdf_values = model(sites)\n",
    "    sites_np = sites.detach().cpu().numpy()\n",
    "    # Compute Voronoi diagram\n",
    "    vor = Voronoi(sites_np)\n",
    "    \n",
    "    neighbors = torch.tensor(np.array(vor.ridge_points), device=device)\n",
    "    \n",
    "    # Extract the SDF values for each site in the pair\n",
    "    sdf_i = sdf_values[neighbors[:, 0]]  # First site in each pair\n",
    "    sdf_j = sdf_values[neighbors[:, 1]]  # Second site in each pair\n",
    "    # Find the indices where SDF values have opposing signs or one is zero\n",
    "    mask_zero_crossing_sites = (sdf_i * sdf_j <= 0).squeeze()\n",
    "    sites_to_upsample = torch.unique(neighbors[mask_zero_crossing_sites].view(-1))\n",
    "    \n",
    "    print(\"Sites to upsample \",sites_to_upsample.shape)\n",
    "    \n",
    "    tet_centroids = sites[sites_to_upsample]\n",
    "\n",
    "    # Tetrahedron relative positions (unit tetrahedron)\n",
    "    basic_tet_1 = torch.tensor([[1, 1, 1]], device=device, dtype=torch.float64)\n",
    "    basic_tet_1 = basic_tet_1.repeat(len(tet_centroids), 1)\n",
    "    basic_tet_2 = torch.tensor([-1, -1, 1], device=device, dtype=torch.float64)    \n",
    "    basic_tet_2 = basic_tet_2.repeat(len(tet_centroids), 1)\n",
    "    basic_tet_3 = torch.tensor([-1, 1, -1], device=device, dtype=torch.float64)    \n",
    "    basic_tet_3 = basic_tet_3.repeat(len(tet_centroids), 1)\n",
    "    basic_tet_4 = torch.tensor([1, -1, -1], device=device, dtype=torch.float64)\n",
    "    basic_tet_4 = basic_tet_4.repeat(len(tet_centroids), 1)\n",
    "\n",
    "\n",
    "    #compute scale based on cell volume\n",
    "    centroids = torch.tensor(np.array([vor.vertices[vor.regions[vor.point_region[i]]].mean(axis=0) for i in range(len(sites_np))]), device=device)\n",
    "    #centroids = torch.tensor(np.array(centroids), device=sites.device, dtype=sites.dtype)\n",
    "    cells_vertices = [vor.vertices[vor.regions[vor.point_region[i]]] for i in range(len(sites_np))]\n",
    "\n",
    "    #compute the distance between each centroid  and each vertex in cells_vertices row\n",
    "    distances = []\n",
    "    for i in range(len(cells_vertices)):\n",
    "        min_dist = 100000000000\n",
    "        for j in range(len(cells_vertices[i])):\n",
    "            dist = torch.norm(centroids[i] - torch.tensor(cells_vertices[i][j], device=device), p=2)\n",
    "            if dist < min_dist:\n",
    "                min_dist = dist\n",
    "        distances.append(min_dist)\n",
    "    distances = torch.tensor(distances, device=device)\n",
    " \n",
    "    \n",
    "    scale = distances[sites_to_upsample] / 2\n",
    "    \n",
    "    scale = scale.unsqueeze(1)\n",
    "    \n",
    "    \n",
    "    new_sites = torch.cat((tet_centroids + basic_tet_1 * scale, tet_centroids + basic_tet_2 * scale, tet_centroids + basic_tet_3 * scale, tet_centroids + basic_tet_4 * scale), dim=0)\n",
    "\n",
    "    updated_sites = torch.cat((sites, new_sites), dim=0)\n",
    "\n",
    "    return updated_sites\n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvt_loss_values = []\n",
    "min_distance_loss_values = []\n",
    "chamfer_distance_loss_values = []\n",
    "eikonal_loss_values = []\n",
    "domain_restriction_loss_values = []\n",
    "sdf_loss_values = []\n",
    "div_loss_values = []\n",
    "loss_values = []\n",
    "\n",
    "\n",
    "def autograd(sites, model, max_iter=100, stop_train_threshold=1e-6, upsampling=0, lambda_weights = [0.1,1.0,0.1,0.1,1.0,1.0,0.1]):\n",
    "    optimizer = torch.optim.Adam([\n",
    "    {'params': [p for _, p in model.named_parameters()], 'lr': 5e-5},\n",
    "    {'params': [sites], 'lr': lr_sites}\n",
    "], betas=(0.9, 0.999))\n",
    "\n",
    "    prev_loss = float(\"inf\")\n",
    "    best_loss = float(\"inf\")\n",
    "    upsampled = 0.0\n",
    "    epoch = 0\n",
    "    lambda_cvt = lambda_weights[0]\n",
    "    # lambda_pc = lambda_weights[1]\n",
    "    lambda_min_distance = lambda_weights[2]\n",
    "    # lambda_laplace = lambda_weights[3]\n",
    "    lamda_chamfer = lambda_weights[4]\n",
    "    lambda_eikonal = lambda_weights[5]\n",
    "    lambda_domain_restriction = lambda_weights[6]\n",
    "    # lambda_target_points = lambda_weights[7]\n",
    "    lambda_sdf = 5e3\n",
    "    lambda_div = 1e3\n",
    "    lambda_eikonal = 5e1\n",
    "    best_sites = sites.clone()\n",
    "    best_sites.best_loss = best_loss\n",
    "    \n",
    "    while epoch <= max_iter:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # compute voronoi and delaunay once for each epoch and pass it around\n",
    "        # Compute Voronoi diagram\n",
    "        sites_np = sites.detach().cpu().numpy()\n",
    "        vor = Voronoi(sites_np)\n",
    "        tri = Delaunay(sites_np)\n",
    "                \n",
    "        #vertices_to_compute, bisectors_to_compute = su.compute_zero_crossing_vertices_3d(sites, None, tri, model)\n",
    "        vertices_to_compute, bisectors_to_compute = su.compute_zero_crossing_vertices_3d(sites, vor, tri, model)\n",
    "        \n",
    "        vertices = su.compute_vertices_3d_vectorized(sites, vertices_to_compute)    \n",
    "        bisectors = su.compute_all_bisectors_vectorized(sites, bisectors_to_compute)\n",
    "        points = torch.cat((vertices, bisectors), 0)\n",
    "\n",
    "        # Compute losses       \n",
    "        cvt_loss = lf.compute_cvt_loss_vectorized_voronoi(sites, vor)\n",
    "        #cvt_loss = lf.compute_cvt_loss_vectorized_delaunay(sites, tri)\n",
    "        \n",
    "        #min_distance_loss = lf.sdf_weighted_min_distance_loss(model, sites)\n",
    "        print(\"mnfld\", mnfld_points.shape)\n",
    "        print(\"points\", points.shape) \n",
    "        \n",
    "        from pytorch3d.loss import chamfer_distance\n",
    "        chamfer_loss, _ = chamfer_distance(mnfld_points.unsqueeze(0).detach(), points.unsqueeze(0))\n",
    "        print(f\"After Chamfer loss PYTORCH3D {chamfer_loss} : Allocated: {torch.cuda.memory_allocated() / 1e6} MB,\\\n",
    "                  Reserved: {torch.cuda.memory_reserved() / 1e6} MB\")\n",
    "            \n",
    "        \n",
    "        # chamfer_loss = lf.chamfer_distance(mnfld_points, points)\n",
    "        \n",
    "        sites_loss = (\n",
    "            lambda_cvt * cvt_loss +\n",
    "            lamda_chamfer * chamfer_loss\n",
    "        )\n",
    "        print(f\"After site loss and Before model loss : Allocated: {torch.cuda.memory_allocated() / 1e6} MB,\\\n",
    "                  Reserved: {torch.cuda.memory_reserved() / 1e6} MB\")\n",
    "            \n",
    "        # Compute model loss               \n",
    "        non_manifold_pred = model(nonmnfld_points)\n",
    "        manifold_pred = model(mnfld_points)\n",
    "        div_loss = torch.tensor([0.0], device=mnfld_points.device)\n",
    "        # compute gradients for div (divergence), curl and curv (curvature)\n",
    "        if manifold_pred is not None:\n",
    "            mnfld_grad = Stu.gradient(mnfld_points, manifold_pred)\n",
    "        else:\n",
    "            mnfld_grad = None\n",
    "\n",
    "        nonmnfld_grad = Stu.gradient(nonmnfld_points, non_manifold_pred)\n",
    "        div_loss = torch.abs(lf.directional_div(nonmnfld_points, nonmnfld_grad)).mean() #+ mnfld_divergence_term.mean()\n",
    "        eikonal_term = lf.eikonal_loss(nonmnfld_grad, mnfld_grad=mnfld_grad, eikonal_type='abs')\n",
    "        sdf_term = torch.abs(manifold_pred).mean()\n",
    "        domain_restriction_loss = lf.domain_restriction_sphere(mnfld_points, model, input_dim=input_dims)\n",
    "        \n",
    "\n",
    "        model_loss = (\n",
    "            lambda_sdf*sdf_term +\n",
    "            lambda_eikonal*eikonal_term +\n",
    "            lambda_div*div_loss +\n",
    "            lambda_domain_restriction * domain_restriction_loss\n",
    "        )\n",
    "        #print weights\n",
    "        print(f\"lambda_sdf: {lambda_sdf}, lambda_eikonal: {lambda_eikonal}, lambda_div: {lambda_div}, lambda_domain_restriction: {lambda_domain_restriction}\")\n",
    "        print(f\"sdf_term: {sdf_term}, eikonal_term: {eikonal_term}, div_loss: {div_loss}, domain_restriction_loss: {domain_restriction_loss}\")\n",
    "        print(f\"Epoch {epoch}: model_loss = {model_loss.item()}\")\n",
    "        \n",
    "        #DIVDECAY='linear' # 'linear' | 'quintic' | 'step'\n",
    "        div_decay_params = [1e2, 0.2, 1e2, 0.4, 0.0, 0.0]\n",
    "        \n",
    "        div_decay_params = [5e2, 0.2, 5e2, 0.8, 0.0, 0.0]\n",
    "        \n",
    "        # div_decay_params = [lambda_div, 0.5, lambda_div/2, 0.8, 0.0, 0.0]\n",
    "        \n",
    "        #div_decay_params = [300, 0.5, 100, 0.8, 0.0, 0.0]\n",
    "        lambda_div = lf.update_div_weight(epoch, max_iter, lambda_div, 'linear', div_decay_params)\n",
    "               \n",
    "\n",
    "        #print weights\n",
    "        print(f\"cvt_loss: {cvt_loss}, chamfer_loss: {chamfer_loss}\")\n",
    "              #, min_distance_loss: {min_distance_loss}, \n",
    "        print(f\"Epoch {epoch}: site_loss = {sites_loss.item()}\")\n",
    "\n",
    "        print(f\"lambda_cvt: {lambda_cvt}, lambda_min_distance: {lambda_min_distance}, lambda_chamfer: {lamda_chamfer}\")\n",
    "         \n",
    "        loss = model_loss + sites_loss\n",
    "        loss_values.append(loss.item())\n",
    "        print(f\"Epoch {epoch}: loss = {loss.item()}\")\n",
    "        print(f\"before loss.backward(): Allocated: {torch.cuda.memory_allocated() / 1e6} MB, Reserved: {torch.cuda.memory_reserved() / 1e6} MB\")\n",
    "\n",
    "        loss.backward()\n",
    "        print(f\"After loss.backward(): Allocated: {torch.cuda.memory_allocated() / 1e6} MB, Reserved: {torch.cuda.memory_reserved() / 1e6} MB\")\n",
    "        print(\"-----------------\")\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        if loss.item() < best_loss:\n",
    "            best_loss = loss.item()\n",
    "            best_epoch = epoch\n",
    "            best_sites = sites.clone()\n",
    "            best_sites.best_loss = best_loss\n",
    "            #if upsampled > 0:\n",
    "                #print(f\"UPSAMPLED {upsampled} Best Epoch {best_epoch}: Best loss = {best_loss}\")\n",
    "                #return best_sites\n",
    "        \n",
    "        if abs(prev_loss - loss.item()) < stop_train_threshold:\n",
    "            print(f\"Converged at epoch {epoch} with loss {loss.item()}\")\n",
    "            #break\n",
    "        \n",
    "        prev_loss = loss.item() \n",
    "        \n",
    "        # if epoch>100 and (epoch // 100) == upsampled+1 and loss.item() < 0.5 and upsampled < upsampling:\n",
    "        if epoch/max_iter > (upsampled+1)/(upsampling+1) and upsampled < upsampling:\n",
    "            print(\"sites length BEFORE UPSAMPLING: \",len(sites))\n",
    "            \n",
    "            #new_sites = su.upsampling_inside(best_sites, model)\n",
    "            #new_sites = su.adaptive_density_upsampling(best_sites, model)\n",
    "            \n",
    "            #sites = su.add_upsampled_sites(best_sites, new_sites)\n",
    "            \n",
    "            sites = upsampling_vectorized(sites, model)\n",
    "            \n",
    "            sites = sites.detach().requires_grad_(True)\n",
    "            #print(\"upsampled sites length: \",len(sites))\n",
    "            \n",
    "            #best_sites = sites.clone()\n",
    "            #best_sites.best_loss = best_loss\n",
    "            \n",
    "            optimizer = torch.optim.Adam([{'params': [p for _, p in model.named_parameters()], 'lr': lr_model},\n",
    "                                          {'params': [sites], 'lr': lr_sites}])\n",
    "            upsampled += 1.0\n",
    "            print(\"sites length AFTER: \",len(sites))\n",
    "            \n",
    "          \n",
    "        if epoch % (max_iter/50) == 0:\n",
    "            #print(f\"Epoch {epoch}: loss = {loss.item()}\")\n",
    "            #print(f\"Best Epoch {best_epoch}: Best loss = {best_loss}\")\n",
    "            #save model and sites\n",
    "            site_file_path = f'{destination}{mesh[0]}{max_iter}_{epoch}_3d_sites_{num_centroids}_chamfer{lamda_chamfer}.pth'\n",
    "            model_file_path = f'{destination}{mesh[0]}{max_iter}_{epoch}_3d_model_{num_centroids}_chamfer{lamda_chamfer}.pth'\n",
    "            torch.save(model.state_dict(), model_file_path)\n",
    "            torch.save(sites, site_file_path)\n",
    "            \n",
    "        epoch += 1           \n",
    "        \n",
    "    return best_sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-04-02 16:02:09 43339:43339 ActivityProfilerController.cpp:311] Completed Stage: Warm Up\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnfld torch.Size([32768, 3])\n",
      "points torch.Size([7871, 3])\n",
      "After Chamfer loss PYTORCH3D 0.11807261693941709 : Allocated: 22.21824 MB,                  Reserved: 132.120576 MB\n",
      "After site loss and Before model loss : Allocated: 22.218752 MB,                  Reserved: 132.120576 MB\n",
      "lambda_sdf: 5000.0, lambda_eikonal: 50.0, lambda_div: 1000.0, lambda_domain_restriction: 100\n",
      "sdf_term: 0.16736669220282954, eikonal_term: 0.30363813016103125, div_loss: 0.4386246870216942, domain_restriction_loss: 0.0\n",
      "Epoch 0: model_loss = 1290.6400545438935\n",
      "cvt_loss: 0.009902812863965675, chamfer_loss: 0.11807261693941709\n",
      "Epoch 0: site_loss = 3.689354190773443\n",
      "lambda_cvt: 252, lambda_min_distance: 0, lambda_chamfer: 10.111111111111\n",
      "Epoch 0: loss = 1294.329408734667\n",
      "before loss.backward(): Allocated: 939.899392 MB, Reserved: 1178.599424 MB\n",
      "After loss.backward(): Allocated: 61.941248 MB, Reserved: 1186.988032 MB\n",
      "-----------------\n",
      "mnfld torch.Size([32768, 3])\n",
      "points torch.Size([7097, 3])\n",
      "After Chamfer loss PYTORCH3D 0.09304479431704196 : Allocated: 69.094912 MB,                  Reserved: 1186.988032 MB\n",
      "After site loss and Before model loss : Allocated: 69.094912 MB,                  Reserved: 1186.988032 MB\n",
      "lambda_sdf: 5000.0, lambda_eikonal: 50.0, lambda_div: 500.0, lambda_domain_restriction: 100\n",
      "sdf_term: 0.14792891866646124, eikonal_term: 0.28565558721545387, div_loss: 0.43400009336409995, domain_restriction_loss: 0.0\n",
      "Epoch 1: model_loss = 970.9274193751288\n",
      "cvt_loss: 0.012424003402649545, chamfer_loss: 0.09304479431704196\n",
      "Epoch 1: site_loss = 4.071635111117766\n",
      "lambda_cvt: 252, lambda_min_distance: 0, lambda_chamfer: 10.111111111111\n",
      "Epoch 1: loss = 974.9990544862466\n",
      "before loss.backward(): Allocated: 942.601216 MB, Reserved: 1186.988032 MB\n",
      "After loss.backward(): Allocated: 63.643136 MB, Reserved: 1189.085184 MB\n",
      "-----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2025-04-02 16:02:11 43339:43339 ActivityProfilerController.cpp:317] Completed Stage: Collection\n",
      "STAGE:2025-04-02 16:02:11 43339:43339 ActivityProfilerController.cpp:321] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                               aten::mm         1.77%      10.159ms         6.47%      37.166ms     165.920us     316.038ms        72.09%     336.666ms       1.503ms           224  \n",
      "void cutlass::Kernel<cutlass_80_tensorop_d884gemm_64...         0.00%       0.000us         0.00%       0.000us       0.000us     112.765ms        25.72%     112.765ms       2.014ms            56  \n",
      "void cutlass::Kernel<cutlass_80_tensorop_d884gemm_64...         0.00%       0.000us         0.00%       0.000us       0.000us      93.470ms        21.32%      93.470ms       2.337ms            40  \n",
      "                                            _knn_points         0.03%     194.000us         1.41%       8.125ms       2.031ms      88.749ms        20.24%      88.777ms      22.194ms             4  \n",
      "void KNearestNeighborKernelV3<double, 3, 1>(double c...         0.00%       0.000us         0.00%       0.000us       0.000us      88.749ms        20.24%      88.749ms      22.187ms             4  \n",
      "void cutlass::Kernel<cutlass_80_tensorop_d884gemm_64...         0.00%       0.000us         0.00%       0.000us       0.000us      87.231ms        19.90%      87.231ms       2.181ms            40  \n",
      "                                       cudaLaunchKernel        22.53%     129.361ms        22.53%     129.361ms      56.366us      24.771ms         5.65%      31.897ms      13.898us          2295  \n",
      "                               aten::threshold_backward         0.08%     472.000us         0.75%       4.305ms      43.929us      10.393ms         2.37%      15.305ms     156.173us            98  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      10.393ms         2.37%      10.393ms     106.051us            98  \n",
      "                                   cudaFuncSetAttribute         0.00%      12.000us         0.00%      12.000us       0.077us       9.362ms         2.14%       9.362ms      60.013us           156  \n",
      "void cutlass::Kernel<cutlass_80_tensorop_d884gemm_32...         0.00%       0.000us         0.00%       0.000us       0.000us       7.496ms         1.71%       7.496ms     374.800us            20  \n",
      "                                  cudaStreamIsCapturing         0.00%      17.000us         0.00%      17.000us       0.195us       7.117ms         1.62%       7.117ms      81.805us            87  \n",
      "void cutlass::Kernel<cutlass_80_tensorop_d884gemm_32...         0.00%       0.000us         0.00%       0.000us       0.000us       6.067ms         1.38%       6.067ms     505.583us            12  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       5.662ms         1.29%       5.662ms      19.937us           284  \n",
      "                                             aten::add_         0.07%     397.000us         0.12%     673.000us       3.348us       4.306ms         0.98%       4.334ms      21.562us           201  \n",
      "                                            aten::copy_         0.11%     622.000us        22.54%     129.447ms     602.079us       4.090ms         0.93%       4.298ms      19.991us           215  \n",
      "                                             cudaMalloc         0.74%       4.238ms         0.74%       4.238ms      59.690us       3.917ms         0.89%       4.052ms      57.070us            71  \n",
      "                                  ampere_dgemm_64x64_tn         0.00%       0.000us         0.00%       0.000us       0.000us       3.295ms         0.75%       3.295ms     274.583us            12  \n",
      "          cudaOccupancyMaxActiveBlocksPerMultiprocessor         0.05%     277.000us         0.05%     277.000us      21.308us       2.516ms         0.57%       2.516ms     193.538us            13  \n",
      "                                            aten::fill_         0.08%     484.000us         0.33%       1.920ms       8.384us       2.508ms         0.57%       2.801ms      12.231us           229  \n",
      "                       Memcpy HtoD (Pageable -> Device)         0.00%       0.000us         0.00%       0.000us       0.000us       2.498ms         0.57%       2.498ms     131.474us            19  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       2.434ms         0.56%       2.434ms      11.702us           208  \n",
      "void cutlass::Kernel<cutlass_80_tensorop_d884gemm_64...         0.00%       0.000us         0.00%       0.000us       0.000us       2.390ms         0.55%       2.390ms     199.167us            12  \n",
      "                                              aten::mul         0.34%       1.933ms         0.72%       4.138ms       9.257us       2.151ms         0.49%      10.360ms      23.177us           447  \n",
      "                                        aten::clamp_min         0.04%     245.000us         0.86%       4.931ms     117.405us       2.084ms         0.48%       7.300ms     173.810us            42  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       2.084ms         0.48%       2.084ms      49.619us            42  \n",
      "void cutlass::Kernel<cutlass_80_tensorop_d884gemm_64...         0.00%       0.000us         0.00%       0.000us       0.000us       2.024ms         0.46%       2.024ms     253.000us             8  \n",
      "                                              aten::add         0.09%     510.000us         0.15%     840.000us       6.176us       1.594ms         0.36%       6.864ms      50.471us           136  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       1.267ms         0.29%       1.267ms       5.150us           246  \n",
      "cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFla...         4.09%      23.489ms         4.09%      23.489ms     104.862us       1.213ms         0.28%       1.213ms       5.415us           224  \n",
      "                       Memcpy DtoH (Device -> Pageable)         0.00%       0.000us         0.00%       0.000us       0.000us     880.000us         0.20%     880.000us      11.139us            79  \n",
      "                                              aten::cos         0.04%     228.000us         0.23%       1.317ms      21.950us     668.000us         0.15%     688.000us      11.467us            60  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     668.000us         0.15%     668.000us      11.133us            60  \n",
      "                                              aten::sin         0.05%     280.000us         0.26%       1.486ms      24.767us     658.000us         0.15%     824.000us      13.733us            60  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     658.000us         0.15%     658.000us      10.967us            60  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     657.000us         0.15%     657.000us       4.761us           138  \n",
      "                                aten::_foreach_addcdiv_         0.00%      25.000us         0.01%      50.000us      12.500us     506.000us         0.12%     506.000us     126.500us             4  \n",
      "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us     506.000us         0.12%     506.000us     126.500us             4  \n",
      "                                    aten::_foreach_div_         0.01%      44.000us         0.13%     718.000us     179.500us     466.000us         0.11%     466.000us     116.500us             4  \n",
      "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us     466.000us         0.11%     466.000us     116.500us             4  \n",
      "                                 aten::_index_put_impl_         0.05%     262.000us         4.70%      26.971ms       3.371ms     413.000us         0.09%     562.000us      70.250us             8  \n",
      "void splitKreduce_kernel<32, 16, int, double, double...         0.00%       0.000us         0.00%       0.000us       0.000us     408.000us         0.09%     408.000us       6.000us            68  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     371.000us         0.08%     371.000us       5.456us            68  \n",
      "                                              aten::neg         0.05%     278.000us         0.67%       3.836ms      47.950us     351.000us         0.08%       1.240ms      15.500us            80  \n",
      "                                              aten::div         0.06%     335.000us         0.10%     595.000us       7.438us     350.000us         0.08%     928.000us      11.600us            80  \n",
      "void gemv2T_kernel_val<int, int, double, double, dou...         0.00%       0.000us         0.00%       0.000us       0.000us     338.000us         0.08%     338.000us      42.250us             8  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     327.000us         0.07%     327.000us       4.419us            74  \n",
      "                                    aten::_foreach_sqrt         0.02%      90.000us         1.34%       7.694ms       1.923ms     324.000us         0.07%     324.000us      81.000us             4  \n",
      "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us     324.000us         0.07%     324.000us      81.000us             4  \n",
      "                                              aten::sum         0.06%     328.000us         0.62%       3.570ms      81.136us     320.000us         0.07%     379.000us       8.614us            44  \n",
      "void gemvNSP_kernel<double, double, double, double, ...         0.00%       0.000us         0.00%       0.000us       0.000us     297.000us         0.07%     297.000us      37.125us             8  \n",
      "                                 cudaDeviceGetAttribute         0.00%       6.000us         0.00%       6.000us       0.176us     285.000us         0.07%     285.000us       8.382us            34  \n",
      "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us     282.000us         0.06%     282.000us       7.833us            36  \n",
      "void gemmk1_kernel<int, double, 256, 5, false, false...         0.00%       0.000us         0.00%       0.000us       0.000us     257.000us         0.06%     257.000us      32.125us             8  \n",
      "                         Memcpy DtoD (Device -> Device)         0.00%       0.000us         0.00%       0.000us       0.000us     240.000us         0.05%     240.000us       3.478us            69  \n",
      "                                             aten::mean         0.03%     171.000us         0.59%       3.362ms     258.615us     230.000us         0.05%     238.000us      18.308us            13  \n",
      "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us     230.000us         0.05%     230.000us      19.167us            12  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     229.000us         0.05%     229.000us       4.771us            48  \n",
      "                                          aten::normal_         0.01%      81.000us         0.02%     120.000us       6.000us     181.000us         0.04%       2.329ms     116.450us            20  \n",
      "void at::native::(anonymous namespace)::distribution...         0.00%       0.000us         0.00%       0.000us       0.000us     181.000us         0.04%     181.000us       9.050us            20  \n",
      "                                              aten::cat         0.04%     248.000us         0.07%     422.000us      17.583us     171.000us         0.04%     185.000us       7.708us            24  \n",
      "void at_cuda_detail::cub::DeviceRadixSortOnesweepKer...         0.00%       0.000us         0.00%       0.000us       0.000us     166.000us         0.04%     166.000us      10.375us            16  \n",
      "                               aten::linalg_vector_norm         0.03%     145.000us         5.52%      31.721ms       1.322ms     164.000us         0.04%     407.000us      16.958us            24  \n",
      "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us     164.000us         0.04%     164.000us       6.833us            24  \n",
      "                                            aten::index         0.04%     245.000us         0.21%       1.232ms      51.333us     147.000us         0.03%     657.000us      27.375us            24  \n",
      "                                           aten::arange         0.04%     243.000us         0.34%       1.956ms      22.227us     135.000us         0.03%     269.000us       3.057us            88  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     133.000us         0.03%     133.000us       3.500us            38  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     131.000us         0.03%     131.000us       4.679us            28  \n",
      "                              aten::_local_scalar_dense         0.02%     140.000us        38.43%     220.647ms       3.448ms     130.000us         0.03%     133.000us       2.078us            64  \n",
      "void at::native::(anonymous namespace)::CatArrayBatc...         0.00%       0.000us         0.00%       0.000us       0.000us     126.000us         0.03%     126.000us       7.875us            16  \n",
      "                                  aten::linalg_lu_solve         0.03%     146.000us         0.57%       3.245ms     405.625us     126.000us         0.03%     202.000us      25.250us             8  \n",
      "void at::native::index_elementwise_kernel<128, 4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     122.000us         0.03%     122.000us       6.100us            20  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     121.000us         0.03%     121.000us       4.654us            26  \n",
      "void (anonymous namespace)::indexing_backward_kernel...         0.00%       0.000us         0.00%       0.000us       0.000us     113.000us         0.03%     113.000us      14.125us             8  \n",
      "                                    aten::_foreach_mul_         0.01%      32.000us         0.01%      67.000us       8.375us     112.000us         0.03%     112.000us      14.000us             8  \n",
      "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us     112.000us         0.03%     112.000us      14.000us             8  \n",
      "void (anonymous namespace)::elementwise_kernel_with_...         0.00%       0.000us         0.00%       0.000us       0.000us     111.000us         0.03%     111.000us       3.083us            36  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     105.000us         0.02%     105.000us       5.250us            20  \n",
      "                                aten::_foreach_addcmul_         0.01%      30.000us         0.21%       1.216ms     304.000us      91.000us         0.02%      91.000us      22.750us             4  \n",
      "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us      91.000us         0.02%      91.000us      22.750us             4  \n",
      "                                          aten::nonzero         0.02%     101.000us         0.06%     324.000us      81.000us      78.000us         0.02%     349.000us      87.250us             4  \n",
      "                                    aten::_foreach_add_         0.01%      68.000us         0.31%       1.794ms     224.250us      78.000us         0.02%      78.000us       9.750us             8  \n",
      "                                        Memset (Device)         0.00%       0.000us         0.00%       0.000us       0.000us      73.000us         0.02%      73.000us       2.281us            32  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      69.000us         0.02%      69.000us       4.312us            16  \n",
      "                                        cudaMemcpyAsync        38.78%     222.686ms        38.78%     222.686ms       1.333ms      68.000us         0.02%      68.000us       0.407us           167  \n",
      "                              aten::linalg_lu_factor_ex         0.42%       2.386ms         1.30%       7.462ms     932.750us      64.000us         0.01%     164.000us      20.500us             8  \n",
      "void getrf_semiwarp<double, double, 2, 3, true>(int,...         0.00%       0.000us         0.00%       0.000us       0.000us      64.000us         0.01%      64.000us       8.000us             8  \n",
      "void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us      64.000us         0.01%      64.000us       5.333us            12  \n",
      "                                               aten::le         0.02%      95.000us         0.02%     124.000us       8.857us      62.000us         0.01%      69.000us       4.929us            14  \n",
      "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us      62.000us         0.01%      62.000us      15.500us             4  \n",
      "                                     aten::_foreach_add         0.01%      51.000us         0.02%     113.000us      28.250us      59.000us         0.01%      59.000us      14.750us             4  \n",
      "void at::native::(anonymous namespace)::multi_tensor...         0.00%       0.000us         0.00%       0.000us       0.000us      59.000us         0.01%      59.000us      14.750us             4  \n",
      "                                              aten::max         0.00%      19.000us         0.01%      31.000us      15.500us      58.000us         0.01%      58.000us      29.000us             2  \n",
      "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us      58.000us         0.01%      58.000us      29.000us             2  \n",
      "                                             aten::div_         0.02%     123.000us         3.48%      19.967ms       1.248ms      57.000us         0.01%      62.000us       3.875us            16  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us      56.000us         0.01%      56.000us       4.667us            12  \n",
      "void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us      54.000us         0.01%      54.000us       4.500us            12  \n",
      "                                               aten::eq         0.01%      65.000us         0.02%     104.000us      10.400us      52.000us         0.01%      52.000us       5.200us            10  \n",
      "void trsm_batch_left_upper_kernel_small<double, 4, 4...         0.00%       0.000us         0.00%       0.000us       0.000us      52.000us         0.01%      52.000us       6.500us             8  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      51.000us         0.01%      51.000us       3.188us            16  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 574.221ms\n",
      "Self CUDA time total: 438.397ms\n",
      "\n",
      "Sites length:  13824\n",
      "min sites:  tensor(-1.8273, grad_fn=<MinBackward1>)\n",
      "max sites:  tensor(1.8716, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "lambda_weights = [252,0,0,0,10.111111111111000001,0,100,0]\n",
    "\n",
    "lambda_cvt = lambda_weights[0]\n",
    "lambda_sdf = lambda_weights[1]\n",
    "lambda_min_distance = lambda_weights[2]\n",
    "lambda_laplace = lambda_weights[3]\n",
    "lamda_chamfer = lambda_weights[4]\n",
    "lambda_eikonal = lambda_weights[5]\n",
    "lambda_domain_restriction = lambda_weights[6]\n",
    "lambda_true_points = lambda_weights[7]\n",
    "\n",
    "max_iter = 1\n",
    "\n",
    "site_file_path = f'{destination}{max_iter}_cvt_{lambda_cvt}_chamfer_{lamda_chamfer}_eikonal_{lambda_eikonal}.npy'\n",
    "#check if optimized sites file exists\n",
    "if os.path.exists(site_file_path):\n",
    "    #import sites\n",
    "    print(\"Importing sites\")\n",
    "    sites = np.load(site_file_path)\n",
    "    sites = torch.from_numpy(sites).to(device).requires_grad_(True)\n",
    "else:\n",
    "    # import cProfile, pstats\n",
    "    # import time\n",
    "    # profiler = cProfile.Profile()\n",
    "    # profiler.enable()\n",
    "    with torch.profiler.profile(activities=[\n",
    "            torch.profiler.ProfilerActivity.CPU,\n",
    "            torch.profiler.ProfilerActivity.CUDA,\n",
    "        ],\n",
    "        record_shapes=False,\n",
    "        with_stack=True  # Captures function calls\n",
    "    ) as prof:\n",
    "        sites = autograd(sites, model, max_iter=max_iter, upsampling=0, lambda_weights=lambda_weights)\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "    print(prof.key_averages().table(sort_by=\"self_cuda_time_total\"))\n",
    "    prof.export_chrome_trace(\"trace.json\")\n",
    "\n",
    "    \n",
    "    # profiler.disable()\n",
    "    # stats = pstats.Stats(profiler).sort_stats('cumtime')\n",
    "    # stats.print_stats()\n",
    "    # stats.dump_stats(f'{destination}{mesh[0]}{max_iter}_3d_profile_{num_centroids}_chamfer{lamda_chamfer}.prof')\n",
    "    \n",
    "    \n",
    "    sites_np = sites.detach().cpu().numpy()\n",
    "    np.save(site_file_path, sites_np)\n",
    "    \n",
    "    \n",
    "\n",
    "print(\"Sites length: \", len(sites))\n",
    "print(\"min sites: \", torch.min(sites))\n",
    "print(\"max sites: \", torch.max(sites))\n",
    "#ps_cloud = ps.register_point_cloud(\"best_optimized_cvt_grid\",sites.detach().cpu().numpy())\n",
    "    \n",
    "lim=torch.abs(torch.max(sites)).detach().cpu().numpy()*1.1\n",
    "#plot_voronoi_3d(sites,lim,lim,lim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './images/autograd/3Dsteik/bunny1_300_3d_sites_13824_chamfer10.111111111111.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m model_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdestination\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmesh[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmax_iter\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_3d_model_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_centroids\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_chamfer\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlamda_chamfer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m site_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdestination\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmesh[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmax_iter\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_3d_sites_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_centroids\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_chamfer\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlamda_chamfer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 5\u001b[0m sites \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43msite_file_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m sites_np \u001b[38;5;241m=\u001b[39m sites\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(model_file_path))\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/serialization.py:791\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    789\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 791\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    792\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    793\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    794\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    795\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    796\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/serialization.py:271\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 271\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    273\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/serialization.py:252\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 252\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './images/autograd/3Dsteik/bunny1_300_3d_sites_13824_chamfer10.111111111111.pth'"
     ]
    }
   ],
   "source": [
    "epoch = 300\n",
    "model_file_path = f'{destination}{mesh[0]}{max_iter}_{epoch}_3d_model_{num_centroids}_chamfer{lamda_chamfer}.pth'\n",
    "site_file_path = f'{destination}{mesh[0]}{max_iter}_{epoch}_3d_sites_{num_centroids}_chamfer{lamda_chamfer}.pth'\n",
    " \n",
    "sites = torch.load(site_file_path)\n",
    "sites_np = sites.detach().cpu().numpy()\n",
    "model.load_state_dict(torch.load(model_file_path))\n",
    "#\n",
    "#polyscope_sdf(model)\n",
    "#\n",
    "print(\"model\", model_file_path)\n",
    "print(\"sites\", site_file_path)\n",
    "ps_cloud = ps.register_point_cloud(f\"{epoch} epoch_cvt_grid\",sites_np)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(tensor([[-0.5272, -0.1636,  0.0341],\n",
      "        [-0.4997, -0.1258, -0.0195],\n",
      "        [-0.5176, -0.2079, -0.0073],\n",
      "        ...,\n",
      "        [ 0.8522, -0.2395, -0.1107],\n",
      "        [ 0.7616, -0.1692, -0.2785],\n",
      "        [ 0.8072, -0.2262, -0.0627]], grad_fn=<SumBackward1>),), (tensor([[ 4453,  4455,   809],\n",
      "        [10068,  6148,  9590],\n",
      "        [ 3067,  5900,  6230],\n",
      "        ...,\n",
      "        [ 1854,  7794,  5462],\n",
      "        [ 4631,  1853,  1854],\n",
      "        [ 4631,  4628,  1853]]),)]\n"
     ]
    }
   ],
   "source": [
    "final_mesh = su.get_zero_crossing_mesh_3d(sites, model)\n",
    "ps.register_point_cloud(\"mnfld\", mnfld_points.detach().cpu().numpy())\n",
    "\n",
    "ps.register_surface_mesh(\"Zero-Crossing faces final\", final_mesh[0], final_mesh[1])\n",
    "#polyscope_sdf(model,2)\n",
    "\n",
    "import scipy.spatial as spatial\n",
    "from scipy.spatial import Delaunay\n",
    "\n",
    "tri = Delaunay(sites_np)\n",
    "delaunay_vertices =torch.tensor(np.array(tri.simplices), device=device)\n",
    "sdf_values = model(sites)\n",
    "\n",
    "\n",
    "# Assuming sites is a PyTorch tensor of shape [M, 3]\n",
    "sites = sites.unsqueeze(0)  # Now shape [1, M, 3]\n",
    "\n",
    "# Assuming SDF_Values is a PyTorch tensor of shape [M]\n",
    "sdf_values = sdf_values.unsqueeze(0)  # Now shape [1, M]\n",
    "\n",
    "marching_tetrehedra_mesh = kaolin.ops.conversions.marching_tetrahedra(sites, delaunay_vertices, sdf_values, return_tet_idx=False)\n",
    "print(marching_tetrehedra_mesh)\n",
    "vertices_list, faces_list = marching_tetrehedra_mesh\n",
    "vertices = vertices_list[0]\n",
    "faces = faces_list[0]\n",
    "vertices_np = vertices.detach().cpu().numpy()  # Shape [N, 3]\n",
    "faces_np = faces.detach().cpu().numpy()  # Shape [M, 3] (triangles)\n",
    "ps.register_surface_mesh(\"Marching Tetrahedra Mesh final\", vertices_np, faces_np)\n",
    "\n",
    "\n",
    "ps.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_visualisation_3d():\n",
    "    import imageio\n",
    "    img_buffer_mesh = []\n",
    "    img_buffer_model = []\n",
    "    for i in range(int(max_iter/10)+1):\n",
    "        epoch = i*int(max_iter/10)\n",
    "        \n",
    "        site_file_path = f'{destination}{mesh[0]}{max_iter}_{epoch}_3d_sites_{num_centroids}_chamfer{lamda_chamfer}.pth'\n",
    "        model_file_path = f'{destination}{mesh[0]}{max_iter}_{epoch}_3d_model_{num_centroids}_chamfer{lamda_chamfer}.pth'\n",
    "        if os.path.exists(site_file_path) and os.path.exists(model_file_path):\n",
    "            print(\"importing sites and model\")\n",
    "        else:\n",
    "            print(\"files not found\")\n",
    "            continue\n",
    "        print(\"mesh of epoch: \", epoch)\n",
    "        \n",
    "        model.load_state_dict(torch.load(model_file_path))\n",
    "    \n",
    "        current_mesh = su.get_zero_crossing_mesh_3d(torch.load(site_file_path), model)\n",
    "        ps.remove_all_structures()\n",
    "        ps.register_surface_mesh(\"Zero-Crossing faces\", current_mesh[0], current_mesh[1])\n",
    "        ps.register_point_cloud(\"Mesh vertices\", current_mesh[0])\n",
    "        img_buffer_mesh.append(ps.screenshot_to_buffer(transparent_bg=False))\n",
    "        \n",
    "        ps.remove_all_structures()\n",
    "        #polyscope_sdf(model)\n",
    "        img_buffer_model.append(ps.screenshot_to_buffer(transparent_bg=False))\n",
    "\n",
    "\n",
    "    imageio.mimsave(f'{destination}{max_iter}_3d_{num_centroids}_optimization_mesh.gif',img_buffer_mesh, fps=1, duration=1, loop=0)\n",
    "    imageio.mimsave(f'{destination}{max_iter}_3d_{num_centroids}_optimization_sdf.gif', img_buffer_model, fps=1, duration=1, loop=0)\n",
    "\n",
    "#export_visualisation_3d()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
