{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device:  NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "import kaolin\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import polyscope as ps\n",
    "import interactive_polyscope\n",
    "from scipy.spatial import Voronoi, voronoi_plot_2d\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import sdfpred_utils.sdfpred_utils as su\n",
    "import sdfpred_utils.sdf_MLP as mlp\n",
    "import sdfpred_utils.sdf_functions as sdf\n",
    "import sdfpred_utils.loss_functions as lf\n",
    "import trimesh\n",
    "from scipy.spatial import Delaunay, Voronoi\n",
    "\n",
    "\n",
    "#cuda devices\n",
    "device = torch.device(\"cuda:0\")\n",
    "print(\"Using device: \", torch.cuda.get_device_name(device))\n",
    "\n",
    "#default tensor types\n",
    "torch.set_default_tensor_type(torch.cuda.DoubleTensor)\n",
    "\n",
    "multires = 2\n",
    "input_dims = 3\n",
    "lr_sites = 0.03\n",
    "lr_model = 0.0003\n",
    "iterations = 5000\n",
    "save_every = 100\n",
    "max_iter = 100\n",
    "#learning_rate = 0.03\n",
    "destination = \"./images/autograd/3D/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sites loaded: torch.Size([4096, 3])\n"
     ]
    }
   ],
   "source": [
    "#currently sites are between -5 and 5 in all 3 dimensions\n",
    "# check if sites exists\n",
    "#num_centroids = 16*16*16\n",
    "num_centroids =16*16*16\n",
    "site_fp = f'sites_{num_centroids}_{input_dims}.pt'\n",
    "\n",
    "if os.path.exists(site_fp):\n",
    "    sites = torch.load(site_fp)\n",
    "    print(\"Sites loaded:\", sites.shape)\n",
    "else:\n",
    "    print(\"Creating new sites\")\n",
    "    sites = su.createCVTgrid(num_centroids=num_centroids, dimensionality=input_dims)\n",
    "    #save the initial sites torch tensor\n",
    "    torch.save(sites, site_fp)\n",
    "\n",
    "\n",
    "def plot_voronoi_3d(sites, xlim=5, ylim=5, zlim=5):\n",
    "    import numpy as np\n",
    "    import pyvoro\n",
    "    import matplotlib.pyplot as plt\n",
    "    from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "    # initialize random number generator\n",
    "    rng = np.random.default_rng(11)\n",
    "    # create a set of points in 3D\n",
    "    points = sites.detach().cpu().numpy()\n",
    "\n",
    "    # use pyvoro to compute the Voronoi tessellation\n",
    "    # the second argument gives the the axis limits in x,y and z direction\n",
    "    # in this case all between 0 and 1.\n",
    "    # the third argument gives \"dispersion = max distance between two points\n",
    "    # that might be adjacent\" (not sure how exactly this works)\n",
    "    voronoi = pyvoro.compute_voronoi(points,[[-xlim,xlim],[-ylim,ylim],[-zlim,zlim]],1)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # for each Voronoi cell, plot all the faces of the corresponding polygon\n",
    "    for vnoicell in voronoi:\n",
    "        faces = []\n",
    "        # the vertices are the corner points of the Voronoi cell\n",
    "        vertices = np.array(vnoicell['vertices'])\n",
    "        # cycle through all faces of the polygon\n",
    "        for face in vnoicell['faces']:\n",
    "            faces.append(vertices[np.array(face['vertices'])])\n",
    "            \n",
    "        # join the faces into a 3D polygon\n",
    "        polygon = Poly3DCollection(faces, alpha=0.5, \n",
    "                                facecolors=rng.uniform(0,1,3),\n",
    "                                linewidths=0.5,edgecolors='black')\n",
    "        ax.add_collection3d(polygon)\n",
    "    \n",
    "    ax.set_xlim([-xlim,xlim])\n",
    "    ax.set_ylim([-ylim,ylim])\n",
    "    ax.set_zlim([-zlim,zlim])\n",
    "            \n",
    "    plt.show()\n",
    "\n",
    "#plot_voronoi_3d(sites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[polyscope] Backend: openGL3_glfw -- Loaded openGL version: 3.3.0 NVIDIA 570.86.16\n"
     ]
    }
   ],
   "source": [
    "ps.init()\n",
    "ps_cloud = ps.register_point_cloud(\"initial_cvt_grid\",sites.detach().cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target points: torch.Size([32768, 3])\n",
      "min_target tensor([-3.9985, -3.9561, -3.0987])\n",
      "max_target tensor([3.9997, 3.9588, 3.0998])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the mesh\n",
    "mesh = [\"bunny\", \"Resources/stanford-bunny.obj\"]\n",
    "#mesh = [\"staryu\", \"Resources/staryu.obj\"]\n",
    "#mesh = [\"chair\", \"Resources/chair_low.obj\"]\n",
    "\n",
    "bunny = trimesh.load(mesh[1])\n",
    "\n",
    "# Get current bounding box\n",
    "min_bound = bunny.bounds[0]  # Min (x, y, z)\n",
    "max_bound = bunny.bounds[1]  # Max (x, y, z)\n",
    "\n",
    "# Compute scale factor\n",
    "current_size = max_bound - min_bound  # Size in each dimension\n",
    "target_size = 8  # Because we want [-5, 5], the total size is 10\n",
    "\n",
    "scale_factor = target_size / np.max(current_size)  # Scale based on the largest dimension\n",
    "\n",
    "# Compute new center after scaling\n",
    "new_vertices = bunny.vertices * scale_factor  # Scale the vertices\n",
    "new_min = np.min(new_vertices, axis=0)\n",
    "new_max = np.max(new_vertices, axis=0)\n",
    "new_center = (new_min + new_max) / 2  # New center after scaling\n",
    "\n",
    "# Compute translation to center the bunny at (0,0,0)\n",
    "translation = -new_center  # Move to the origin\n",
    "\n",
    "# Apply transformation (scaling + translation)\n",
    "bunny.vertices = new_vertices + translation\n",
    "\n",
    "#target_points = bunny.sample(16*16*16)\n",
    "target_points = bunny.sample(num_centroids*8)\n",
    "target_points = torch.tensor(target_points, device=device)\n",
    "print(\"Target points:\", target_points.shape)\n",
    "min_target = target_points.min(0)[0]\n",
    "max_target = target_points.max(0)[0]\n",
    "print(\"min_target\", min_target)\n",
    "print(\"max_target\", max_target)\n",
    "\n",
    "ps_cloud = ps.register_point_cloud(\"Target_points\",target_points.detach().cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ps.show()\n",
    "\n",
    "def polyscope_sdf(model,i):\n",
    "    # Render the SDF as an implicit surface (zero-level set)\n",
    "    def model_sdf(pts):\n",
    "        pts_tensor = torch.tensor(pts, dtype=torch.float64, device=device)\n",
    "        sdf_values = model(pts_tensor)\n",
    "        sdf_values_np = sdf_values.detach().cpu().numpy().flatten()  # Convert to NumPy\n",
    "        \n",
    "        return sdf_values_np\n",
    "\n",
    "    ps.render_implicit_surface(f\"SDF Surface {i}\", model_sdf, mode=\"sphere_march\", enabled=True, subsample_factor=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no model found, pretraining\n",
      "Train MLP with GT mesh\n",
      "scale tensor(4.1354)\n",
      "minmax grid tensor([-3.9618, -3.9918, -3.9868]) tensor([4.0998, 3.9231, 3.8794])\n",
      "minmax sdf tensor(-1.9528) tensor(2.9969)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [00:27<00:00, 109.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT Trained MLP 4.434413818417703e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import os\n",
    "\n",
    "model = mlp.Decoder(multires=multires, input_dims=input_dims).to(device)\n",
    "#model_path = 'models_resources/pretrained_sphere_small.pth'\n",
    "#model_path = 'models_resources/pretrained_sphere_small.pth'\n",
    "model_path = 'models_resources/trained_bunny_GT_from_sphere.pth'\n",
    "\n",
    "\n",
    "if not os.path.exists(model_path):\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    print('loaded model')\n",
    "else:\n",
    "    print(\"no model found, pretraining\")\n",
    "    model.pre_train_sphere(1000,3)\n",
    "    #model.train_GT_mesh(3000, mesh, target_points)\n",
    "    #model.cleanup(10)\n",
    "    #model.train_GT_grid(300)\n",
    "    torch.save(model.state_dict(),model_path)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a camera view from parameters\n",
    "intrinsics = ps.CameraIntrinsics(fov_vertical_deg=60, aspect=2)\n",
    "extrinsics = ps.CameraExtrinsics(root=(2., -2., 2.), look_dir=(-1., -1.,-1.), up_dir=(0.,1.,0.))\n",
    "params = ps.CameraParameters(intrinsics, extrinsics)\n",
    "cam = ps.register_camera_view(\"cam\", params)\n",
    "polyscope_sdf(model,1)\n",
    "\n",
    "ps.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as nps\n",
    "# import trimesh\n",
    "# import pyrender\n",
    "# from skimage.measure import marching_cubes\n",
    "\n",
    "\n",
    "# # Create a grid of points\n",
    "# grid_size = 64  # Resolution of the grid\n",
    "# x = np.linspace(-4, 4, grid_size)\n",
    "# y = np.linspace(-4, 4, grid_size)\n",
    "# z = np.linspace(-4, 4, grid_size)\n",
    "# X, Y, Z = np.meshgrid(x, y, z, indexing=\"ij\")\n",
    "\n",
    "# grid_x = X.flatten()\n",
    "# grid_y = Y.flatten()\n",
    "# grid_z = Z.flatten()\n",
    "\n",
    "# grid = np.stack([grid_x, grid_y, grid_z], axis=1)\n",
    "# grid = torch.tensor(grid, dtype=torch.float64, device=device)\n",
    "\n",
    "# # Compute SDF values on the grid\n",
    "# sdf_values = model(grid)\n",
    "\n",
    "# #sdf_values should be a 3d numpy array\n",
    "# sdf_values = sdf_values.detach().cpu().numpy().reshape(grid_size, grid_size, grid_size)\n",
    "\n",
    "# # Extract mesh using Marching Cubes\n",
    "# vertices, faces, _, _ = marching_cubes(sdf_values, level=0)\n",
    "\n",
    "# # Create a mesh\n",
    "# mesh = trimesh.Trimesh(vertices, faces)\n",
    "\n",
    "# # Render with Pyrender\n",
    "# scene = pyrender.Scene()\n",
    "# mesh_pyrender = pyrender.Mesh.from_trimesh(mesh)\n",
    "# scene.add(mesh_pyrender)\n",
    "\n",
    "# # Set up the renderer\n",
    "# viewer = pyrender.Viewer(scene, use_raymond_lighting=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsampling_vectorized(sites, model):\n",
    "    sdf_values = model(sites)\n",
    "    sites_np = sites.detach().cpu().numpy()\n",
    "    # Compute Voronoi diagram\n",
    "    vor = Voronoi(sites_np)\n",
    "    \n",
    "    neighbors = torch.tensor(np.array(vor.ridge_points), device=device)\n",
    "    \n",
    "    # Extract the SDF values for each site in the pair\n",
    "    sdf_i = sdf_values[neighbors[:, 0]]  # First site in each pair\n",
    "    sdf_j = sdf_values[neighbors[:, 1]]  # Second site in each pair\n",
    "    # Find the indices where SDF values have opposing signs or one is zero\n",
    "    mask_zero_crossing_sites = (sdf_i * sdf_j <= 0).squeeze()\n",
    "    sites_to_upsample = torch.unique(neighbors[mask_zero_crossing_sites].view(-1))\n",
    "    \n",
    "    print(\"Sites to upsample \",sites_to_upsample.shape)\n",
    "    \n",
    "    tet_centroids = sites[sites_to_upsample]\n",
    "\n",
    "    # Tetrahedron relative positions (unit tetrahedron)\n",
    "    basic_tet_1 = torch.tensor([[1, 1, 1]], device=device, dtype=torch.float64)\n",
    "    basic_tet_1 = basic_tet_1.repeat(len(tet_centroids), 1)\n",
    "    basic_tet_2 = torch.tensor([-1, -1, 1], device=device, dtype=torch.float64)    \n",
    "    basic_tet_2 = basic_tet_2.repeat(len(tet_centroids), 1)\n",
    "    basic_tet_3 = torch.tensor([-1, 1, -1], device=device, dtype=torch.float64)    \n",
    "    basic_tet_3 = basic_tet_3.repeat(len(tet_centroids), 1)\n",
    "    basic_tet_4 = torch.tensor([1, -1, -1], device=device, dtype=torch.float64)\n",
    "    basic_tet_4 = basic_tet_4.repeat(len(tet_centroids), 1)\n",
    "\n",
    "\n",
    "    #compute scale based on cell volume\n",
    "    centroids = torch.tensor(np.array([vor.vertices[vor.regions[vor.point_region[i]]].mean(axis=0) for i in range(len(sites_np))]), device=device)\n",
    "    #centroids = torch.tensor(np.array(centroids), device=sites.device, dtype=sites.dtype)\n",
    "    cells_vertices = [vor.vertices[vor.regions[vor.point_region[i]]] for i in range(len(sites_np))]\n",
    "\n",
    "    #compute the distance between each centroid  and each vertex in cells_vertices row\n",
    "    distances = []\n",
    "    for i in range(len(cells_vertices)):\n",
    "        min_dist = 100000000000\n",
    "        for j in range(len(cells_vertices[i])):\n",
    "            dist = torch.norm(centroids[i] - torch.tensor(cells_vertices[i][j], device=device), p=2)\n",
    "            if dist < min_dist:\n",
    "                min_dist = dist\n",
    "        distances.append(min_dist)\n",
    "    distances = torch.tensor(distances, device=device)\n",
    " \n",
    "    \n",
    "    scale = distances[sites_to_upsample] / 2\n",
    "    \n",
    "    scale = scale.unsqueeze(1)\n",
    "    \n",
    "    \n",
    "    new_sites = torch.cat((tet_centroids + basic_tet_1 * scale, tet_centroids + basic_tet_2 * scale, tet_centroids + basic_tet_3 * scale, tet_centroids + basic_tet_4 * scale), dim=0)\n",
    "\n",
    "    updated_sites = torch.cat((sites, new_sites), dim=0)\n",
    "\n",
    "    return updated_sites\n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvt_loss_values = []\n",
    "min_distance_loss_values = []\n",
    "edge_smoothing_loss_values = []\n",
    "chamfer_distance_loss_values = []\n",
    "eikonal_loss_values = []\n",
    "domain_restriction_loss_values = []\n",
    "zero_target_points_loss_values = []\n",
    "loss_values = []\n",
    "\n",
    "def autograd(sites, model, max_iter=100, stop_train_threshold=1e-6, upsampling=0, lambda_weights = [0.1,1.0,0.1,0.1,1.0,1.0,0.1]):\n",
    "    optimizer = torch.optim.Adam([\n",
    "    #{'params': [p for _, p in model.named_parameters()], 'lr': lr_model},\n",
    "    {'params': [sites], 'lr': lr_sites}\n",
    "], betas=(0.5, 0.999))\n",
    "\n",
    "    prev_loss = float(\"inf\")\n",
    "    best_loss = float(\"inf\")\n",
    "    upsampled = 0.0\n",
    "    epoch = 0\n",
    "    lambda_cvt = lambda_weights[0]\n",
    "    lambda_sdf = lambda_weights[1]\n",
    "    lambda_min_distance = lambda_weights[2]\n",
    "    lambda_laplace = lambda_weights[3]\n",
    "    lamda_chamfer = lambda_weights[4]\n",
    "    lamda_eikonal = lambda_weights[5]\n",
    "    lambda_domain_restriction = lambda_weights[6]\n",
    "    lambda_target_points = lambda_weights[7]\n",
    "    \n",
    "    best_sites = sites.clone()\n",
    "    best_sites.best_loss = best_loss\n",
    "    \n",
    "    while epoch <= max_iter:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        vertices_to_compute, bisectors_to_compute = su.compute_zero_crossing_vertices_3d(sites, model)\n",
    "        vertices = su.compute_vertices_3d_vectorized(sites, vertices_to_compute)    \n",
    "        bisectors = su.compute_all_bisectors_vectorized(sites, bisectors_to_compute)\n",
    "        #combine vertices and bisectors to one tensor for chamfer\n",
    "        points = torch.cat((vertices, bisectors), 0)\n",
    "\n",
    "\n",
    "        # Compute losses       \n",
    "        cvt_loss = lf.compute_cvt_loss_vectorized(sites, model)\n",
    "        #min_distance_loss = min_distance_regularization_for_op_sites(edges,sites)\n",
    "        #min_distance_loss = lf.sdf_weighted_min_distance_loss(model, sites)\n",
    "        #edge_smoothing_loss = compute_edge_smoothing_loss(edges, sites, model)\n",
    "        chamfer_loss = lf.chamfer_distance(target_points, points)\n",
    "        eikonal_loss = torch.tensor(0.0)#lf.eikonal(model, input_dimensions=input_dims)\n",
    "        #domain_restriction_loss = lf.domain_restriction(target_points, model)\n",
    "        \n",
    "        sdf_values_target_points = model(target_points)[:,0]\n",
    "        zero_target_points_loss_L2 = torch.mean(sdf_values_target_points**2)\n",
    "        zero_target_points_loss_L1 = torch.mean(torch.abs(model(target_points)[:, 0]))\n",
    "        lambda_1, lambda_2 = 0 , 0.99  # Adjust weights as needed\n",
    "        zero_target_points_loss = lambda_1 * zero_target_points_loss_L1 + lambda_2 * zero_target_points_loss_L2\n",
    "\n",
    "               \n",
    "        # Track raw losses (unweighted)\n",
    "        cvt_loss_values.append(cvt_loss.item())\n",
    "        #min_distance_loss_values.append(min_distance_loss.item())\n",
    "        #edge_smoothing_loss_values.append(edge_smoothing_loss.item())\n",
    "        chamfer_distance_loss_values.append(chamfer_loss.item())\n",
    "        eikonal_loss_values.append(eikonal_loss.item())\n",
    "        #domain_restriction_loss_values.append(domain_restriction_loss.item())\n",
    "        zero_target_points_loss_values.append(zero_target_points_loss.item())\n",
    "  \n",
    "        loss = (\n",
    "            lambda_cvt * cvt_loss +\n",
    "            #lambda_min_distance * min_distance_loss + \n",
    "            #lambda_laplace * edge_smoothing_loss +\n",
    "            lamda_chamfer * chamfer_loss +\n",
    "            lamda_eikonal * eikonal_loss +\n",
    "            #lambda_domain_restriction * domain_restriction_loss +\n",
    "            lambda_target_points * zero_target_points_loss\n",
    "        )\n",
    "        loss_values.append(loss.item())\n",
    "        print(f\"Epoch {epoch}: loss = {loss.item()}\")\n",
    "                \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if loss.item() < best_loss:\n",
    "            best_loss = loss.item()\n",
    "            best_epoch = epoch\n",
    "            best_sites = sites.clone()\n",
    "            best_sites.best_loss = best_loss\n",
    "            if upsampled > 0:\n",
    "                print(f\"UPSAMPLED {upsampled} Best Epoch {best_epoch}: Best loss = {best_loss}\")\n",
    "                #return best_sites\n",
    "        \n",
    "        if abs(prev_loss - loss.item()) < stop_train_threshold:\n",
    "            print(f\"Converged at epoch {epoch} with loss {loss.item()}\")\n",
    "            #break\n",
    "        \n",
    "        prev_loss = loss.item() \n",
    "        \n",
    "        if epoch>100 and (epoch // 100) == upsampled+1 and loss.item() < 0.5 and upsampled < upsampling:\n",
    "            print(\"sites length BEFORE UPSAMPLING: \",len(sites))\n",
    "            \n",
    "            #new_sites = su.upsampling_inside(best_sites, model)\n",
    "            #new_sites = su.adaptive_density_upsampling(best_sites, model)\n",
    "            \n",
    "            #sites = su.add_upsampled_sites(best_sites, new_sites)\n",
    "            \n",
    "            sites = upsampling_vectorized(sites, model)\n",
    "            \n",
    "            sites = sites.detach().requires_grad_(True)\n",
    "            #print(\"upsampled sites length: \",len(sites))\n",
    "            \n",
    "            #best_sites = sites.clone()\n",
    "            #best_sites.best_loss = best_loss\n",
    "            \n",
    "            optimizer = torch.optim.Adam([{'params': [p for _, p in model.named_parameters()], 'lr': lr_model},\n",
    "                                          {'params': [sites], 'lr': lr_sites}])\n",
    "            upsampled += 1.0\n",
    "            print(\"sites length AFTER: \",len(sites))\n",
    "            \n",
    "          \n",
    "        if epoch % (max_iter/10) == 0:\n",
    "            print(f\"Epoch {epoch}: loss = {loss.item()}\")\n",
    "            print(f\"Best Epoch {best_epoch}: Best loss = {best_loss}\")\n",
    "            #save model and sites\n",
    "            site_file_path = f'{destination}{mesh[0]}{max_iter}_{epoch}_3d_sites_{num_centroids}_chamfer{lamda_chamfer}.pth'\n",
    "            model_file_path = f'{destination}{mesh[0]}{max_iter}_{epoch}_3d_model_{num_centroids}_chamfer{lamda_chamfer}.pth'\n",
    "            torch.save(model.state_dict(), model_file_path)\n",
    "            torch.save(sites, site_file_path)\n",
    "            \n",
    "        \n",
    "        epoch += 1           \n",
    "        \n",
    "    return best_sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cvt_loss:  tensor(0.0776, grad_fn=<MeanBackward0>)\n",
      "Epoch 0: loss = 4.406394580626848\n",
      "Epoch 0: loss = 4.406394580626848\n",
      "Best Epoch 0: Best loss = 4.406394580626848\n",
      "cvt_loss:  tensor(0.0769, grad_fn=<MeanBackward0>)\n",
      "Epoch 1: loss = 2.764461800579586\n",
      "cvt_loss:  tensor(0.0876, grad_fn=<MeanBackward0>)\n",
      "Epoch 2: loss = 2.6531825307381687\n",
      "cvt_loss:  tensor(0.0877, grad_fn=<MeanBackward0>)\n",
      "Epoch 3: loss = 3.2862159202181154\n",
      "cvt_loss:  tensor(0.0897, grad_fn=<MeanBackward0>)\n",
      "Epoch 4: loss = 2.619160305791902\n",
      "cvt_loss:  tensor(0.0945, grad_fn=<MeanBackward0>)\n",
      "Epoch 5: loss = 4.1045855602479\n",
      "cvt_loss:  tensor(0.0853, grad_fn=<MeanBackward0>)\n",
      "Epoch 6: loss = 2.550268724261678\n",
      "cvt_loss:  tensor(0.1051, grad_fn=<MeanBackward0>)\n",
      "Epoch 7: loss = 2.444862304013288\n",
      "cvt_loss:  tensor(0.0932, grad_fn=<MeanBackward0>)\n",
      "Epoch 8: loss = 2.348606793964791\n",
      "cvt_loss:  tensor(0.0836, grad_fn=<MeanBackward0>)\n",
      "Epoch 9: loss = 2.7836551140691954\n",
      "cvt_loss:  tensor(0.0873, grad_fn=<MeanBackward0>)\n",
      "Epoch 10: loss = 2.72873775305497\n",
      "cvt_loss:  tensor(0.0886, grad_fn=<MeanBackward0>)\n",
      "Epoch 11: loss = 2.4344456821825275\n",
      "cvt_loss:  tensor(0.0815, grad_fn=<MeanBackward0>)\n",
      "Epoch 12: loss = 2.3712722972199396\n",
      "cvt_loss:  tensor(0.0869, grad_fn=<MeanBackward0>)\n",
      "Epoch 13: loss = 2.323864602036299\n",
      "cvt_loss:  tensor(0.0769, grad_fn=<MeanBackward0>)\n",
      "Epoch 14: loss = 2.4086495650997257\n",
      "cvt_loss:  tensor(0.0796, grad_fn=<MeanBackward0>)\n",
      "Epoch 15: loss = 2.4082044592375365\n",
      "cvt_loss:  tensor(0.0856, grad_fn=<MeanBackward0>)\n",
      "Epoch 16: loss = 2.3629909555542308\n",
      "cvt_loss:  tensor(0.0859, grad_fn=<MeanBackward0>)\n",
      "Epoch 17: loss = 2.39818382423066\n",
      "cvt_loss:  tensor(0.0870, grad_fn=<MeanBackward0>)\n",
      "Epoch 18: loss = 2.2707257145408\n",
      "cvt_loss:  tensor(0.0728, grad_fn=<MeanBackward0>)\n",
      "Epoch 19: loss = 2.2980846735885754\n",
      "cvt_loss:  tensor(0.0752, grad_fn=<MeanBackward0>)\n",
      "Epoch 20: loss = 2.303196889542761\n",
      "cvt_loss:  tensor(0.0712, grad_fn=<MeanBackward0>)\n",
      "Epoch 21: loss = 2.300611484137478\n",
      "cvt_loss:  tensor(0.0723, grad_fn=<MeanBackward0>)\n",
      "Epoch 22: loss = 2.3708610992172003\n",
      "cvt_loss:  tensor(0.0645, grad_fn=<MeanBackward0>)\n",
      "Epoch 23: loss = 2.3025538150098543\n",
      "cvt_loss:  tensor(0.0623, grad_fn=<MeanBackward0>)\n",
      "Epoch 24: loss = 2.2812425959566602\n",
      "cvt_loss:  tensor(0.0616, grad_fn=<MeanBackward0>)\n",
      "Epoch 25: loss = 2.247246181774332\n",
      "cvt_loss:  tensor(0.0617, grad_fn=<MeanBackward0>)\n",
      "Epoch 26: loss = 2.253697043276074\n",
      "cvt_loss:  tensor(0.0636, grad_fn=<MeanBackward0>)\n",
      "Epoch 27: loss = 2.408621970891156\n",
      "cvt_loss:  tensor(0.0569, grad_fn=<MeanBackward0>)\n",
      "Epoch 28: loss = 2.297384921730671\n",
      "cvt_loss:  tensor(0.0621, grad_fn=<MeanBackward0>)\n",
      "Epoch 29: loss = 2.523787909134318\n",
      "cvt_loss:  tensor(0.0680, grad_fn=<MeanBackward0>)\n",
      "Epoch 30: loss = 2.531454334698293\n",
      "cvt_loss:  tensor(0.0549, grad_fn=<MeanBackward0>)\n",
      "Epoch 31: loss = 2.530361001846863\n",
      "cvt_loss:  tensor(0.0587, grad_fn=<MeanBackward0>)\n",
      "Epoch 32: loss = 2.4801440141709437\n",
      "cvt_loss:  tensor(0.0625, grad_fn=<MeanBackward0>)\n",
      "Epoch 33: loss = 2.5378133172818274\n",
      "cvt_loss:  tensor(0.0557, grad_fn=<MeanBackward0>)\n",
      "Epoch 34: loss = 2.5924159319547275\n",
      "cvt_loss:  tensor(0.0528, grad_fn=<MeanBackward0>)\n",
      "Epoch 35: loss = 2.462165870889663\n",
      "cvt_loss:  tensor(0.0481, grad_fn=<MeanBackward0>)\n",
      "Epoch 36: loss = 2.5600822635652447\n",
      "cvt_loss:  tensor(0.0541, grad_fn=<MeanBackward0>)\n",
      "Epoch 37: loss = 2.5531561278482897\n",
      "cvt_loss:  tensor(0.0577, grad_fn=<MeanBackward0>)\n",
      "Epoch 38: loss = 2.535292290915706\n",
      "cvt_loss:  tensor(0.0623, grad_fn=<MeanBackward0>)\n",
      "Epoch 39: loss = 2.5871558592304513\n",
      "cvt_loss:  tensor(0.0559, grad_fn=<MeanBackward0>)\n",
      "Epoch 40: loss = 2.5140966994720966\n",
      "cvt_loss:  tensor(0.0503, grad_fn=<MeanBackward0>)\n",
      "Epoch 41: loss = 2.4910180817687033\n",
      "cvt_loss:  tensor(0.0374, grad_fn=<MeanBackward0>)\n",
      "Epoch 42: loss = 2.422679611639304\n",
      "cvt_loss:  tensor(0.0484, grad_fn=<MeanBackward0>)\n",
      "Epoch 43: loss = 2.555176219527451\n",
      "cvt_loss:  tensor(0.0508, grad_fn=<MeanBackward0>)\n",
      "Epoch 44: loss = 2.6871265063956136\n",
      "cvt_loss:  tensor(0.0476, grad_fn=<MeanBackward0>)\n",
      "Epoch 45: loss = 2.86466711063421\n",
      "cvt_loss:  tensor(0.0453, grad_fn=<MeanBackward0>)\n",
      "Epoch 46: loss = 2.799325355606936\n",
      "cvt_loss:  tensor(0.0546, grad_fn=<MeanBackward0>)\n",
      "Epoch 47: loss = 2.746298387455469\n",
      "cvt_loss:  tensor(0.0421, grad_fn=<MeanBackward0>)\n",
      "Epoch 48: loss = 2.868702956252813\n",
      "cvt_loss:  tensor(0.0439, grad_fn=<MeanBackward0>)\n",
      "Epoch 49: loss = 2.6977393245556294\n",
      "cvt_loss:  tensor(0.0455, grad_fn=<MeanBackward0>)\n",
      "Epoch 50: loss = 2.5632403188276367\n",
      "Epoch 50: loss = 2.5632403188276367\n",
      "Best Epoch 25: Best loss = 2.247246181774332\n",
      "cvt_loss:  tensor(0.0413, grad_fn=<MeanBackward0>)\n",
      "Epoch 51: loss = 2.519573458184526\n",
      "cvt_loss:  tensor(0.0368, grad_fn=<MeanBackward0>)\n",
      "Epoch 52: loss = 2.558282261198146\n",
      "cvt_loss:  tensor(0.0413, grad_fn=<MeanBackward0>)\n",
      "Epoch 53: loss = 2.4043233133574833\n",
      "cvt_loss:  tensor(0.0393, grad_fn=<MeanBackward0>)\n",
      "Epoch 54: loss = 2.5147350764947705\n",
      "cvt_loss:  tensor(0.0416, grad_fn=<MeanBackward0>)\n",
      "Epoch 55: loss = 2.4274131590272154\n",
      "cvt_loss:  tensor(0.0361, grad_fn=<MeanBackward0>)\n",
      "Epoch 56: loss = 2.4287770179187445\n",
      "cvt_loss:  tensor(0.0378, grad_fn=<MeanBackward0>)\n",
      "Epoch 57: loss = 3.0084828782014448\n",
      "cvt_loss:  tensor(0.0374, grad_fn=<MeanBackward0>)\n",
      "Epoch 58: loss = 2.774127635510677\n",
      "cvt_loss:  tensor(0.0304, grad_fn=<MeanBackward0>)\n",
      "Epoch 59: loss = 2.713717098415766\n",
      "cvt_loss:  tensor(0.0333, grad_fn=<MeanBackward0>)\n",
      "Epoch 60: loss = 2.609315363582529\n",
      "cvt_loss:  tensor(0.0351, grad_fn=<MeanBackward0>)\n",
      "Epoch 61: loss = 2.630645497724214\n",
      "cvt_loss:  tensor(0.0336, grad_fn=<MeanBackward0>)\n",
      "Epoch 62: loss = 2.49624671742736\n",
      "cvt_loss:  tensor(0.0361, grad_fn=<MeanBackward0>)\n",
      "Epoch 63: loss = 2.708940107634392\n",
      "cvt_loss:  tensor(0.0313, grad_fn=<MeanBackward0>)\n",
      "Epoch 64: loss = 2.7880138517261956\n",
      "cvt_loss:  tensor(0.0336, grad_fn=<MeanBackward0>)\n",
      "Epoch 65: loss = 2.675637489776051\n",
      "cvt_loss:  tensor(0.0392, grad_fn=<MeanBackward0>)\n",
      "Epoch 66: loss = 2.8759041716645655\n",
      "cvt_loss:  tensor(0.0272, grad_fn=<MeanBackward0>)\n",
      "Epoch 67: loss = 2.8726742115815274\n",
      "cvt_loss:  tensor(0.0321, grad_fn=<MeanBackward0>)\n",
      "Epoch 68: loss = 2.7787153259521187\n",
      "cvt_loss:  tensor(0.0358, grad_fn=<MeanBackward0>)\n",
      "Epoch 69: loss = 2.939337388675142\n",
      "cvt_loss:  tensor(0.0289, grad_fn=<MeanBackward0>)\n",
      "Epoch 70: loss = 2.7819473857439743\n",
      "cvt_loss:  tensor(0.0300, grad_fn=<MeanBackward0>)\n",
      "Epoch 71: loss = 2.7696204752452998\n",
      "cvt_loss:  tensor(0.0209, grad_fn=<MeanBackward0>)\n",
      "Epoch 72: loss = 2.7085318160720497\n",
      "cvt_loss:  tensor(0.0275, grad_fn=<MeanBackward0>)\n",
      "Epoch 73: loss = 2.5953891504379656\n",
      "cvt_loss:  tensor(0.0270, grad_fn=<MeanBackward0>)\n",
      "Epoch 74: loss = 2.5963151892984495\n",
      "cvt_loss:  tensor(0.0299, grad_fn=<MeanBackward0>)\n",
      "Epoch 75: loss = 4.430374036426689\n",
      "cvt_loss:  tensor(0.0244, grad_fn=<MeanBackward0>)\n",
      "Epoch 76: loss = 2.738327051324283\n",
      "cvt_loss:  tensor(0.0205, grad_fn=<MeanBackward0>)\n",
      "Epoch 77: loss = 2.670969701365406\n",
      "cvt_loss:  tensor(0.0180, grad_fn=<MeanBackward0>)\n",
      "Epoch 78: loss = 2.5939604146438784\n",
      "cvt_loss:  tensor(0.0196, grad_fn=<MeanBackward0>)\n",
      "Epoch 79: loss = 2.5189155702614574\n",
      "cvt_loss:  tensor(0.0241, grad_fn=<MeanBackward0>)\n",
      "Epoch 80: loss = 2.5582566103641198\n",
      "cvt_loss:  tensor(0.0183, grad_fn=<MeanBackward0>)\n",
      "Epoch 81: loss = 2.4477146785762462\n",
      "cvt_loss:  tensor(0.0204, grad_fn=<MeanBackward0>)\n",
      "Epoch 82: loss = 2.441372478559181\n",
      "cvt_loss:  tensor(0.0199, grad_fn=<MeanBackward0>)\n",
      "Epoch 83: loss = 2.5857710670515703\n",
      "cvt_loss:  tensor(0.0230, grad_fn=<MeanBackward0>)\n",
      "Epoch 84: loss = 2.4341733877385376\n",
      "cvt_loss:  tensor(0.0216, grad_fn=<MeanBackward0>)\n",
      "Epoch 85: loss = 2.461256472595835\n",
      "cvt_loss:  tensor(0.0198, grad_fn=<MeanBackward0>)\n",
      "Epoch 86: loss = 2.531870764509515\n",
      "cvt_loss:  tensor(0.0258, grad_fn=<MeanBackward0>)\n",
      "Epoch 87: loss = 2.5727062560937997\n",
      "cvt_loss:  tensor(0.0203, grad_fn=<MeanBackward0>)\n",
      "Epoch 88: loss = 2.525426449414283\n",
      "cvt_loss:  tensor(0.0160, grad_fn=<MeanBackward0>)\n",
      "Epoch 89: loss = 2.4081324166749862\n",
      "cvt_loss:  tensor(0.0177, grad_fn=<MeanBackward0>)\n",
      "Epoch 90: loss = 2.45052228941426\n",
      "cvt_loss:  tensor(0.0194, grad_fn=<MeanBackward0>)\n",
      "Epoch 91: loss = 2.440098366911146\n",
      "cvt_loss:  tensor(0.0176, grad_fn=<MeanBackward0>)\n",
      "Epoch 92: loss = 2.4364553697257803\n",
      "cvt_loss:  tensor(0.0169, grad_fn=<MeanBackward0>)\n",
      "Epoch 93: loss = 2.4184936895975357\n",
      "cvt_loss:  tensor(0.0196, grad_fn=<MeanBackward0>)\n",
      "Epoch 94: loss = 2.435301836325603\n",
      "cvt_loss:  tensor(0.0210, grad_fn=<MeanBackward0>)\n",
      "Epoch 95: loss = 2.4071096579086277\n",
      "cvt_loss:  tensor(0.0268, grad_fn=<MeanBackward0>)\n",
      "Epoch 96: loss = 2.555391504800993\n",
      "cvt_loss:  tensor(0.0196, grad_fn=<MeanBackward0>)\n",
      "Epoch 97: loss = 2.4613006604829897\n",
      "cvt_loss:  tensor(0.0261, grad_fn=<MeanBackward0>)\n",
      "Epoch 98: loss = 2.3945142309166716\n",
      "cvt_loss:  tensor(0.0212, grad_fn=<MeanBackward0>)\n",
      "Epoch 99: loss = 2.3468109355062885\n",
      "cvt_loss:  tensor(0.0180, grad_fn=<MeanBackward0>)\n",
      "Epoch 100: loss = 2.33792730846747\n",
      "Epoch 100: loss = 2.33792730846747\n",
      "Best Epoch 25: Best loss = 2.247246181774332\n",
      "cvt_loss:  tensor(0.0193, grad_fn=<MeanBackward0>)\n",
      "Epoch 101: loss = 2.341725106737413\n",
      "cvt_loss:  tensor(0.0147, grad_fn=<MeanBackward0>)\n",
      "Epoch 102: loss = 2.3054686730011458\n",
      "cvt_loss:  tensor(0.0190, grad_fn=<MeanBackward0>)\n",
      "Epoch 103: loss = 2.344868019225599\n",
      "cvt_loss:  tensor(0.0174, grad_fn=<MeanBackward0>)\n",
      "Epoch 104: loss = 2.3468112156451957\n",
      "cvt_loss:  tensor(0.0234, grad_fn=<MeanBackward0>)\n",
      "Epoch 105: loss = 2.569438369338425\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m profiler \u001b[38;5;241m=\u001b[39m cProfile\u001b[38;5;241m.\u001b[39mProfile()\n\u001b[1;32m     25\u001b[0m profiler\u001b[38;5;241m.\u001b[39menable()\n\u001b[0;32m---> 27\u001b[0m sites \u001b[38;5;241m=\u001b[39m \u001b[43mautograd\u001b[49m\u001b[43m(\u001b[49m\u001b[43msites\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupsampling\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlambda_weights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m profiler\u001b[38;5;241m.\u001b[39mdisable()\n\u001b[1;32m     30\u001b[0m stats \u001b[38;5;241m=\u001b[39m pstats\u001b[38;5;241m.\u001b[39mStats(profiler)\u001b[38;5;241m.\u001b[39msort_stats(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcumtime\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[10], line 43\u001b[0m, in \u001b[0;36mautograd\u001b[0;34m(sites, model, max_iter, stop_train_threshold, upsampling, lambda_weights)\u001b[0m\n\u001b[1;32m     39\u001b[0m points \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((vertices, bisectors), \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Compute losses       \u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m cvt_loss \u001b[38;5;241m=\u001b[39m \u001b[43mlf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_cvt_loss_vectorized\u001b[49m\u001b[43m(\u001b[49m\u001b[43msites\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m#min_distance_loss = min_distance_regularization_for_op_sites(edges,sites)\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m#min_distance_loss = lf.sdf_weighted_min_distance_loss(model, sites)\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m#edge_smoothing_loss = compute_edge_smoothing_loss(edges, sites, model)\u001b[39;00m\n\u001b[1;32m     47\u001b[0m chamfer_loss \u001b[38;5;241m=\u001b[39m lf\u001b[38;5;241m.\u001b[39mchamfer_distance(target_points, points)\n",
      "File \u001b[0;32m~/dev/Kyushu_experiments/sdfpred_utils/loss_functions.py:96\u001b[0m, in \u001b[0;36mcompute_cvt_loss_vectorized\u001b[0;34m(sites, model)\u001b[0m\n\u001b[1;32m     94\u001b[0m sdf_values \u001b[38;5;241m=\u001b[39m model(sites)\n\u001b[1;32m     95\u001b[0m sites_np \u001b[38;5;241m=\u001b[39m sites\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m---> 96\u001b[0m vor \u001b[38;5;241m=\u001b[39m \u001b[43mVoronoi\u001b[49m\u001b[43m(\u001b[49m\u001b[43msites_np\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;66;03m#Todo C++ loop for this\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# create a nested list of vertices for each site\u001b[39;00m\n\u001b[1;32m    100\u001b[0m centroids \u001b[38;5;241m=\u001b[39m [vor\u001b[38;5;241m.\u001b[39mvertices[vor\u001b[38;5;241m.\u001b[39mregions[vor\u001b[38;5;241m.\u001b[39mpoint_region[i]]]\u001b[38;5;241m.\u001b[39mmean(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(sites_np)) \u001b[38;5;28;01mif\u001b[39;00m vor\u001b[38;5;241m.\u001b[39mregions[vor\u001b[38;5;241m.\u001b[39mpoint_region[i]] \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m vor\u001b[38;5;241m.\u001b[39mregions[vor\u001b[38;5;241m.\u001b[39mpoint_region[i]]]\n",
      "File \u001b[0;32m_qhull.pyx:2615\u001b[0m, in \u001b[0;36mscipy.spatial._qhull.Voronoi.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_qhull.pyx:1532\u001b[0m, in \u001b[0;36mscipy.spatial._qhull._QhullUser.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_qhull.pyx:2626\u001b[0m, in \u001b[0;36mscipy.spatial._qhull.Voronoi._update\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_qhull.pyx:1561\u001b[0m, in \u001b[0;36mscipy.spatial._qhull._QhullUser._update\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/numpy/core/_methods.py:43\u001b[0m, in \u001b[0;36m_amin\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_amax\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     40\u001b[0m           initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m umr_maximum(a, axis, \u001b[38;5;28;01mNone\u001b[39;00m, out, keepdims, initial, where)\n\u001b[0;32m---> 43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_amin\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     44\u001b[0m           initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m umr_minimum(a, axis, \u001b[38;5;28;01mNone\u001b[39;00m, out, keepdims, initial, where)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     48\u001b[0m          initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "lambda_weights = [0.2,0,0.2,0,1.000111111111101101000101,0.1,0,2]\n",
    "\n",
    "lambda_cvt = lambda_weights[0]\n",
    "lambda_sdf = lambda_weights[1]\n",
    "lambda_min_distance = lambda_weights[2]\n",
    "lambda_laplace = lambda_weights[3]\n",
    "lamda_chamfer = lambda_weights[4]\n",
    "lambda_eikonal = lambda_weights[5]\n",
    "lambda_domain_restriction = lambda_weights[6]\n",
    "lambda_target_points = lambda_weights[7]\n",
    "\n",
    "max_iter = 500\n",
    "\n",
    "site_file_path = f'{destination}{mesh[0]}{max_iter}3d_sites_{num_centroids}_chamfer{lamda_chamfer}.npy'\n",
    "#check if optimized sites file exists\n",
    "if os.path.exists(site_file_path):\n",
    "    #import sites\n",
    "    print(\"Importing sites\")\n",
    "    sites = np.load(site_file_path)\n",
    "    sites = torch.from_numpy(sites).to(device).requires_grad_(True)    \n",
    "else:\n",
    "    import cProfile, pstats\n",
    "    import time\n",
    "    profiler = cProfile.Profile()\n",
    "    profiler.enable()\n",
    "    \n",
    "    sites = autograd(sites, model, max_iter=max_iter, upsampling=0, lambda_weights=lambda_weights)\n",
    "    \n",
    "    profiler.disable()\n",
    "    stats = pstats.Stats(profiler).sort_stats('cumtime')\n",
    "    stats.print_stats()\n",
    "    stats.dump_stats(f'{destination}{mesh[0]}{max_iter}_3d_profile_{num_centroids}_chamfer{lamda_chamfer}.prof')\n",
    "    \n",
    "    \n",
    "    sites_np = sites.detach().cpu().numpy()\n",
    "    np.save(site_file_path, sites_np)\n",
    "    \n",
    "\n",
    "print(\"Sites length: \", len(sites))\n",
    "print(\"min sites: \", torch.min(sites))\n",
    "print(\"max sites: \", torch.max(sites))\n",
    "ps_cloud = ps.register_point_cloud(\"best_optimized_cvt_grid\",sites.detach().cpu().numpy())\n",
    "    \n",
    "lim=torch.abs(torch.max(sites)).detach().cpu().numpy()*1.1\n",
    "#plot_voronoi_3d(sites,lim,lim,lim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model ./images/autograd/3D/bunny500_100_3d_model_4096_chamfer1.0001111111111012.pth\n",
      "sites ./images/autograd/3D/bunny500_100_3d_sites_4096_chamfer1.0001111111111012.pth\n"
     ]
    }
   ],
   "source": [
    "epoch = 100\n",
    "\n",
    "model_file_path = f'{destination}{mesh[0]}{max_iter}_{epoch}_3d_model_{num_centroids}_chamfer{lamda_chamfer}.pth'\n",
    "site_file_path = f'{destination}{mesh[0]}{max_iter}_{epoch}_3d_sites_{num_centroids}_chamfer{lamda_chamfer}.pth'\n",
    "sites = torch.load(site_file_path)\n",
    "sites_np = sites.detach().cpu().numpy()\n",
    "model.load_state_dict(torch.load(model_file_path))\n",
    "#\n",
    "#polyscope_sdf(model)\n",
    "#\n",
    "print(\"model\", model_file_path)\n",
    "print(\"sites\", site_file_path)\n",
    "ps_cloud = ps.register_point_cloud(f\"{epoch} epoch_cvt_grid\",sites_np)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_mesh = su.get_zero_crossing_mesh_3d(sites, model)\n",
    "\n",
    "ps.register_surface_mesh(\"Zero-Crossing faces\", final_mesh[0], final_mesh[1])\n",
    "ps.register_point_cloud(\"Mesh vertices\", final_mesh[0])\n",
    "\n",
    "ps.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_visualisation_3d():\n",
    "    import imageio\n",
    "    img_buffer_mesh = []\n",
    "    img_buffer_model = []\n",
    "    for i in range(int(max_iter/10)+1):\n",
    "        epoch = i*int(max_iter/10)\n",
    "        \n",
    "        site_file_path = f'{destination}{mesh[0]}{max_iter}_{epoch}_3d_sites_{num_centroids}_chamfer{lamda_chamfer}.pth'\n",
    "        model_file_path = f'{destination}{mesh[0]}{max_iter}_{epoch}_3d_model_{num_centroids}_chamfer{lamda_chamfer}.pth'\n",
    "        if os.path.exists(site_file_path) and os.path.exists(model_file_path):\n",
    "            print(\"importing sites and model\")\n",
    "        else:\n",
    "            print(\"files not found\")\n",
    "            continue\n",
    "        print(\"mesh of epoch: \", epoch)\n",
    "        \n",
    "        model.load_state_dict(torch.load(model_file_path))\n",
    "    \n",
    "        current_mesh = su.get_zero_crossing_mesh_3d(torch.load(site_file_path), model)\n",
    "        ps.remove_all_structures()\n",
    "        ps.register_surface_mesh(\"Zero-Crossing faces\", current_mesh[0], current_mesh[1])\n",
    "        ps.register_point_cloud(\"Mesh vertices\", current_mesh[0])\n",
    "        img_buffer_mesh.append(ps.screenshot_to_buffer(transparent_bg=False))\n",
    "        \n",
    "        ps.remove_all_structures()\n",
    "        polyscope_sdf(model)\n",
    "        img_buffer_model.append(ps.screenshot_to_buffer(transparent_bg=False))\n",
    "\n",
    "\n",
    "    imageio.mimsave(f'{destination}{max_iter}_3d_{num_centroids}_optimization_mesh.gif',img_buffer_mesh, fps=1, duration=1, loop=0)\n",
    "    imageio.mimsave(f'{destination}{max_iter}_3d_{num_centroids}_optimization_sdf.gif', img_buffer_model, fps=1, duration=1, loop=0)\n",
    "\n",
    "export_visualisation_3d()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
