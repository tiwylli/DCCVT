{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device:  NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "import kaolin\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import polyscope as ps\n",
    "import interactive_polyscope\n",
    "from scipy.spatial import Voronoi, voronoi_plot_2d\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import sdfpred_utils.sdfpred_utils as su\n",
    "import sdfpred_utils.sdf_MLP as mlp\n",
    "import sdfpred_utils.sdf_functions as sdf\n",
    "import sdfpred_utils.loss_functions as lf\n",
    "import trimesh\n",
    "from scipy.spatial import Delaunay, Voronoi\n",
    "\n",
    "\n",
    "#cuda devices\n",
    "device = torch.device(\"cuda:0\")\n",
    "print(\"Using device: \", torch.cuda.get_device_name(device))\n",
    "\n",
    "#default tensor types\n",
    "torch.set_default_tensor_type(torch.cuda.DoubleTensor)\n",
    "\n",
    "multires = 2\n",
    "input_dims = 3\n",
    "lr_sites = 0.03\n",
    "lr_model = 0.0003\n",
    "iterations = 5000\n",
    "save_every = 100\n",
    "max_iter = 100\n",
    "#learning_rate = 0.03\n",
    "destination = \"./images/autograd/3D/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sites loaded: torch.Size([13824, 3])\n"
     ]
    }
   ],
   "source": [
    "#currently sites are between -5 and 5 in all 3 dimensions\n",
    "# check if sites exists\n",
    "#num_centroids = 16*16*16\n",
    "num_centroids =24*24*24\n",
    "site_fp = f'sites_{num_centroids}_{input_dims}.pt'\n",
    "\n",
    "if os.path.exists(site_fp):\n",
    "    sites = torch.load(site_fp)\n",
    "    print(\"Sites loaded:\", sites.shape)\n",
    "else:\n",
    "    print(\"Creating new sites\")\n",
    "    sites = su.createCVTgrid(num_centroids=num_centroids, dimensionality=input_dims)\n",
    "    #save the initial sites torch tensor\n",
    "    torch.save(sites, site_fp)\n",
    "\n",
    "\n",
    "def plot_voronoi_3d(sites, xlim=5, ylim=5, zlim=5):\n",
    "    import numpy as np\n",
    "    import pyvoro\n",
    "    import matplotlib.pyplot as plt\n",
    "    from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "    # initialize random number generator\n",
    "    rng = np.random.default_rng(11)\n",
    "    # create a set of points in 3D\n",
    "    points = sites.detach().cpu().numpy()\n",
    "\n",
    "    # use pyvoro to compute the Voronoi tessellation\n",
    "    # the second argument gives the the axis limits in x,y and z direction\n",
    "    # in this case all between 0 and 1.\n",
    "    # the third argument gives \"dispersion = max distance between two points\n",
    "    # that might be adjacent\" (not sure how exactly this works)\n",
    "    voronoi = pyvoro.compute_voronoi(points,[[-xlim,xlim],[-ylim,ylim],[-zlim,zlim]],1)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # for each Voronoi cell, plot all the faces of the corresponding polygon\n",
    "    for vnoicell in voronoi:\n",
    "        faces = []\n",
    "        # the vertices are the corner points of the Voronoi cell\n",
    "        vertices = np.array(vnoicell['vertices'])\n",
    "        # cycle through all faces of the polygon\n",
    "        for face in vnoicell['faces']:\n",
    "            faces.append(vertices[np.array(face['vertices'])])\n",
    "            \n",
    "        # join the faces into a 3D polygon\n",
    "        polygon = Poly3DCollection(faces, alpha=0.5, \n",
    "                                facecolors=rng.uniform(0,1,3),\n",
    "                                linewidths=0.5,edgecolors='black')\n",
    "        ax.add_collection3d(polygon)\n",
    "    \n",
    "    ax.set_xlim([-xlim,xlim])\n",
    "    ax.set_ylim([-ylim,ylim])\n",
    "    ax.set_zlim([-zlim,zlim])\n",
    "            \n",
    "    plt.show()\n",
    "\n",
    "#plot_voronoi_3d(sites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps.init()\n",
    "#ps_cloud = ps.register_point_cloud(\"initial_cvt_grid\",sites.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the mesh\n",
    "mesh = [\"bunny\", \"Resources/stanford-bunny.obj\"]\n",
    "bunny = trimesh.load(mesh[1])\n",
    "\n",
    "# Step 1: Get current bounding box\n",
    "min_bound = bunny.bounds[0]  # Min (x, y, z)\n",
    "max_bound = bunny.bounds[1]  # Max (x, y, z)\n",
    "\n",
    "# Step 2: Compute scale factor\n",
    "current_size = max_bound - min_bound  # Size in each dimension\n",
    "target_size = 8  # Because we want [-5, 5], the total size is 10\n",
    "\n",
    "scale_factor = target_size / np.max(current_size)  # Scale based on the largest dimension\n",
    "\n",
    "# Step 3: Compute new center after scaling\n",
    "new_vertices = bunny.vertices * scale_factor  # Scale the vertices\n",
    "new_min = np.min(new_vertices, axis=0)\n",
    "new_max = np.max(new_vertices, axis=0)\n",
    "new_center = (new_min + new_max) / 2  # New center after scaling\n",
    "\n",
    "# Step 4: Compute translation to center the bunny at (0,0,0)\n",
    "translation = -new_center  # Move to the origin\n",
    "\n",
    "# Step 5: Apply transformation (scaling + translation)\n",
    "bunny.vertices = new_vertices + translation\n",
    "\n",
    "target_points = bunny.sample(16*16*16)\n",
    "target_points = torch.tensor(target_points, device=device)\n",
    "\n",
    "ps_cloud = ps.register_point_cloud(\"Target_points\",target_points.detach().cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import os\n",
    "\n",
    "model = mlp.Decoder(multires=multires, input_dims=input_dims).to(device)\n",
    "model_path = 'models_resources/pretrained_sphere_small.pth'\n",
    "if os.path.exists(model_path):\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    print('loaded model')\n",
    "else:\n",
    "    print(\"no model found, pretraining\")\n",
    "    model.pre_train_sphere(3000)\n",
    "    torch.save(model.state_dict(),model_path)\n",
    "    \n",
    "def polyscope_sdf(model):\n",
    "    # Render the SDF as an implicit surface (zero-level set)\n",
    "    def model_sdf(pts):\n",
    "        pts_tensor = torch.tensor(pts, dtype=torch.float64, device=device)\n",
    "        sdf_values = model(pts_tensor)\n",
    "        sdf_values_np = sdf_values.detach().cpu().numpy().flatten()  # Convert to NumPy\n",
    "        \n",
    "        return sdf_values_np\n",
    "\n",
    "    ps.render_implicit_surface(\"SDF Surface\", model_sdf, mode=\"sphere_march\", enabled=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvt_loss_values = []\n",
    "min_distance_loss_values = []\n",
    "edge_smoothing_loss_values = []\n",
    "chamfer_distance_loss_values = []\n",
    "eikonal_loss_values = []\n",
    "domain_restriction_loss_values = []\n",
    "zero_target_points_loss_values = []\n",
    "loss_values = []\n",
    "\n",
    "def autograd(sites, model, max_iter=100, stop_train_threshold=1e-6, upsampling=0, lambda_weights = [0.1,1.0,0.1,0.1,1.0,1.0,0.1]):\n",
    "    optimizer = torch.optim.Adam([\n",
    "    {'params': [p for _, p in model.named_parameters()], 'lr': lr_model},\n",
    "    {'params': [sites], 'lr': lr_sites}\n",
    "], betas=(0.5, 0.999))\n",
    "\n",
    "    prev_loss = float(\"inf\")\n",
    "    best_loss = float(\"inf\")\n",
    "    upsampled = 0.0\n",
    "    epoch = 0\n",
    "    lambda_cvt = lambda_weights[0]\n",
    "    lambda_sdf = lambda_weights[1]\n",
    "    lambda_min_distance = lambda_weights[2]\n",
    "    lambda_laplace = lambda_weights[3]\n",
    "    lamda_chamfer = lambda_weights[4]\n",
    "    lamda_eikonal = lambda_weights[5]\n",
    "    lambda_domain_restriction = lambda_weights[6]\n",
    "    lambda_target_points = lambda_weights[7]\n",
    "    \n",
    "    best_sites = sites.clone()\n",
    "    best_sites.best_loss = best_loss\n",
    "    \n",
    "    while epoch <= max_iter:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        vertices_to_compute, bisectors_to_compute = su.compute_zero_crossing_vertices_3d(sites, model)\n",
    "        vertices = su.compute_vertices_3d_vectorized(sites, vertices_to_compute)    \n",
    "        bisectors = su.compute_all_bisectors_vectorized(sites, bisectors_to_compute)\n",
    "        #combine vertices and bisectors to one tensor for chamfer\n",
    "        points = torch.cat((vertices, bisectors), 0)\n",
    "\n",
    "\n",
    "        # Compute losses       \n",
    "        cvt_loss = lf.compute_cvt_loss_vectorized(sites, model)\n",
    "        #min_distance_loss = min_distance_regularization_for_op_sites(edges,sites)\n",
    "        #min_distance_loss = lf.sdf_weighted_min_distance_loss(model, sites)\n",
    "        #edge_smoothing_loss = compute_edge_smoothing_loss(edges, sites, model)\n",
    "        chamfer_loss = lf.chamfer_distance(target_points, points)\n",
    "        eikonal_loss = lf.eikonal(model, input_dimensions=input_dims)\n",
    "        #domain_restriction_loss = lf.domain_restriction(target_points, model)\n",
    "        \n",
    "        sdf_values_target_points = model(target_points)[:,0]\n",
    "        zero_target_points_loss_L2 = torch.mean(sdf_values_target_points**2)\n",
    "        zero_target_points_loss_L1 = torch.mean(torch.abs(model(target_points)[:, 0]))\n",
    "        lambda_1, lambda_2 = 0 , 0.99  # Adjust weights as needed\n",
    "        zero_target_points_loss = lambda_1 * zero_target_points_loss_L1 + lambda_2 * zero_target_points_loss_L2\n",
    "\n",
    "               \n",
    "        # Track raw losses (unweighted)\n",
    "        cvt_loss_values.append(cvt_loss.item())\n",
    "        #min_distance_loss_values.append(min_distance_loss.item())\n",
    "        #edge_smoothing_loss_values.append(edge_smoothing_loss.item())\n",
    "        chamfer_distance_loss_values.append(chamfer_loss.item())\n",
    "        eikonal_loss_values.append(eikonal_loss.item())\n",
    "        #domain_restriction_loss_values.append(domain_restriction_loss.item())\n",
    "        zero_target_points_loss_values.append(zero_target_points_loss.item())\n",
    "  \n",
    "        loss = (\n",
    "            lambda_cvt * cvt_loss +\n",
    "            #lambda_min_distance * min_distance_loss + \n",
    "            #lambda_laplace * edge_smoothing_loss +\n",
    "            lamda_chamfer * chamfer_loss +\n",
    "            lamda_eikonal * eikonal_loss +\n",
    "            #lambda_domain_restriction * domain_restriction_loss +\n",
    "            lambda_target_points * zero_target_points_loss\n",
    "        )\n",
    "        loss_values.append(loss.item())\n",
    "        print(f\"Epoch {epoch}: loss = {loss.item()}\")\n",
    "                \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if loss.item() < best_loss:\n",
    "            best_loss = loss.item()\n",
    "            best_epoch = epoch\n",
    "            best_sites = sites.clone()\n",
    "            best_sites.best_loss = best_loss\n",
    "            if upsampled > 0:\n",
    "                print(f\"UPSAMPLED {upsampled} Best Epoch {best_epoch}: Best loss = {best_loss}\")\n",
    "                #return best_sites\n",
    "        \n",
    "        if abs(prev_loss - loss.item()) < stop_train_threshold:\n",
    "            print(f\"Converged at epoch {epoch} with loss {loss.item()}\")\n",
    "            #break\n",
    "        \n",
    "        prev_loss = loss.item() \n",
    "        \n",
    "        if epoch>100 and (epoch // 100) == upsampled+1 and loss.item() < 0.5 and upsampled < upsampling:\n",
    "            print(\"sites length: \",len(sites))\n",
    "            \n",
    "            new_sites = su.upsampling_inside(best_sites, model)\n",
    "            #new_sites = su.adaptive_density_upsampling(best_sites, model)\n",
    "            print(new_sites)\n",
    "            sites = su.add_upsampled_sites(best_sites, new_sites)\n",
    "            sites = sites.detach().requires_grad_(True)\n",
    "            print(\"upsampled sites length: \",len(sites))\n",
    "            \n",
    "            best_sites = sites.clone()\n",
    "            best_sites.best_loss = best_loss\n",
    "            \n",
    "            optimizer = torch.optim.Adam([{'params': [p for _, p in model.named_parameters()], 'lr': lr_model},\n",
    "                                          {'params': [sites], 'lr': lr_sites}])\n",
    "            upsampled += 1.0\n",
    "          \n",
    "        if epoch % (max_iter/10) == 0:\n",
    "            print(f\"Epoch {epoch}: loss = {loss.item()}\")\n",
    "            print(f\"Best Epoch {best_epoch}: Best loss = {best_loss}\")\n",
    "            #save model and sites\n",
    "            site_file_path = f'{destination}{mesh[0]}{max_iter}_{epoch}_3d_sites_{num_centroids}_chamfer{lamda_chamfer}.pth'\n",
    "            model_file_path = f'{destination}{mesh[0]}{max_iter}_{epoch}_3d_model_{num_centroids}_chamfer{lamda_chamfer}.pth'\n",
    "            torch.save(model.state_dict(), model_file_path)\n",
    "            torch.save(sites, site_file_path)\n",
    "            \n",
    "        \n",
    "        epoch += 1           \n",
    "        \n",
    "    return best_sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cvt_loss:  tensor(163.1549, grad_fn=<MeanBackward0>)\n",
      "Epoch 0: loss = 40.29397439986374\n",
      "Epoch 0: loss = 40.29397439986374\n",
      "Best Epoch 0: Best loss = 40.29397439986374\n",
      "cvt_loss:  tensor(0.2076, grad_fn=<MeanBackward0>)\n",
      "Epoch 1: loss = 8.647026352468652\n",
      "cvt_loss:  tensor(1.2899, grad_fn=<MeanBackward0>)\n",
      "Epoch 2: loss = 7.087427068754456\n",
      "cvt_loss:  tensor(6.3024, grad_fn=<MeanBackward0>)\n",
      "Epoch 3: loss = 6.1370202572943935\n",
      "cvt_loss:  tensor(0.4846, grad_fn=<MeanBackward0>)\n",
      "Epoch 4: loss = 3.503154287030082\n",
      "cvt_loss:  tensor(1.0002, grad_fn=<MeanBackward0>)\n",
      "Epoch 5: loss = 2.731111869479089\n",
      "cvt_loss:  tensor(1.5935, grad_fn=<MeanBackward0>)\n",
      "Epoch 6: loss = 2.4551146793160346\n",
      "cvt_loss:  tensor(3.5178, grad_fn=<MeanBackward0>)\n",
      "Epoch 7: loss = 2.69565451109806\n",
      "cvt_loss:  tensor(0.2585, grad_fn=<MeanBackward0>)\n",
      "Epoch 8: loss = 1.9056087643937598\n",
      "cvt_loss:  tensor(1.3792, grad_fn=<MeanBackward0>)\n",
      "Epoch 9: loss = 1.9891584534115325\n",
      "cvt_loss:  tensor(2.5557, grad_fn=<MeanBackward0>)\n",
      "Epoch 10: loss = 2.10522885312848\n",
      "cvt_loss:  tensor(10.6599, grad_fn=<MeanBackward0>)\n",
      "Epoch 11: loss = 3.6309397419705185\n",
      "cvt_loss:  tensor(0.9121, grad_fn=<MeanBackward0>)\n",
      "Epoch 12: loss = 1.643504438831954\n",
      "cvt_loss:  tensor(0.1015, grad_fn=<MeanBackward0>)\n",
      "Epoch 13: loss = 1.4379466908412144\n",
      "cvt_loss:  tensor(0.7115, grad_fn=<MeanBackward0>)\n",
      "Epoch 14: loss = 1.485250105682019\n",
      "cvt_loss:  tensor(0.4917, grad_fn=<MeanBackward0>)\n",
      "Epoch 15: loss = 1.3709708884884655\n",
      "cvt_loss:  tensor(0.0670, grad_fn=<MeanBackward0>)\n",
      "Epoch 16: loss = 1.2293778392739378\n",
      "cvt_loss:  tensor(0.0409, grad_fn=<MeanBackward0>)\n",
      "Epoch 17: loss = 1.1862372786019237\n",
      "cvt_loss:  tensor(1.1386, grad_fn=<MeanBackward0>)\n",
      "Epoch 18: loss = 1.3829977410972973\n",
      "cvt_loss:  tensor(0.1290, grad_fn=<MeanBackward0>)\n",
      "Epoch 19: loss = 1.1550017607081395\n",
      "cvt_loss:  tensor(0.7861, grad_fn=<MeanBackward0>)\n",
      "Epoch 20: loss = 1.2676795557589164\n",
      "cvt_loss:  tensor(0.1337, grad_fn=<MeanBackward0>)\n",
      "Epoch 21: loss = 1.1044638142609435\n",
      "cvt_loss:  tensor(6.9081, grad_fn=<MeanBackward0>)\n",
      "Epoch 22: loss = 2.42012626517812\n",
      "cvt_loss:  tensor(0.1487, grad_fn=<MeanBackward0>)\n",
      "Epoch 23: loss = 1.0639589236340892\n",
      "cvt_loss:  tensor(0.0623, grad_fn=<MeanBackward0>)\n",
      "Epoch 24: loss = 1.0133443713831414\n",
      "cvt_loss:  tensor(0.4408, grad_fn=<MeanBackward0>)\n",
      "Epoch 25: loss = 1.0781216424119668\n",
      "cvt_loss:  tensor(0.1702, grad_fn=<MeanBackward0>)\n",
      "Epoch 26: loss = 0.9857056608866814\n",
      "cvt_loss:  tensor(0.1122, grad_fn=<MeanBackward0>)\n",
      "Epoch 27: loss = 0.9558040959250214\n",
      "cvt_loss:  tensor(0.0158, grad_fn=<MeanBackward0>)\n",
      "Epoch 28: loss = 0.9158353792218838\n",
      "cvt_loss:  tensor(0.0153, grad_fn=<MeanBackward0>)\n",
      "Epoch 29: loss = 0.9040489055935397\n",
      "cvt_loss:  tensor(0.0242, grad_fn=<MeanBackward0>)\n",
      "Epoch 30: loss = 0.8877800998225278\n",
      "cvt_loss:  tensor(0.1239, grad_fn=<MeanBackward0>)\n",
      "Epoch 31: loss = 0.9032089291732424\n",
      "cvt_loss:  tensor(0.0198, grad_fn=<MeanBackward0>)\n",
      "Epoch 32: loss = 0.8698864676931614\n",
      "cvt_loss:  tensor(0.0280, grad_fn=<MeanBackward0>)\n",
      "Epoch 33: loss = 0.8549264177467997\n",
      "cvt_loss:  tensor(0.0521, grad_fn=<MeanBackward0>)\n",
      "Epoch 34: loss = 0.8569816478271142\n",
      "cvt_loss:  tensor(0.0136, grad_fn=<MeanBackward0>)\n",
      "Epoch 35: loss = 0.8459869431990013\n",
      "cvt_loss:  tensor(0.0647, grad_fn=<MeanBackward0>)\n",
      "Epoch 36: loss = 0.8261260560606261\n",
      "cvt_loss:  tensor(0.0450, grad_fn=<MeanBackward0>)\n",
      "Epoch 37: loss = 0.8183063466548419\n",
      "cvt_loss:  tensor(0.0461, grad_fn=<MeanBackward0>)\n",
      "Epoch 38: loss = 0.7800871435556647\n",
      "cvt_loss:  tensor(0.0138, grad_fn=<MeanBackward0>)\n",
      "Epoch 39: loss = 0.7722360464803839\n",
      "cvt_loss:  tensor(0.0788, grad_fn=<MeanBackward0>)\n",
      "Epoch 40: loss = 0.7803977127973948\n",
      "cvt_loss:  tensor(0.0313, grad_fn=<MeanBackward0>)\n",
      "Epoch 41: loss = 0.7525669130506428\n",
      "cvt_loss:  tensor(1.2938, grad_fn=<MeanBackward0>)\n",
      "Epoch 42: loss = 1.0086326758992328\n",
      "cvt_loss:  tensor(0.0713, grad_fn=<MeanBackward0>)\n",
      "Epoch 43: loss = 0.735048897496304\n",
      "cvt_loss:  tensor(0.0090, grad_fn=<MeanBackward0>)\n",
      "Epoch 44: loss = 0.7182385799509823\n",
      "cvt_loss:  tensor(10.5428, grad_fn=<MeanBackward0>)\n",
      "Epoch 45: loss = 2.805375921594387\n",
      "cvt_loss:  tensor(0.0597, grad_fn=<MeanBackward0>)\n",
      "Epoch 46: loss = 0.8154812200391142\n",
      "cvt_loss:  tensor(0.0160, grad_fn=<MeanBackward0>)\n",
      "Epoch 47: loss = 0.818945933664088\n",
      "cvt_loss:  tensor(0.0044, grad_fn=<MeanBackward0>)\n",
      "Epoch 48: loss = 0.7465185666089352\n",
      "cvt_loss:  tensor(0.0061, grad_fn=<MeanBackward0>)\n",
      "Epoch 49: loss = 0.7226292646498453\n",
      "cvt_loss:  tensor(0.0072, grad_fn=<MeanBackward0>)\n",
      "Epoch 50: loss = 0.7383312741587496\n",
      "Epoch 50: loss = 0.7383312741587496\n",
      "Best Epoch 44: Best loss = 0.7182385799509823\n",
      "cvt_loss:  tensor(0.0394, grad_fn=<MeanBackward0>)\n",
      "Epoch 51: loss = 0.7287140379359138\n",
      "cvt_loss:  tensor(0.0209, grad_fn=<MeanBackward0>)\n",
      "Epoch 52: loss = 0.6975970681761872\n",
      "cvt_loss:  tensor(0.0110, grad_fn=<MeanBackward0>)\n",
      "Epoch 53: loss = 0.6840765891825877\n",
      "cvt_loss:  tensor(0.0615, grad_fn=<MeanBackward0>)\n",
      "Epoch 54: loss = 0.6883371956546331\n",
      "cvt_loss:  tensor(0.0225, grad_fn=<MeanBackward0>)\n",
      "Epoch 55: loss = 0.6620977006287055\n",
      "cvt_loss:  tensor(0.0116, grad_fn=<MeanBackward0>)\n",
      "Epoch 56: loss = 0.6604812161340078\n",
      "cvt_loss:  tensor(0.0060, grad_fn=<MeanBackward0>)\n",
      "Epoch 57: loss = 0.6613512359897449\n",
      "cvt_loss:  tensor(0.0169, grad_fn=<MeanBackward0>)\n",
      "Epoch 58: loss = 0.6546896262817352\n",
      "cvt_loss:  tensor(0.0122, grad_fn=<MeanBackward0>)\n",
      "Epoch 59: loss = 0.651501927979669\n",
      "cvt_loss:  tensor(0.0113, grad_fn=<MeanBackward0>)\n",
      "Epoch 60: loss = 0.6418975010752636\n",
      "cvt_loss:  tensor(0.0135, grad_fn=<MeanBackward0>)\n",
      "Epoch 61: loss = 0.6313564755683513\n",
      "cvt_loss:  tensor(0.0058, grad_fn=<MeanBackward0>)\n",
      "Epoch 62: loss = 0.6227195860734438\n",
      "cvt_loss:  tensor(0.0089, grad_fn=<MeanBackward0>)\n",
      "Epoch 63: loss = 0.6092554559550476\n",
      "cvt_loss:  tensor(0.8567, grad_fn=<MeanBackward0>)\n",
      "Epoch 64: loss = 0.7622467759405683\n",
      "cvt_loss:  tensor(0.4525, grad_fn=<MeanBackward0>)\n",
      "Epoch 65: loss = 0.6827048480605883\n",
      "cvt_loss:  tensor(0.0840, grad_fn=<MeanBackward0>)\n",
      "Epoch 66: loss = 0.6013787697064901\n",
      "cvt_loss:  tensor(0.0982, grad_fn=<MeanBackward0>)\n",
      "Epoch 67: loss = 0.6183225672773324\n",
      "cvt_loss:  tensor(0.0394, grad_fn=<MeanBackward0>)\n",
      "Epoch 68: loss = 0.6086380520675384\n",
      "cvt_loss:  tensor(0.0224, grad_fn=<MeanBackward0>)\n",
      "Epoch 69: loss = 0.5935108931433868\n",
      "cvt_loss:  tensor(0.0106, grad_fn=<MeanBackward0>)\n",
      "Epoch 70: loss = 0.5867574557867263\n",
      "cvt_loss:  tensor(0.0108, grad_fn=<MeanBackward0>)\n",
      "Epoch 71: loss = 0.5627234654600552\n",
      "cvt_loss:  tensor(0.0043, grad_fn=<MeanBackward0>)\n",
      "Epoch 72: loss = 0.5508159059168145\n",
      "cvt_loss:  tensor(0.0039, grad_fn=<MeanBackward0>)\n",
      "Epoch 73: loss = 0.5569849607402195\n",
      "cvt_loss:  tensor(0.0058, grad_fn=<MeanBackward0>)\n",
      "Epoch 74: loss = 0.5688673589302059\n",
      "cvt_loss:  tensor(0.0445, grad_fn=<MeanBackward0>)\n",
      "Epoch 75: loss = 0.5521020711368907\n",
      "cvt_loss:  tensor(0.0067, grad_fn=<MeanBackward0>)\n",
      "Epoch 76: loss = 0.5469459016124977\n",
      "cvt_loss:  tensor(3.4316, grad_fn=<MeanBackward0>)\n",
      "Epoch 77: loss = 1.2430927451048355\n",
      "cvt_loss:  tensor(0.0711, grad_fn=<MeanBackward0>)\n",
      "Epoch 78: loss = 0.6288182628912485\n",
      "cvt_loss:  tensor(0.0053, grad_fn=<MeanBackward0>)\n",
      "Epoch 79: loss = 0.6153041013709458\n",
      "cvt_loss:  tensor(0.0145, grad_fn=<MeanBackward0>)\n",
      "Epoch 80: loss = 0.5649987870674726\n",
      "cvt_loss:  tensor(1.2405, grad_fn=<MeanBackward0>)\n",
      "Epoch 81: loss = 0.8065879863281791\n",
      "cvt_loss:  tensor(0.0113, grad_fn=<MeanBackward0>)\n",
      "Epoch 82: loss = 0.5437337644122751\n",
      "cvt_loss:  tensor(0.0059, grad_fn=<MeanBackward0>)\n",
      "Epoch 83: loss = 0.5271171005025564\n",
      "cvt_loss:  tensor(0.0197, grad_fn=<MeanBackward0>)\n",
      "Epoch 84: loss = 0.531157595976257\n",
      "cvt_loss:  tensor(0.0083, grad_fn=<MeanBackward0>)\n",
      "Epoch 85: loss = 0.5169557731334596\n",
      "cvt_loss:  tensor(0.0470, grad_fn=<MeanBackward0>)\n",
      "Epoch 86: loss = 0.5270743379658236\n",
      "cvt_loss:  tensor(0.0093, grad_fn=<MeanBackward0>)\n",
      "Epoch 87: loss = 0.5190192862172084\n",
      "cvt_loss:  tensor(0.0089, grad_fn=<MeanBackward0>)\n",
      "Epoch 88: loss = 0.5245152489946531\n",
      "cvt_loss:  tensor(0.0044, grad_fn=<MeanBackward0>)\n",
      "Epoch 89: loss = 0.5095048949419083\n",
      "cvt_loss:  tensor(0.0050, grad_fn=<MeanBackward0>)\n",
      "Epoch 90: loss = 0.4953261428241638\n",
      "cvt_loss:  tensor(0.0222, grad_fn=<MeanBackward0>)\n",
      "Epoch 91: loss = 0.5020487785359427\n",
      "cvt_loss:  tensor(0.0068, grad_fn=<MeanBackward0>)\n",
      "Epoch 92: loss = 0.5054782058179643\n",
      "cvt_loss:  tensor(0.0057, grad_fn=<MeanBackward0>)\n",
      "Epoch 93: loss = 0.4940513896322305\n",
      "cvt_loss:  tensor(2.4948, grad_fn=<MeanBackward0>)\n",
      "Epoch 94: loss = 0.9923493695898121\n",
      "cvt_loss:  tensor(0.8923, grad_fn=<MeanBackward0>)\n",
      "Epoch 95: loss = 0.6998803304608567\n",
      "cvt_loss:  tensor(0.0054, grad_fn=<MeanBackward0>)\n",
      "Epoch 96: loss = 0.5768643680334142\n",
      "cvt_loss:  tensor(0.0123, grad_fn=<MeanBackward0>)\n",
      "Epoch 97: loss = 0.5156479926612675\n",
      "cvt_loss:  tensor(0.0054, grad_fn=<MeanBackward0>)\n",
      "Epoch 98: loss = 0.5319186829952784\n",
      "cvt_loss:  tensor(0.0146, grad_fn=<MeanBackward0>)\n",
      "Epoch 99: loss = 0.5316459325219224\n",
      "cvt_loss:  tensor(0.0069, grad_fn=<MeanBackward0>)\n",
      "Epoch 100: loss = 0.49932246130841357\n",
      "Epoch 100: loss = 0.49932246130841357\n",
      "Best Epoch 93: Best loss = 0.4940513896322305\n",
      "cvt_loss:  tensor(73.1886, grad_fn=<MeanBackward0>)\n",
      "Epoch 101: loss = 15.134321778934218\n",
      "cvt_loss:  tensor(0.1226, grad_fn=<MeanBackward0>)\n",
      "Epoch 102: loss = 5.5104728538366885\n",
      "cvt_loss:  tensor(0.0173, grad_fn=<MeanBackward0>)\n",
      "Epoch 103: loss = 5.047239284736413\n",
      "cvt_loss:  tensor(0.0033, grad_fn=<MeanBackward0>)\n",
      "Epoch 104: loss = 2.1146400956700875\n",
      "cvt_loss:  tensor(0.0085, grad_fn=<MeanBackward0>)\n",
      "Epoch 105: loss = 1.673163766624693\n",
      "cvt_loss:  tensor(0.3550, grad_fn=<MeanBackward0>)\n",
      "Epoch 106: loss = 1.834391780125959\n",
      "cvt_loss:  tensor(0.0042, grad_fn=<MeanBackward0>)\n",
      "Epoch 107: loss = 1.5318317998741953\n",
      "cvt_loss:  tensor(0.0447, grad_fn=<MeanBackward0>)\n",
      "Epoch 108: loss = 1.123938282111294\n",
      "cvt_loss:  tensor(0.0046, grad_fn=<MeanBackward0>)\n",
      "Epoch 109: loss = 0.8594092994815217\n",
      "cvt_loss:  tensor(0.0645, grad_fn=<MeanBackward0>)\n",
      "Epoch 110: loss = 0.774745907835511\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m profiler \u001b[38;5;241m=\u001b[39m cProfile\u001b[38;5;241m.\u001b[39mProfile()\n\u001b[1;32m     25\u001b[0m profiler\u001b[38;5;241m.\u001b[39menable()\n\u001b[0;32m---> 26\u001b[0m sites \u001b[38;5;241m=\u001b[39m \u001b[43mautograd\u001b[49m\u001b[43m(\u001b[49m\u001b[43msites\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupsampling\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlambda_weights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m profiler\u001b[38;5;241m.\u001b[39mdisable()\n\u001b[1;32m     29\u001b[0m stats \u001b[38;5;241m=\u001b[39m pstats\u001b[38;5;241m.\u001b[39mStats(profiler)\u001b[38;5;241m.\u001b[39msort_stats(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcumtime\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[13], line 43\u001b[0m, in \u001b[0;36mautograd\u001b[0;34m(sites, model, max_iter, stop_train_threshold, upsampling, lambda_weights)\u001b[0m\n\u001b[1;32m     39\u001b[0m points \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((vertices, bisectors), \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Compute losses       \u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m cvt_loss \u001b[38;5;241m=\u001b[39m \u001b[43mlf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_cvt_loss_vectorized\u001b[49m\u001b[43m(\u001b[49m\u001b[43msites\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m#min_distance_loss = min_distance_regularization_for_op_sites(edges,sites)\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m#min_distance_loss = lf.sdf_weighted_min_distance_loss(model, sites)\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m#edge_smoothing_loss = compute_edge_smoothing_loss(edges, sites, model)\u001b[39;00m\n\u001b[1;32m     47\u001b[0m chamfer_loss \u001b[38;5;241m=\u001b[39m lf\u001b[38;5;241m.\u001b[39mchamfer_distance(target_points, points)\n",
      "File \u001b[0;32m~/dev/Kyushu_experiments/sdfpred_utils/loss_functions.py:97\u001b[0m, in \u001b[0;36mcompute_cvt_loss_vectorized\u001b[0;34m(sites, model)\u001b[0m\n\u001b[1;32m     94\u001b[0m vor \u001b[38;5;241m=\u001b[39m Voronoi(sites_np)\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# create a nested list of vertices for each site\u001b[39;00m\n\u001b[0;32m---> 97\u001b[0m centroids \u001b[38;5;241m=\u001b[39m [vor\u001b[38;5;241m.\u001b[39mvertices[vor\u001b[38;5;241m.\u001b[39mregions[vor\u001b[38;5;241m.\u001b[39mpoint_region[i]]]\u001b[38;5;241m.\u001b[39mmean(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(sites_np)) \u001b[38;5;28;01mif\u001b[39;00m vor\u001b[38;5;241m.\u001b[39mregions[vor\u001b[38;5;241m.\u001b[39mpoint_region[i]] \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m vor\u001b[38;5;241m.\u001b[39mregions[vor\u001b[38;5;241m.\u001b[39mpoint_region[i]]]\n\u001b[1;32m     98\u001b[0m centroids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(np\u001b[38;5;241m.\u001b[39marray(centroids), device\u001b[38;5;241m=\u001b[39msites\u001b[38;5;241m.\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39msites\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m     99\u001b[0m valid_indices \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(sites_np)) \u001b[38;5;28;01mif\u001b[39;00m vor\u001b[38;5;241m.\u001b[39mregions[vor\u001b[38;5;241m.\u001b[39mpoint_region[i]] \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m vor\u001b[38;5;241m.\u001b[39mregions[vor\u001b[38;5;241m.\u001b[39mpoint_region[i]]], device\u001b[38;5;241m=\u001b[39msites\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/dev/Kyushu_experiments/sdfpred_utils/loss_functions.py:97\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     94\u001b[0m vor \u001b[38;5;241m=\u001b[39m Voronoi(sites_np)\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# create a nested list of vertices for each site\u001b[39;00m\n\u001b[0;32m---> 97\u001b[0m centroids \u001b[38;5;241m=\u001b[39m [\u001b[43mvor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvertices\u001b[49m\u001b[43m[\u001b[49m\u001b[43mvor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregions\u001b[49m\u001b[43m[\u001b[49m\u001b[43mvor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoint_region\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(sites_np)) \u001b[38;5;28;01mif\u001b[39;00m vor\u001b[38;5;241m.\u001b[39mregions[vor\u001b[38;5;241m.\u001b[39mpoint_region[i]] \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m vor\u001b[38;5;241m.\u001b[39mregions[vor\u001b[38;5;241m.\u001b[39mpoint_region[i]]]\n\u001b[1;32m     98\u001b[0m centroids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(np\u001b[38;5;241m.\u001b[39marray(centroids), device\u001b[38;5;241m=\u001b[39msites\u001b[38;5;241m.\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39msites\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m     99\u001b[0m valid_indices \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(sites_np)) \u001b[38;5;28;01mif\u001b[39;00m vor\u001b[38;5;241m.\u001b[39mregions[vor\u001b[38;5;241m.\u001b[39mpoint_region[i]] \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m vor\u001b[38;5;241m.\u001b[39mregions[vor\u001b[38;5;241m.\u001b[39mpoint_region[i]]], device\u001b[38;5;241m=\u001b[39msites\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/numpy/core/_methods.py:120\u001b[0m, in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m    118\u001b[0m ret \u001b[38;5;241m=\u001b[39m umr_sum(arr, axis, dtype, out, keepdims, where\u001b[38;5;241m=\u001b[39mwhere)\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, mu\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m--> 120\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _no_nep50_warning():\n\u001b[1;32m    121\u001b[0m         ret \u001b[38;5;241m=\u001b[39m um\u001b[38;5;241m.\u001b[39mtrue_divide(\n\u001b[1;32m    122\u001b[0m                 ret, rcount, out\u001b[38;5;241m=\u001b[39mret, casting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munsafe\u001b[39m\u001b[38;5;124m'\u001b[39m, subok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_float16_result \u001b[38;5;129;01mand\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch3d/lib/python3.9/contextlib.py:114\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01m_GeneratorContextManager\u001b[39;00m(\n\u001b[1;32m    108\u001b[0m     _GeneratorContextManagerBase,\n\u001b[1;32m    109\u001b[0m     AbstractContextManager,\n\u001b[1;32m    110\u001b[0m     ContextDecorator,\n\u001b[1;32m    111\u001b[0m ):\n\u001b[1;32m    112\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Helper for @contextmanager decorator.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    115\u001b[0m         \u001b[38;5;66;03m# do not keep args and kwds alive unnecessarily\u001b[39;00m\n\u001b[1;32m    116\u001b[0m         \u001b[38;5;66;03m# they are only needed for recreation, which is not possible anymore\u001b[39;00m\n\u001b[1;32m    117\u001b[0m         \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    118\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "lambda_weights = [0.2,0,0.2,0,1.00011111101101000101,0.1,0,2]\n",
    "\n",
    "lambda_cvt = lambda_weights[0]\n",
    "lambda_sdf = lambda_weights[1]\n",
    "lambda_min_distance = lambda_weights[2]\n",
    "lambda_laplace = lambda_weights[3]\n",
    "lamda_chamfer = lambda_weights[4]\n",
    "lambda_eikonal = lambda_weights[5]\n",
    "lambda_domain_restriction = lambda_weights[6]\n",
    "lambda_target_points = lambda_weights[7]\n",
    "\n",
    "max_iter = 500\n",
    "\n",
    "site_file_path = f'{destination}{mesh[0]}{max_iter}3d_sites_{num_centroids}_chamfer{lamda_chamfer}.npy'\n",
    "#check if optimized sites file exists\n",
    "if os.path.exists(site_file_path):\n",
    "    #import sites\n",
    "    print(\"Importing sites\")\n",
    "    sites = np.load(site_file_path)\n",
    "    sites = torch.from_numpy(sites).to(device).requires_grad_(True)    \n",
    "else:\n",
    "    import cProfile, pstats\n",
    "    import time\n",
    "    profiler = cProfile.Profile()\n",
    "    profiler.enable()\n",
    "    sites = autograd(sites, model, max_iter=max_iter, upsampling=0, lambda_weights=lambda_weights)\n",
    "    \n",
    "    profiler.disable()\n",
    "    stats = pstats.Stats(profiler).sort_stats('cumtime')\n",
    "    stats.print_stats()\n",
    "    stats.dump_stats(f'{destination}{mesh[0]}{max_iter}_3d_profile_{num_centroids}_chamfer{lamda_chamfer}.prof')\n",
    "    \n",
    "    \n",
    "    sites_np = sites.detach().cpu().numpy()\n",
    "    np.save(site_file_path, sites_np)\n",
    "    \n",
    "\n",
    "print(\"Sites length: \", len(sites))\n",
    "print(\"min sites: \", torch.min(sites))\n",
    "print(\"max sites: \", torch.max(sites))\n",
    "ps_cloud = ps.register_point_cloud(\"best_optimized_cvt_grid\",sites.detach().cpu().numpy())\n",
    "    \n",
    "lim=torch.abs(torch.max(sites)).detach().cpu().numpy()*1.1\n",
    "#plot_voronoi_3d(sites,lim,lim,lim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model ./images/autograd/3D/bunny500_100_3d_model_13824_chamfer1.00011111101101.pth\n",
      "sites ./images/autograd/3D/bunny500_100_3d_sites_13824_chamfer1.00011111101101.pth\n"
     ]
    }
   ],
   "source": [
    "epoch = 100\n",
    "\n",
    "model_file_path = f'{destination}{mesh[0]}{max_iter}_{epoch}_3d_model_{num_centroids}_chamfer{lamda_chamfer}.pth'\n",
    "site_file_path = f'{destination}{mesh[0]}{max_iter}_{epoch}_3d_sites_{num_centroids}_chamfer{lamda_chamfer}.pth'\n",
    "sites = torch.load(site_file_path)\n",
    "sites_np = sites.detach().cpu().numpy()\n",
    "model.load_state_dict(torch.load(model_file_path))\n",
    "#\n",
    "#polyscope_sdf(model)\n",
    "#\n",
    "print(\"model\", model_file_path)\n",
    "print(\"sites\", site_file_path)\n",
    "#ps_cloud = ps.register_point_cloud(f\"{epoch} epoch_cvt_grid\",sites_np)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_mesh = su.get_zero_crossing_mesh_3d(sites, model)\n",
    "\n",
    "ps.register_surface_mesh(\"Zero-Crossing faces\", final_mesh[0], final_mesh[1])\n",
    "ps.register_point_cloud(\"Mesh vertices\", final_mesh[0])\n",
    "\n",
    "ps.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_visualisation_3d():\n",
    "    import imageio\n",
    "    img_buffer_mesh = []\n",
    "    img_buffer_model = []\n",
    "    for i in range(int(max_iter/10)+1):\n",
    "        epoch = i*10\n",
    "        site_file_path = f'{destination}{mesh[0]}{max_iter}_{epoch}_3d_sites_{num_centroids}_chamfer{lamda_chamfer}.pth'\n",
    "        model_file_path = f'{destination}{mesh[0]}{max_iter}_{epoch}_3d_model_{num_centroids}_chamfer{lamda_chamfer}.pth'\n",
    "        \n",
    "        print(\"mesh of epoch: \", epoch)\n",
    "        \n",
    "        model.load_state_dict(torch.load(model_file_path))\n",
    "    \n",
    "        current_mesh = su.get_zero_crossing_mesh_3d(torch.load(site_file_path), model)\n",
    "        ps.remove_all_structures()\n",
    "        ps.register_surface_mesh(\"Zero-Crossing faces\", current_mesh[0], current_mesh[1])\n",
    "        ps.register_point_cloud(\"Mesh vertices\", current_mesh[0])\n",
    "        img_buffer_mesh.append(ps.screenshot_to_buffer(transparent_bg=False))\n",
    "        \n",
    "        ps.remove_all_structures()\n",
    "        polyscope_sdf(model)\n",
    "        img_buffer_model.append(ps.screenshot_to_buffer(transparent_bg=False))\n",
    "\n",
    "\n",
    "    imageio.mimsave(f'{destination}{max_iter}_3d_{num_centroids}_optimization_mesh.gif',img_buffer_mesh, fps=1, duration=1, loop=0)\n",
    "    imageio.mimsave(f'{destination}{max_iter}_3d_{num_centroids}_optimization_sdf.gif', img_buffer_model, fps=1, duration=1, loop=0)\n",
    "\n",
    "#export_visualisation_3d()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
