{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9bd2cd3ba2cdece",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T02:44:14.815313Z",
     "start_time": "2024-07-17T02:44:14.738633Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import gradientUtils as gu\n",
    "\n",
    "# Define a threshold for early stopping\n",
    "threshold = 1e-16\n",
    "# Define the ground truth vertex\n",
    "X_g = torch.tensor([1.0], requires_grad=False)\n",
    "Y_g = torch.tensor([1.0], requires_grad=False)\n",
    "# Initialize the sites\n",
    "s_i = gu.Site(1.0, 1.0)\n",
    "s_j = gu.Site(2.0, 2.0)\n",
    "s_k = gu.Site(1.50, 2.750)\n",
    "destination = \"images/autograd/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d0d1304549ae68",
   "metadata": {},
   "source": [
    "### AUTO GRAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46b82dee2f33b8ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T02:44:15.423327Z",
     "start_time": "2024-07-17T02:44:14.818537Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.8612499237060547\n",
      "Epoch 100, Loss: 0.0021477900445461273\n",
      "Epoch 200, Loss: 5.845098627332845e-09\n",
      "Stopping early at epoch 279 due to minimal loss change\n",
      "Final site coordinates:\n",
      "s_i: (0.10342850536108017, 0.35356053709983826)\n",
      "s_j: (1.8965137004852295, 1.6465104818344116)\n",
      "s_k: (1.1535061597824097, 2.094599962234497)\n",
      "Final vertex coordinates: (0.9999982714653015, 0.9999975562095642)\n"
     ]
    }
   ],
   "source": [
    "def autograd(s_i, s_j, s_k, X_g, Y_g, destination):\n",
    "    # Define an optimizer\n",
    "    optimizer = torch.optim.Adam([s_i.x, s_i.y, s_j.x, s_j.y, s_k.x, s_k.y], lr=0.01)\n",
    "    # Previous loss\n",
    "    prev_loss = float('inf')\n",
    "    # Training loop\n",
    "    for epoch in range(1000):\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Compute the vertex\n",
    "        X, Y = gu.compute_vertex(s_i, s_j, s_k)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = (X - X_g) ** 2 + (Y - Y_g) ** 2\n",
    "        # Early stopping condition\n",
    "        if abs(prev_loss - loss.item()) < threshold:\n",
    "            print(f\"Stopping early at epoch {epoch} due to minimal loss change\")\n",
    "            gu.plot_and_save(epoch, s_i, s_j, s_k, X_g, Y_g, destination)\n",
    "            break\n",
    "\n",
    "        prev_loss = loss.item()\n",
    "        # Backpropagate the error\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print the loss\n",
    "        if epoch % 100 == 0:\n",
    "            print(f'Epoch {epoch}, Loss: {loss.item()}')\n",
    "            gu.plot_and_save(epoch, s_i, s_j, s_k, X_g, Y_g, destination)\n",
    "\n",
    "    # Print the final site coordinates\n",
    "    print(f'Final site coordinates:')\n",
    "    print(f's_i: ({s_i.x.item()}, {s_i.y.item()})')\n",
    "    print(f's_j: ({s_j.x.item()}, {s_j.y.item()})')\n",
    "    print(f's_k: ({s_k.x.item()}, {s_k.y.item()})')\n",
    "\n",
    "    # Compute the final vertex\n",
    "    final_X, final_Y = gu.compute_vertex(s_i, s_j, s_k)\n",
    "\n",
    "    # Print the final vertex coordinates\n",
    "    print(f'Final vertex coordinates: ({final_X.item()}, {final_Y.item()})')\n",
    "    return s_i, s_j, s_k\n",
    "\n",
    "\n",
    "s_i, s_j, s_k = autograd(s_i, s_j, s_k, X_g, Y_g, destination)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79d867f3270cdc8",
   "metadata": {},
   "source": [
    "### Custom gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8dbf9be4d4ae301e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T02:44:15.428274Z",
     "start_time": "2024-07-17T02:44:15.424649Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define a threshold for early stopping\n",
    "threshold = 1e-16\n",
    "# Define the ground truth vertex\n",
    "X_g = torch.tensor([1.0], requires_grad=False)\n",
    "Y_g = torch.tensor([1.0], requires_grad=False)\n",
    "# Initialize the sites\n",
    "s_i = gu.Site(1.0, 1.0)\n",
    "s_j = gu.Site(2.0, 2.0)\n",
    "s_k = gu.Site(1.50, 2.750)\n",
    "destination = \"images/customgrad\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b10a84d21844100",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T02:44:15.934480Z",
     "start_time": "2024-07-17T02:44:15.429104Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.8612499237060547\n",
      "Epoch 100, Loss: 0.16594450175762177\n",
      "Epoch 200, Loss: 0.0030409719329327345\n",
      "Epoch 300, Loss: 4.169791282038204e-06\n",
      "Stopping early at epoch 381 due to minimal loss change\n",
      "Final site coordinates:\n",
      "s_i: (-0.010905168950557709, 1.029019832611084)\n",
      "s_j: (1.496026635169983, 1.881323218345642)\n",
      "s_k: (0.9567925333976746, 2.0104000568389893)\n",
      "Final vertex coordinates: (0.9999986290931702, 1.0000028610229492)\n"
     ]
    }
   ],
   "source": [
    "def customgrad(s_i, s_j, s_k, X_g, Y_g, destination):\n",
    "    # Define an optimizer\n",
    "    optimizer = torch.optim.Adam([s_i.x, s_i.y, s_j.x, s_j.y, s_k.x, s_k.y], lr=0.01)\n",
    "    prev_loss = float('inf')\n",
    "\n",
    "    class CustomVertexFunction(torch.autograd.Function):\n",
    "        @staticmethod\n",
    "        def forward(ctx, x_i, y_i, x_j, y_j, x_k, y_k):\n",
    "            N_X = x_i ** 2 * (y_j - y_k) - x_j ** 2 * (y_i - y_k) + (x_k ** 2 + (y_i - y_k) * (y_j - y_k)) * (y_i - y_j)\n",
    "            N_Y = -(x_i ** 2 * (x_j - x_k) - x_i * (\n",
    "                        x_j ** 2 - x_k ** 2 + y_j ** 2 - y_k ** 2) + x_j ** 2 * x_k - x_j * (\n",
    "                                x_k ** 2 - y_i ** 2 + y_k ** 2) - x_k * (y_i ** 2 - y_j ** 2))\n",
    "            D = 2 * (x_i * (y_j - y_k) - x_j * (y_i - y_k) + x_k * (y_i - y_j))\n",
    "\n",
    "            X = N_X / D\n",
    "            Y = N_Y / D\n",
    "\n",
    "            ctx.save_for_backward(x_i, y_i, x_j, y_j, x_k, y_k, X, Y, N_X, N_Y, D)\n",
    "            return X, Y\n",
    "\n",
    "        @staticmethod\n",
    "        def backward(ctx, grad_output_X, grad_output_Y):\n",
    "            x_i, y_i, x_j, y_j, x_k, y_k, X, Y, N_X, N_Y, D = ctx.saved_tensors\n",
    "\n",
    "            # Compute partial derivatives of X and Y wrt each site coordinate\n",
    "            dN_X_dx_i = 2 * x_i * (y_j - y_k)\n",
    "            dN_X_dx_j = -2 * x_j * (y_i - y_k)\n",
    "            dN_X_dx_k = 2 * x_k * (y_i - y_j)\n",
    "\n",
    "            dN_Y_dx_i = -2 * x_i * (x_j - x_k) - x_j ** 2 + x_k ** 2 - y_j ** 2 + y_k ** 2\n",
    "            dN_Y_dx_j = -x_i ** 2 + x_k ** 2\n",
    "            dN_Y_dx_k = -x_i ** 2 + x_j ** 2\n",
    "\n",
    "            dD_dx_i = 2 * (y_j - y_k)\n",
    "            dD_dx_j = 2 * (y_i - y_k)\n",
    "            dD_dx_k = 2 * (y_i - y_j)\n",
    "\n",
    "            dX_dx_i = (dN_X_dx_i * D - N_X * dD_dx_i) / (D ** 2)\n",
    "            dX_dx_j = (dN_X_dx_j * D - N_X * dD_dx_j) / (D ** 2)\n",
    "            dX_dx_k = (dN_X_dx_k * D - N_X * dD_dx_k) / (D ** 2)\n",
    "\n",
    "            dY_dx_i = (dN_Y_dx_i * D - N_Y * dD_dx_i) / (D ** 2)\n",
    "            dY_dx_j = (dN_Y_dx_j * D - N_Y * dD_dx_j) / (D ** 2)\n",
    "            dY_dx_k = (dN_Y_dx_k * D - N_Y * dD_dx_k) / (D ** 2)\n",
    "\n",
    "            # Similarly for the y coordinates\n",
    "            dN_X_dy_i = 2 * (x_j - x_k) * x_i - x_j ** 2 + x_k ** 2 + y_j ** 2 - y_k ** 2\n",
    "            dN_X_dy_j = -2 * (x_i - x_k) * x_j + x_i ** 2 - x_k ** 2 - y_i ** 2 + y_k ** 2\n",
    "            dN_X_dy_k = 2 * (x_i - x_j) * x_k - x_i ** 2 + x_j ** 2 + y_i ** 2 - y_j ** 2\n",
    "\n",
    "            dN_Y_dy_i = 0\n",
    "            dN_Y_dy_j = 0\n",
    "            dN_Y_dy_k = 0\n",
    "\n",
    "            dD_dy_i = 2 * (x_j - x_k)\n",
    "            dD_dy_j = 2 * (x_i - x_k)\n",
    "            dD_dy_k = 2 * (x_i - x_j)\n",
    "\n",
    "            dX_dy_i = (dN_X_dy_i * D - N_X * dD_dy_i) / (D ** 2)\n",
    "            dX_dy_j = (dN_X_dy_j * D - N_X * dD_dy_j) / (D ** 2)\n",
    "            dX_dy_k = (dN_X_dy_k * D - N_X * dD_dy_k) / (D ** 2)\n",
    "\n",
    "            dY_dy_i = (dN_Y_dy_i * D - N_Y * dD_dy_i) / (D ** 2)\n",
    "            dY_dy_j = (dN_Y_dy_j * D - N_Y * dD_dy_j) / (D ** 2)\n",
    "            dY_dy_k = (dN_Y_dy_k * D - N_Y * dD_dy_k) / (D ** 2)\n",
    "\n",
    "            grad_x_i = grad_output_X * dX_dx_i + grad_output_Y * dY_dx_i\n",
    "            grad_y_i = grad_output_X * dX_dy_i + grad_output_Y * dY_dy_i\n",
    "            grad_x_j = grad_output_X * dX_dx_j + grad_output_Y * dY_dx_j\n",
    "            grad_y_j = grad_output_X * dX_dy_j + grad_output_Y * dY_dy_j\n",
    "            grad_x_k = grad_output_X * dX_dx_k + grad_output_Y * dY_dx_k\n",
    "            grad_y_k = grad_output_X * dX_dy_k + grad_output_Y * dY_dy_k\n",
    "\n",
    "            return grad_x_i, grad_y_i, grad_x_j, grad_y_j, grad_x_k, grad_y_k\n",
    "\n",
    "    def compute_vertex(s_i, s_j, s_k):\n",
    "        return CustomVertexFunction.apply(s_i.x, s_i.y, s_j.x, s_j.y, s_k.x, s_k.y)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(10000):\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Compute the vertex\n",
    "        X, Y = compute_vertex(s_i, s_j, s_k)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = (X - X_g) ** 2 + (Y - Y_g) ** 2\n",
    "        # Early stopping condition\n",
    "        if abs(prev_loss - loss.item()) < threshold:\n",
    "            print(f\"Stopping early at epoch {epoch} due to minimal loss change\")\n",
    "            gu.plot_and_save(epoch, s_i, s_j, s_k, X_g, Y_g, destination)\n",
    "            break\n",
    "\n",
    "        prev_loss = loss.item()\n",
    "        # Backpropagate the error\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print the loss\n",
    "        if epoch % 100 == 0:\n",
    "            print(f'Epoch {epoch}, Loss: {loss.item()}')\n",
    "            gu.plot_and_save(epoch, s_i, s_j, s_k, X_g, Y_g, destination)\n",
    "\n",
    "    # Print the final site coordinates\n",
    "    print(f'Final site coordinates:')\n",
    "    print(f's_i: ({s_i.x.item()}, {s_i.y.item()})')\n",
    "    print(f's_j: ({s_j.x.item()}, {s_j.y.item()})')\n",
    "    print(f's_k: ({s_k.x.item()}, {s_k.y.item()})')\n",
    "\n",
    "    # Compute the final vertex\n",
    "    final_X, final_Y = compute_vertex(s_i, s_j, s_k)\n",
    "\n",
    "    # Print the final vertex coordinates\n",
    "    print(f'Final vertex coordinates: ({final_X.item()}, {final_Y.item()})')\n",
    "    return s_i, s_j, s_k\n",
    "\n",
    "\n",
    "s_i, s_j, s_k = customgrad(s_i, s_j, s_k, X_g, Y_g, destination)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912830c67f800c7",
   "metadata": {},
   "source": [
    "### Harder starting positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1025379e2a7762d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T02:44:17.580435Z",
     "start_time": "2024-07-17T02:44:15.935857Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 12.8125\n",
      "Epoch 100, Loss: 1.977822184562683\n",
      "Epoch 200, Loss: 0.4384814500808716\n",
      "Epoch 300, Loss: 0.057316653430461884\n",
      "Epoch 400, Loss: 0.006678937003016472\n",
      "Epoch 500, Loss: 0.0006953967968001962\n",
      "Epoch 600, Loss: 5.227408837527037e-05\n",
      "Epoch 700, Loss: 2.7584478630160447e-06\n",
      "Epoch 800, Loss: 1.0029931729604868e-07\n",
      "Epoch 900, Loss: 2.4478516991166543e-09\n",
      "Stopping early at epoch 985 due to minimal loss change\n",
      "Final site coordinates:\n",
      "s_i: (2.416391134262085, 2.1902499198913574)\n",
      "s_j: (-0.7706083059310913, 0.46346449851989746)\n",
      "s_k: (1.7692984342575073, -0.6825821399688721)\n",
      "Final vertex coordinates: (0.9999929070472717, 0.9999938011169434)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<gradientUtils.Site at 0x7f87b40d3ee0>,\n",
       " <gradientUtils.Site at 0x7f86d110d400>,\n",
       " <gradientUtils.Site at 0x7f86d3ef1e50>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a threshold for early stopping\n",
    "threshold = 1e-16\n",
    "# Define the ground truth vertex\n",
    "X_g = torch.tensor([1.0], requires_grad=False)\n",
    "Y_g = torch.tensor([1.0], requires_grad=False)\n",
    "# Initialize the sites\n",
    "s_i = gu.Site(1.0, 1.0)\n",
    "s_j = gu.Site(-2.0, 1.0)\n",
    "s_k = gu.Site(3, -3)\n",
    "destination = \"images/autograd/2/\"\n",
    "autograd(s_i, s_j, s_k, X_g, Y_g, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffff26bab14e72db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T02:44:21.908695Z",
     "start_time": "2024-07-17T02:44:17.581411Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 12.8125\n",
      "Epoch 100, Loss: 8.707025527954102\n",
      "Epoch 200, Loss: 0.672167956829071\n",
      "Epoch 300, Loss: 0.3487200438976288\n",
      "Epoch 400, Loss: 0.45868346095085144\n",
      "Epoch 500, Loss: 1.050619125366211\n",
      "Epoch 600, Loss: 2.3740522861480713\n",
      "Epoch 700, Loss: 3.048783540725708\n",
      "Epoch 800, Loss: 2.7810897827148438\n",
      "Epoch 900, Loss: 2.4095890522003174\n",
      "Epoch 1000, Loss: 2.2590322494506836\n",
      "Epoch 1100, Loss: 2.453824996948242\n",
      "Epoch 1200, Loss: 3.080860137939453\n",
      "Epoch 1300, Loss: 4.132190227508545\n",
      "Epoch 1400, Loss: 5.3906145095825195\n",
      "Epoch 1500, Loss: 6.529107570648193\n",
      "Epoch 1600, Loss: 7.323753833770752\n",
      "Epoch 1700, Loss: 7.705397605895996\n",
      "Epoch 1800, Loss: 7.711126804351807\n",
      "Epoch 1900, Loss: 7.430761337280273\n",
      "Epoch 2000, Loss: 6.966740608215332\n",
      "Epoch 2100, Loss: 6.4090895652771\n",
      "Epoch 2200, Loss: 5.825100898742676\n",
      "Epoch 2300, Loss: 5.258607387542725\n",
      "Epoch 2400, Loss: 4.734340190887451\n",
      "Epoch 2500, Loss: 4.263580799102783\n",
      "Epoch 2600, Loss: 3.8492672443389893\n",
      "Epoch 2700, Loss: 3.489206075668335\n",
      "Epoch 2800, Loss: 3.179044723510742\n",
      "Epoch 2900, Loss: 2.913395404815674\n",
      "Epoch 3000, Loss: 2.6868793964385986\n",
      "Epoch 3100, Loss: 2.494387149810791\n",
      "Epoch 3200, Loss: 2.331324338912964\n",
      "Epoch 3300, Loss: 2.193840265274048\n",
      "Epoch 3400, Loss: 2.0785064697265625\n",
      "Epoch 3500, Loss: 1.9824846982955933\n",
      "Epoch 3600, Loss: 1.9033249616622925\n",
      "Epoch 3700, Loss: 1.8390408754348755\n",
      "Epoch 3800, Loss: 1.7879184484481812\n",
      "Epoch 3900, Loss: 1.748479962348938\n",
      "Epoch 4000, Loss: 1.7194995880126953\n",
      "Epoch 4100, Loss: 1.6999326944351196\n",
      "Epoch 4200, Loss: 1.6887726783752441\n",
      "Stopping early at epoch 4290 due to minimal loss change\n",
      "Final site coordinates:\n",
      "s_i: (32.38459396362305, 10.458799362182617)\n",
      "s_j: (3.7237908840179443, 35.03289794921875)\n",
      "s_k: (5.1679229736328125, -31.981884002685547)\n",
      "Final vertex coordinates: (-0.22670312225818634, 1.4248158931732178)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<gradientUtils.Site at 0x7f86d10b8880>,\n",
       " <gradientUtils.Site at 0x7f86d10b8a00>,\n",
       " <gradientUtils.Site at 0x7f86d10b8c70>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a threshold for early stopping\n",
    "threshold = 1e-16\n",
    "# Define the ground truth vertex\n",
    "X_g = torch.tensor([1.0], requires_grad=False)\n",
    "Y_g = torch.tensor([1.0], requires_grad=False)\n",
    "# Initialize the sites\n",
    "s_i = gu.Site(1.0, 1.0)\n",
    "s_j = gu.Site(-2.0, 1.0)\n",
    "s_k = gu.Site(3, -3)\n",
    "destination = \"images/customgrad/2/\"\n",
    "customgrad(s_i, s_j, s_k, X_g, Y_g, destination)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
