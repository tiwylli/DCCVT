{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T07:25:06.598220Z",
     "start_time": "2024-06-28T07:25:06.595110Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import gradientUtils as gu\n",
    "\n",
    "# Define a threshold for early stopping\n",
    "threshold = 1e-16\n",
    "# Define the ground truth vertex\n",
    "X_g = torch.tensor([1.0], requires_grad=False)\n",
    "Y_g = torch.tensor([1.0], requires_grad=False)\n",
    "# Initialize the sites\n",
    "s_i = gu.Site(1.0, 1.0)\n",
    "s_j = gu.Site(2.0, 2.0)\n",
    "s_k = gu.Site(1.50, 2.750)\n",
    "destination = \"images/autograd/\""
   ],
   "id": "d9bd2cd3ba2cdece",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### AUTO GRAD",
   "id": "f1d0d1304549ae68"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T07:25:06.956401Z",
     "start_time": "2024-06-28T07:25:06.608073Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def autograd(s_i, s_j, s_k, X_g, Y_g, destination):\n",
    "    # Define an optimizer\n",
    "    optimizer = torch.optim.Adam([s_i.x, s_i.y, s_j.x, s_j.y, s_k.x, s_k.y], lr=0.01)\n",
    "    # Previous loss\n",
    "    prev_loss = float('inf')\n",
    "    # Training loop\n",
    "    for epoch in range(1000):\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Compute the vertex\n",
    "        X, Y = gu.compute_vertex(s_i, s_j, s_k)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = (X - X_g) ** 2 + (Y - Y_g) ** 2\n",
    "        # Early stopping condition\n",
    "        if abs(prev_loss - loss.item()) < threshold:\n",
    "            print(f\"Stopping early at epoch {epoch} due to minimal loss change\")\n",
    "            gu.plot_and_save(epoch, s_i, s_j, s_k, X_g, Y_g, destination)\n",
    "            break\n",
    "\n",
    "        prev_loss = loss.item()\n",
    "        # Backpropagate the error\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print the loss\n",
    "        if epoch % 100 == 0:\n",
    "            print(f'Epoch {epoch}, Loss: {loss.item()}')\n",
    "            gu.plot_and_save(epoch, s_i, s_j, s_k, X_g, Y_g, destination)\n",
    "\n",
    "    # Print the final site coordinates\n",
    "    print(f'Final site coordinates:')\n",
    "    print(f's_i: ({s_i.x.item()}, {s_i.y.item()})')\n",
    "    print(f's_j: ({s_j.x.item()}, {s_j.y.item()})')\n",
    "    print(f's_k: ({s_k.x.item()}, {s_k.y.item()})')\n",
    "\n",
    "    # Compute the final vertex\n",
    "    final_X, final_Y = gu.compute_vertex(s_i, s_j, s_k)\n",
    "\n",
    "    # Print the final vertex coordinates\n",
    "    print(f'Final vertex coordinates: ({final_X.item()}, {final_Y.item()})')\n",
    "    return s_i, s_j, s_k\n",
    "\n",
    "\n",
    "s_i, s_j, s_k = autograd(s_i, s_j, s_k, X_g, Y_g, destination)"
   ],
   "id": "46b82dee2f33b8ab",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.8612499237060547\n",
      "Epoch 100, Loss: 0.0021477900445461273\n",
      "Epoch 200, Loss: 5.845098627332845e-09\n",
      "Stopping early at epoch 279 due to minimal loss change\n",
      "Final site coordinates:\n",
      "s_i: (0.10342850536108017, 0.35356053709983826)\n",
      "s_j: (1.8965137004852295, 1.6465104818344116)\n",
      "s_k: (1.1535061597824097, 2.094599962234497)\n",
      "Final vertex coordinates: (0.9999982714653015, 0.9999975562095642)\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Custom gradient",
   "id": "d79d867f3270cdc8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T07:25:06.960787Z",
     "start_time": "2024-06-28T07:25:06.957606Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define a threshold for early stopping\n",
    "threshold = 1e-16\n",
    "# Define the ground truth vertex\n",
    "X_g = torch.tensor([1.0], requires_grad=False)\n",
    "Y_g = torch.tensor([1.0], requires_grad=False)\n",
    "# Initialize the sites\n",
    "s_i = gu.Site(1.0, 1.0)\n",
    "s_j = gu.Site(2.0, 2.0)\n",
    "s_k = gu.Site(1.50, 2.750)\n",
    "destination = \"images/customgrad\""
   ],
   "id": "8dbf9be4d4ae301e",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T07:25:17.201495Z",
     "start_time": "2024-06-28T07:25:06.961960Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def customgrad(s_i, s_j, s_k, X_g, Y_g, destination):\n",
    "    # Define an optimizer\n",
    "    optimizer = torch.optim.Adam([s_i.x, s_i.y, s_j.x, s_j.y, s_k.x, s_k.y], lr=0.01)\n",
    "    prev_loss = float('inf')\n",
    "\n",
    "    class CustomVertexFunction(torch.autograd.Function):\n",
    "        @staticmethod\n",
    "        def forward(ctx, x_i, y_i, x_j, y_j, x_k, y_k):\n",
    "            N_X = x_i ** 2 * (y_j - y_k) - x_j ** 2 * (y_i - y_k) + (x_k ** 2 + (y_i - y_k) * (y_j - y_k)) * (y_i - y_j)\n",
    "            N_Y = -(x_i ** 2 * (x_j - x_k) - x_i * (\n",
    "                        x_j ** 2 - x_k ** 2 + y_j ** 2 - y_k ** 2) + x_j ** 2 * x_k - x_j * (\n",
    "                                x_k ** 2 - y_i ** 2 + y_k ** 2) - x_k * (y_i ** 2 - y_j ** 2))\n",
    "            D = 2 * (x_i * (y_j - y_k) - x_j * (y_i - y_k) + x_k * (y_i - y_j))\n",
    "\n",
    "            X = N_X / D\n",
    "            Y = N_Y / D\n",
    "\n",
    "            ctx.save_for_backward(x_i, y_i, x_j, y_j, x_k, y_k, X, Y, N_X, N_Y, D)\n",
    "            return X, Y\n",
    "\n",
    "        @staticmethod\n",
    "        def backward(ctx, grad_output_X, grad_output_Y):\n",
    "            x_i, y_i, x_j, y_j, x_k, y_k, X, Y, N_X, N_Y, D = ctx.saved_tensors\n",
    "\n",
    "            # Compute partial derivatives of X and Y wrt each site coordinate\n",
    "            dN_X_dx_i = 2 * x_i * (y_j - y_k)\n",
    "            dN_X_dx_j = -2 * x_j * (y_i - y_k)\n",
    "            dN_X_dx_k = 2 * x_k * (y_i - y_j)\n",
    "\n",
    "            dN_Y_dx_i = -2 * x_i * (x_j - x_k) - x_j ** 2 + x_k ** 2 - y_j ** 2 + y_k ** 2\n",
    "            dN_Y_dx_j = -x_i ** 2 + x_k ** 2\n",
    "            dN_Y_dx_k = -x_i ** 2 + x_j ** 2\n",
    "\n",
    "            dD_dx_i = 2 * (y_j - y_k)\n",
    "            dD_dx_j = 2 * (y_i - y_k)\n",
    "            dD_dx_k = 2 * (y_i - y_j)\n",
    "\n",
    "            dX_dx_i = (dN_X_dx_i * D - N_X * dD_dx_i) / (D ** 2)\n",
    "            dX_dx_j = (dN_X_dx_j * D - N_X * dD_dx_j) / (D ** 2)\n",
    "            dX_dx_k = (dN_X_dx_k * D - N_X * dD_dx_k) / (D ** 2)\n",
    "\n",
    "            dY_dx_i = (dN_Y_dx_i * D - N_Y * dD_dx_i) / (D ** 2)\n",
    "            dY_dx_j = (dN_Y_dx_j * D - N_Y * dD_dx_j) / (D ** 2)\n",
    "            dY_dx_k = (dN_Y_dx_k * D - N_Y * dD_dx_k) / (D ** 2)\n",
    "\n",
    "            # Similarly for the y coordinates\n",
    "            dN_X_dy_i = 2 * (x_j - x_k) * x_i - x_j ** 2 + x_k ** 2 + y_j ** 2 - y_k ** 2\n",
    "            dN_X_dy_j = -2 * (x_i - x_k) * x_j + x_i ** 2 - x_k ** 2 - y_i ** 2 + y_k ** 2\n",
    "            dN_X_dy_k = 2 * (x_i - x_j) * x_k - x_i ** 2 + x_j ** 2 + y_i ** 2 - y_j ** 2\n",
    "\n",
    "            dN_Y_dy_i = 0\n",
    "            dN_Y_dy_j = 0\n",
    "            dN_Y_dy_k = 0\n",
    "\n",
    "            dD_dy_i = 2 * (x_j - x_k)\n",
    "            dD_dy_j = 2 * (x_i - x_k)\n",
    "            dD_dy_k = 2 * (x_i - x_j)\n",
    "\n",
    "            dX_dy_i = (dN_X_dy_i * D - N_X * dD_dy_i) / (D ** 2)\n",
    "            dX_dy_j = (dN_X_dy_j * D - N_X * dD_dy_j) / (D ** 2)\n",
    "            dX_dy_k = (dN_X_dy_k * D - N_X * dD_dy_k) / (D ** 2)\n",
    "\n",
    "            dY_dy_i = (dN_Y_dy_i * D - N_Y * dD_dy_i) / (D ** 2)\n",
    "            dY_dy_j = (dN_Y_dy_j * D - N_Y * dD_dy_j) / (D ** 2)\n",
    "            dY_dy_k = (dN_Y_dy_k * D - N_Y * dD_dy_k) / (D ** 2)\n",
    "\n",
    "            grad_x_i = grad_output_X * dX_dx_i + grad_output_Y * dY_dx_i\n",
    "            grad_y_i = grad_output_X * dX_dy_i + grad_output_Y * dY_dy_i\n",
    "            grad_x_j = grad_output_X * dX_dx_j + grad_output_Y * dY_dx_j\n",
    "            grad_y_j = grad_output_X * dX_dy_j + grad_output_Y * dY_dy_j\n",
    "            grad_x_k = grad_output_X * dX_dx_k + grad_output_Y * dY_dx_k\n",
    "            grad_y_k = grad_output_X * dX_dy_k + grad_output_Y * dY_dy_k\n",
    "\n",
    "            return grad_x_i, grad_y_i, grad_x_j, grad_y_j, grad_x_k, grad_y_k\n",
    "\n",
    "    def compute_vertex(s_i, s_j, s_k):\n",
    "        return CustomVertexFunction.apply(s_i.x, s_i.y, s_j.x, s_j.y, s_k.x, s_k.y)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(10000):\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Compute the vertex\n",
    "        X, Y = compute_vertex(s_i, s_j, s_k)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = (X - X_g) ** 2 + (Y - Y_g) ** 2\n",
    "        # Early stopping condition\n",
    "        # if abs(prev_loss - loss.item()) < threshold:\n",
    "        #     print(f\"Stopping early at epoch {epoch} due to minimal loss change\")\n",
    "        #     gu.plot_and_save(epoch, s_i, s_j, s_k, X_g, Y_g, destination)\n",
    "        #     break\n",
    "\n",
    "        prev_loss = loss.item()\n",
    "        # Backpropagate the error\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print the loss\n",
    "        if epoch % 100 == 0:\n",
    "            print(f'Epoch {epoch}, Loss: {loss.item()}')\n",
    "            gu.plot_and_save(epoch, s_i, s_j, s_k, X_g, Y_g, destination)\n",
    "\n",
    "    # Print the final site coordinates\n",
    "    print(f'Final site coordinates:')\n",
    "    print(f's_i: ({s_i.x.item()}, {s_i.y.item()})')\n",
    "    print(f's_j: ({s_j.x.item()}, {s_j.y.item()})')\n",
    "    print(f's_k: ({s_k.x.item()}, {s_k.y.item()})')\n",
    "\n",
    "    # Compute the final vertex\n",
    "    final_X, final_Y = compute_vertex(s_i, s_j, s_k)\n",
    "\n",
    "    # Print the final vertex coordinates\n",
    "    print(f'Final vertex coordinates: ({final_X.item()}, {final_Y.item()})')\n",
    "    return s_i, s_j, s_k\n",
    "\n",
    "\n",
    "s_i, s_j, s_k = customgrad(s_i, s_j, s_k, X_g, Y_g, destination)\n"
   ],
   "id": "8b10a84d21844100",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.8612499237060547\n",
      "Epoch 100, Loss: 0.16594450175762177\n",
      "Epoch 200, Loss: 0.0030409719329327345\n",
      "Epoch 300, Loss: 4.169791282038204e-06\n",
      "Epoch 400, Loss: 2.886579864025407e-11\n",
      "Epoch 500, Loss: 7.105427357601002e-12\n",
      "Epoch 600, Loss: 5.9117155615240335e-12\n",
      "Epoch 700, Loss: 5.8122395785176195e-12\n",
      "Epoch 800, Loss: 1.7195134205394424e-12\n",
      "Epoch 900, Loss: 9.237055564881302e-13\n",
      "Epoch 1000, Loss: 1.1510792319313623e-12\n",
      "Epoch 1100, Loss: 3.325340003357269e-12\n",
      "Epoch 1200, Loss: 5.826450433232822e-13\n",
      "Epoch 1300, Loss: 2.9132252166164108e-12\n",
      "Epoch 1400, Loss: 4.831690603168681e-13\n",
      "Epoch 1500, Loss: 9.414691248821327e-13\n",
      "Epoch 1600, Loss: 1.0373923942097463e-12\n",
      "Epoch 1700, Loss: 3.872457909892546e-13\n",
      "Epoch 1800, Loss: 1.2789769243681803e-12\n",
      "Epoch 1900, Loss: 2.842170943040401e-14\n",
      "Epoch 2000, Loss: 4.121147867408581e-13\n",
      "Epoch 2100, Loss: 4.831690603168681e-13\n",
      "Epoch 2200, Loss: 2.842170943040401e-14\n",
      "Epoch 2300, Loss: 1.5987211554602254e-13\n",
      "Epoch 2400, Loss: 3.872457909892546e-13\n",
      "Epoch 2500, Loss: 1.5987211554602254e-13\n",
      "Epoch 2600, Loss: 7.105427357601002e-14\n",
      "Epoch 2700, Loss: 7.105427357601002e-14\n",
      "Epoch 2800, Loss: 2.4158453015843406e-13\n",
      "Epoch 2900, Loss: 2.842170943040401e-14\n",
      "Epoch 3000, Loss: 1.4210854715202004e-14\n",
      "Epoch 3100, Loss: 3.197442310920451e-14\n",
      "Epoch 3200, Loss: 7.105427357601002e-14\n",
      "Epoch 3300, Loss: 7.105427357601002e-14\n",
      "Epoch 3400, Loss: 0.0\n",
      "Epoch 3500, Loss: 0.0\n",
      "Epoch 3600, Loss: 0.0\n",
      "Epoch 3700, Loss: 0.0\n",
      "Epoch 3800, Loss: 0.0\n",
      "Epoch 3900, Loss: 0.0\n",
      "Epoch 4000, Loss: 0.0\n",
      "Epoch 4100, Loss: 0.0\n",
      "Epoch 4200, Loss: 0.0\n",
      "Epoch 4300, Loss: 0.0\n",
      "Epoch 4400, Loss: 0.0\n",
      "Epoch 4500, Loss: 0.0\n",
      "Epoch 4600, Loss: 0.0\n",
      "Epoch 4700, Loss: 0.0\n",
      "Epoch 4800, Loss: 0.0\n",
      "Epoch 4900, Loss: 0.0\n",
      "Epoch 5000, Loss: 0.0\n",
      "Epoch 5100, Loss: 0.0\n",
      "Epoch 5200, Loss: 0.0\n",
      "Epoch 5300, Loss: 0.0\n",
      "Epoch 5400, Loss: 0.0\n",
      "Epoch 5500, Loss: 0.0\n",
      "Epoch 5600, Loss: 0.0\n",
      "Epoch 5700, Loss: 0.0\n",
      "Epoch 5800, Loss: 0.0\n",
      "Epoch 5900, Loss: 0.0\n",
      "Epoch 6000, Loss: 0.0\n",
      "Epoch 6100, Loss: 0.0\n",
      "Epoch 6200, Loss: 0.0\n",
      "Epoch 6300, Loss: 0.0\n",
      "Epoch 6400, Loss: 0.0\n",
      "Epoch 6500, Loss: 0.0\n",
      "Epoch 6600, Loss: 0.0\n",
      "Epoch 6700, Loss: 0.0\n",
      "Epoch 6800, Loss: 0.0\n",
      "Epoch 6900, Loss: 0.0\n",
      "Epoch 7000, Loss: 0.0\n",
      "Epoch 7100, Loss: 0.0\n",
      "Epoch 7200, Loss: 0.0\n",
      "Epoch 7300, Loss: 0.0\n",
      "Epoch 7400, Loss: 0.0\n",
      "Epoch 7500, Loss: 0.0\n",
      "Epoch 7600, Loss: 0.0\n",
      "Epoch 7700, Loss: 0.0\n",
      "Epoch 7800, Loss: 0.0\n",
      "Epoch 7900, Loss: 0.0\n",
      "Epoch 8000, Loss: 0.0\n",
      "Epoch 8100, Loss: 0.0\n",
      "Epoch 8200, Loss: 0.0\n",
      "Epoch 8300, Loss: 0.0\n",
      "Epoch 8400, Loss: 0.0\n",
      "Epoch 8500, Loss: 0.0\n",
      "Epoch 8600, Loss: 0.0\n",
      "Epoch 8700, Loss: 0.0\n",
      "Epoch 8800, Loss: 0.0\n",
      "Epoch 8900, Loss: 0.0\n",
      "Epoch 9000, Loss: 0.0\n",
      "Epoch 9100, Loss: 0.0\n",
      "Epoch 9200, Loss: 0.0\n",
      "Epoch 9300, Loss: 0.0\n",
      "Epoch 9400, Loss: 0.0\n",
      "Epoch 9500, Loss: 0.0\n",
      "Epoch 9600, Loss: 0.0\n",
      "Epoch 9700, Loss: 0.0\n",
      "Epoch 9800, Loss: 0.0\n",
      "Epoch 9900, Loss: 0.0\n",
      "Final site coordinates:\n",
      "s_i: (-0.01085682027041912, 1.0290207862854004)\n",
      "s_j: (1.4959988594055176, 1.881282925605774)\n",
      "s_k: (0.9565105438232422, 2.010338068008423)\n",
      "Final vertex coordinates: (1.0, 1.0)\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T07:25:18.320287Z",
     "start_time": "2024-06-28T07:25:17.202638Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define a threshold for early stopping\n",
    "threshold = 1e-16\n",
    "# Define the ground truth vertex\n",
    "X_g = torch.tensor([1.0], requires_grad=False)\n",
    "Y_g = torch.tensor([1.0], requires_grad=False)\n",
    "# Initialize the sites\n",
    "s_i = gu.Site(1.0, 1.0)\n",
    "s_j = gu.Site(-2.0, 1.0)\n",
    "s_k = gu.Site(3, -3)\n",
    "destination = \"images/autograd/2/\"\n",
    "autograd(s_i, s_j, s_k, X_g, Y_g, destination)"
   ],
   "id": "c1025379e2a7762d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 12.8125\n",
      "Epoch 100, Loss: 1.977822184562683\n",
      "Epoch 200, Loss: 0.4384814500808716\n",
      "Epoch 300, Loss: 0.057316653430461884\n",
      "Epoch 400, Loss: 0.006678937003016472\n",
      "Epoch 500, Loss: 0.0006953967968001962\n",
      "Epoch 600, Loss: 5.227408837527037e-05\n",
      "Epoch 700, Loss: 2.7584478630160447e-06\n",
      "Epoch 800, Loss: 1.0029931729604868e-07\n",
      "Epoch 900, Loss: 2.4478516991166543e-09\n",
      "Stopping early at epoch 985 due to minimal loss change\n",
      "Final site coordinates:\n",
      "s_i: (2.416391134262085, 2.1902499198913574)\n",
      "s_j: (-0.7706083059310913, 0.46346449851989746)\n",
      "s_k: (1.7692984342575073, -0.6825821399688721)\n",
      "Final vertex coordinates: (0.9999929070472717, 0.9999938011169434)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<gradientUtils.Site at 0x7f82ac290700>,\n",
       " <gradientUtils.Site at 0x7f82a64463a0>,\n",
       " <gradientUtils.Site at 0x7f82a191f550>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T07:25:28.194726Z",
     "start_time": "2024-06-28T07:25:18.321281Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define a threshold for early stopping\n",
    "threshold = 1e-16\n",
    "# Define the ground truth vertex\n",
    "X_g = torch.tensor([1.0], requires_grad=False)\n",
    "Y_g = torch.tensor([1.0], requires_grad=False)\n",
    "# Initialize the sites\n",
    "s_i = gu.Site(1.0, 1.0)\n",
    "s_j = gu.Site(-2.0, 1.0)\n",
    "s_k = gu.Site(3, -3)\n",
    "destination = \"images/customgrad/2/\"\n",
    "customgrad(s_i, s_j, s_k, X_g, Y_g, destination)"
   ],
   "id": "6166e337e9f11851",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 12.8125\n",
      "Epoch 100, Loss: 8.707025527954102\n",
      "Epoch 200, Loss: 0.672167956829071\n",
      "Epoch 300, Loss: 0.3487200438976288\n",
      "Epoch 400, Loss: 0.45868346095085144\n",
      "Epoch 500, Loss: 1.050619125366211\n",
      "Epoch 600, Loss: 2.3740522861480713\n",
      "Epoch 700, Loss: 3.048783540725708\n",
      "Epoch 800, Loss: 2.7810897827148438\n",
      "Epoch 900, Loss: 2.4095890522003174\n",
      "Epoch 1000, Loss: 2.2590322494506836\n",
      "Epoch 1100, Loss: 2.453824996948242\n",
      "Epoch 1200, Loss: 3.080860137939453\n",
      "Epoch 1300, Loss: 4.132190227508545\n",
      "Epoch 1400, Loss: 5.3906145095825195\n",
      "Epoch 1500, Loss: 6.529107570648193\n",
      "Epoch 1600, Loss: 7.323753833770752\n",
      "Epoch 1700, Loss: 7.705397605895996\n",
      "Epoch 1800, Loss: 7.711126804351807\n",
      "Epoch 1900, Loss: 7.430761337280273\n",
      "Epoch 2000, Loss: 6.966740608215332\n",
      "Epoch 2100, Loss: 6.4090895652771\n",
      "Epoch 2200, Loss: 5.825100898742676\n",
      "Epoch 2300, Loss: 5.258607387542725\n",
      "Epoch 2400, Loss: 4.734340190887451\n",
      "Epoch 2500, Loss: 4.263580799102783\n",
      "Epoch 2600, Loss: 3.8492672443389893\n",
      "Epoch 2700, Loss: 3.489206075668335\n",
      "Epoch 2800, Loss: 3.179044723510742\n",
      "Epoch 2900, Loss: 2.913395404815674\n",
      "Epoch 3000, Loss: 2.6868793964385986\n",
      "Epoch 3100, Loss: 2.494387149810791\n",
      "Epoch 3200, Loss: 2.331324338912964\n",
      "Epoch 3300, Loss: 2.193840265274048\n",
      "Epoch 3400, Loss: 2.0785064697265625\n",
      "Epoch 3500, Loss: 1.9824846982955933\n",
      "Epoch 3600, Loss: 1.9033249616622925\n",
      "Epoch 3700, Loss: 1.8390408754348755\n",
      "Epoch 3800, Loss: 1.7879184484481812\n",
      "Epoch 3900, Loss: 1.748479962348938\n",
      "Epoch 4000, Loss: 1.7194995880126953\n",
      "Epoch 4100, Loss: 1.6999326944351196\n",
      "Epoch 4200, Loss: 1.6887726783752441\n",
      "Epoch 4300, Loss: 1.6852327585220337\n",
      "Epoch 4400, Loss: 1.688507318496704\n",
      "Epoch 4500, Loss: 1.697965383529663\n",
      "Epoch 4600, Loss: 1.7129127979278564\n",
      "Epoch 4700, Loss: 1.7326940298080444\n",
      "Epoch 4800, Loss: 1.7566606998443604\n",
      "Epoch 4900, Loss: 1.7842633724212646\n",
      "Epoch 5000, Loss: 1.8148177862167358\n",
      "Epoch 5100, Loss: 1.8477360010147095\n",
      "Epoch 5200, Loss: 1.8824303150177002\n",
      "Epoch 5300, Loss: 1.9182193279266357\n",
      "Epoch 5400, Loss: 1.9545047283172607\n",
      "Epoch 5500, Loss: 1.9907598495483398\n",
      "Epoch 5600, Loss: 2.0263171195983887\n",
      "Epoch 5700, Loss: 2.060706377029419\n",
      "Epoch 5800, Loss: 2.0933637619018555\n",
      "Epoch 5900, Loss: 2.1238441467285156\n",
      "Epoch 6000, Loss: 2.1517746448516846\n",
      "Epoch 6100, Loss: 2.1769394874572754\n",
      "Epoch 6200, Loss: 2.1990716457366943\n",
      "Epoch 6300, Loss: 2.2181177139282227\n",
      "Epoch 6400, Loss: 2.233987331390381\n",
      "Epoch 6500, Loss: 2.2469029426574707\n",
      "Epoch 6600, Loss: 2.2571582794189453\n",
      "Epoch 6700, Loss: 2.264794111251831\n",
      "Epoch 6800, Loss: 2.2704429626464844\n",
      "Epoch 6900, Loss: 2.2743706703186035\n",
      "Epoch 7000, Loss: 2.2770862579345703\n",
      "Epoch 7100, Loss: 2.2790544033050537\n",
      "Epoch 7200, Loss: 2.280820369720459\n",
      "Epoch 7300, Loss: 2.283022165298462\n",
      "Epoch 7400, Loss: 2.2858598232269287\n",
      "Epoch 7500, Loss: 2.2898387908935547\n",
      "Epoch 7600, Loss: 2.2950289249420166\n",
      "Epoch 7700, Loss: 2.3016068935394287\n",
      "Epoch 7800, Loss: 2.3103606700897217\n",
      "Epoch 7900, Loss: 2.320505142211914\n",
      "Epoch 8000, Loss: 2.333078622817993\n",
      "Epoch 8100, Loss: 2.3479855060577393\n",
      "Epoch 8200, Loss: 2.3643763065338135\n",
      "Epoch 8300, Loss: 2.382922887802124\n",
      "Epoch 8400, Loss: 2.402656316757202\n",
      "Epoch 8500, Loss: 2.423788547515869\n",
      "Epoch 8600, Loss: 2.445725202560425\n",
      "Epoch 8700, Loss: 2.4686224460601807\n",
      "Epoch 8800, Loss: 2.492137908935547\n",
      "Epoch 8900, Loss: 2.516223907470703\n",
      "Epoch 9000, Loss: 2.540318489074707\n",
      "Epoch 9100, Loss: 2.5649869441986084\n",
      "Epoch 9200, Loss: 2.590118408203125\n",
      "Epoch 9300, Loss: 2.6154699325561523\n",
      "Epoch 9400, Loss: 2.6414661407470703\n",
      "Epoch 9500, Loss: 2.6677188873291016\n",
      "Epoch 9600, Loss: 2.6942994594573975\n",
      "Epoch 9700, Loss: 2.7212154865264893\n",
      "Epoch 9800, Loss: 2.74849534034729\n",
      "Epoch 9900, Loss: 2.776261329650879\n",
      "Final site coordinates:\n",
      "s_i: (89.51846313476562, 19.805696487426758)\n",
      "s_j: (14.545440673828125, 92.25154876708984)\n",
      "s_k: (19.296918869018555, -88.13589477539062)\n",
      "Final vertex coordinates: (-0.5646731853485107, 1.5972450971603394)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<gradientUtils.Site at 0x7f82a26dcf40>,\n",
       " <gradientUtils.Site at 0x7f82a26dcd60>,\n",
       " <gradientUtils.Site at 0x7f82a1f3e4f0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
