{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device:  NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "import kaolin\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import polyscope as ps\n",
    "import interactive_polyscope\n",
    "from scipy.spatial import Voronoi, voronoi_plot_2d\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import sdfpred_utils.sdfpred_utils as su\n",
    "import sdfpred_utils.sdf_MLP as mlp\n",
    "import sdfpred_utils.sdf_functions as sdf\n",
    "import sdfpred_utils.loss_functions as lf\n",
    "import trimesh\n",
    "from scipy.spatial import Delaunay, Voronoi\n",
    "\n",
    "\n",
    "#cuda devices\n",
    "device = torch.device(\"cuda:0\")\n",
    "print(\"Using device: \", torch.cuda.get_device_name(device))\n",
    "\n",
    "#default tensor types\n",
    "torch.set_default_tensor_type(torch.cuda.DoubleTensor)\n",
    "\n",
    "multires = 2\n",
    "input_dims = 3\n",
    "lr_sites = 0.03\n",
    "lr_model = 0.0003\n",
    "iterations = 5000\n",
    "save_every = 100\n",
    "max_iter = 100\n",
    "#learning_rate = 0.03\n",
    "destination = \"./images/autograd/3D/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sites loaded: torch.Size([4096, 3])\n"
     ]
    }
   ],
   "source": [
    "#currently sites are between -5 and 5 in all 3 dimensions\n",
    "# check if sites exists\n",
    "#num_centroids = 16*16*16\n",
    "num_centroids =16*16*16\n",
    "site_fp = f'sites_{num_centroids}_{input_dims}.pt'\n",
    "\n",
    "if os.path.exists(site_fp):\n",
    "    sites = torch.load(site_fp)\n",
    "    print(\"Sites loaded:\", sites.shape)\n",
    "else:\n",
    "    print(\"Creating new sites\")\n",
    "    sites = su.createCVTgrid(num_centroids=num_centroids, dimensionality=input_dims)\n",
    "    #save the initial sites torch tensor\n",
    "    torch.save(sites, site_fp)\n",
    "\n",
    "\n",
    "def plot_voronoi_3d(sites, xlim=5, ylim=5, zlim=5):\n",
    "    import numpy as np\n",
    "    import pyvoro\n",
    "    import matplotlib.pyplot as plt\n",
    "    from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "    # initialize random number generator\n",
    "    rng = np.random.default_rng(11)\n",
    "    # create a set of points in 3D\n",
    "    points = sites.detach().cpu().numpy()\n",
    "\n",
    "    # use pyvoro to compute the Voronoi tessellation\n",
    "    # the second argument gives the the axis limits in x,y and z direction\n",
    "    # in this case all between 0 and 1.\n",
    "    # the third argument gives \"dispersion = max distance between two points\n",
    "    # that might be adjacent\" (not sure how exactly this works)\n",
    "    voronoi = pyvoro.compute_voronoi(points,[[-xlim,xlim],[-ylim,ylim],[-zlim,zlim]],1)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # for each Voronoi cell, plot all the faces of the corresponding polygon\n",
    "    for vnoicell in voronoi:\n",
    "        faces = []\n",
    "        # the vertices are the corner points of the Voronoi cell\n",
    "        vertices = np.array(vnoicell['vertices'])\n",
    "        # cycle through all faces of the polygon\n",
    "        for face in vnoicell['faces']:\n",
    "            faces.append(vertices[np.array(face['vertices'])])\n",
    "            \n",
    "        # join the faces into a 3D polygon\n",
    "        polygon = Poly3DCollection(faces, alpha=0.5, \n",
    "                                facecolors=rng.uniform(0,1,3),\n",
    "                                linewidths=0.5,edgecolors='black')\n",
    "        ax.add_collection3d(polygon)\n",
    "    \n",
    "    ax.set_xlim([-xlim,xlim])\n",
    "    ax.set_ylim([-ylim,ylim])\n",
    "    ax.set_zlim([-zlim,zlim])\n",
    "            \n",
    "    plt.show()\n",
    "\n",
    "#plot_voronoi_3d(sites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[polyscope] Backend: openGL3_glfw -- Loaded openGL version: 3.3.0 NVIDIA 570.86.16\n"
     ]
    }
   ],
   "source": [
    "ps.init()\n",
    "ps.register_point_cloud(\"initial_cvt_grid\",sites.detach().cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 128, 128)\n",
      "-0.30097997 2.9298177\n"
     ]
    }
   ],
   "source": [
    "# Load the mesh\n",
    "filename = \"./Resources/dolphin.obj\"\n",
    "#load npy\n",
    "sdf_grid = np.load(filename[:-4] + '.npy')\n",
    "print(sdf_grid.shape)\n",
    "print(sdf_grid.min(), sdf_grid.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2097152, 3)\n",
      "[polyscope] To render large point clouds efficiently, set their render mode to 'quad' instead of 'sphere'. (disable these warnings by setting Polyscope's verbosity < 2)\n"
     ]
    }
   ],
   "source": [
    "#render sdf grid as a point cloud\n",
    "#create a 128x128s128 grid\n",
    "\n",
    "x = np.linspace(-1, 1, 128)\n",
    "y = np.linspace(-1, 1, 128)\n",
    "z = np.linspace(-1, 1, 128)\n",
    "X, Y, Z = np.meshgrid(x, y, z)\n",
    "points = np.vstack([X.ravel(), Y.ravel(), Z.ravel()]).T\n",
    "print(points.shape)\n",
    "\n",
    "#coordinate points with the sdf values\n",
    "sdf_points = np.zeros((points.shape[0], 4))\n",
    "sdf_points[:, :3] = points\n",
    "sdf_points[:, 3] = sdf_grid.ravel()\n",
    "\n",
    "\n",
    "\n",
    "ps.register_point_cloud(\"sdf_points\", sdf_points[sdf_points[:, 3] < 0][:, :3])\n",
    "ps.register_point_cloud(\"sdf_points_pos\", sdf_points[sdf_points[:, 3] >= 0][:, :3])\n",
    "ps.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "torch.Size([128, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "def sdf(sites, sdf_grid):\n",
    "    gridsize = sdf_grid.shape[0]  # Assuming a cubic grid of size (128,128,128)\n",
    "    print(gridsize)\n",
    "    grid = torch.tensor(sdf_grid, device=device)\n",
    "    print(grid.shape)\n",
    "\n",
    "    # Normalize points to [0, 1] range in all dimensions\n",
    "    sites = sites + 5.0 #shift to 0-10\n",
    "    points_normalized = sites / 10.0\n",
    "\n",
    "    # Scale to grid coordinates\n",
    "    points_grid = points_normalized * (gridsize - 1)\n",
    "\n",
    "    # Separate grid coordinates into integer and fractional parts\n",
    "    x, y, z = points_grid[:, 0], points_grid[:, 1], points_grid[:, 2]\n",
    "    x0 = x.floor().long().clamp(0, gridsize - 1)\n",
    "    y0 = y.floor().long().clamp(0, gridsize - 1)\n",
    "    z0 = z.floor().long().clamp(0, gridsize - 1)\n",
    "    x1 = (x0 + 1).clamp(0, gridsize - 1)\n",
    "    y1 = (y0 + 1).clamp(0, gridsize - 1)\n",
    "    z1 = (z0 + 1).clamp(0, gridsize - 1)\n",
    "    dx, dy, dz = x - x0, y - y0, z - z0\n",
    "\n",
    "    # Perform trilinear interpolation\n",
    "    values = (\n",
    "        (1 - dx) * (1 - dy) * (1 - dz) * grid[x0, y0, z0] +\n",
    "        dx * (1 - dy) * (1 - dz) * grid[x1, y0, z0] +\n",
    "        (1 - dx) * dy * (1 - dz) * grid[x0, y1, z0] +\n",
    "        dx * dy * (1 - dz) * grid[x1, y1, z0] +\n",
    "        (1 - dx) * (1 - dy) * dz * grid[x0, y0, z1] +\n",
    "        dx * (1 - dy) * dz * grid[x1, y0, z1] +\n",
    "        (1 - dx) * dy * dz * grid[x0, y1, z1] +\n",
    "        dx * dy * dz * grid[x1, y1, z1]\n",
    "    )\n",
    "\n",
    "    return values\n",
    "\n",
    "sdf_values = sdf(sites, sdf_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4096])\n",
      "tensor(1.6209, grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(sdf_values.shape)\n",
    "print(sdf_values[0])\n",
    "ps.init()\n",
    "\n",
    "ps_cloud = ps.register_point_cloud(\"sites_w_sdf\", sites.detach().cpu().numpy())\n",
    "ps_cloud.add_scalar_quantity(\"sdf_values\", sdf_values.detach().cpu().numpy(), enabled=True)\n",
    "\n",
    "ps.show()\n",
    "\n",
    "#TODO : HERE continue implementation of true sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsampling_vectorized(sites, model):\n",
    "    sdf_values = model(sites)\n",
    "    sites_np = sites.detach().cpu().numpy()\n",
    "    # Compute Voronoi diagram\n",
    "    vor = Voronoi(sites_np)\n",
    "    \n",
    "    neighbors = torch.tensor(np.array(vor.ridge_points), device=device)\n",
    "    \n",
    "    # Extract the SDF values for each site in the pair\n",
    "    sdf_i = sdf_values[neighbors[:, 0]]  # First site in each pair\n",
    "    sdf_j = sdf_values[neighbors[:, 1]]  # Second site in each pair\n",
    "    # Find the indices where SDF values have opposing signs or one is zero\n",
    "    mask_zero_crossing_sites = (sdf_i * sdf_j <= 0).squeeze()\n",
    "    sites_to_upsample = torch.unique(neighbors[mask_zero_crossing_sites].view(-1))\n",
    "    \n",
    "    print(\"Sites to upsample \",sites_to_upsample.shape)\n",
    "    \n",
    "    tet_centroids = sites[sites_to_upsample]\n",
    "\n",
    "    # Tetrahedron relative positions (unit tetrahedron)\n",
    "    basic_tet_1 = torch.tensor([[1, 1, 1]], device=device, dtype=torch.float64)\n",
    "    basic_tet_1 = basic_tet_1.repeat(len(tet_centroids), 1)\n",
    "    basic_tet_2 = torch.tensor([-1, -1, 1], device=device, dtype=torch.float64)    \n",
    "    basic_tet_2 = basic_tet_2.repeat(len(tet_centroids), 1)\n",
    "    basic_tet_3 = torch.tensor([-1, 1, -1], device=device, dtype=torch.float64)    \n",
    "    basic_tet_3 = basic_tet_3.repeat(len(tet_centroids), 1)\n",
    "    basic_tet_4 = torch.tensor([1, -1, -1], device=device, dtype=torch.float64)\n",
    "    basic_tet_4 = basic_tet_4.repeat(len(tet_centroids), 1)\n",
    "\n",
    "\n",
    "    #compute scale based on cell volume\n",
    "    centroids = torch.tensor(np.array([vor.vertices[vor.regions[vor.point_region[i]]].mean(axis=0) for i in range(len(sites_np))]), device=device)\n",
    "    #centroids = torch.tensor(np.array(centroids), device=sites.device, dtype=sites.dtype)\n",
    "    cells_vertices = [vor.vertices[vor.regions[vor.point_region[i]]] for i in range(len(sites_np))]\n",
    "\n",
    "    #compute the distance between each centroid  and each vertex in cells_vertices row\n",
    "    distances = []\n",
    "    for i in range(len(cells_vertices)):\n",
    "        min_dist = 100000000000\n",
    "        for j in range(len(cells_vertices[i])):\n",
    "            dist = torch.norm(centroids[i] - torch.tensor(cells_vertices[i][j], device=device), p=2)\n",
    "            if dist < min_dist:\n",
    "                min_dist = dist\n",
    "        distances.append(min_dist)\n",
    "    distances = torch.tensor(distances, device=device)\n",
    " \n",
    "    \n",
    "    scale = distances[sites_to_upsample] / 2\n",
    "    \n",
    "    scale = scale.unsqueeze(1)\n",
    "    \n",
    "    \n",
    "    new_sites = torch.cat((tet_centroids + basic_tet_1 * scale, tet_centroids + basic_tet_2 * scale, tet_centroids + basic_tet_3 * scale, tet_centroids + basic_tet_4 * scale), dim=0)\n",
    "\n",
    "    updated_sites = torch.cat((sites, new_sites), dim=0)\n",
    "\n",
    "    return updated_sites\n",
    "                \n",
    "def compute_zero_crossing_vertices_3d(sites, model):\n",
    "    \"\"\"\n",
    "    Computes the indices of the sites composing vertices where neighboring sites have opposite or zero SDF values.\n",
    "\n",
    "    Args:\n",
    "        sites (torch.Tensor): (N, D) tensor of site positions.\n",
    "        model (callable): Function or neural network that computes SDF values.\n",
    "\n",
    "    Returns:\n",
    "        zero_crossing_vertices_index (list of triplets): List of sites indices (si, sj, sk) where atleast 2 sites have opposing SDF signs.\n",
    "    \"\"\"\n",
    "    # Compute Delaunay neighbors\n",
    "    # Detach and convert to NumPy for Delaunay triangulation\n",
    "    points_np = sites.detach().cpu().numpy()\n",
    "    \n",
    "    # Compute the Delaunay tessellation\n",
    "    tri = Delaunay(points_np)\n",
    "    vor = Voronoi(points_np)\n",
    "    \n",
    "    # Compute SDF values for all sites\n",
    "    sdf_values = model(sites)  # Assuming model outputs (N, 1) or (N,) tensor\n",
    "\n",
    "    neighbors = torch.tensor(np.array(vor.ridge_points), device=device)\n",
    "    all_tetrahedra = torch.tensor(np.array(tri.simplices), device=device)\n",
    "    \n",
    "    # Extract the SDF values for each site in the pair\n",
    "    sdf_i = sdf_values[neighbors[:, 0]]  # First site in each pair\n",
    "    sdf_j = sdf_values[neighbors[:, 1]]  # Second site in each pair\n",
    "    # Find the indices where SDF values have opposing signs or one is zero\n",
    "    mask_zero_crossing_sites = (sdf_i * sdf_j <= 0).squeeze()\n",
    "    zero_crossing_pairs = neighbors[mask_zero_crossing_sites]\n",
    "\n",
    "    # Check if vertices has a pair of zero crossing sites\n",
    "    sdf_0 = sdf_values[all_tetrahedra[:, 0]]  # First site in each pair\n",
    "    sdf_1 = sdf_values[all_tetrahedra[:, 1]]  # Second site in each pair\n",
    "    sdf_2 = sdf_values[all_tetrahedra[:, 2]]  # Third site in each pair\n",
    "    sdf_3 = sdf_values[all_tetrahedra[:, 3]]  # Fourth site in each pair\n",
    "    mask_zero_crossing_faces = (sdf_0*sdf_1<=0).squeeze() | (sdf_0*sdf_2<=0).squeeze() | (sdf_0*sdf_3<=0).squeeze() | (sdf_1*sdf_2<=0).squeeze() | (sdf_1*sdf_3<=0).squeeze() | (sdf_2*sdf_3<=0).squeeze()\n",
    "    zero_crossing_vertices_index = all_tetrahedra[mask_zero_crossing_faces]\n",
    "    return zero_crossing_vertices_index, zero_crossing_pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvt_loss_values = []\n",
    "min_distance_loss_values = []\n",
    "edge_smoothing_loss_values = []\n",
    "chamfer_distance_loss_values = []\n",
    "eikonal_loss_values = []\n",
    "domain_restriction_loss_values = []\n",
    "zero_target_points_loss_values = []\n",
    "loss_values = []\n",
    "\n",
    "def autograd(sites, model, max_iter=100, stop_train_threshold=1e-6, upsampling=0, lambda_weights = [0.1,1.0,0.1,0.1,1.0,1.0,0.1]):\n",
    "    optimizer = torch.optim.Adam([\n",
    "    {'params': [p for _, p in model.named_parameters()], 'lr': lr_model},\n",
    "    {'params': [sites], 'lr': lr_sites}\n",
    "], betas=(0.5, 0.999))\n",
    "\n",
    "    prev_loss = float(\"inf\")\n",
    "    best_loss = float(\"inf\")\n",
    "    upsampled = 0.0\n",
    "    epoch = 0\n",
    "    lambda_cvt = lambda_weights[0]\n",
    "    lambda_sdf = lambda_weights[1]\n",
    "    lambda_min_distance = lambda_weights[2]\n",
    "    lambda_laplace = lambda_weights[3]\n",
    "    lamda_chamfer = lambda_weights[4]\n",
    "    lamda_eikonal = lambda_weights[5]\n",
    "    lambda_domain_restriction = lambda_weights[6]\n",
    "    lambda_target_points = lambda_weights[7]\n",
    "    \n",
    "    best_sites = sites.clone()\n",
    "    best_sites.best_loss = best_loss\n",
    "    \n",
    "    while epoch <= max_iter:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        vertices_to_compute, bisectors_to_compute = compute_zero_crossing_vertices_3d(sites)\n",
    "        vertices = su.compute_vertices_3d_vectorized(sites, vertices_to_compute)    \n",
    "        bisectors = su.compute_all_bisectors_vectorized(sites, bisectors_to_compute)\n",
    "        #combine vertices and bisectors to one tensor for chamfer\n",
    "        points = torch.cat((vertices, bisectors), 0)\n",
    "\n",
    "\n",
    "        # Compute losses       \n",
    "        cvt_loss = lf.compute_cvt_loss_vectorized(sites, model)\n",
    "        #min_distance_loss = min_distance_regularization_for_op_sites(edges,sites)\n",
    "        #min_distance_loss = lf.sdf_weighted_min_distance_loss(model, sites)\n",
    "        #edge_smoothing_loss = compute_edge_smoothing_loss(edges, sites, model)\n",
    "        chamfer_loss = lf.chamfer_distance(target_points, points)\n",
    "        eikonal_loss = lf.eikonal(model, input_dimensions=input_dims)\n",
    "        #domain_restriction_loss = lf.domain_restriction(target_points, model)\n",
    "        \n",
    "        sdf_values_target_points = model(target_points)[:,0]\n",
    "        zero_target_points_loss_L2 = torch.mean(sdf_values_target_points**2)\n",
    "        zero_target_points_loss_L1 = torch.mean(torch.abs(model(target_points)[:, 0]))\n",
    "        lambda_1, lambda_2 = 0 , 0.99  # Adjust weights as needed\n",
    "        zero_target_points_loss = lambda_1 * zero_target_points_loss_L1 + lambda_2 * zero_target_points_loss_L2\n",
    "\n",
    "               \n",
    "        # Track raw losses (unweighted)\n",
    "        cvt_loss_values.append(cvt_loss.item())\n",
    "        #min_distance_loss_values.append(min_distance_loss.item())\n",
    "        #edge_smoothing_loss_values.append(edge_smoothing_loss.item())\n",
    "        chamfer_distance_loss_values.append(chamfer_loss.item())\n",
    "        eikonal_loss_values.append(eikonal_loss.item())\n",
    "        #domain_restriction_loss_values.append(domain_restriction_loss.item())\n",
    "        zero_target_points_loss_values.append(zero_target_points_loss.item())\n",
    "  \n",
    "        loss = (\n",
    "            lambda_cvt * cvt_loss +\n",
    "            #lambda_min_distance * min_distance_loss + \n",
    "            #lambda_laplace * edge_smoothing_loss +\n",
    "            lamda_chamfer * chamfer_loss +\n",
    "            lamda_eikonal * eikonal_loss +\n",
    "            #lambda_domain_restriction * domain_restriction_loss +\n",
    "            lambda_target_points * zero_target_points_loss\n",
    "        )\n",
    "        loss_values.append(loss.item())\n",
    "        print(f\"Epoch {epoch}: loss = {loss.item()}\")\n",
    "                \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if loss.item() < best_loss:\n",
    "            best_loss = loss.item()\n",
    "            best_epoch = epoch\n",
    "            best_sites = sites.clone()\n",
    "            best_sites.best_loss = best_loss\n",
    "            if upsampled > 0:\n",
    "                print(f\"UPSAMPLED {upsampled} Best Epoch {best_epoch}: Best loss = {best_loss}\")\n",
    "                #return best_sites\n",
    "        \n",
    "        if abs(prev_loss - loss.item()) < stop_train_threshold:\n",
    "            print(f\"Converged at epoch {epoch} with loss {loss.item()}\")\n",
    "            #break\n",
    "        \n",
    "        prev_loss = loss.item() \n",
    "        \n",
    "        if epoch>100 and (epoch // 100) == upsampled+1 and loss.item() < 0.5 and upsampled < upsampling:\n",
    "            print(\"sites length BEFORE UPSAMPLING: \",len(sites))\n",
    "            \n",
    "            #new_sites = su.upsampling_inside(best_sites, model)\n",
    "            #new_sites = su.adaptive_density_upsampling(best_sites, model)\n",
    "            \n",
    "            #sites = su.add_upsampled_sites(best_sites, new_sites)\n",
    "            \n",
    "            sites = upsampling_vectorized(sites, model)\n",
    "            \n",
    "            sites = sites.detach().requires_grad_(True)\n",
    "            #print(\"upsampled sites length: \",len(sites))\n",
    "            \n",
    "            #best_sites = sites.clone()\n",
    "            #best_sites.best_loss = best_loss\n",
    "            \n",
    "            optimizer = torch.optim.Adam([{'params': [p for _, p in model.named_parameters()], 'lr': lr_model},\n",
    "                                          {'params': [sites], 'lr': lr_sites}])\n",
    "            upsampled += 1.0\n",
    "            print(\"sites length AFTER: \",len(sites))\n",
    "            \n",
    "          \n",
    "        if epoch % (max_iter/10) == 0:\n",
    "            print(f\"Epoch {epoch}: loss = {loss.item()}\")\n",
    "            print(f\"Best Epoch {best_epoch}: Best loss = {best_loss}\")\n",
    "            #save model and sites\n",
    "            site_file_path = f'{destination}{mesh[0]}{max_iter}_{epoch}_3d_sites_{num_centroids}_chamfer{lamda_chamfer}.pth'\n",
    "            model_file_path = f'{destination}{mesh[0]}{max_iter}_{epoch}_3d_model_{num_centroids}_chamfer{lamda_chamfer}.pth'\n",
    "            torch.save(model.state_dict(), model_file_path)\n",
    "            torch.save(sites, site_file_path)\n",
    "            \n",
    "        \n",
    "        epoch += 1           \n",
    "        \n",
    "    return best_sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cvt_loss:  tensor(0.4153, grad_fn=<MeanBackward0>)\n",
      "Epoch 0: loss = 7.620295848840643\n",
      "Epoch 0: loss = 7.620295848840643\n",
      "Best Epoch 0: Best loss = 7.620295848840643\n",
      "cvt_loss:  tensor(0.4141, grad_fn=<MeanBackward0>)\n",
      "Epoch 1: loss = 8.582582808141012\n",
      "cvt_loss:  tensor(0.3454, grad_fn=<MeanBackward0>)\n",
      "Epoch 2: loss = 3.722546308996204\n",
      "cvt_loss:  tensor(0.3736, grad_fn=<MeanBackward0>)\n",
      "Epoch 3: loss = 3.489603259257034\n",
      "cvt_loss:  tensor(0.3462, grad_fn=<MeanBackward0>)\n",
      "Epoch 4: loss = 2.522196314639081\n",
      "cvt_loss:  tensor(0.3288, grad_fn=<MeanBackward0>)\n",
      "Epoch 5: loss = 2.571463159578138\n",
      "cvt_loss:  tensor(0.2980, grad_fn=<MeanBackward0>)\n",
      "Epoch 6: loss = 2.297674042882702\n",
      "cvt_loss:  tensor(0.2714, grad_fn=<MeanBackward0>)\n",
      "Epoch 7: loss = 2.86603488587313\n",
      "cvt_loss:  tensor(0.2766, grad_fn=<MeanBackward0>)\n",
      "Epoch 8: loss = 2.7191242867769154\n",
      "cvt_loss:  tensor(0.2551, grad_fn=<MeanBackward0>)\n",
      "Epoch 9: loss = 2.2409177287968083\n",
      "cvt_loss:  tensor(0.2574, grad_fn=<MeanBackward0>)\n",
      "Epoch 10: loss = 2.0563275767946654\n",
      "cvt_loss:  tensor(0.2389, grad_fn=<MeanBackward0>)\n",
      "Epoch 11: loss = 1.9943522633316864\n",
      "cvt_loss:  tensor(0.2371, grad_fn=<MeanBackward0>)\n",
      "Epoch 12: loss = 1.895351581664593\n",
      "cvt_loss:  tensor(0.2217, grad_fn=<MeanBackward0>)\n",
      "Epoch 13: loss = 2.718367641945773\n",
      "cvt_loss:  tensor(0.2411, grad_fn=<MeanBackward0>)\n",
      "Epoch 14: loss = 1.6143873911571727\n",
      "cvt_loss:  tensor(0.2137, grad_fn=<MeanBackward0>)\n",
      "Epoch 15: loss = 1.563871263558406\n",
      "cvt_loss:  tensor(0.2212, grad_fn=<MeanBackward0>)\n",
      "Epoch 16: loss = 1.5219048992612831\n",
      "cvt_loss:  tensor(0.2095, grad_fn=<MeanBackward0>)\n",
      "Epoch 17: loss = 1.4783395402524198\n",
      "cvt_loss:  tensor(0.2066, grad_fn=<MeanBackward0>)\n",
      "Epoch 18: loss = 1.5096428674177884\n",
      "cvt_loss:  tensor(0.2004, grad_fn=<MeanBackward0>)\n",
      "Epoch 19: loss = 1.4658174189719744\n",
      "cvt_loss:  tensor(0.2105, grad_fn=<MeanBackward0>)\n",
      "Epoch 20: loss = 1.4574710615196713\n",
      "cvt_loss:  tensor(0.1786, grad_fn=<MeanBackward0>)\n",
      "Epoch 21: loss = 1.4127964951968526\n",
      "cvt_loss:  tensor(0.1933, grad_fn=<MeanBackward0>)\n",
      "Epoch 22: loss = 1.4853138822371876\n",
      "cvt_loss:  tensor(0.1774, grad_fn=<MeanBackward0>)\n",
      "Epoch 23: loss = 1.4536643873032118\n",
      "cvt_loss:  tensor(0.1686, grad_fn=<MeanBackward0>)\n",
      "Epoch 24: loss = 1.4215999601448988\n",
      "cvt_loss:  tensor(0.1601, grad_fn=<MeanBackward0>)\n",
      "Epoch 25: loss = 1.4207266353725136\n",
      "cvt_loss:  tensor(0.1621, grad_fn=<MeanBackward0>)\n",
      "Epoch 26: loss = 1.432034905209477\n",
      "cvt_loss:  tensor(0.1584, grad_fn=<MeanBackward0>)\n",
      "Epoch 27: loss = 1.382430754438365\n",
      "cvt_loss:  tensor(0.1804, grad_fn=<MeanBackward0>)\n",
      "Epoch 28: loss = 1.44664400817877\n",
      "cvt_loss:  tensor(0.1482, grad_fn=<MeanBackward0>)\n",
      "Epoch 29: loss = 1.399022915787628\n",
      "cvt_loss:  tensor(0.1715, grad_fn=<MeanBackward0>)\n",
      "Epoch 30: loss = 1.3615598822057655\n",
      "cvt_loss:  tensor(0.1551, grad_fn=<MeanBackward0>)\n",
      "Epoch 31: loss = 1.368452416286655\n",
      "cvt_loss:  tensor(0.1481, grad_fn=<MeanBackward0>)\n",
      "Epoch 32: loss = 1.3683888704875073\n",
      "cvt_loss:  tensor(0.1490, grad_fn=<MeanBackward0>)\n",
      "Epoch 33: loss = 1.34999510615424\n",
      "cvt_loss:  tensor(0.1685, grad_fn=<MeanBackward0>)\n",
      "Epoch 34: loss = 1.403491640362591\n",
      "cvt_loss:  tensor(0.1608, grad_fn=<MeanBackward0>)\n",
      "Epoch 35: loss = 1.2604940714178157\n",
      "cvt_loss:  tensor(0.1454, grad_fn=<MeanBackward0>)\n",
      "Epoch 36: loss = 1.238087640242033\n",
      "cvt_loss:  tensor(0.1476, grad_fn=<MeanBackward0>)\n",
      "Epoch 37: loss = 1.2460941164598272\n",
      "cvt_loss:  tensor(0.1495, grad_fn=<MeanBackward0>)\n",
      "Epoch 38: loss = 1.2315325476811776\n",
      "cvt_loss:  tensor(0.1433, grad_fn=<MeanBackward0>)\n",
      "Epoch 39: loss = 1.2418204961531656\n",
      "cvt_loss:  tensor(0.1385, grad_fn=<MeanBackward0>)\n",
      "Epoch 40: loss = 1.2649363468393713\n",
      "cvt_loss:  tensor(0.1309, grad_fn=<MeanBackward0>)\n",
      "Epoch 41: loss = 1.2286295946690797\n",
      "cvt_loss:  tensor(0.1413, grad_fn=<MeanBackward0>)\n",
      "Epoch 42: loss = 1.2149669068915825\n",
      "cvt_loss:  tensor(0.1510, grad_fn=<MeanBackward0>)\n",
      "Epoch 43: loss = 1.1114905249506428\n",
      "cvt_loss:  tensor(0.1351, grad_fn=<MeanBackward0>)\n",
      "Epoch 44: loss = 1.1302165015875578\n",
      "cvt_loss:  tensor(0.1359, grad_fn=<MeanBackward0>)\n",
      "Epoch 45: loss = 1.1188184261554712\n",
      "cvt_loss:  tensor(0.1416, grad_fn=<MeanBackward0>)\n",
      "Epoch 46: loss = 1.0658664872487287\n",
      "cvt_loss:  tensor(0.1232, grad_fn=<MeanBackward0>)\n",
      "Epoch 47: loss = 1.1023855653247445\n",
      "cvt_loss:  tensor(0.1263, grad_fn=<MeanBackward0>)\n",
      "Epoch 48: loss = 1.123317976030976\n",
      "cvt_loss:  tensor(0.1158, grad_fn=<MeanBackward0>)\n",
      "Epoch 49: loss = 1.079081827569217\n",
      "cvt_loss:  tensor(0.1222, grad_fn=<MeanBackward0>)\n",
      "Epoch 50: loss = 1.0321960843353903\n",
      "Epoch 50: loss = 1.0321960843353903\n",
      "Best Epoch 50: Best loss = 1.0321960843353903\n",
      "cvt_loss:  tensor(0.1206, grad_fn=<MeanBackward0>)\n",
      "Epoch 51: loss = 0.9632697590929123\n",
      "cvt_loss:  tensor(0.1087, grad_fn=<MeanBackward0>)\n",
      "Epoch 52: loss = 0.9895584603555657\n",
      "cvt_loss:  tensor(0.1069, grad_fn=<MeanBackward0>)\n",
      "Epoch 53: loss = 0.9926474306177522\n",
      "cvt_loss:  tensor(0.1094, grad_fn=<MeanBackward0>)\n",
      "Epoch 54: loss = 0.9980200707099184\n",
      "cvt_loss:  tensor(0.0993, grad_fn=<MeanBackward0>)\n",
      "Epoch 55: loss = 0.9781024150517932\n",
      "cvt_loss:  tensor(0.0964, grad_fn=<MeanBackward0>)\n",
      "Epoch 56: loss = 0.9325261194246067\n",
      "cvt_loss:  tensor(0.1023, grad_fn=<MeanBackward0>)\n",
      "Epoch 57: loss = 0.8711979521089167\n",
      "cvt_loss:  tensor(0.0972, grad_fn=<MeanBackward0>)\n",
      "Epoch 58: loss = 0.9095486882176586\n",
      "cvt_loss:  tensor(0.0937, grad_fn=<MeanBackward0>)\n",
      "Epoch 59: loss = 0.9052603642121771\n",
      "cvt_loss:  tensor(0.0951, grad_fn=<MeanBackward0>)\n",
      "Epoch 60: loss = 0.8785429913977961\n",
      "cvt_loss:  tensor(0.0938, grad_fn=<MeanBackward0>)\n",
      "Epoch 61: loss = 0.9617992251576275\n",
      "cvt_loss:  tensor(0.0983, grad_fn=<MeanBackward0>)\n",
      "Epoch 62: loss = 0.9577581649737429\n",
      "cvt_loss:  tensor(0.1082, grad_fn=<MeanBackward0>)\n",
      "Epoch 63: loss = 0.8788160166840402\n",
      "cvt_loss:  tensor(0.1050, grad_fn=<MeanBackward0>)\n",
      "Epoch 64: loss = 0.8376511787028111\n",
      "cvt_loss:  tensor(0.1065, grad_fn=<MeanBackward0>)\n",
      "Epoch 65: loss = 0.8541418714887238\n",
      "cvt_loss:  tensor(0.1065, grad_fn=<MeanBackward0>)\n",
      "Epoch 66: loss = 0.8266462232987296\n",
      "cvt_loss:  tensor(0.1048, grad_fn=<MeanBackward0>)\n",
      "Epoch 67: loss = 0.80023963313922\n",
      "cvt_loss:  tensor(0.0981, grad_fn=<MeanBackward0>)\n",
      "Epoch 68: loss = 0.776022068581347\n",
      "cvt_loss:  tensor(0.0897, grad_fn=<MeanBackward0>)\n",
      "Epoch 69: loss = 0.7770493327795368\n",
      "cvt_loss:  tensor(0.0817, grad_fn=<MeanBackward0>)\n",
      "Epoch 70: loss = 0.7491395876425061\n",
      "cvt_loss:  tensor(0.0752, grad_fn=<MeanBackward0>)\n",
      "Epoch 71: loss = 0.7927065262514849\n",
      "cvt_loss:  tensor(0.0798, grad_fn=<MeanBackward0>)\n",
      "Epoch 72: loss = 0.8053946890706668\n",
      "cvt_loss:  tensor(0.0802, grad_fn=<MeanBackward0>)\n",
      "Epoch 73: loss = 0.7696107259438973\n",
      "cvt_loss:  tensor(0.0785, grad_fn=<MeanBackward0>)\n",
      "Epoch 74: loss = 0.7653303613833692\n",
      "cvt_loss:  tensor(0.0773, grad_fn=<MeanBackward0>)\n",
      "Epoch 75: loss = 0.7779691737001977\n",
      "cvt_loss:  tensor(0.0705, grad_fn=<MeanBackward0>)\n",
      "Epoch 76: loss = 0.7621307167625386\n",
      "cvt_loss:  tensor(0.0650, grad_fn=<MeanBackward0>)\n",
      "Epoch 77: loss = 0.7532164214537059\n",
      "cvt_loss:  tensor(0.0661, grad_fn=<MeanBackward0>)\n",
      "Epoch 78: loss = 0.7625253832594574\n",
      "cvt_loss:  tensor(0.0578, grad_fn=<MeanBackward0>)\n",
      "Epoch 79: loss = 0.7803283066461592\n",
      "cvt_loss:  tensor(0.0606, grad_fn=<MeanBackward0>)\n",
      "Epoch 80: loss = 0.7819616328184861\n",
      "cvt_loss:  tensor(0.0560, grad_fn=<MeanBackward0>)\n",
      "Epoch 81: loss = 0.788946235907917\n",
      "cvt_loss:  tensor(0.0528, grad_fn=<MeanBackward0>)\n",
      "Epoch 82: loss = 0.7978876949398074\n",
      "cvt_loss:  tensor(0.0520, grad_fn=<MeanBackward0>)\n",
      "Epoch 83: loss = 0.7876508266585485\n",
      "cvt_loss:  tensor(0.0506, grad_fn=<MeanBackward0>)\n",
      "Epoch 84: loss = 0.7830276803925694\n",
      "cvt_loss:  tensor(0.0492, grad_fn=<MeanBackward0>)\n",
      "Epoch 85: loss = 0.7736435389003062\n",
      "cvt_loss:  tensor(0.0450, grad_fn=<MeanBackward0>)\n",
      "Epoch 86: loss = 0.7921817080070179\n",
      "cvt_loss:  tensor(0.0470, grad_fn=<MeanBackward0>)\n",
      "Epoch 87: loss = 0.7789481707368755\n",
      "cvt_loss:  tensor(0.0447, grad_fn=<MeanBackward0>)\n",
      "Epoch 88: loss = 0.7579236711519007\n",
      "cvt_loss:  tensor(0.0436, grad_fn=<MeanBackward0>)\n",
      "Epoch 89: loss = 0.783671265842251\n",
      "cvt_loss:  tensor(0.0453, grad_fn=<MeanBackward0>)\n",
      "Epoch 90: loss = 0.7958292682204903\n",
      "cvt_loss:  tensor(0.0418, grad_fn=<MeanBackward0>)\n",
      "Epoch 91: loss = 0.7747333517694425\n",
      "cvt_loss:  tensor(0.0426, grad_fn=<MeanBackward0>)\n",
      "Epoch 92: loss = 0.7891345254736446\n",
      "cvt_loss:  tensor(0.0402, grad_fn=<MeanBackward0>)\n",
      "Epoch 93: loss = 0.7472775619458907\n",
      "cvt_loss:  tensor(0.0424, grad_fn=<MeanBackward0>)\n",
      "Epoch 94: loss = 0.7549788143562589\n",
      "cvt_loss:  tensor(0.0391, grad_fn=<MeanBackward0>)\n",
      "Epoch 95: loss = 0.7372567785567153\n",
      "cvt_loss:  tensor(0.0417, grad_fn=<MeanBackward0>)\n",
      "Epoch 96: loss = 0.8049583144827342\n",
      "cvt_loss:  tensor(0.0415, grad_fn=<MeanBackward0>)\n",
      "Epoch 97: loss = 0.7315096601888421\n",
      "cvt_loss:  tensor(0.0374, grad_fn=<MeanBackward0>)\n",
      "Epoch 98: loss = 0.8054874956295716\n",
      "cvt_loss:  tensor(0.0375, grad_fn=<MeanBackward0>)\n",
      "Epoch 99: loss = 0.782456266960313\n",
      "cvt_loss:  tensor(0.0371, grad_fn=<MeanBackward0>)\n",
      "Epoch 100: loss = 0.7751995970962167\n",
      "Epoch 100: loss = 0.7751995970962167\n",
      "Best Epoch 97: Best loss = 0.7315096601888421\n",
      "cvt_loss:  tensor(0.0346, grad_fn=<MeanBackward0>)\n",
      "Epoch 101: loss = 0.8056272239720608\n",
      "cvt_loss:  tensor(0.0355, grad_fn=<MeanBackward0>)\n",
      "Epoch 102: loss = 0.7720891074076486\n",
      "cvt_loss:  tensor(0.0349, grad_fn=<MeanBackward0>)\n",
      "Epoch 103: loss = 0.8133543041258138\n",
      "cvt_loss:  tensor(0.0367, grad_fn=<MeanBackward0>)\n",
      "Epoch 104: loss = 0.7512029996052644\n",
      "cvt_loss:  tensor(0.0359, grad_fn=<MeanBackward0>)\n",
      "Epoch 105: loss = 0.7630524844450972\n",
      "cvt_loss:  tensor(0.0346, grad_fn=<MeanBackward0>)\n",
      "Epoch 106: loss = 0.7776868118513626\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m profiler \u001b[38;5;241m=\u001b[39m cProfile\u001b[38;5;241m.\u001b[39mProfile()\n\u001b[1;32m     25\u001b[0m profiler\u001b[38;5;241m.\u001b[39menable()\n\u001b[0;32m---> 27\u001b[0m sites \u001b[38;5;241m=\u001b[39m \u001b[43mautograd\u001b[49m\u001b[43m(\u001b[49m\u001b[43msites\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupsampling\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlambda_weights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m profiler\u001b[38;5;241m.\u001b[39mdisable()\n\u001b[1;32m     30\u001b[0m stats \u001b[38;5;241m=\u001b[39m pstats\u001b[38;5;241m.\u001b[39mStats(profiler)\u001b[38;5;241m.\u001b[39msort_stats(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcumtime\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[19], line 80\u001b[0m, in \u001b[0;36mautograd\u001b[0;34m(sites, model, max_iter, stop_train_threshold, upsampling, lambda_weights)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: loss = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     79\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 80\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m<\u001b[39m best_loss:\n\u001b[1;32m     83\u001b[0m     best_loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/optim/optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m                                \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 280\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    283\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/optim/optimizer.py:33\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 33\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/optim/adam.py:141\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    130\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    133\u001b[0m         group,\n\u001b[1;32m    134\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    139\u001b[0m         state_steps)\n\u001b[0;32m--> 141\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/optim/adam.py:281\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    279\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 281\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/optim/adam.py:489\u001b[0m, in \u001b[0;36m_multi_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    487\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_foreach_addcdiv_(params_, device_exp_avgs, denom)\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 489\u001b[0m     bias_correction1 \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta1 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m _get_value(step) \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m device_state_steps]\n\u001b[1;32m    490\u001b[0m     bias_correction2 \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta2 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m _get_value(step) \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m device_state_steps]\n\u001b[1;32m    492\u001b[0m     step_size \u001b[38;5;241m=\u001b[39m _stack_if_compiling([(lr \u001b[38;5;241m/\u001b[39m bc) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m bc \u001b[38;5;129;01min\u001b[39;00m bias_correction1])\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/optim/adam.py:489\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    487\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_foreach_addcdiv_(params_, device_exp_avgs, denom)\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 489\u001b[0m     bias_correction1 \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta1 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m device_state_steps]\n\u001b[1;32m    490\u001b[0m     bias_correction2 \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta2 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m _get_value(step) \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m device_state_steps]\n\u001b[1;32m    492\u001b[0m     step_size \u001b[38;5;241m=\u001b[39m _stack_if_compiling([(lr \u001b[38;5;241m/\u001b[39m bc) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m bc \u001b[38;5;129;01min\u001b[39;00m bias_correction1])\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/optim/optimizer.py:44\u001b[0m, in \u001b[0;36m_get_value\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "lambda_weights = [0.2,0,0.2,0,1.00011111111101101000101,0.1,0,2]\n",
    "\n",
    "lambda_cvt = lambda_weights[0]\n",
    "lambda_sdf = lambda_weights[1]\n",
    "lambda_min_distance = lambda_weights[2]\n",
    "lambda_laplace = lambda_weights[3]\n",
    "lamda_chamfer = lambda_weights[4]\n",
    "lambda_eikonal = lambda_weights[5]\n",
    "lambda_domain_restriction = lambda_weights[6]\n",
    "lambda_target_points = lambda_weights[7]\n",
    "\n",
    "max_iter = 500\n",
    "\n",
    "site_file_path = f'{destination}{mesh[0]}{max_iter}3d_sites_{num_centroids}_chamfer{lamda_chamfer}.npy'\n",
    "#check if optimized sites file exists\n",
    "if os.path.exists(site_file_path):\n",
    "    #import sites\n",
    "    print(\"Importing sites\")\n",
    "    sites = np.load(site_file_path)\n",
    "    sites = torch.from_numpy(sites).to(device).requires_grad_(True)    \n",
    "else:\n",
    "    import cProfile, pstats\n",
    "    import time\n",
    "    profiler = cProfile.Profile()\n",
    "    profiler.enable()\n",
    "    \n",
    "    sites = autograd(sites, model, max_iter=max_iter, upsampling=0, lambda_weights=lambda_weights)\n",
    "    \n",
    "    profiler.disable()\n",
    "    stats = pstats.Stats(profiler).sort_stats('cumtime')\n",
    "    stats.print_stats()\n",
    "    stats.dump_stats(f'{destination}{mesh[0]}{max_iter}_3d_profile_{num_centroids}_chamfer{lamda_chamfer}.prof')\n",
    "    \n",
    "    \n",
    "    sites_np = sites.detach().cpu().numpy()\n",
    "    np.save(site_file_path, sites_np)\n",
    "    \n",
    "\n",
    "print(\"Sites length: \", len(sites))\n",
    "print(\"min sites: \", torch.min(sites))\n",
    "print(\"max sites: \", torch.max(sites))\n",
    "ps_cloud = ps.register_point_cloud(\"best_optimized_cvt_grid\",sites.detach().cpu().numpy())\n",
    "    \n",
    "lim=torch.abs(torch.max(sites)).detach().cpu().numpy()*1.1\n",
    "#plot_voronoi_3d(sites,lim,lim,lim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model ./images/autograd/3D/bunny500_100_3d_model_4096_chamfer1.000111111111011.pth\n",
      "sites ./images/autograd/3D/bunny500_100_3d_sites_4096_chamfer1.000111111111011.pth\n"
     ]
    }
   ],
   "source": [
    "epoch = 100\n",
    "\n",
    "model_file_path = f'{destination}{mesh[0]}{max_iter}_{epoch}_3d_model_{num_centroids}_chamfer{lamda_chamfer}.pth'\n",
    "site_file_path = f'{destination}{mesh[0]}{max_iter}_{epoch}_3d_sites_{num_centroids}_chamfer{lamda_chamfer}.pth'\n",
    "sites = torch.load(site_file_path)\n",
    "sites_np = sites.detach().cpu().numpy()\n",
    "model.load_state_dict(torch.load(model_file_path))\n",
    "#\n",
    "polyscope_sdf(model)\n",
    "#\n",
    "print(\"model\", model_file_path)\n",
    "print(\"sites\", site_file_path)\n",
    "ps_cloud = ps.register_point_cloud(f\"{epoch} epoch_cvt_grid\",sites_np)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_mesh = su.get_zero_crossing_mesh_3d(sites, model)\n",
    "\n",
    "ps.register_surface_mesh(\"Zero-Crossing faces\", final_mesh[0], final_mesh[1])\n",
    "ps.register_point_cloud(\"Mesh vertices\", final_mesh[0])\n",
    "\n",
    "ps.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_visualisation_3d():\n",
    "    import imageio\n",
    "    img_buffer_mesh = []\n",
    "    img_buffer_model = []\n",
    "    for i in range(int(max_iter/10)+1):\n",
    "        epoch = i*int(max_iter/10)\n",
    "        \n",
    "        site_file_path = f'{destination}{mesh[0]}{max_iter}_{epoch}_3d_sites_{num_centroids}_chamfer{lamda_chamfer}.pth'\n",
    "        model_file_path = f'{destination}{mesh[0]}{max_iter}_{epoch}_3d_model_{num_centroids}_chamfer{lamda_chamfer}.pth'\n",
    "        if os.path.exists(site_file_path) and os.path.exists(model_file_path):\n",
    "            print(\"importing sites and model\")\n",
    "        else:\n",
    "            print(\"files not found\")\n",
    "            continue\n",
    "        print(\"mesh of epoch: \", epoch)\n",
    "        \n",
    "        model.load_state_dict(torch.load(model_file_path))\n",
    "    \n",
    "        current_mesh = su.get_zero_crossing_mesh_3d(torch.load(site_file_path), model)\n",
    "        ps.remove_all_structures()\n",
    "        ps.register_surface_mesh(\"Zero-Crossing faces\", current_mesh[0], current_mesh[1])\n",
    "        ps.register_point_cloud(\"Mesh vertices\", current_mesh[0])\n",
    "        img_buffer_mesh.append(ps.screenshot_to_buffer(transparent_bg=False))\n",
    "        \n",
    "        ps.remove_all_structures()\n",
    "        polyscope_sdf(model)\n",
    "        img_buffer_model.append(ps.screenshot_to_buffer(transparent_bg=False))\n",
    "\n",
    "\n",
    "    imageio.mimsave(f'{destination}{max_iter}_3d_{num_centroids}_optimization_mesh.gif',img_buffer_mesh, fps=1, duration=1, loop=0)\n",
    "    imageio.mimsave(f'{destination}{max_iter}_3d_{num_centroids}_optimization_sdf.gif', img_buffer_model, fps=1, duration=1, loop=0)\n",
    "\n",
    "export_visualisation_3d()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
