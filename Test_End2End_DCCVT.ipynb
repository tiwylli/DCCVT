{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f9796c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "Using device:  NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "import kaolin\n",
    "import torch\n",
    "import math\n",
    "import matplotlib\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import polyscope as ps\n",
    "import trimesh\n",
    "import diffvoronoi\n",
    "\n",
    "from scipy.spatial import Voronoi, voronoi_plot_2d, Delaunay\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import sdfpred_utils.sdfpred_utils as su\n",
    "import sdfpred_utils.sdf_MLP as mlp\n",
    "import sdfpred_utils.sdf_functions as sdf\n",
    "import sdfpred_utils.loss_functions as lf\n",
    "import sdfpred_utils.Steik_data3d as sd3d\n",
    "import sdfpred_utils.Steik_Loss as sl\n",
    "import sdfpred_utils.Steik_utils as Stu \n",
    "import open3d as o3d\n",
    "\n",
    "#cuda devices\n",
    "device = torch.device(\"cuda:0\")\n",
    "print(\"Using device: \", torch.cuda.get_device_name(device))\n",
    "\n",
    "#default tensor types\n",
    "#torch.set_default_tensor_type(torch.cuda.DoubleTensor)\n",
    "\n",
    "multires = 2\n",
    "input_dims = 3\n",
    "lr_sites = 0.005\n",
    "lr_model = 0.00001\n",
    "destination = \"./images/autograd/End2End_DCCVT/\"\n",
    "model_trained_it = \"\"\n",
    "\n",
    "# mesh = [\"gargoyle\",\"/home/wylliam/dev/Kyushu_experiments/data/gargoyle\"]\n",
    "# trained_model_path = f\"/home/wylliam/dev/HotSpot/log/3D/pc/HotSpot-all-2025-04-24-18-16-03/gargoyle/gargoyle/trained_models/model{model_trained_it}.pth\"\n",
    "\n",
    "# mesh = [\"chair\",\"/home/wylliam/dev/Kyushu_experiments/data/chair\"]\n",
    "# trained_model_path = f\"/home/wylliam/dev/HotSpot/log/3D/pc/HotSpot-all-2025-05-02-17-56-25/chair/chair/trained_models/model{model_trained_it}.pth\"\n",
    "\n",
    "mesh = [\"bunny\",\"/home/wylliam/dev/Kyushu_experiments/data/bunny\"]\n",
    "trained_model_path = f\"/home/wylliam/dev/HotSpot/log/3D/pc/HotSpot-all-2025-04-25-17-32-49/bunny/bunny/trained_models/model{model_trained_it}.pth\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3f27a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new sites\n",
      "Sites shape:  torch.Size([512, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wylliam/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1678402412426/work/aten/src/ATen/native/TensorShape.cpp:3483.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[polyscope] Backend: openGL3_glfw -- Loaded openGL version: 3.3.0 NVIDIA 570.144\n"
     ]
    }
   ],
   "source": [
    "num_centroids = 8**3\n",
    "\n",
    "print(\"Creating new sites\")\n",
    "noise_scale = 0.1\n",
    "domain_limit = 1\n",
    "x = torch.linspace(-domain_limit, domain_limit, int(round(num_centroids**(1/3))))\n",
    "y = torch.linspace(-domain_limit, domain_limit, int(round(num_centroids**(1/3))))\n",
    "z = torch.linspace(-domain_limit, domain_limit, int(round(num_centroids**(1/3))))\n",
    "meshgrid = torch.meshgrid(x, y, z)\n",
    "meshgrid = torch.stack(meshgrid, dim=3).view(-1, 3)\n",
    "\n",
    "\n",
    "#add noise to meshgrid\n",
    "#meshgrid += torch.randn_like(meshgrid) * noise_scale\n",
    "\n",
    "\n",
    "sites = meshgrid.to(device, dtype=torch.float32).requires_grad_(True)\n",
    "\n",
    "print(\"Sites shape: \", sites.shape)\n",
    "ps.init()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2df77f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnfld_points shape:  torch.Size([1, 153600, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wylliam/anaconda3/envs/pytorch3d/lib/python3.9/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LOAD MODEL WITH HOTSPOT\n",
    "import sys\n",
    "sys.path.append(\"3rdparty/HotSpot\")\n",
    "from dataset import shape_3d\n",
    "import models.Net as Net\n",
    "\n",
    "loss_type = \"igr_w_heat\"\n",
    "loss_weights = [350, 0, 0, 1, 0, 0, 20]\n",
    "\n",
    "train_set = shape_3d.ReconDataset(\n",
    "    file_path = mesh[1]+\".ply\",\n",
    "    n_points=32*32*150,#15000, #args.n_points,\n",
    "    n_samples=10001, #args.n_iterations,\n",
    "    grid_res=256, #args.grid_res,\n",
    "    grid_range=1.1, #args.grid_range,\n",
    "    sample_type=\"uniform_central_gaussian\", #args.nonmnfld_sample_type,\n",
    "    sampling_std=0.5, #args.nonmnfld_sample_std,\n",
    "    n_random_samples=7500, #args.n_random_samples,\n",
    "    resample=True,\n",
    "    compute_sal_dist_gt=(\n",
    "        True if \"sal\" in loss_type and loss_weights[5] > 0 else False\n",
    "    ),\n",
    "    scale_method=\"mean\"#\"mean\" #args.pcd_scale_method,\n",
    ")\n",
    "\n",
    "model = Net.Network(\n",
    "    latent_size=0,#args.latent_size,\n",
    "    in_dim=3,\n",
    "    decoder_hidden_dim=128,#args.decoder_hidden_dim,\n",
    "    nl=\"sine\",#args.nl,\n",
    "    encoder_type=\"none\",#args.encoder_type,\n",
    "    decoder_n_hidden_layers=5,#args.decoder_n_hidden_layers,\n",
    "    neuron_type=\"quadratic\",#args.neuron_type,\n",
    "    init_type=\"mfgi\",#args.init_type,\n",
    "    sphere_init_params=[1.6, 0.1],#args.sphere_init_params,\n",
    "    n_repeat_period=30#args.n_repeat_period,\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "######       \n",
    "test_dataloader = torch.utils.data.DataLoader(train_set, batch_size=1, shuffle=False, num_workers=0, pin_memory=False)   \n",
    "test_data = next(iter(test_dataloader))\n",
    "mnfld_points = test_data[\"mnfld_points\"].to(device)\n",
    "mnfld_points.requires_grad_()\n",
    "print(\"mnfld_points shape: \", mnfld_points.shape)\n",
    "if torch.cuda.is_available():\n",
    "    map_location = torch.device(\"cuda\")\n",
    "else:\n",
    "    map_location = torch.device(\"cpu\")\n",
    "model.load_state_dict(torch.load(trained_model_path, weights_only=True, map_location=map_location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7570e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #add mnfld points with random noise to sites \n",
    "N = mnfld_points.squeeze(0).shape[0]\n",
    "num_samples = 16**3\n",
    "idx = torch.randint(0, N, (num_samples,))\n",
    "sampled = mnfld_points.squeeze(0)[idx]\n",
    "perturbed = sampled + (torch.rand_like(sampled)-0.5)*0.1\n",
    "sites = torch.cat((sites, perturbed), dim=0)\n",
    "\n",
    "# make sites a leaf tensor\n",
    "sites = sites.detach().requires_grad_()\n",
    "\n",
    "sites_pred = model(sites)#[\"nonmanifold_pnts_pred\"]\n",
    "#mnfld_preds = model(mnfld_points)#[\"nonmanifold_pnts_pred\"]\n",
    "\n",
    "ps_cloud = ps.register_point_cloud(\"initial_cvt_grid+pc_gt\",sites.detach().cpu().numpy())\n",
    "mnf_cloud = ps.register_point_cloud(\"mnfld_points_pred\",mnfld_points.squeeze(0).detach().cpu().numpy())\n",
    "#mnf_cloud.add_scalar_quantity(\"mnfld_points_pred\", mnfld_preds.reshape(-1).detach().cpu().numpy(), enabled=True)\n",
    "ps_cloud.add_scalar_quantity(\"vis_grid_pred\", sites_pred.reshape(-1).detach().cpu().numpy(), enabled=True)\n",
    "\n",
    "initial_mesh = su.get_zero_crossing_mesh_3d(sites, model)\n",
    "ps.register_surface_mesh(\"initial Zero-Crossing faces\", initial_mesh[0], initial_mesh[1])\n",
    "\n",
    "v_vect, f_vect = su.get_clipped_mesh_torch(sites, model, None, batch_size=4096)\n",
    "triangle_faces = [[f[0], f[i], f[i+1]] for f in f_vect for i in range(1, len(f)-1)]\n",
    "ps.register_surface_mesh(\"initial triangle clipped mesh\", v_vect.detach().cpu().numpy(), triangle_faces)\n",
    "ps.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c1a4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SITES OPTIMISATION LOOP\n",
    "cvt_loss_values = []\n",
    "min_distance_loss_values = []\n",
    "chamfer_distance_loss_values = []\n",
    "eikonal_loss_values = []\n",
    "domain_restriction_loss_values = []\n",
    "sdf_loss_values = []\n",
    "div_loss_values = []\n",
    "loss_values = []\n",
    "\n",
    "\n",
    "\n",
    "def autograd(sites, model, max_iter=100, stop_train_threshold=1e-6, upsampling=0, lambda_weights = [0.1,1.0,0.1,0.1,1.0,1.0,0.1]):\n",
    "    optimizer = torch.optim.Adam([\n",
    "    {'params': [sites], 'lr': lr_sites},\n",
    "    {'params': model.parameters(), 'lr': lr_model}\n",
    "], betas=(0.9, 0.999))\n",
    "\n",
    "    prev_loss = float(\"inf\")\n",
    "    best_loss = float(\"inf\")\n",
    "    upsampled = 0.0\n",
    "    epoch = 0\n",
    "    lambda_cvt = lambda_weights[0]\n",
    "    lambda_chamfer = lambda_weights[4]\n",
    "    best_sites = sites.clone()\n",
    "    best_sites.best_loss = best_loss\n",
    "    \n",
    "    while epoch <= max_iter:\n",
    "        optimizer.zero_grad()\n",
    "        sites_np = sites.detach().cpu().numpy()\n",
    "        d3dsimplices = diffvoronoi.get_delaunay_simplices(sites_np.reshape(input_dims*sites_np.shape[0]))\n",
    "        d3dsimplices = np.array(d3dsimplices)\n",
    "\n",
    "        vertices_to_compute, bisectors_to_compute = su.compute_zero_crossing_vertices_3d(sites, None, None, d3dsimplices, model)\n",
    "        vertices = su.compute_vertices_3d_vectorized(sites, vertices_to_compute)    \n",
    "        bisectors = su.compute_all_bisectors_vectorized(sites, bisectors_to_compute)\n",
    "        points = torch.cat((vertices, bisectors), 0)\n",
    "        # print(\"points\", points.shape) \n",
    "    \n",
    "        cvt_loss = lf.compute_cvt_loss_vectorized_delaunay(sites, None, d3dsimplices)\n",
    "        print(\"CVT loss: \", cvt_loss, \"weighted: \", lambda_cvt*cvt_loss)\n",
    "        #min_distance_loss = lf.sdf_weighted_min_distance_loss(model, sites)\n",
    "        \n",
    "        from pytorch3d.loss import chamfer_distance\n",
    "        chamfer_loss_points, _ = chamfer_distance(mnfld_points.detach(), points.unsqueeze(0))\n",
    "        print(f\"Chamfer loss PYTORCH3D {chamfer_loss_points} weighted: {lambda_chamfer*chamfer_loss_points} : Allocated: {torch.cuda.memory_allocated() / 1e6} MB, Reserved: {torch.cuda.memory_reserved() / 1e6} MB\")\n",
    "\n",
    "        sdf_loss = torch.mean(model(points)**2) + torch.maximum((model(sites).abs() - 0.05), torch.tensor(0.0)).mean()\n",
    "\n",
    "        \n",
    "        v_vect, f_vect = su.get_clipped_mesh_torch(sites, model, d3dsimplices, batch_size=4096)\n",
    "        #ps.register_surface_mesh(\"polygon clipped mesh\", v_vect.detach().cpu().numpy(), f_vect)\n",
    "\n",
    "        # fanning to transform polygon faces to triangle faces\n",
    "        triangle_faces = [[f[0], f[i], f[i+1]] for f in f_vect for i in range(1, len(f)-1)]\n",
    "        #ps.register_surface_mesh(\"triangle clipped mesh\", v_vect.detach().cpu().numpy(), triangle_faces)\n",
    "\n",
    "        triangle_faces = torch.tensor(triangle_faces, device=device)\n",
    "        hs_p = su.sample_mesh_points_heitz(v_vect, triangle_faces, num_samples=150*32**2)\n",
    "        print(\"hs_p shape: \", hs_p.shape)\n",
    "        #ps.register_point_cloud(\"heitz clipped mesh\", hs_p.detach().cpu().numpy())\n",
    "        \n",
    "        from pytorch3d.loss import chamfer_distance\n",
    "        chamfer_loss_mesh, _ = chamfer_distance(mnfld_points.detach(), hs_p.unsqueeze(0))\n",
    "        print(f\"Chamfer loss PYTORCH3D {chamfer_loss_mesh} weighted: {lambda_chamfer*chamfer_loss_mesh} : Allocated: {torch.cuda.memory_allocated() / 1e6} MB, Reserved: {torch.cuda.memory_reserved() / 1e6} MB\")\n",
    "\n",
    "\n",
    "        # # triangle area loss\n",
    "        # # 1) Gather triangle vertices\n",
    "        # v0 = v_vect[triangle_faces[:, 0]]  # (F,3)\n",
    "        # v1 = v_vect[triangle_faces[:, 1]]  # (F,3)\n",
    "        # v2 = v_vect[triangle_faces[:, 2]]  # (F,3)\n",
    "\n",
    "        # # 2) Compute triangle areas for weighting\n",
    "        # e0 = v1 - v0               # (F,3)\n",
    "        # e1 = v2 - v0               # (F,3)\n",
    "        # cross = torch.cross(e0, e1, dim=1)  # (F,3)\n",
    "        # areas = 0.5 * cross.norm(dim=1)     # (F,)\n",
    "        # mean_area = areas.mean()  # (1,)\n",
    "        # triangle_area_loss = torch.mean(areas-mean_area)**2\n",
    "        # print(\"triangle loss: \", triangle_area_loss, \"weighted: \", lambda_chamfer*0.01*triangle_area_loss)\n",
    "\n",
    "\n",
    "        sites_loss = (\n",
    "            lambda_cvt * cvt_loss +\n",
    "            lambda_chamfer * chamfer_loss_mesh \n",
    "            #+ lambda_chamfer*0.01 * triangle_area_loss\n",
    "            + lambda_chamfer * chamfer_loss_points\n",
    "            #+ lambda_chamfer/10 * sdf_loss\n",
    "        )\n",
    "            \n",
    "        loss = sites_loss\n",
    "        loss_values.append(loss.item())\n",
    "        print(f\"Epoch {epoch}: loss = {loss.item()}\")\n",
    "        print(f\"before loss.backward(): Allocated: {torch.cuda.memory_allocated() / 1e6} MB, Reserved: {torch.cuda.memory_reserved() / 1e6} MB\")\n",
    "\n",
    "        loss.backward()\n",
    "        print(f\"After loss.backward(): Allocated: {torch.cuda.memory_allocated() / 1e6} MB, Reserved: {torch.cuda.memory_reserved() / 1e6} MB\")\n",
    "        print(\"-----------------\")\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        if loss.item() < best_loss:\n",
    "            best_loss = loss.item()\n",
    "            best_epoch = epoch\n",
    "            best_sites = sites.clone()\n",
    "            best_sites.best_loss = best_loss\n",
    "            #if upsampled > 0:\n",
    "                #print(f\"UPSAMPLED {upsampled} Best Epoch {best_epoch}: Best loss = {best_loss}\")\n",
    "                #return best_sites\n",
    "        \n",
    "        if abs(prev_loss - loss.item()) < stop_train_threshold:\n",
    "            print(f\"Converged at epoch {epoch} with loss {loss.item()}\")\n",
    "            #break\n",
    "        \n",
    "        prev_loss = loss.item() \n",
    "        \n",
    "        # if epoch>100 and (epoch // 100) == upsampled+1 and loss.item() < 0.5 and upsampled < upsampling:\n",
    "        if epoch/max_iter > (upsampled+1)/(upsampling+1) and upsampled < upsampling:\n",
    "            print(\"sites length BEFORE UPSAMPLING: \",len(sites))\n",
    "            sites = su.upsampling_vectorized(sites, tri=None, vor=None, simplices=d3dsimplices, model=model)\n",
    "            sites = sites.detach().requires_grad_(True)\n",
    "            optimizer = torch.optim.Adam([{'params': [sites], 'lr': lr_sites}])\n",
    "            upsampled += 1.0\n",
    "            print(\"sites length AFTER: \",len(sites))\n",
    "            \n",
    "          \n",
    "        if epoch % (max_iter/10) == 0:\n",
    "            #print(f\"Epoch {epoch}: loss = {loss.item()}\")\n",
    "            #print(f\"Best Epoch {best_epoch}: Best loss = {best_loss}\")\n",
    "            #save model and sites\n",
    "            #ps.register_surface_mesh(f\"{epoch} triangle clipped mesh\", v_vect.detach().cpu().numpy(), triangle_faces.detach().cpu().numpy())\n",
    "            \n",
    "            site_file_path = f'{destination}{mesh[0]}{max_iter}_{epoch}_3d_sites_{num_centroids}_chamfer{lambda_chamfer}.pth'\n",
    "            model_file_path = f'{destination}{mesh[0]}{max_iter}_{epoch}_3d_model_{num_centroids}_chamfer{lambda_chamfer}.pth'\n",
    "            torch.save(model.state_dict(), model_file_path)\n",
    "            torch.save(sites, site_file_path)\n",
    "            \n",
    "        epoch += 1           \n",
    "    \n",
    "    #Export the sites, their sdf values, the gradients of the sdf values and the hessian\n",
    "    sdf_values = model(sites)\n",
    "\n",
    "    sdf_gradients = torch.autograd.grad(outputs=sdf_values, inputs=sites, grad_outputs=torch.ones_like(sdf_values), create_graph=True, retain_graph=True,)[0] # (N, 3)\n",
    "\n",
    "    N, D = sites.shape\n",
    "    hess_sdf = torch.zeros(N, D, D, device=sites.device)\n",
    "    for i in range(D):\n",
    "        grad2 = torch.autograd.grad(outputs=sdf_gradients[:, i], inputs=sites, grad_outputs=torch.ones_like(sdf_gradients[:, i]), create_graph=False, retain_graph=True,)[0] # (N, 3)\n",
    "        hess_sdf[:, i, :] = grad2 # fill row i of each 3Ã—3 Hessian\n",
    "    \n",
    "    np.savez(f'{mesh[0]}voroloss_to_clip{model_trained_it}.npz', sites=sites.detach().cpu().numpy(), sdf_values=sdf_values.detach().cpu().numpy(), sdf_gradients=sdf_gradients.detach().cpu().numpy(), sdf_hessians=hess_sdf.detach().cpu().numpy())\n",
    "    print(f\"Saved to {mesh[0]}voroloss_to_clip{model_trained_it}.npz\")\n",
    "    return best_sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "447548a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lambda_weights = [252,0,0,0,10.211111,0,100,0]\n",
    "#lambda_weights = [500,0,0,0,1000,0,100,0]\n",
    "lambda_weights = [100,0,0,0,1000,0,100,0]\n",
    "\n",
    "\n",
    "lambda_cvt = lambda_weights[0]\n",
    "lambda_sdf = lambda_weights[1]\n",
    "lambda_min_distance = lambda_weights[2]\n",
    "lambda_laplace = lambda_weights[3]\n",
    "lambda_chamfer = lambda_weights[4]\n",
    "lambda_eikonal = lambda_weights[5]\n",
    "lambda_domain_restriction = lambda_weights[6]\n",
    "lambda_true_points = lambda_weights[7]\n",
    "\n",
    "max_iter = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccb5e968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CVT loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.0855, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.00032851987634785473 weighted: 0.32851988077163696 : Allocated: 466.3552 MB, Reserved: 1845.49376 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 2.410622255410999e-05 weighted: 0.0241062231361866 : Allocated: 1156.99968 MB, Reserved: 2808.086528 MB\n",
      "Epoch 0: loss = 7.279580593109131\n",
      "before loss.backward(): Allocated: 1157.000192 MB, Reserved: 2808.086528 MB\n",
      "After loss.backward(): Allocated: 460.494848 MB, Reserved: 2808.086528 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.0008, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.0843, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.00017002382082864642 weighted: 0.1700238138437271 : Allocated: 470.499328 MB, Reserved: 2808.086528 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 1.69107206602348e-05 weighted: 0.016910720616579056 : Allocated: 1141.459968 MB, Reserved: 2808.086528 MB\n",
      "Epoch 1: loss = 6.359157085418701\n",
      "before loss.backward(): Allocated: 1141.459968 MB, Reserved: 2808.086528 MB\n",
      "After loss.backward(): Allocated: 462.011904 MB, Reserved: 2808.086528 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.0901, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.00011064091813750565 weighted: 0.11064092069864273 : Allocated: 470.3616 MB, Reserved: 2808.086528 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 1.4533068679156713e-05 weighted: 0.014533068984746933 : Allocated: 1144.256 MB, Reserved: 3776.970752 MB\n",
      "Epoch 2: loss = 5.627948760986328\n",
      "before loss.backward(): Allocated: 1144.256 MB, Reserved: 3776.970752 MB\n",
      "After loss.backward(): Allocated: 462.019072 MB, Reserved: 3776.970752 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.0011, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(0.1134, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 9.306526044383645e-05 weighted: 0.09306526184082031 : Allocated: 470.412288 MB, Reserved: 3776.970752 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 1.391518071613973e-05 weighted: 0.013915181159973145 : Allocated: 1147.3536 MB, Reserved: 3776.970752 MB\n",
      "Epoch 3: loss = 5.01401424407959\n",
      "before loss.backward(): Allocated: 1147.3536 MB, Reserved: 3776.970752 MB\n",
      "After loss.backward(): Allocated: 462.030336 MB, Reserved: 3776.970752 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.0102, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(1.0236, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 9.015275281853974e-05 weighted: 0.09015275537967682 : Allocated: 470.44608 MB, Reserved: 3776.970752 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 1.4165839274937753e-05 weighted: 0.014165839180350304 : Allocated: 1150.741504 MB, Reserved: 3776.970752 MB\n",
      "Epoch 4: loss = 5.352967262268066\n",
      "before loss.backward(): Allocated: 1150.741504 MB, Reserved: 3776.970752 MB\n",
      "After loss.backward(): Allocated: 462.035456 MB, Reserved: 3776.970752 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.0979, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(9.7883, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 8.931814227253199e-05 weighted: 0.08931814134120941 : Allocated: 470.51264 MB, Reserved: 3776.970752 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 1.49207799040596e-05 weighted: 0.014920779503881931 : Allocated: 1155.019776 MB, Reserved: 4752.146432 MB\n",
      "Epoch 5: loss = 13.601940155029297\n",
      "before loss.backward(): Allocated: 1155.019776 MB, Reserved: 4752.146432 MB\n",
      "After loss.backward(): Allocated: 462.048768 MB, Reserved: 4752.146432 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.2201, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(22.0104, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 8.683247142471373e-05 weighted: 0.08683247119188309 : Allocated: 470.527488 MB, Reserved: 4752.146432 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 1.5939687727950513e-05 weighted: 0.015939688310027122 : Allocated: 1156.005376 MB, Reserved: 5727.322112 MB\n",
      "Epoch 6: loss = 25.360427856445312\n",
      "before loss.backward(): Allocated: 1156.005376 MB, Reserved: 5727.322112 MB\n",
      "After loss.backward(): Allocated: 462.049792 MB, Reserved: 5727.322112 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.2888, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(28.8829, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.0001895955647341907 weighted: 0.189595565199852 : Allocated: 470.610944 MB, Reserved: 5727.322112 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 0.0006977830780670047 weighted: 0.6977830529212952 : Allocated: 1161.677312 MB, Reserved: 5727.322112 MB\n",
      "Epoch 7: loss = 32.613346099853516\n",
      "before loss.backward(): Allocated: 1161.677312 MB, Reserved: 5727.322112 MB\n",
      "After loss.backward(): Allocated: 462.065152 MB, Reserved: 5727.322112 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.2852, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(28.5209, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 8.002100366866216e-05 weighted: 0.08002100139856339 : Allocated: 470.467072 MB, Reserved: 5727.322112 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 1.7982907593250275e-05 weighted: 0.017982907593250275 : Allocated: 1150.688768 MB, Reserved: 5727.322112 MB\n",
      "Epoch 8: loss = 31.11113739013672\n",
      "before loss.backward(): Allocated: 1150.688768 MB, Reserved: 5727.322112 MB\n",
      "After loss.backward(): Allocated: 462.189568 MB, Reserved: 5727.322112 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.2775, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(27.7456, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 7.674057269468904e-05 weighted: 0.0767405703663826 : Allocated: 470.611968 MB, Reserved: 5727.322112 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 1.9001039618160576e-05 weighted: 0.019001038745045662 : Allocated: 1151.450112 MB, Reserved: 5727.322112 MB\n",
      "Epoch 9: loss = 30.029197692871094\n",
      "before loss.backward(): Allocated: 1151.450112 MB, Reserved: 5727.322112 MB\n",
      "After loss.backward(): Allocated: 462.037504 MB, Reserved: 5727.322112 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.2376, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(23.7646, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 7.417321467073634e-05 weighted: 0.0741732120513916 : Allocated: 470.445056 MB, Reserved: 5727.322112 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 2.0008481442346238e-05 weighted: 0.020008482038974762 : Allocated: 1149.351424 MB, Reserved: 5727.322112 MB\n",
      "Epoch 10: loss = 25.77849006652832\n",
      "before loss.backward(): Allocated: 1149.351424 MB, Reserved: 5727.322112 MB\n",
      "After loss.backward(): Allocated: 462.035456 MB, Reserved: 5727.322112 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.2769, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(27.6930, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 7.207666203612462e-05 weighted: 0.07207666337490082 : Allocated: 470.434304 MB, Reserved: 5727.322112 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 2.081139973597601e-05 weighted: 0.020811399444937706 : Allocated: 1151.591424 MB, Reserved: 5727.322112 MB\n",
      "Epoch 11: loss = 29.469125747680664\n",
      "before loss.backward(): Allocated: 1151.591424 MB, Reserved: 5727.322112 MB\n",
      "After loss.backward(): Allocated: 462.033408 MB, Reserved: 5727.322112 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.2565, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(25.6534, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 6.971269613131881e-05 weighted: 0.06971269845962524 : Allocated: 470.429184 MB, Reserved: 5727.322112 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 2.1353625925257802e-05 weighted: 0.021353626623749733 : Allocated: 1149.04832 MB, Reserved: 5727.322112 MB\n",
      "Epoch 12: loss = 27.219036102294922\n",
      "before loss.backward(): Allocated: 1149.04832 MB, Reserved: 5727.322112 MB\n",
      "After loss.backward(): Allocated: 462.033408 MB, Reserved: 5727.322112 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.2599, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(25.9904, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 6.78799333400093e-05 weighted: 0.06787993013858795 : Allocated: 470.42304 MB, Reserved: 5727.322112 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 2.1687683329219e-05 weighted: 0.02168768271803856 : Allocated: 1148.622336 MB, Reserved: 5727.322112 MB\n",
      "Epoch 13: loss = 27.369998931884766\n",
      "before loss.backward(): Allocated: 1148.622336 MB, Reserved: 5727.322112 MB\n",
      "After loss.backward(): Allocated: 462.031872 MB, Reserved: 5727.322112 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.2789, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(27.8861, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 6.632611621171236e-05 weighted: 0.06632611900568008 : Allocated: 470.423552 MB, Reserved: 5727.322112 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 2.2128067939775065e-05 weighted: 0.022128067910671234 : Allocated: 1150.016 MB, Reserved: 5727.322112 MB\n",
      "Epoch 14: loss = 29.102554321289062\n",
      "before loss.backward(): Allocated: 1150.016 MB, Reserved: 5727.322112 MB\n",
      "After loss.backward(): Allocated: 462.032384 MB, Reserved: 5727.322112 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.2640, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(26.3966, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 6.489895167760551e-05 weighted: 0.06489895284175873 : Allocated: 470.432768 MB, Reserved: 5727.322112 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 2.220943133579567e-05 weighted: 0.02220943197607994 : Allocated: 1150.5152 MB, Reserved: 5727.322112 MB\n",
      "Epoch 15: loss = 27.4707088470459\n",
      "before loss.backward(): Allocated: 1150.5152 MB, Reserved: 5727.322112 MB\n",
      "After loss.backward(): Allocated: 462.033408 MB, Reserved: 5727.322112 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.2110, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(21.0975, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 6.334194040391594e-05 weighted: 0.06334193795919418 : Allocated: 470.429184 MB, Reserved: 5727.322112 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 2.2417605578084476e-05 weighted: 0.02241760492324829 : Allocated: 1148.919296 MB, Reserved: 5727.322112 MB\n",
      "Epoch 16: loss = 22.04837417602539\n",
      "before loss.backward(): Allocated: 1148.919296 MB, Reserved: 5727.322112 MB\n",
      "After loss.backward(): Allocated: 462.032896 MB, Reserved: 5727.322112 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.2530, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(25.2992, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 6.197439506649971e-05 weighted: 0.06197439506649971 : Allocated: 470.444032 MB, Reserved: 5727.322112 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 2.2593903850065544e-05 weighted: 0.022593904286623 : Allocated: 1152.685056 MB, Reserved: 5727.322112 MB\n",
      "Epoch 17: loss = 26.144315719604492\n",
      "before loss.backward(): Allocated: 1152.685056 MB, Reserved: 5727.322112 MB\n",
      "After loss.backward(): Allocated: 462.94528 MB, Reserved: 5727.322112 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.2490, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(24.8989, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 6.071569805499166e-05 weighted: 0.0607156977057457 : Allocated: 471.358976 MB, Reserved: 5727.322112 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 2.2444963178713806e-05 weighted: 0.022444963455200195 : Allocated: 1150.232576 MB, Reserved: 5727.322112 MB\n",
      "Epoch 18: loss = 25.65260887145996\n",
      "before loss.backward(): Allocated: 1150.232576 MB, Reserved: 5727.322112 MB\n",
      "After loss.backward(): Allocated: 462.036992 MB, Reserved: 5727.322112 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.2122, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(21.2197, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 6.076051795389503e-05 weighted: 0.06076051667332649 : Allocated: 470.455808 MB, Reserved: 5727.322112 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 2.274937287438661e-05 weighted: 0.02274937368929386 : Allocated: 1150.41792 MB, Reserved: 5727.322112 MB\n",
      "Epoch 19: loss = 21.896095275878906\n",
      "before loss.backward(): Allocated: 1150.41792 MB, Reserved: 5727.322112 MB\n",
      "After loss.backward(): Allocated: 462.038528 MB, Reserved: 5727.322112 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.2550, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(25.5016, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 5.950211198069155e-05 weighted: 0.05950211361050606 : Allocated: 470.43072 MB, Reserved: 5727.322112 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 2.2184034605743363e-05 weighted: 0.022184034809470177 : Allocated: 1149.198336 MB, Reserved: 5727.322112 MB\n",
      "Epoch 20: loss = 26.108356475830078\n",
      "before loss.backward(): Allocated: 1149.198336 MB, Reserved: 5727.322112 MB\n",
      "After loss.backward(): Allocated: 462.033408 MB, Reserved: 5727.322112 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.2392, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(23.9239, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 5.795207107439637e-05 weighted: 0.057952072471380234 : Allocated: 470.43328 MB, Reserved: 5727.322112 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 2.1594349163933657e-05 weighted: 0.021594349294900894 : Allocated: 1149.404672 MB, Reserved: 5727.322112 MB\n",
      "Epoch 21: loss = 24.4676513671875\n",
      "before loss.backward(): Allocated: 1149.404672 MB, Reserved: 5727.322112 MB\n",
      "After loss.backward(): Allocated: 462.03392 MB, Reserved: 5727.322112 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.2363, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(23.6323, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 5.696348307537846e-05 weighted: 0.0569634847342968 : Allocated: 470.411264 MB, Reserved: 5727.322112 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 2.117753138008993e-05 weighted: 0.02117753215134144 : Allocated: 1149.6192 MB, Reserved: 5727.322112 MB\n",
      "Epoch 22: loss = 24.11918067932129\n",
      "before loss.backward(): Allocated: 1149.6192 MB, Reserved: 5727.322112 MB\n",
      "After loss.backward(): Allocated: 462.030336 MB, Reserved: 5727.322112 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.2475, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(24.7515, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 5.59616310056299e-05 weighted: 0.05596163123846054 : Allocated: 470.416896 MB, Reserved: 5727.322112 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 2.056887387880124e-05 weighted: 0.02056887373328209 : Allocated: 1149.691904 MB, Reserved: 5727.322112 MB\n",
      "Epoch 23: loss = 25.184772491455078\n",
      "before loss.backward(): Allocated: 1149.691904 MB, Reserved: 5727.322112 MB\n",
      "After loss.backward(): Allocated: 462.030848 MB, Reserved: 5727.322112 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.1820, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(18.2037, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 5.545343447010964e-05 weighted: 0.05545343458652496 : Allocated: 470.393344 MB, Reserved: 5727.322112 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 2.0513962226687e-05 weighted: 0.02051396295428276 : Allocated: 1148.71552 MB, Reserved: 5727.322112 MB\n",
      "Epoch 24: loss = 18.58690643310547\n",
      "before loss.backward(): Allocated: 1148.71552 MB, Reserved: 5727.322112 MB\n",
      "After loss.backward(): Allocated: 462.025728 MB, Reserved: 5727.322112 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.2453, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(24.5319, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 5.447130388347432e-05 weighted: 0.05447130277752876 : Allocated: 470.396416 MB, Reserved: 5727.322112 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 1.9560853615985252e-05 weighted: 0.019560853019356728 : Allocated: 1149.057536 MB, Reserved: 5727.322112 MB\n",
      "Epoch 25: loss = 24.86532974243164\n",
      "before loss.backward(): Allocated: 1149.057536 MB, Reserved: 5727.322112 MB\n",
      "After loss.backward(): Allocated: 462.026752 MB, Reserved: 5727.322112 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.1619, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(16.1899, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 5.363929449231364e-05 weighted: 0.05363929271697998 : Allocated: 470.385152 MB, Reserved: 5727.322112 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 1.8991595425177366e-05 weighted: 0.01899159513413906 : Allocated: 1148.521984 MB, Reserved: 5727.322112 MB\n",
      "Epoch 26: loss = 16.47495460510254\n",
      "before loss.backward(): Allocated: 1148.521984 MB, Reserved: 5727.322112 MB\n",
      "After loss.backward(): Allocated: 462.025216 MB, Reserved: 5727.322112 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.2053, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(20.5250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 5.272713315207511e-05 weighted: 0.05272713303565979 : Allocated: 470.391808 MB, Reserved: 5727.322112 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 1.8459269995219074e-05 weighted: 0.018459269776940346 : Allocated: 1148.895744 MB, Reserved: 5727.322112 MB\n",
      "Epoch 27: loss = 20.76256561279297\n",
      "before loss.backward(): Allocated: 1148.895744 MB, Reserved: 5727.322112 MB\n",
      "After loss.backward(): Allocated: 462.02624 MB, Reserved: 5727.322112 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.2735, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(27.3500, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 5.2253351896069944e-05 weighted: 0.052253350615501404 : Allocated: 470.355968 MB, Reserved: 5727.322112 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 1.8183323845732957e-05 weighted: 0.018183324486017227 : Allocated: 1144.137728 MB, Reserved: 5727.322112 MB\n",
      "Epoch 28: loss = 27.54390525817871\n",
      "before loss.backward(): Allocated: 1144.137728 MB, Reserved: 5727.322112 MB\n",
      "After loss.backward(): Allocated: 462.019072 MB, Reserved: 5727.322112 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.2511, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(25.1128, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 5.165754919289611e-05 weighted: 0.051657550036907196 : Allocated: 470.332416 MB, Reserved: 5727.322112 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 1.780180900823325e-05 weighted: 0.017801808193325996 : Allocated: 1143.099392 MB, Reserved: 5727.322112 MB\n",
      "Epoch 29: loss = 25.269634246826172\n",
      "before loss.backward(): Allocated: 1143.099392 MB, Reserved: 5727.322112 MB\n",
      "After loss.backward(): Allocated: 462.014976 MB, Reserved: 5727.322112 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.2416, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(24.1567, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 5.1066519517917186e-05 weighted: 0.05106651782989502 : Allocated: 470.33088 MB, Reserved: 5727.322112 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 1.7603299056645483e-05 weighted: 0.017603298649191856 : Allocated: 1142.126592 MB, Reserved: 5727.322112 MB\n",
      "Epoch 30: loss = 24.286191940307617\n",
      "before loss.backward(): Allocated: 1142.126592 MB, Reserved: 5727.322112 MB\n",
      "After loss.backward(): Allocated: 462.2336 MB, Reserved: 5727.322112 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.2202, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(22.0223, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 5.034053901908919e-05 weighted: 0.05034054070711136 : Allocated: 470.565376 MB, Reserved: 5727.322112 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 1.7210302758030593e-05 weighted: 0.017210302874445915 : Allocated: 1143.305728 MB, Reserved: 5727.322112 MB\n",
      "Epoch 31: loss = 22.1330623626709\n",
      "before loss.backward(): Allocated: 1143.305728 MB, Reserved: 5727.322112 MB\n",
      "After loss.backward(): Allocated: 462.01856 MB, Reserved: 5727.322112 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.2403, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(24.0287, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 4.973976319888607e-05 weighted: 0.049739763140678406 : Allocated: 470.332928 MB, Reserved: 5727.322112 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 1.6941357898758724e-05 weighted: 0.016941357403993607 : Allocated: 1141.2352 MB, Reserved: 5727.322112 MB\n",
      "Epoch 32: loss = 24.12704849243164\n",
      "before loss.backward(): Allocated: 1141.2352 MB, Reserved: 5727.322112 MB\n",
      "After loss.backward(): Allocated: 462.237184 MB, Reserved: 5727.322112 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.2288, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(22.8777, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 5.009541564504616e-05 weighted: 0.050095416605472565 : Allocated: 470.529536 MB, Reserved: 5727.322112 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 1.7816164472606033e-05 weighted: 0.01781616359949112 : Allocated: 1141.385728 MB, Reserved: 5727.322112 MB\n",
      "Epoch 33: loss = 22.969295501708984\n",
      "before loss.backward(): Allocated: 1141.385728 MB, Reserved: 5727.322112 MB\n",
      "After loss.backward(): Allocated: 462.49472 MB, Reserved: 5727.322112 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.2141, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(21.4086, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 4.8986359615810215e-05 weighted: 0.04898636043071747 : Allocated: 470.808576 MB, Reserved: 5727.322112 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 1.687462645350024e-05 weighted: 0.01687462627887726 : Allocated: 1141.75744 MB, Reserved: 5727.322112 MB\n",
      "Epoch 34: loss = 21.49214744567871\n",
      "before loss.backward(): Allocated: 1141.75744 MB, Reserved: 5727.322112 MB\n",
      "After loss.backward(): Allocated: 462.427648 MB, Reserved: 5727.322112 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.2308, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(23.0803, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 4.8292997234966606e-05 weighted: 0.04829299822449684 : Allocated: 470.729216 MB, Reserved: 5727.322112 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 1.6321499060723e-05 weighted: 0.016321498900651932 : Allocated: 1141.774848 MB, Reserved: 5727.322112 MB\n",
      "Epoch 35: loss = 23.15835189819336\n",
      "before loss.backward(): Allocated: 1141.774848 MB, Reserved: 5727.322112 MB\n",
      "After loss.backward(): Allocated: 462.518784 MB, Reserved: 5727.322112 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.2551, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(25.5112, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 4.7710993385408074e-05 weighted: 0.04771099239587784 : Allocated: 470.802944 MB, Reserved: 5727.322112 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 1.603159762453288e-05 weighted: 0.016031596809625626 : Allocated: 1139.118592 MB, Reserved: 5727.322112 MB\n",
      "Epoch 36: loss = 25.585132598876953\n",
      "before loss.backward(): Allocated: 1139.118592 MB, Reserved: 5727.322112 MB\n",
      "After loss.backward(): Allocated: 462.64832 MB, Reserved: 5727.322112 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.2307, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(23.0688, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 4.719485150417313e-05 weighted: 0.04719484969973564 : Allocated: 470.929408 MB, Reserved: 5727.322112 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 1.5781717593199573e-05 weighted: 0.015781717374920845 : Allocated: 1138.161664 MB, Reserved: 5727.322112 MB\n",
      "Epoch 37: loss = 23.139530181884766\n",
      "before loss.backward(): Allocated: 1138.161664 MB, Reserved: 5727.322112 MB\n",
      "After loss.backward(): Allocated: 462.72768 MB, Reserved: 5727.322112 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.2162, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(21.6222, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.0010544833494350314 weighted: 1.0544832944869995 : Allocated: 471.026176 MB, Reserved: 5727.322112 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 0.106223464012146 weighted: 106.22346496582031 : Allocated: 1141.425152 MB, Reserved: 5727.322112 MB\n",
      "Epoch 38: loss = 128.90618896484375\n",
      "before loss.backward(): Allocated: 1141.425152 MB, Reserved: 5727.322112 MB\n",
      "After loss.backward(): Allocated: 462.506496 MB, Reserved: 5727.322112 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.1915, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(19.1468, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.0014666973147541285 weighted: 1.466697335243225 : Allocated: 470.8352 MB, Reserved: 5727.322112 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 0.1278761774301529 weighted: 127.87617492675781 : Allocated: 1142.324736 MB, Reserved: 5727.322112 MB\n",
      "Epoch 39: loss = 148.49790954589844\n",
      "before loss.backward(): Allocated: 1142.324736 MB, Reserved: 5727.322112 MB\n",
      "After loss.backward(): Allocated: 462.017024 MB, Reserved: 5727.322112 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.2521, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(25.2120, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 4.5740049245068803e-05 weighted: 0.045740049332380295 : Allocated: 470.2976 MB, Reserved: 5727.322112 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 1.5874429664108902e-05 weighted: 0.015874430537223816 : Allocated: 1140.22912 MB, Reserved: 5727.322112 MB\n",
      "Epoch 40: loss = 25.287607192993164\n",
      "before loss.backward(): Allocated: 1140.22912 MB, Reserved: 5727.322112 MB\n",
      "After loss.backward(): Allocated: 462.170624 MB, Reserved: 5727.322112 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.2023, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(20.2345, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 4.52175663667731e-05 weighted: 0.045217566192150116 : Allocated: 470.44096 MB, Reserved: 5727.322112 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 1.6435546058346517e-05 weighted: 0.016435546800494194 : Allocated: 1140.066304 MB, Reserved: 5727.322112 MB\n",
      "Epoch 41: loss = 20.323745727539062\n",
      "before loss.backward(): Allocated: 1140.066304 MB, Reserved: 5727.322112 MB\n",
      "After loss.backward(): Allocated: 462.76352 MB, Reserved: 5727.322112 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.2259, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(22.5883, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 4.476343383430503e-05 weighted: 0.044763434678316116 : Allocated: 471.051776 MB, Reserved: 5727.322112 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 1.6992515156744048e-05 weighted: 0.016992514953017235 : Allocated: 1139.342336 MB, Reserved: 5727.322112 MB\n",
      "Epoch 42: loss = 22.699462890625\n",
      "before loss.backward(): Allocated: 1139.342336 MB, Reserved: 5727.322112 MB\n",
      "After loss.backward(): Allocated: 462.140416 MB, Reserved: 5727.322112 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.1934, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(19.3403, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 4.4644370063906536e-05 weighted: 0.044644370675086975 : Allocated: 470.422016 MB, Reserved: 5727.322112 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 1.755769335431978e-05 weighted: 0.017557693645358086 : Allocated: 1139.459072 MB, Reserved: 5727.322112 MB\n",
      "Epoch 43: loss = 19.478023529052734\n",
      "before loss.backward(): Allocated: 1139.459072 MB, Reserved: 5727.322112 MB\n",
      "After loss.backward(): Allocated: 462.700544 MB, Reserved: 5727.322112 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.1846, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(18.4607, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 4.448559775482863e-05 weighted: 0.04448559880256653 : Allocated: 470.958592 MB, Reserved: 5727.322112 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 1.793249793990981e-05 weighted: 0.017932498827576637 : Allocated: 1137.081344 MB, Reserved: 5727.322112 MB\n",
      "Epoch 44: loss = 18.625202178955078\n",
      "before loss.backward(): Allocated: 1137.081344 MB, Reserved: 5727.322112 MB\n",
      "After loss.backward(): Allocated: 462.871552 MB, Reserved: 5727.322112 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.1819, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(18.1937, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 4.434427319210954e-05 weighted: 0.04434427246451378 : Allocated: 471.13984 MB, Reserved: 5727.322112 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 1.813543713069521e-05 weighted: 0.01813543774187565 : Allocated: 1137.673216 MB, Reserved: 5727.322112 MB\n",
      "Epoch 45: loss = 18.38219451904297\n",
      "before loss.backward(): Allocated: 1137.673216 MB, Reserved: 5727.322112 MB\n",
      "After loss.backward(): Allocated: 462.004736 MB, Reserved: 5727.322112 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.2622, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(26.2188, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 4.410853944136761e-05 weighted: 0.04410853981971741 : Allocated: 470.257152 MB, Reserved: 5727.322112 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 1.8068127246806398e-05 weighted: 0.01806812733411789 : Allocated: 1137.268736 MB, Reserved: 5727.322112 MB\n",
      "Epoch 46: loss = 26.42559242248535\n",
      "before loss.backward(): Allocated: 1137.268736 MB, Reserved: 5727.322112 MB\n",
      "After loss.backward(): Allocated: 462.380544 MB, Reserved: 5727.322112 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.2008, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(20.0808, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 4.3924064812017605e-05 weighted: 0.04392406344413757 : Allocated: 470.624768 MB, Reserved: 5727.322112 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 1.786340362741612e-05 weighted: 0.017863404005765915 : Allocated: 1136.686592 MB, Reserved: 5727.322112 MB\n",
      "Epoch 47: loss = 20.29988670349121\n",
      "before loss.backward(): Allocated: 1136.686592 MB, Reserved: 5727.322112 MB\n",
      "After loss.backward(): Allocated: 461.999104 MB, Reserved: 5727.322112 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.1825, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(18.2546, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 4.371384784462862e-05 weighted: 0.043713849037885666 : Allocated: 470.240256 MB, Reserved: 5727.322112 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 1.7569909687153995e-05 weighted: 0.017569908872246742 : Allocated: 1135.453184 MB, Reserved: 5727.322112 MB\n",
      "Epoch 48: loss = 18.4789981842041\n",
      "before loss.backward(): Allocated: 1135.453184 MB, Reserved: 5727.322112 MB\n",
      "After loss.backward(): Allocated: 461.998592 MB, Reserved: 5727.322112 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.1844, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(18.4353, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 4.3947256926912814e-05 weighted: 0.0439472571015358 : Allocated: 470.230016 MB, Reserved: 5727.322112 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 1.7594826204003766e-05 weighted: 0.017594825476408005 : Allocated: 1134.3104 MB, Reserved: 5727.322112 MB\n",
      "Epoch 49: loss = 18.659212112426758\n",
      "before loss.backward(): Allocated: 1134.3104 MB, Reserved: 5727.322112 MB\n",
      "After loss.backward(): Allocated: 461.997056 MB, Reserved: 5727.322112 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.2198, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(21.9784, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 4.331992386141792e-05 weighted: 0.04331992566585541 : Allocated: 470.229504 MB, Reserved: 5727.322112 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 1.7439306247979403e-05 weighted: 0.017439305782318115 : Allocated: 1136.1536 MB, Reserved: 5727.322112 MB\n",
      "Epoch 50: loss = 22.194581985473633\n",
      "before loss.backward(): Allocated: 1136.1536 MB, Reserved: 5727.322112 MB\n",
      "After loss.backward(): Allocated: 461.997056 MB, Reserved: 5727.322112 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.1914, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(19.1352, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 9.254674660041928e-05 weighted: 0.092546746134758 : Allocated: 470.25408 MB, Reserved: 5727.322112 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 0.000849488249514252 weighted: 0.8494882583618164 : Allocated: 1136.031744 MB, Reserved: 5727.322112 MB\n",
      "Epoch 51: loss = 20.2210636138916\n",
      "before loss.backward(): Allocated: 1136.031744 MB, Reserved: 5727.322112 MB\n",
      "After loss.backward(): Allocated: 462.00064 MB, Reserved: 5727.322112 MB\n",
      "-----------------\n",
      "sites length BEFORE UPSAMPLING:  4608\n",
      "Sites to upsample  torch.Size([3462])\n",
      "sites length AFTER:  18456\n",
      "CVT loss:  tensor(0.0524, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(5.2433, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 5.164022877579555e-05 weighted: 0.05164022743701935 : Allocated: 479.477248 MB, Reserved: 5727.322112 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 2.0999039406888187e-05 weighted: 0.020999038591980934 : Allocated: 1879.13472 MB, Reserved: 11312.037888 MB\n",
      "Epoch 52: loss = 5.3502607345581055\n",
      "before loss.backward(): Allocated: 1879.13472 MB, Reserved: 11312.037888 MB\n",
      "After loss.backward(): Allocated: 462.090752 MB, Reserved: 11312.037888 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.0531, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(5.3112, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 5.196699930820614e-05 weighted: 0.05196699872612953 : Allocated: 480.828928 MB, Reserved: 11312.037888 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 2.240936373709701e-05 weighted: 0.022409364581108093 : Allocated: 2034.540032 MB, Reserved: 15216.934912 MB\n",
      "Epoch 53: loss = 5.4197845458984375\n",
      "before loss.backward(): Allocated: 2034.540032 MB, Reserved: 15216.934912 MB\n",
      "After loss.backward(): Allocated: 462.960128 MB, Reserved: 15216.934912 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.0626, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(6.2616, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 4.781862298841588e-05 weighted: 0.047818623483181 : Allocated: 481.391616 MB, Reserved: 15216.934912 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 2.3102027626009658e-05 weighted: 0.02310202829539776 : Allocated: 2006.605824 MB, Reserved: 9644.802048 MB\n",
      "Epoch 54: loss = 6.366635322570801\n",
      "before loss.backward(): Allocated: 2006.605824 MB, Reserved: 9644.802048 MB\n",
      "After loss.backward(): Allocated: 463.10656 MB, Reserved: 9644.802048 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.0671, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(6.7119, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 6.319665408227593e-05 weighted: 0.06319665163755417 : Allocated: 481.120256 MB, Reserved: 9644.802048 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 0.00029718931182287633 weighted: 0.297189325094223 : Allocated: 1987.703296 MB, Reserved: 13566.476288 MB\n",
      "Epoch 55: loss = 7.105888843536377\n",
      "before loss.backward(): Allocated: 1987.703296 MB, Reserved: 13566.476288 MB\n",
      "After loss.backward(): Allocated: 463.258624 MB, Reserved: 13566.476288 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.0642, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(6.4178, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 6.470405787695199e-05 weighted: 0.0647040605545044 : Allocated: 481.137152 MB, Reserved: 13566.476288 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 0.00033101168810389936 weighted: 0.33101168274879456 : Allocated: 1978.518528 MB, Reserved: 13566.476288 MB\n",
      "Epoch 56: loss = 6.8465094566345215\n",
      "before loss.backward(): Allocated: 1978.518528 MB, Reserved: 13566.476288 MB\n",
      "After loss.backward(): Allocated: 463.29088 MB, Reserved: 13566.476288 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.0677, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(6.7694, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 8.938810060499236e-05 weighted: 0.08938810229301453 : Allocated: 481.754624 MB, Reserved: 13566.476288 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 0.00036161349271424115 weighted: 0.3616134822368622 : Allocated: 1970.326528 MB, Reserved: 13566.476288 MB\n",
      "Epoch 57: loss = 7.253012657165527\n",
      "before loss.backward(): Allocated: 1970.326528 MB, Reserved: 13566.476288 MB\n",
      "After loss.backward(): Allocated: 462.823936 MB, Reserved: 13566.476288 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.0558, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(5.5845, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 9.326455619884655e-05 weighted: 0.09326455742120743 : Allocated: 480.895488 MB, Reserved: 13566.476288 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 0.000346009066561237 weighted: 0.3460090756416321 : Allocated: 1968.3072 MB, Reserved: 13566.476288 MB\n",
      "Epoch 58: loss = 6.055466651916504\n",
      "before loss.backward(): Allocated: 1968.3072 MB, Reserved: 13566.476288 MB\n",
      "After loss.backward(): Allocated: 463.234048 MB, Reserved: 13566.476288 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.0548, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(5.4827, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 9.231404692400247e-05 weighted: 0.09231404960155487 : Allocated: 481.10336 MB, Reserved: 13566.476288 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 0.0003253848699387163 weighted: 0.32538485527038574 : Allocated: 1969.55136 MB, Reserved: 17490.24768 MB\n",
      "Epoch 59: loss = 5.931636810302734\n",
      "before loss.backward(): Allocated: 1969.55136 MB, Reserved: 17490.24768 MB\n",
      "After loss.backward(): Allocated: 463.518208 MB, Reserved: 17490.24768 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.0578, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(5.7773, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 9.044745820574462e-05 weighted: 0.09044745564460754 : Allocated: 481.383424 MB, Reserved: 17490.24768 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 0.0003153419238515198 weighted: 0.31534191966056824 : Allocated: 1968.86016 MB, Reserved: 17490.24768 MB\n",
      "Epoch 60: loss = 6.214012622833252\n",
      "before loss.backward(): Allocated: 1968.86016 MB, Reserved: 17490.24768 MB\n",
      "After loss.backward(): Allocated: 463.261184 MB, Reserved: 17490.24768 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.0476, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(4.7571, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 7.473309233319014e-05 weighted: 0.07473309338092804 : Allocated: 481.127424 MB, Reserved: 17490.24768 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 0.0002466730948071927 weighted: 0.2466730922460556 : Allocated: 1969.41056 MB, Reserved: 17490.24768 MB\n",
      "Epoch 61: loss = 5.108912467956543\n",
      "before loss.backward(): Allocated: 1969.41056 MB, Reserved: 17490.24768 MB\n",
      "After loss.backward(): Allocated: 463.422464 MB, Reserved: 17490.24768 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.0558, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(5.5775, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 8.373016316909343e-05 weighted: 0.08373016119003296 : Allocated: 481.235968 MB, Reserved: 17490.24768 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 0.00033752041053958237 weighted: 0.33752042055130005 : Allocated: 1974.857728 MB, Reserved: 17490.24768 MB\n",
      "Epoch 62: loss = 6.029223918914795\n",
      "before loss.backward(): Allocated: 1974.857728 MB, Reserved: 17490.24768 MB\n",
      "After loss.backward(): Allocated: 462.824448 MB, Reserved: 17490.24768 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.0727, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(7.2701, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 9.85122169367969e-05 weighted: 0.09851221740245819 : Allocated: 480.899584 MB, Reserved: 17490.24768 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 0.00035190972266718745 weighted: 0.35190972685813904 : Allocated: 1981.812224 MB, Reserved: 17490.24768 MB\n",
      "Epoch 63: loss = 7.750748634338379\n",
      "before loss.backward(): Allocated: 1981.812224 MB, Reserved: 17490.24768 MB\n",
      "After loss.backward(): Allocated: 463.494144 MB, Reserved: 17490.24768 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.0626, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(6.2637, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.00010625246068229899 weighted: 0.10625246167182922 : Allocated: 481.401856 MB, Reserved: 17490.24768 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 0.0003773164935410023 weighted: 0.37731650471687317 : Allocated: 1985.43104 MB, Reserved: 17490.24768 MB\n",
      "Epoch 64: loss = 6.7775373458862305\n",
      "before loss.backward(): Allocated: 1985.43104 MB, Reserved: 17490.24768 MB\n",
      "After loss.backward(): Allocated: 464.250368 MB, Reserved: 17490.24768 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.0690, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(6.8982, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.00011260908650001511 weighted: 0.11260908842086792 : Allocated: 482.157568 MB, Reserved: 17490.24768 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 0.00036670337431132793 weighted: 0.3667033612728119 : Allocated: 1984.047104 MB, Reserved: 17490.24768 MB\n",
      "Epoch 65: loss = 7.407716274261475\n",
      "before loss.backward(): Allocated: 1984.047104 MB, Reserved: 17490.24768 MB\n",
      "After loss.backward(): Allocated: 463.415296 MB, Reserved: 17490.24768 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.0577, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(5.7662, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.00010926902905339375 weighted: 0.10926903039216995 : Allocated: 481.606656 MB, Reserved: 17490.24768 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 0.0004136573406867683 weighted: 0.4136573374271393 : Allocated: 1985.129984 MB, Reserved: 17490.24768 MB\n",
      "Epoch 66: loss = 6.31939697265625\n",
      "before loss.backward(): Allocated: 1985.129984 MB, Reserved: 17490.24768 MB\n",
      "After loss.backward(): Allocated: 464.385536 MB, Reserved: 17490.24768 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.0708, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(7.0752, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.00010145032138098031 weighted: 0.10145032405853271 : Allocated: 482.305536 MB, Reserved: 17490.24768 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 0.0003951127000618726 weighted: 0.39511269330978394 : Allocated: 1986.124288 MB, Reserved: 17490.24768 MB\n",
      "Epoch 67: loss = 7.601816654205322\n",
      "before loss.backward(): Allocated: 1986.124288 MB, Reserved: 17490.24768 MB\n",
      "After loss.backward(): Allocated: 463.3984 MB, Reserved: 17490.24768 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.0546, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(5.4570, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.00012145199434598908 weighted: 0.12145199626684189 : Allocated: 481.485312 MB, Reserved: 17490.24768 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 0.0004514011670835316 weighted: 0.4514011740684509 : Allocated: 1992.89344 MB, Reserved: 17490.24768 MB\n",
      "Epoch 68: loss = 6.060238838195801\n",
      "before loss.backward(): Allocated: 1992.89344 MB, Reserved: 17490.24768 MB\n",
      "After loss.backward(): Allocated: 463.317504 MB, Reserved: 17490.24768 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.0617, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(6.1719, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.00015199245535768569 weighted: 0.15199245512485504 : Allocated: 481.87392 MB, Reserved: 17490.24768 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 0.0005239627789705992 weighted: 0.5239627957344055 : Allocated: 1996.013056 MB, Reserved: 17490.24768 MB\n",
      "Epoch 69: loss = 6.878136157989502\n",
      "before loss.backward(): Allocated: 1996.013056 MB, Reserved: 17490.24768 MB\n",
      "After loss.backward(): Allocated: 463.220736 MB, Reserved: 17490.24768 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.0568, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(5.6815, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.00012649872223846614 weighted: 0.1264987289905548 : Allocated: 481.746944 MB, Reserved: 17490.24768 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 0.00038764337659813464 weighted: 0.38764336705207825 : Allocated: 1993.664512 MB, Reserved: 17490.24768 MB\n",
      "Epoch 70: loss = 6.225766658782959\n",
      "before loss.backward(): Allocated: 1993.664512 MB, Reserved: 17490.24768 MB\n",
      "After loss.backward(): Allocated: 463.218176 MB, Reserved: 17490.24768 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.0595, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(5.9466, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.00011310228728689253 weighted: 0.11310228705406189 : Allocated: 481.203712 MB, Reserved: 17490.24768 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 0.0003741196996998042 weighted: 0.37411969900131226 : Allocated: 1992.259584 MB, Reserved: 17490.24768 MB\n",
      "Epoch 71: loss = 6.463728904724121\n",
      "before loss.backward(): Allocated: 1992.259584 MB, Reserved: 17490.24768 MB\n",
      "After loss.backward(): Allocated: 463.73888 MB, Reserved: 17490.24768 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.0499, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(4.9883, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.00011525920126587152 weighted: 0.11525920033454895 : Allocated: 481.666048 MB, Reserved: 17490.24768 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 0.00037272507324814796 weighted: 0.37272506952285767 : Allocated: 1990.548992 MB, Reserved: 17490.24768 MB\n",
      "Epoch 72: loss = 5.50627326965332\n",
      "before loss.backward(): Allocated: 1990.548992 MB, Reserved: 17490.24768 MB\n",
      "After loss.backward(): Allocated: 463.400448 MB, Reserved: 17490.24768 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.0561, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(5.6097, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.00012419751146808267 weighted: 0.12419751286506653 : Allocated: 481.35168 MB, Reserved: 17490.24768 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 0.0003896586422342807 weighted: 0.3896586298942566 : Allocated: 1994.461696 MB, Reserved: 17490.24768 MB\n",
      "Epoch 73: loss = 6.153812408447266\n",
      "before loss.backward(): Allocated: 1994.461696 MB, Reserved: 17490.24768 MB\n",
      "After loss.backward(): Allocated: 463.33952 MB, Reserved: 17490.24768 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.0548, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(5.4843, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.00011930050095543265 weighted: 0.11930049955844879 : Allocated: 481.293824 MB, Reserved: 17490.24768 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 0.00041524527478031814 weighted: 0.41524526476860046 : Allocated: 1996.710912 MB, Reserved: 17490.24768 MB\n",
      "Epoch 74: loss = 6.049043655395508\n",
      "before loss.backward(): Allocated: 1996.710912 MB, Reserved: 17490.24768 MB\n",
      "After loss.backward(): Allocated: 464.009216 MB, Reserved: 17490.24768 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.0686, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(6.8552, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.00010405870852991939 weighted: 0.10405870527029037 : Allocated: 481.936896 MB, Reserved: 17490.24768 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 0.0004046880058012903 weighted: 0.4046880006790161 : Allocated: 1990.959104 MB, Reserved: 17490.24768 MB\n",
      "Epoch 75: loss = 7.394162178039551\n",
      "before loss.backward(): Allocated: 1990.959104 MB, Reserved: 17490.24768 MB\n",
      "After loss.backward(): Allocated: 463.090176 MB, Reserved: 17490.24768 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.0696, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(6.9636, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.00010183703852817416 weighted: 0.10183703899383545 : Allocated: 481.99168 MB, Reserved: 17490.24768 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 0.00038421733188442886 weighted: 0.3842173218727112 : Allocated: 1989.653504 MB, Reserved: 17490.24768 MB\n",
      "Epoch 76: loss = 7.48011589050293\n",
      "before loss.backward(): Allocated: 1989.653504 MB, Reserved: 17490.24768 MB\n",
      "After loss.backward(): Allocated: 463.081472 MB, Reserved: 17490.24768 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.0567, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(5.6719, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.00011124041338916868 weighted: 0.11124041676521301 : Allocated: 481.015296 MB, Reserved: 17490.24768 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 0.0004453678266145289 weighted: 0.44536781311035156 : Allocated: 1991.668736 MB, Reserved: 17490.24768 MB\n",
      "Epoch 77: loss = 6.259037494659424\n",
      "before loss.backward(): Allocated: 1991.668736 MB, Reserved: 17490.24768 MB\n",
      "After loss.backward(): Allocated: 463.3344 MB, Reserved: 17490.24768 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.0519, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(5.1908, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 9.693237370811403e-05 weighted: 0.09693237394094467 : Allocated: 481.233408 MB, Reserved: 17490.24768 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 0.0003236553748138249 weighted: 0.323655366897583 : Allocated: 1984.649728 MB, Reserved: 17490.24768 MB\n",
      "Epoch 78: loss = 5.64182186126709\n",
      "before loss.backward(): Allocated: 1984.649728 MB, Reserved: 17490.24768 MB\n",
      "After loss.backward(): Allocated: 464.115712 MB, Reserved: 17490.24768 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.0602, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(6.0244, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 8.37918632896617e-05 weighted: 0.08379186689853668 : Allocated: 482.034176 MB, Reserved: 17490.24768 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 0.0002795038453768939 weighted: 0.27950385212898254 : Allocated: 1986.148352 MB, Reserved: 17490.24768 MB\n",
      "Epoch 79: loss = 6.4178667068481445\n",
      "before loss.backward(): Allocated: 1986.148352 MB, Reserved: 17490.24768 MB\n",
      "After loss.backward(): Allocated: 463.490048 MB, Reserved: 17490.24768 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.0652, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(6.5201, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 8.557750697946176e-05 weighted: 0.08557751029729843 : Allocated: 481.397248 MB, Reserved: 17490.24768 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 0.00029279961017891765 weighted: 0.29279962182044983 : Allocated: 1984.912896 MB, Reserved: 17490.24768 MB\n",
      "Epoch 80: loss = 6.928953170776367\n",
      "before loss.backward(): Allocated: 1984.912896 MB, Reserved: 17490.24768 MB\n",
      "After loss.backward(): Allocated: 464.137728 MB, Reserved: 17490.24768 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.0770, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(7.6971, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 9.263404353987426e-05 weighted: 0.09263404458761215 : Allocated: 482.093056 MB, Reserved: 17490.24768 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 0.00028855534037575126 weighted: 0.2885553538799286 : Allocated: 1993.076736 MB, Reserved: 17490.24768 MB\n",
      "Epoch 81: loss = 8.108928680419922\n",
      "before loss.backward(): Allocated: 1993.076736 MB, Reserved: 17490.24768 MB\n",
      "After loss.backward(): Allocated: 463.245824 MB, Reserved: 17490.24768 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.0590, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(5.8955, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.0001102631795220077 weighted: 0.11026317626237869 : Allocated: 481.276928 MB, Reserved: 17490.24768 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 0.0005077783134765923 weighted: 0.5077782869338989 : Allocated: 1994.605056 MB, Reserved: 17490.24768 MB\n",
      "Epoch 82: loss = 6.544576168060303\n",
      "before loss.backward(): Allocated: 1994.605056 MB, Reserved: 17490.24768 MB\n",
      "After loss.backward(): Allocated: 462.970368 MB, Reserved: 17490.24768 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.0627, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(6.2737, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.00010277954424964264 weighted: 0.10277954488992691 : Allocated: 480.894976 MB, Reserved: 17490.24768 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 0.0005159458378329873 weighted: 0.5159458518028259 : Allocated: 1993.842176 MB, Reserved: 17490.24768 MB\n",
      "Epoch 83: loss = 6.923588752746582\n",
      "before loss.backward(): Allocated: 1993.842176 MB, Reserved: 17490.24768 MB\n",
      "After loss.backward(): Allocated: 462.923264 MB, Reserved: 17490.24768 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.0560, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(5.6040, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 0.00010169221786782146 weighted: 0.10169221460819244 : Allocated: 481.117696 MB, Reserved: 17490.24768 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 0.0004969025030732155 weighted: 0.4969024956226349 : Allocated: 1989.119488 MB, Reserved: 17490.24768 MB\n",
      "Epoch 84: loss = 6.233980178833008\n",
      "before loss.backward(): Allocated: 1989.119488 MB, Reserved: 17490.24768 MB\n",
      "After loss.backward(): Allocated: 462.912512 MB, Reserved: 17490.24768 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.0605, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(6.0532, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 8.393086318392307e-05 weighted: 0.0839308649301529 : Allocated: 481.059328 MB, Reserved: 17490.24768 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 0.0004595222126226872 weighted: 0.45952221751213074 : Allocated: 1988.458496 MB, Reserved: 17490.24768 MB\n",
      "Epoch 85: loss = 6.627608776092529\n",
      "before loss.backward(): Allocated: 1988.458496 MB, Reserved: 17490.24768 MB\n",
      "After loss.backward(): Allocated: 463.291904 MB, Reserved: 17490.24768 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.0724, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(7.2432, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 6.287424912443385e-05 weighted: 0.06287425011396408 : Allocated: 481.456128 MB, Reserved: 17490.24768 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 0.0002711150445975363 weighted: 0.2711150348186493 : Allocated: 1984.358912 MB, Reserved: 17490.24768 MB\n",
      "Epoch 86: loss = 7.608016490936279\n",
      "before loss.backward(): Allocated: 1984.358912 MB, Reserved: 17490.24768 MB\n",
      "After loss.backward(): Allocated: 463.066112 MB, Reserved: 17490.24768 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.0600, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(5.9977, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 6.932902033440769e-05 weighted: 0.06932902336120605 : Allocated: 481.217536 MB, Reserved: 17490.24768 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 0.00031562906224280596 weighted: 0.3156290650367737 : Allocated: 1980.496384 MB, Reserved: 17490.24768 MB\n",
      "Epoch 87: loss = 6.413768291473389\n",
      "before loss.backward(): Allocated: 1980.496384 MB, Reserved: 17490.24768 MB\n",
      "After loss.backward(): Allocated: 462.892032 MB, Reserved: 17490.24768 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.0636, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(6.3590, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 7.056753383949399e-05 weighted: 0.0705675333738327 : Allocated: 481.538048 MB, Reserved: 17490.24768 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 0.00029792767600156367 weighted: 0.2979276776313782 : Allocated: 1985.317888 MB, Reserved: 17490.24768 MB\n",
      "Epoch 88: loss = 6.758734226226807\n",
      "before loss.backward(): Allocated: 1985.317888 MB, Reserved: 17490.24768 MB\n",
      "After loss.backward(): Allocated: 462.902784 MB, Reserved: 17490.24768 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.0632, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(6.3232, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 6.862385635031387e-05 weighted: 0.0686238557100296 : Allocated: 482.043904 MB, Reserved: 17490.24768 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 0.000295432866550982 weighted: 0.2954328656196594 : Allocated: 1982.16448 MB, Reserved: 17490.24768 MB\n",
      "Epoch 89: loss = 6.718594074249268\n",
      "before loss.backward(): Allocated: 1982.16448 MB, Reserved: 17490.24768 MB\n",
      "After loss.backward(): Allocated: 462.990336 MB, Reserved: 17490.24768 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.0510, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(5.0988, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 7.30659521650523e-05 weighted: 0.07306595146656036 : Allocated: 481.12128 MB, Reserved: 17490.24768 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 0.00027450808556750417 weighted: 0.2745080888271332 : Allocated: 1972.649984 MB, Reserved: 17490.24768 MB\n",
      "Epoch 90: loss = 5.477904796600342\n",
      "before loss.backward(): Allocated: 1972.649984 MB, Reserved: 17490.24768 MB\n",
      "After loss.backward(): Allocated: 463.131136 MB, Reserved: 17490.24768 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.0537, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(5.3739, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 9.870785288512707e-05 weighted: 0.09870785474777222 : Allocated: 481.281024 MB, Reserved: 17490.24768 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 0.0004864464281126857 weighted: 0.48644644021987915 : Allocated: 1975.868416 MB, Reserved: 17490.24768 MB\n",
      "Epoch 91: loss = 5.990950584411621\n",
      "before loss.backward(): Allocated: 1975.868416 MB, Reserved: 17490.24768 MB\n",
      "After loss.backward(): Allocated: 462.886912 MB, Reserved: 17490.24768 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.0453, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(4.5281, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 9.444676106795669e-05 weighted: 0.09444676339626312 : Allocated: 481.013248 MB, Reserved: 17490.24768 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 0.0004685761814471334 weighted: 0.46857619285583496 : Allocated: 1971.703296 MB, Reserved: 17490.24768 MB\n",
      "Epoch 92: loss = 5.1230950355529785\n",
      "before loss.backward(): Allocated: 1971.703296 MB, Reserved: 17490.24768 MB\n",
      "After loss.backward(): Allocated: 462.88128 MB, Reserved: 17490.24768 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.0515, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(5.1488, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 9.47905209613964e-05 weighted: 0.094790518283844 : Allocated: 481.014784 MB, Reserved: 17490.24768 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 0.0004234753723721951 weighted: 0.42347538471221924 : Allocated: 1972.475392 MB, Reserved: 17490.24768 MB\n",
      "Epoch 93: loss = 5.6989665031433105\n",
      "before loss.backward(): Allocated: 1972.475392 MB, Reserved: 17490.24768 MB\n",
      "After loss.backward(): Allocated: 462.882304 MB, Reserved: 17490.24768 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.0514, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(5.1442, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 9.543524356558919e-05 weighted: 0.0954352468252182 : Allocated: 481.601024 MB, Reserved: 17490.24768 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 0.00040764332516118884 weighted: 0.40764331817626953 : Allocated: 1971.264512 MB, Reserved: 17490.24768 MB\n",
      "Epoch 94: loss = 5.679228782653809\n",
      "before loss.backward(): Allocated: 1971.264512 MB, Reserved: 17490.24768 MB\n",
      "After loss.backward(): Allocated: 463.21664 MB, Reserved: 17490.24768 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.0548, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(5.4798, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 9.33644623728469e-05 weighted: 0.09336446225643158 : Allocated: 481.335296 MB, Reserved: 17490.24768 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 0.0003923658514395356 weighted: 0.39236584305763245 : Allocated: 1969.755648 MB, Reserved: 17490.24768 MB\n",
      "Epoch 95: loss = 5.997592926025391\n",
      "before loss.backward(): Allocated: 1969.755648 MB, Reserved: 17490.24768 MB\n",
      "After loss.backward(): Allocated: 462.973952 MB, Reserved: 17490.24768 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.0506, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(5.0557, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 9.01677121873945e-05 weighted: 0.09016770869493484 : Allocated: 481.8048 MB, Reserved: 17490.24768 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 0.000418501062085852 weighted: 0.4185010492801666 : Allocated: 1964.741632 MB, Reserved: 17490.24768 MB\n",
      "Epoch 96: loss = 5.596495151519775\n",
      "before loss.backward(): Allocated: 1964.741632 MB, Reserved: 17490.24768 MB\n",
      "After loss.backward(): Allocated: 462.944768 MB, Reserved: 17490.24768 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.0583, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(5.8274, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 9.504993795417249e-05 weighted: 0.09504994004964828 : Allocated: 481.055744 MB, Reserved: 17490.24768 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 0.0005033889901824296 weighted: 0.5033890008926392 : Allocated: 1966.934016 MB, Reserved: 17490.24768 MB\n",
      "Epoch 97: loss = 6.4579901695251465\n",
      "before loss.backward(): Allocated: 1966.934016 MB, Reserved: 17490.24768 MB\n",
      "After loss.backward(): Allocated: 462.807552 MB, Reserved: 17490.24768 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.0571, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(5.7143, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 9.139436588156968e-05 weighted: 0.09139436483383179 : Allocated: 481.136128 MB, Reserved: 17490.24768 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 0.0005169015494175255 weighted: 0.5169015526771545 : Allocated: 1965.822976 MB, Reserved: 17490.24768 MB\n",
      "Epoch 98: loss = 6.3548970222473145\n",
      "before loss.backward(): Allocated: 1965.822976 MB, Reserved: 17490.24768 MB\n",
      "After loss.backward(): Allocated: 463.682048 MB, Reserved: 17490.24768 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.0483, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(4.8341, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 8.640108717372641e-05 weighted: 0.0864010900259018 : Allocated: 481.513472 MB, Reserved: 17490.24768 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 0.0005171922384761274 weighted: 0.5171922445297241 : Allocated: 1962.227712 MB, Reserved: 17490.24768 MB\n",
      "Epoch 99: loss = 5.469934940338135\n",
      "before loss.backward(): Allocated: 1962.227712 MB, Reserved: 17490.24768 MB\n",
      "After loss.backward(): Allocated: 463.674368 MB, Reserved: 17490.24768 MB\n",
      "-----------------\n",
      "CVT loss:  tensor(0.0549, device='cuda:0', grad_fn=<MeanBackward0>) weighted:  tensor(5.4942, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Chamfer loss PYTORCH3D 8.823807729640976e-05 weighted: 0.08823807537555695 : Allocated: 481.499648 MB, Reserved: 17490.24768 MB\n",
      "hs_p shape:  torch.Size([153600, 3])\n",
      "Chamfer loss PYTORCH3D 0.0005691098049283028 weighted: 0.5691097974777222 : Allocated: 1960.889856 MB, Reserved: 17490.24768 MB\n",
      "Epoch 100: loss = 6.183867454528809\n",
      "before loss.backward(): Allocated: 1960.889856 MB, Reserved: 17490.24768 MB\n",
      "After loss.backward(): Allocated: 463.66976 MB, Reserved: 17490.24768 MB\n",
      "-----------------\n",
      "Saved to bunnyvoroloss_to_clip.npz\n",
      "Sites length:  4608\n",
      "min sites:  tensor(-0.9812, device='cuda:0', grad_fn=<MinBackward1>)\n",
      "max sites:  tensor(0.9809, device='cuda:0', grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "site_file_path = f'{destination}{max_iter}_cvt_{lambda_cvt}_chamfer_{lambda_chamfer}_eikonal_{lambda_eikonal}.npy'\n",
    "#check if optimized sites file exists\n",
    "if not os.path.exists(site_file_path):\n",
    "    #import sites\n",
    "    print(\"Importing sites\")\n",
    "    sites = np.load(site_file_path)\n",
    "    sites = torch.from_numpy(sites).to(device).requires_grad_(True)\n",
    "else:\n",
    "    # import cProfile, pstats\n",
    "    # import time\n",
    "    # profiler = cProfile.Profile()\n",
    "    # profiler.enable()\n",
    "\n",
    "#     with torch.profiler.profile(activities=[\n",
    "#             torch.profiler.ProfilerActivity.CPU,\n",
    "#             torch.profiler.ProfilerActivity.CUDA,\n",
    "#         ],\n",
    "#         record_shapes=False,\n",
    "#         with_stack=True  # Captures function calls\n",
    "#     ) as prof:\n",
    "#         sites = autograd(sites, model, max_iter=max_iter, upsampling=0, lambda_weights=lambda_weights)\n",
    "#         torch.cuda.synchronize()\n",
    "# # \n",
    "#     print(prof.key_averages().table(sort_by=\"self_cuda_time_total\"))\n",
    "#     prof.export_chrome_trace(\"trace.json\")\n",
    "    \n",
    "    # \n",
    "    sites = autograd(sites, model, max_iter=max_iter, upsampling=1, lambda_weights=lambda_weights)\n",
    "\n",
    "    \n",
    "    # profiler.disable()\n",
    "    # stats = pstats.Stats(profiler).sort_stats('cumtime')\n",
    "    # stats.print_stats()\n",
    "    # stats.dump_stats(f'{destination}{mesh[0]}{max_iter}_3d_profile_{num_centroids}_chamfer{lambda_chamfer}.prof')\n",
    "    \n",
    "    \n",
    "    sites_np = sites.detach().cpu().numpy()\n",
    "    np.save(site_file_path, sites_np)\n",
    "    \n",
    "print(\"Sites length: \", len(sites))\n",
    "print(\"min sites: \", torch.min(sites))\n",
    "print(\"max sites: \", torch.max(sites))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b7f7237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model ./images/autograd/End2End_DCCVT/bunny100_100_3d_model_512_chamfer1000.pth\n",
      "sites ./images/autograd/End2End_DCCVT/bunny100_100_3d_sites_512_chamfer1000.pth\n"
     ]
    }
   ],
   "source": [
    "epoch = 100\n",
    "\n",
    "model_file_path = f'{destination}{mesh[0]}{max_iter}_{epoch}_3d_model_{num_centroids}_chamfer{lambda_chamfer}.pth'\n",
    "site_file_path = f'{destination}{mesh[0]}{max_iter}_{epoch}_3d_sites_{num_centroids}_chamfer{lambda_chamfer}.pth'\n",
    " \n",
    "sites = torch.load(site_file_path)\n",
    "\n",
    "sites_np = sites.detach().cpu().numpy()\n",
    "model.load_state_dict(torch.load(model_file_path))\n",
    "#\n",
    "#polyscope_sdf(model)\n",
    "#\n",
    "print(\"model\", model_file_path)\n",
    "print(\"sites\", site_file_path)\n",
    "ps_cloud = ps.register_point_cloud(f\"{epoch} epoch_cvt_grid\",sites_np)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9772bb82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-Crossing faces final shape:  (21898, 3)\n"
     ]
    }
   ],
   "source": [
    "final_mesh = su.get_zero_crossing_mesh_3d(sites, model)\n",
    "#ps.register_surface_mesh(\"Zero-Crossing faces direct\", final_mesh[0], final_mesh[1])\n",
    "\n",
    "#save to file\n",
    "final_mesh_file = f'{mesh[0]}voroloss_sdf_trained{model_trained_it}.npz'\n",
    "faces = np.array(final_mesh[1], dtype=object)\n",
    "np.savez(final_mesh_file, vertices=final_mesh[0], faces=faces)\n",
    "\n",
    "data = np.load(final_mesh_file, allow_pickle=True)\n",
    "verts = data[\"vertices\"]       # (N_vertices, 3)\n",
    "faces = data[\"faces\"].tolist() # back to a list of lists\n",
    "\n",
    "print(\"Zero-Crossing faces final shape: \", verts.shape)\n",
    "ps.register_surface_mesh(\"Zero-Crossing faces final\", verts, faces)\n",
    "\n",
    "v_vect, f_vect = su.get_clipped_mesh_torch(sites, model, None, batch_size=3072)\n",
    "#ps.register_surface_mesh(\"polygon clipped mesh\", v_vect.detach().cpu().numpy(), f_vect)\n",
    "\n",
    "# fanning to transform polygon faces to triangle faces\n",
    "triangle_faces = [[f[0], f[i], f[i+1]] for f in f_vect for i in range(1, len(f)-1)]\n",
    "ps.register_surface_mesh(\"final triangle clipped mesh\", v_vect.detach().cpu().numpy(), triangle_faces)\n",
    "\n",
    "# triangle_faces = torch.tensor(triangle_faces, device=device)\n",
    "# s_p = su.sample_mesh_points(v_vect, triangle_faces, num_samples=150*32**2)\n",
    "# ps.register_point_cloud(\"sampled clipped mesh\", s_p.detach().cpu().numpy())\n",
    "\n",
    "# hs_p = su.sample_mesh_points_heitz(v_vect, triangle_faces, num_samples=150*32**2)\n",
    "# ps.register_point_cloud(\"heitz clipped mesh\", hs_p.detach().cpu().numpy())\n",
    "\n",
    "# ##register original mesh\n",
    "# mesh_file = mesh[1]+\".stl\"\n",
    "# #load mesh \n",
    "# m = trimesh.load(mesh_file)\n",
    "# #convert to numpy\n",
    "# mesh_np = np.array(m.vertices)\n",
    "# #normalize mesh\n",
    "# mesh_np = mesh_np - np.mean(mesh_np, axis=0)\n",
    "# mesh_np = mesh_np / np.max(np.abs(mesh_np))\n",
    "# mesh_faces = np.array(m.faces)\n",
    "# ps.register_surface_mesh(\"Original Mesh\", mesh_np, mesh_faces)\n",
    "\n",
    "\n",
    "import scipy.spatial as spatial\n",
    "from scipy.spatial import Delaunay\n",
    "\n",
    "tri = Delaunay(sites_np)\n",
    "delaunay_vertices =torch.tensor(np.array(tri.simplices), device=device)\n",
    "sdf_values = model(sites)\n",
    "\n",
    "# Assuming sites is a PyTorch tensor of shape [M, 3]\n",
    "sites = sites.unsqueeze(0)  # Now shape [1, M, 3]\n",
    "\n",
    "# Assuming SDF_Values is a PyTorch tensor of shape [M]\n",
    "sdf_values = sdf_values.unsqueeze(0)  # Now shape [1, M]\n",
    "\n",
    "marching_tetrehedra_mesh = kaolin.ops.conversions.marching_tetrahedra(sites, delaunay_vertices, sdf_values, return_tet_idx=False)\n",
    "#print(marching_tetrehedra_mesh)\n",
    "vertices_list, faces_list = marching_tetrehedra_mesh\n",
    "vertices = vertices_list[0]\n",
    "faces = faces_list[0]\n",
    "vertices_np = vertices.detach().cpu().numpy()  # Shape [N, 3]\n",
    "faces_np = faces.detach().cpu().numpy()  # Shape [M, 3] (triangles)\n",
    "ps.register_surface_mesh(\"Marching Tetrahedra Mesh final\", vertices_np, faces_np)\n",
    "\n",
    "# clipped_cvt = \"clipped_CVT.obj\"\n",
    "# if os.path.exists(clipped_cvt):\n",
    "#     clipped_cvt_mesh = trimesh.load(clipped_cvt)\n",
    "#     ps.register_surface_mesh(\"Clipped CVT\", clipped_cvt_mesh.vertices, clipped_cvt_mesh.faces)\n",
    "ps.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
